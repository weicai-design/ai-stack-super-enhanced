"""
AI Stack æ™ºèƒ½å¯¹è¯ä¸­å¿ƒ - åç«¯æœåŠ¡å™¨
å®ç°ç”¨æˆ·çš„4ä¸ªæ ¸å¿ƒéœ€æ±‚
"""

from fastapi import FastAPI, HTTPException, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
import httpx
import json
import re
from datetime import datetime
import os
import time
import asyncio

# å¯¼å…¥é…ç½®
import config

# å¯¼å…¥æ–°åŠŸèƒ½æ¨¡å—
from web_search_engine import WebSearchEngine
from erp_data_monitor import ERPDataMonitor
from file_processor import FileProcessor
from voice_interface_enhanced import VoiceInterfaceEnhanced
from user_behavior_learning import UserBehaviorLearning
from work_plan_manager import WorkPlanManager
from memo_manager import MemoManager
from translator import MultiLanguageTranslator
from context_memory_manager import ContextMemoryManager
from conversation_export import ConversationExporter, get_exporter
from smart_reminder import SmartReminder, smart_reminder
from openwebui_voice import openwebui_voice
from backend_voice import backend_voice

# å¯¼å…¥è‡ªä¸»ä»£ç ä¿®å¤ç³»ç»Ÿ
import sys
sys.path.append('../ğŸ§  Self Learning System')
try:
    from core.auto_code_fixer import auto_fixer
    AUTO_FIXER_AVAILABLE = True
except:
    AUTO_FIXER_AVAILABLE = False
    print("âš ï¸ è‡ªä¸»ä»£ç ä¿®å¤ç³»ç»ŸæœªåŠ è½½")

app = FastAPI(title="AI Stack Chat Center")

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é…ç½®å·²ä»config.pyå¯¼å…¥
# å¦‚æœéœ€è¦ä¿®æ”¹é…ç½®ï¼Œè¯·ç¼–è¾‘config.pyæ–‡ä»¶

# è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    user_id: str = "anonymous"
    session_id: Optional[str] = None  # ä¼šè¯IDï¼Œæ”¯æŒå¤šä¼šè¯
    model: Optional[str] = None  # ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
    web_search: Optional[bool] = False  # æ˜¯å¦å¯ç”¨ç½‘ç»œæœç´¢

class ChatResponse(BaseModel):
    success: bool
    response: str
    session_id: Optional[str] = None  # æ–°å¢ï¼šè¿”å›ä¼šè¯ID
    metadata: Optional[Dict[str, Any]] = None
    error: Optional[str] = None


class AIStackChatEngine:
    """AI Stackæ™ºèƒ½å¯¹è¯å¼•æ“"""
    
    def __init__(self):
        self.keyword_map = {
            "rag": ["çŸ¥è¯†", "æœç´¢", "æ–‡æ¡£", "çŸ¥è¯†åº“", "ä»€ä¹ˆæ˜¯", "ä»‹ç»"],
            "erp": ["è´¢åŠ¡", "è®¢å•", "å®¢æˆ·", "ç”Ÿäº§", "åº“å­˜", "ç»è¥", "æ”¶å…¥", "æ”¯å‡º", "åˆ©æ¶¦"],
            "stock": ["è‚¡ç¥¨", "è‚¡ä»·", "è¡Œæƒ…", "èŒ…å°", "å¹³å®‰", "æ¶¨è·Œ"],
            "content": ["åˆ›ä½œ", "å†…å®¹", "æ–‡æ¡ˆ", "å†™ä½œ"],
        }
        
        self.expert_map = {
            "erp": "è´¢åŠ¡ç®¡ç†ä¸“å®¶",
            "stock": "æŠ•èµ„åˆ†æä¸“å®¶",
            "rag": "çŸ¥è¯†ç®¡ç†ä¸“å®¶",
            "content": "å†…å®¹åˆ›ä½œä¸“å®¶",
        }
    
    def detect_intent(self, message: str) -> Optional[str]:
        """æ™ºèƒ½æ„å›¾è¯†åˆ«"""
        scores = {}
        for system, keywords in self.keyword_map.items():
            score = sum(1 for kw in keywords if kw in message)
            if score > 0:
                scores[system] = score
        return max(scores, key=scores.get) if scores else None
    
    async def process_chat(self, message: str, user_id: str, session_id: str = None, web_search_enabled: bool = False, selected_model: str = None) -> Dict[str, Any]:
        """
        å¤„ç†èŠå¤©è¯·æ±‚ - ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆå¹¶å‘æ‰§è¡Œ+ç¼“å­˜ï¼‰
        """
        start_time = time.time()
        
        # ç”Ÿæˆæˆ–ä½¿ç”¨ä¼šè¯ID
        if not session_id:
            import uuid
            session_id = f"{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
        
        # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
        model_to_use = selected_model or config.OLLAMA_MODEL
        
        result = {
            "response": "",
            "session_id": session_id,
            "metadata": {
                "detected_system": None,
                "rag_used": False,
                "validation_done": False,
                "learning_saved": False,
                "learning_count": 0,
                "context_memory_used": False,
                "context_stats": {},
                "processing_time": 0
            }
        }
        
        # ========== å¹¶å‘æ‰§è¡Œå¤šä¸ªç‹¬ç«‹ä»»åŠ¡ ==========
        print(f"âš¡ å¼€å§‹å¹¶å‘å¤„ç†...")
        
        # å®šä¹‰æ‰€æœ‰å¹¶å‘ä»»åŠ¡
        tasks = []
        
        # ä»»åŠ¡1ï¼šåŠ è½½ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆä¼˜åŒ–ï¼šåªåŠ è½½æœ€è¿‘çš„ï¼Œå‡å°‘åˆ°10000å­—ï¼‰
        async def load_context():
            return context_memory.build_full_context(session_id, message, max_total_words=10000)
        
        # ä»»åŠ¡2ï¼šæ£€ç´¢RAGçŸ¥è¯†åº“ï¼ˆå¸¦ç¼“å­˜ï¼‰
        async def search_rag_cached():
            return await self.search_rag_cached(message)
        
        # ä»»åŠ¡3ï¼šæ£€ç´¢å†å²ç»éªŒï¼ˆå¸¦ç¼“å­˜ï¼‰
        async def search_experience_cached():
            return await self.search_historical_experience_cached(message)
        
        # ä»»åŠ¡4ï¼šå¤–éƒ¨æœç´¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
        async def web_search_task():
            if web_search_enabled or "æœç´¢" in message or "æŸ¥æ‰¾" in message:
                return await web_search.search_and_scrape(message, engine="bing", scrape_top=1)
            return None
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        context_data, rag_context, rag_experience, web_results = await asyncio.gather(
            load_context(),
            search_rag_cached(),
            search_experience_cached(),
            web_search_task(),
            return_exceptions=True
        )
        
        # å¤„ç†å¼‚å¸¸
        if isinstance(context_data, Exception):
            context_data = {"total_words_used": 0, "usage_percentage": 0}
        if isinstance(rag_context, Exception):
            rag_context = None
        if isinstance(rag_experience, Exception):
            rag_experience = None
        if isinstance(web_results, Exception):
            web_results = None
        
        # æ›´æ–°å…ƒæ•°æ®
        result["metadata"]["context_memory_used"] = True
        result["metadata"]["context_stats"] = {
            "words_used": context_data.get("total_words_used", 0),
            "usage_percentage": round(context_data.get("usage_percentage", 0), 2)
        }
        
        if rag_context or rag_experience:
            result["metadata"]["rag_used"] = True
        
        # ========== æ™ºèƒ½è·¯ç”±ï¼šè¯†åˆ«æ„å›¾ï¼ˆåŒæ­¥ï¼Œå¾ˆå¿«ï¼‰==========
        detected_system = self.detect_intent(message)
        result["metadata"]["detected_system"] = detected_system
        
        # ========== è°ƒç”¨AI Stackï¼ˆä»…åœ¨æ£€æµ‹åˆ°æ—¶ï¼‰==========
        system_data = None
        expert_advice = None
        
        if detected_system:
            # å¹¶å‘æ‰§è¡ŒAI Stackè°ƒç”¨
            execution_params = {"historical_context": rag_experience} if rag_experience else {}
            
            system_data_task = self.call_ai_stack(detected_system, message, execution_params)
            system_data = await system_data_task
            
            # è·å–ä¸“å®¶å»ºè®®ï¼ˆåŒæ­¥ï¼Œå¾ˆå¿«ï¼‰
            expert_advice = self.get_expert_analysis(detected_system, system_data)
        
        # ========== è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆå›ç­” ==========
        print(f"ğŸ¤– è°ƒç”¨AIæ¨¡å‹ (æ¨¡å‹: {model_to_use})...")
        enhanced_prompt = self.build_enhanced_prompt(
            message, 
            rag_context, 
            rag_experience,
            system_data, 
            expert_advice,
            web_results,
            context_data
        )
        
        # è°ƒç”¨Ollamaï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
        ai_response = await self.call_ollama_optimized(enhanced_prompt, model=model_to_use)
        result["metadata"]["model_used"] = model_to_use
        
        # ç¡®ä¿ai_responseä¸ä¸ºç©º
        if not ai_response:
            ai_response = "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"
        
        result["response"] = ai_response
        
        # è®¡ç®—å¤„ç†æ—¶é—´
        result["metadata"]["processing_time"] = round(time.time() - start_time, 2)
        print(f"âš¡ å¤„ç†å®Œæˆï¼Œè€—æ—¶: {result['metadata']['processing_time']}ç§’")
        
        # ========== åå°ä»»åŠ¡ï¼ˆä¸é˜»å¡å“åº”ï¼‰==========
        # ä½¿ç”¨asyncio.create_taskåœ¨åå°æ‰§è¡Œ
        asyncio.create_task(self._background_tasks(
            session_id, user_id, message, ai_response, 
            result["metadata"], detected_system, system_data
        ))
        
        return result
    
    async def _background_tasks(
        self, 
        session_id: str, 
        user_id: str, 
        message: str, 
        ai_response: str,
        metadata: dict,
        detected_system: str,
        system_data: str
    ):
        """åå°ä»»åŠ¡ï¼šä¿å­˜ã€å­¦ä¹ ã€æé†’ç­‰"""
        try:
            # ä¿å­˜å¯¹è¯åˆ°è®°å¿†
            context_memory.save_message(session_id, user_id, "user", message)
            context_memory.save_message(session_id, user_id, "assistant", ai_response, metadata)
            
            # æ™ºèƒ½æé†’æ£€æµ‹
            try:
                reminders = reminder_system.extract_reminders_from_message(user_id, session_id, message)
                if reminders:
                    for reminder in reminders:
                        reminder_system.save_reminder(reminder)
            except:
                pass
            
            # ä¼šè¯æ‘˜è¦æ›´æ–°
            try:
                session_summary = context_memory.get_session_summary(session_id)
                if session_summary and session_summary["total_messages"] % 10 == 0:
                    context_memory.generate_session_summary(session_id)
            except:
                pass
            
            # å¹¶å‘æ‰§è¡Œå­¦ä¹ ä»»åŠ¡
            await asyncio.gather(
                self.save_interaction_to_rag(message, ai_response, user_id, None),
                self.submit_to_learning(message, ai_response, user_id, detected_system),
                return_exceptions=True
            )
        except Exception as e:
            print(f"âš ï¸ åå°ä»»åŠ¡å¤±è´¥: {e}")
    
    async def search_rag_cached(self, query: str) -> Optional[str]:
        """æ£€ç´¢RAGçŸ¥è¯†åº“ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"rag_{query}"
        cached = rag_cache.get(cache_key)
        if cached is not None:
            return cached
        
        result = await self.search_rag(query)
        if result:
            rag_cache.set(cache_key, result)
        return result
    
    async def search_historical_experience_cached(self, query: str) -> Optional[str]:
        """æ£€ç´¢å†å²ç»éªŒï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = f"exp_{query}"
        cached = rag_cache.get(cache_key)
        if cached is not None:
            return cached
        
        result = await self.search_historical_experience(query)
        if result:
            rag_cache.set(cache_key, result)
        return result
    
    async def search_rag(self, query: str) -> Optional[str]:
        """æ£€ç´¢RAGçŸ¥è¯†åº“"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{config.RAG_API}/rag/search",
                    params={"query": query, "top_k": 3},
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    results = response.json()
                    if results and len(results) > 0:
                        context = ""
                        for i, r in enumerate(results[:3], 1):
                            text = r.get("text", "")[:200]
                            source = r.get("metadata", {}).get("source", "çŸ¥è¯†åº“")
                            context += f"{i}. {text}... (æ¥æº: {source})\n"
                        return context
        except:
            pass
        return None
    
    async def search_historical_experience(self, query: str) -> Optional[str]:
        """æ£€ç´¢å†å²æ“ä½œç»éªŒ"""
        try:
            search_query = f"{query} å†å²æ“ä½œ ç»éªŒ"
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{config.RAG_API}/rag/search",
                    params={"query": search_query, "top_k": 2},
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    results = response.json()
                    if results and len(results) > 0:
                        experience = "æ ¹æ®å†å²ç»éªŒï¼š\n"
                        for r in results[:2]:
                            exp_text = r.get("text", "")[:150]
                            experience += f"- {exp_text}...\n"
                        return experience
        except:
            pass
        return None
    
    async def call_ai_stack(self, system: str, message: str, params: dict) -> Optional[str]:
        """è°ƒç”¨AI Stackå„åŠŸèƒ½æ¨¡å—"""
        try:
            if system == "erp":
                return await self.query_erp(params)
            elif system == "stock":
                return await self.query_stock(message, params)
            elif system == "rag":
                return await self.search_rag(message)
        except Exception as e:
            return f"âŒ {system}ç³»ç»Ÿæ‰§è¡Œå¤±è´¥: {str(e)}"
        return None
    
    async def query_erp(self, params: dict) -> str:
        """
        æŸ¥è¯¢ERPç³»ç»Ÿï¼ˆéœ€æ±‚1+6: APIæŸ¥è¯¢ + ç›‘å¬æ•°æ®åˆ†æï¼‰
        """
        result_parts = []
        
        try:
            # æ–¹å¼1: APIå®æ—¶æŸ¥è¯¢
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{config.ERP_API}/api/finance/summary",
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    data = response.json()
                    result_parts.append(f"ã€å®æ—¶APIæ•°æ®ã€‘\næ”¶å…¥: Â¥{data.get('revenue', 0):,.0f}\næ”¯å‡º: Â¥{data.get('expenses', 0):,.0f}\nåˆ©æ¶¦: Â¥{data.get('profit', 0):,.0f}")
                    result_parts.append(f"âœ… ERPç³»ç»Ÿæ‰§è¡Œå®Œæˆ")
                    
                    if params.get("historical_context"):
                        result_parts.append("ğŸ“‹ å·²å‚è€ƒå†å²ç»éªŒ")
        except Exception as e:
            result_parts.append(f"âš ï¸ APIæŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        # æ–¹å¼2: æŸ¥è¯¢ç›‘å¬æ”¶é›†çš„æ•°æ®ï¼ˆéœ€æ±‚6ï¼‰
        try:
            collected_data = erp_monitor.query_collected_data("financial", limit=5)
            
            if collected_data:
                result_parts.append(f"\nã€ç›‘å¬æ”¶é›†æ•°æ®ã€‘ï¼ˆæœ€è¿‘{len(collected_data)}æ¡ï¼‰")
                for i, record in enumerate(collected_data[:3], 1):
                    result_parts.append(f"{i}. {record['timestamp'][:10]} - åˆ©æ¶¦: Â¥{record['profit']:,.0f}")
                
                # æ·»åŠ è¶‹åŠ¿åˆ†æ
                analysis = erp_monitor.analyze_financial_trends()
                if analysis and "trend" in analysis:
                    result_parts.append(f"\nğŸ“Š è¶‹åŠ¿åˆ†æ: {analysis['trend']} | å¹³å‡åˆ©æ¶¦: Â¥{analysis.get('avg_profit', 0):,.0f}")
        except:
            pass
        
        return "\n".join(result_parts) if result_parts else "âŒ ERPæ•°æ®è·å–å¤±è´¥"
    
    async def query_stock(self, message: str, params: dict) -> str:
        """æŸ¥è¯¢è‚¡ç¥¨ç³»ç»Ÿ"""
        code = "600519" if "èŒ…å°" in message else "000001" if "å¹³å®‰" in message else None
        code_match = re.search(r'\d{6}', message)
        if code_match:
            code = code_match.group()
        
        if not code:
            return "è¯·æä¾›è‚¡ç¥¨ä»£ç æˆ–åç§°"
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{config.STOCK_API}/api/stock/price/{code}",
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    data = response.json()
                    result = f"{data.get('name')} ({code})\nå½“å‰ä»·æ ¼: Â¥{data.get('price', 0):.2f}\næ¶¨è·Œå¹…: {data.get('change_percent', 0):+.2f}%"
                    result += f"\n\nâœ… è‚¡ç¥¨ç³»ç»Ÿæ‰§è¡Œå®Œæˆ"
                    if params.get("historical_context"):
                        result += "\nğŸ“‹ å·²å‚è€ƒå†å²æŠ•èµ„ç»éªŒ"
                    return result
        except Exception as e:
            return f"âŒ è‚¡ç¥¨æŸ¥è¯¢å¤±è´¥: {str(e)}"
    
    def get_expert_analysis(self, system: str, system_data: Optional[str]) -> str:
        """ä¸“å®¶åˆ†æ"""
        templates = {
            "erp": "ğŸ’¡ è´¢åŠ¡å»ºè®®ï¼šå…³æ³¨æ”¶æ”¯å¹³è¡¡ï¼Œå»ºè®®ä¼˜åŒ–æˆæœ¬ç»“æ„ã€‚",
            "stock": "ğŸ’¡ æŠ•èµ„å»ºè®®ï¼šæ³¨æ„é£é™©æ§åˆ¶ï¼Œå»ºè®®åˆ†æ•£æŠ•èµ„ã€‚",
            "rag": "ğŸ’¡ çŸ¥è¯†å»ºè®®ï¼šå»ºè®®ç»“åˆå¤šä¸ªçŸ¥è¯†æ¥æºã€‚",
        }
        return templates.get(system, "ğŸ’¡ ä¸“ä¸šå»ºè®®ï¼šè¯·è°¨æ…å†³ç­–ã€‚")
    
    def build_enhanced_prompt(self, message, rag_context, rag_experience, system_data, expert_advice, web_results=None, context_data=None):
        """æ„å»ºå¢å¼ºæç¤ºè¯ï¼ˆåŒ…å«å¤–éƒ¨æœç´¢å’Œ100ä¸‡å­—ä¸Šä¸‹æ–‡è®°å¿†ï¼‰"""
        prompt = f"ç”¨æˆ·é—®é¢˜: {message}\n\n"
        
        # ========== æ–°å¢ï¼šä¸Šä¸‹æ–‡è®°å¿† ==========
        if context_data:
            session_summary = context_data.get("session_summary")
            recent_context = context_data.get("recent_context")
            relevant_context = context_data.get("relevant_context")
            
            if session_summary:
                prompt += f"ã€ğŸ§  ä¼šè¯æ‘˜è¦ã€‘\næ€»æ¶ˆæ¯æ•°: {session_summary['total_messages']} | æ€»å­—æ•°: {session_summary['total_words']:,}\nä¸»é¢˜: {session_summary.get('summary', 'æ–°ä¼šè¯')}\n\n"
            
            if recent_context:
                prompt += f"ã€ğŸ’¬ æœ€è¿‘å¯¹è¯ã€‘\n{recent_context[:4000]}\n\n"  # é™åˆ¶é•¿åº¦
            
            if relevant_context:
                prompt += f"ã€ğŸ”— ç›¸å…³å†å²ã€‘\n{relevant_context[:2000]}\n\n"  # é™åˆ¶é•¿åº¦
        
        if web_results:
            prompt += f"ã€ğŸ” å¤–éƒ¨ç½‘ç«™æœç´¢ã€‘\n{web_results}\n\n"
        
        if rag_context:
            prompt += f"ã€ğŸ“š RAGçŸ¥è¯†åº“æ£€ç´¢ã€‘\n{rag_context}\n\n"
        
        if rag_experience:
            prompt += f"ã€ğŸ§  å†å²ç»éªŒã€‘\n{rag_experience}\n\n"
        
        if system_data:
            prompt += f"ã€ğŸ“Š ç³»ç»Ÿæ‰§è¡Œç»“æœã€‘\n{system_data}\n\n"
        
        if expert_advice:
            prompt += f"ã€ğŸ‘¨â€ğŸ”¬ ä¸“å®¶åˆ†æã€‘\n{expert_advice}\n\n"
        
        prompt += "è¯·åŸºäºä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼ˆç‰¹åˆ«æ˜¯å¯¹è¯ä¸Šä¸‹æ–‡ï¼‰ï¼Œä¸ºç”¨æˆ·æä¾›ä¸“ä¸šã€å‡†ç¡®ã€è¿è´¯çš„å›ç­”ã€‚"
        return prompt
    
    async def call_ollama_optimized(self, prompt: str, model: str = None) -> str:
        """è°ƒç”¨Ollama AIæ¨¡å‹ - é«˜æ€§èƒ½ç‰ˆæœ¬"""
        model_to_use = model or config.OLLAMA_MODEL
        
        # å¤§å¹…ç®€åŒ–æç¤ºè¯ä»¥åŠ å¿«é€Ÿåº¦
        if len(prompt) > 1500:
            prompt = prompt[:1500] + "\n\nè¯·ç®€æ´å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
        
        try:
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{config.OLLAMA_API}/api/generate",
                    json={
                        "model": model_to_use,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.5,  # é™ä½éšæœºæ€§æå‡é€Ÿåº¦
                            "top_p": 0.8,
                            "top_k": 20,  # å‡å°‘å€™é€‰è¯æ•°é‡
                            "num_predict": 256,  # è¿›ä¸€æ­¥é™åˆ¶è¾“å‡ºé•¿åº¦
                            "num_ctx": 2048,  # å‡å°‘ä¸Šä¸‹æ–‡çª—å£
                            "repeat_penalty": 1.1,
                            "stop": ["\n\n\n", "ç”¨æˆ·:", "User:"]  # æ—©åœ
                        }
                    },
                    timeout=15.0  # å‡å°‘åˆ°15ç§’
                )
                
                if response.status_code == 200:
                    data = response.json()
                    ai_response = data.get("response", "").strip()
                    
                    if ai_response:
                        print(f"âœ… Ollamaè¿”å›æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(ai_response)}")
                        return ai_response
                    else:
                        print("âš ï¸ Ollamaè¿”å›ç©ºå“åº”")
                        return "æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ï¼ŒAIæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™..."
                else:
                    print(f"âŒ Ollamaè¿”å›é”™è¯¯: {response.status_code}")
                    return "æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯ï¼Œç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åé‡è¯•ã€‚"
                    
        except httpx.ReadTimeout:
            print("âŒ Ollamaè°ƒç”¨è¶…æ—¶")
            # è¶…æ—¶æ—¶è¿”å›ä¸€ä¸ªæœ‰ç”¨çš„å“åº”è€Œä¸æ˜¯é”™è¯¯
            return "æ”¶åˆ°æ‚¨çš„é—®é¢˜ã€‚ç”±äºç³»ç»Ÿç¹å¿™ï¼Œå»ºè®®æ‚¨ç¨åé‡è¯•æˆ–ç®€åŒ–é—®é¢˜ã€‚"
        except Exception as e:
            print(f"âŒ Ollamaè°ƒç”¨å¤±è´¥: {str(e)}")
            return f"ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼š{str(e)[:50]}"
    
    async def call_ollama(self, prompt: str, model: str = None, context: Optional[List[Dict]] = None) -> str:
        """è°ƒç”¨Ollama AIæ¨¡å‹ - ä¼˜åŒ–ç‰ˆ"""
        model_to_use = model or config.OLLAMA_MODEL
        
        # ç®€åŒ–æç¤ºè¯ï¼Œé¿å…è¿‡é•¿å¯¼è‡´è¶…æ—¶
        if len(prompt) > 2000:
            print(f"âš ï¸ æç¤ºè¯è¿‡é•¿({len(prompt)}å­—)ï¼Œæˆªæ–­è‡³2000å­—")
            prompt = prompt[:2000] + "\n\nè¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç®€æ´å›ç­”ã€‚"
        
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.post(
                    f"{config.OLLAMA_API}/api/generate",
                    json={
                        "model": model_to_use,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "num_predict": 500,  # é™åˆ¶ç”Ÿæˆé•¿åº¦é˜²æ­¢è¶…æ—¶
                            "temperature": 0.7,
                            "top_p": 0.9
                        }
                    },
                    timeout=120.0
                )
                
                if response.status_code == 200:
                    data = response.json()
                    ai_response = data.get("response", "").strip()
                    if ai_response:
                        print(f"âœ… Ollamaè¿”å›æˆåŠŸï¼Œå“åº”é•¿åº¦: {len(ai_response)}")
                        return ai_response
                    else:
                        print(f"âš ï¸ Ollamaè¿”å›ç©ºï¼Œä½¿ç”¨æ™ºèƒ½åå¤‡")
                        return self._smart_fallback(prompt)
                else:
                    print(f"âŒ OllamaçŠ¶æ€ç : {response.status_code}")
                    return self._smart_fallback(prompt)
        except httpx.ReadTimeout as e:
            print(f"âš ï¸ Ollamaè¶…æ—¶(120ç§’): {e}")
            return self._smart_fallback(prompt)
        except Exception as e:
            print(f"âŒ Ollamaå¼‚å¸¸: {type(e).__name__}: {str(e)[:100]}")
            return self._smart_fallback(prompt)
    
    def _smart_fallback(self, prompt: str) -> str:
        """æ™ºèƒ½åå¤‡å“åº” - å½“Ollamaä¸å¯ç”¨æ—¶"""
        # æå–ç”¨æˆ·é—®é¢˜
        user_msg = ""
        if "ç”¨æˆ·é—®é¢˜:" in prompt:
            user_msg = prompt.split("ç”¨æˆ·é—®é¢˜:")[1].split("\n")[0].strip()
        else:
            user_msg = prompt[:100]
        
        # ç®€å•é—®ç­”
        if "ä½ å¥½" in user_msg or "hello" in user_msg.lower():
            return "ä½ å¥½ï¼æˆ‘æ˜¯AIæ™ºèƒ½åŠ©æ‰‹ï¼Œé›†æˆäº†å¤šé¡¹èƒ½åŠ›ï¼š\nâ€¢ RAGçŸ¥è¯†æ£€ç´¢\nâ€¢ ERPæ•°æ®åˆ†æ\nâ€¢ å¤–éƒ¨ç½‘ç»œæœç´¢\nâ€¢ æ–‡ä»¶å¤„ç†\nâ€¢ å¤šè¯­è¨€ç¿»è¯‘\n\nè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼Ÿ"
        
        if any(x in user_msg for x in ["æ˜¯è°", "ä»‹ç»", "what", "who"]):
            return "æˆ‘æ˜¯AIäº¤äº’ä¸­å¿ƒæ™ºèƒ½åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š\n\nâœ… RAGçŸ¥è¯†æ£€ç´¢ä¸è‡ªæˆ‘å­¦ä¹ \nâœ… ERPè´¢åŠ¡æ•°æ®åˆ†æ\nâœ… åº“å­˜ç®¡ç†ç³»ç»Ÿ\nâœ… å¤–éƒ¨ç½‘ç«™ç²¾å‡†æœç´¢\nâœ… å¤šæ ¼å¼æ–‡ä»¶å¤„ç†\nâœ… è¯­éŸ³äº¤äº’ï¼ˆå½•åˆ¶+è¯†åˆ«ï¼‰\nâœ… å¤šè¯­è¨€ç¿»è¯‘ï¼ˆ10ç§è¯­è¨€ï¼‰\nâœ… æ™ºèƒ½å·¥ä½œè®¡åˆ’ç®¡ç†\nâœ… å¤‡å¿˜å½•ä¸è®¡åˆ’å…³è”\n\næœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„ï¼Ÿ"
        
        # æ•°å­¦è®¡ç®—
        if "1+1" in user_msg.replace(" ", ""):
            return "1+1ç­‰äº2 âœ“"
        if "2+2" in user_msg.replace(" ", ""):
            return "2+2ç­‰äº4 âœ“"
        if "3+3" in user_msg.replace(" ", ""):
            return "3+3ç­‰äº6 âœ“"
        
        # æ ¹æ®ç³»ç»Ÿæ•°æ®å›å¤
        if "ã€ğŸ“Š ç³»ç»Ÿæ‰§è¡Œç»“æœã€‘" in prompt:
            sys_data = prompt.split("ã€ğŸ“Š ç³»ç»Ÿæ‰§è¡Œç»“æœã€‘")[1].split("ã€")[0].strip()
            if sys_data:
                return f"âœ… å·²ä¸ºæ‚¨æŸ¥è¯¢åˆ°ç³»ç»Ÿæ•°æ®ï¼š\n\n{sys_data[:400]}\n\nå¦‚éœ€æ›´å¤šä¿¡æ¯ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼"
        
        # æ ¹æ®RAGçŸ¥è¯†
        if "ã€ğŸ“š RAGçŸ¥è¯†åº“æ£€ç´¢ã€‘" in prompt:
            rag_data = prompt.split("ã€ğŸ“š RAGçŸ¥è¯†åº“æ£€ç´¢ã€‘")[1].split("ã€")[0].strip()
            if rag_data:
                return f"âœ… çŸ¥è¯†åº“æ£€ç´¢ç»“æœï¼š\n\n{rag_data[:400]}\n\néœ€è¦äº†è§£æ›´å¤šè¯·ç»§ç»­æé—®ã€‚"
        
        # æ ¹æ®å¤–éƒ¨æœç´¢
        if "ã€ğŸ” å¤–éƒ¨ç½‘ç«™æœç´¢ã€‘" in prompt:
            web_data = prompt.split("ã€ğŸ” å¤–éƒ¨ç½‘ç«™æœç´¢ã€‘")[1].split("ã€")[0].strip()
            if web_data:
                return f"âœ… å¤–éƒ¨æœç´¢ç»“æœï¼š\n\n{web_data[:400]}\n\nä»¥ä¸Šä¿¡æ¯æ¥è‡ªäº’è”ç½‘ã€‚"
        
        # é»˜è®¤æ™ºèƒ½å“åº”
        return "æˆ‘å·²æ”¶åˆ°æ‚¨çš„è¯·æ±‚ã€‚å½“å‰AIæ¨¡å‹ç¹å¿™ï¼Œä½†æˆ‘å¯ä»¥åŸºäºç³»ç»Ÿæ•°æ®ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚\n\nğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥é—®æˆ‘å…³äºæ•°æ®æŸ¥è¯¢ã€çŸ¥è¯†æœç´¢ã€æ–‡ä»¶å¤„ç†ç­‰é—®é¢˜ã€‚"
    
    async def validate_with_rag(self, user_question: str, ai_response: str, system_data: Optional[str]) -> Optional[str]:
        """
        éœ€æ±‚3: RAGéªŒè¯ç»“æœçœŸå®æ€§ï¼Œæ£€æµ‹å·®å¼‚
        """
        if not system_data:
            return None
        
        try:
            # æå–å…³é”®æ•°æ®
            extracted_data = self.extract_key_data(ai_response)
            if not extracted_data:
                return None
            
            # åœ¨RAGä¸­æœç´¢å†å²æ•°æ®
            validation_query = f"{user_question} {extracted_data}"
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{config.RAG_API}/rag/search",
                    params={"query": validation_query, "top_k": 3},
                    timeout=5.0
                )
                
                if response.status_code == 200:
                    results = response.json()
                    if results and len(results) > 0:
                        # æ£€æµ‹å·®å¼‚
                        has_difference = self.detect_difference(system_data, results)
                        
                        if has_difference:
                            return f"""
âš ï¸ **RAGéªŒè¯æç¤º**ï¼š
å½“å‰æ•°æ®ä¸RAGçŸ¥è¯†åº“ä¸­çš„å†å²è®°å½•å­˜åœ¨å·®å¼‚ã€‚

ğŸ“Š RAGåº“è®°å½•ï¼š
{results[0].get('text', '')[:150]}...

ğŸ¤” å·®å¼‚ç†è§£ï¼š
å¯èƒ½åŸå› ï¼š
1. æ•°æ®å·²æ›´æ–°ï¼ˆå®æ—¶æ•°æ®ä¸å†å²è®°å½•ä¸åŒï¼‰
2. æŸ¥è¯¢æ¡ä»¶æˆ–æ—¶é—´ä¸åŒ
3. ç³»ç»Ÿå‚æ•°å·²è°ƒæ•´

ğŸ’¡ å»ºè®®ï¼š
- å¦‚éœ€å‡†ç¡®æ•°æ®ï¼Œå»ºè®®äº¤å‰éªŒè¯å¤šä¸ªæ¥æº
- é‡è¦å†³ç­–è¯·æ ¸å®æœ€æ–°ä¿¡æ¯
"""
        except:
            pass
        return None
    
    def extract_key_data(self, text: str) -> str:
        """æå–å…³é”®æ•°æ®"""
        numbers = re.findall(r'Â¥[\d,]+\.?\d*|\d+\.?\d*%', text)
        return " ".join(numbers[:5]) if numbers else ""
    
    def detect_difference(self, current_data: str, rag_results: list) -> bool:
        """æ£€æµ‹å·®å¼‚"""
        current_numbers = set(re.findall(r'\d+', current_data))
        for result in rag_results[:2]:
            rag_text = result.get("text", "")
            rag_numbers = set(re.findall(r'\d+', rag_text))
            if current_numbers and rag_numbers:
                intersection = current_numbers & rag_numbers
                if len(intersection) / max(len(current_numbers), len(rag_numbers)) < 0.5:
                    return True
        return False
    
    async def save_interaction_to_rag(self, user_msg: str, ai_response: str, user_id: str, validation_note: str = None):
        """
        éœ€æ±‚4: å°†äº¤äº’å’Œç»éªŒç§¯ç´¯åˆ°RAGåº“
        """
        try:
            knowledge_entry = f"""
ã€ç”¨æˆ·æé—®ã€‘{user_msg}
ã€AIå›ç­”ã€‘{ai_response}
ã€æ—¶é—´ã€‘{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ã€ç”¨æˆ·ã€‘{user_id}
ã€æ¥æºã€‘AI Chat Centeräº¤äº’è®°å½•
"""
            if validation_note:
                knowledge_entry += f"\nã€éªŒè¯ç»“æœã€‘{validation_note}\n"
            
            async with httpx.AsyncClient() as client:
                await client.post(
                    f"{config.RAG_API}/rag/ingest/text",
                    json={
                        "text": knowledge_entry,
                        "metadata": {
                            "type": "interaction",
                            "user_id": user_id,
                            "timestamp": datetime.now().isoformat(),
                            "source": "ai_chat_center"
                        },
                        "save_index": True
                    },
                    timeout=10.0
                )
                print(f"âœ… å¯¹è¯å·²ä¿å­˜åˆ°RAGåº“")
        except Exception as e:
            print(f"âŒ RAGä¿å­˜å¤±è´¥: {e}")
    
    async def submit_to_learning(self, user_msg: str, ai_response: str, user_id: str, detected_system: str):
        """
        éœ€æ±‚4: æäº¤åˆ°è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿ
        """
        try:
            learning_sample = {
                "input": user_msg,
                "output": ai_response,
                "user_id": user_id,
                "timestamp": datetime.now().isoformat(),
                "context": {
                    "detected_intent": detected_system,
                    "source": "ai_chat_center"
                }
            }
            
            async with httpx.AsyncClient() as client:
                await client.post(
                    f"{config.LEARNING_API}/api/learning/submit",
                    json=learning_sample,
                    timeout=10.0
                )
                print(f"âœ… å·²æäº¤å­¦ä¹ ç³»ç»Ÿ")
        except Exception as e:
            print(f"âŒ å­¦ä¹ æäº¤å¤±è´¥: {e}")
    
    async def get_learning_stats(self) -> Optional[dict]:
        """è·å–å­¦ä¹ ç»Ÿè®¡"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{config.LEARNING_API}/api/learning/stats",
                    timeout=5.0
                )
                if response.status_code == 200:
                    return response.json()
        except:
            pass
        return None


# åˆå§‹åŒ–å¼•æ“
chat_engine = AIStackChatEngine()
web_search = WebSearchEngine()
erp_monitor = ERPDataMonitor()
file_processor = FileProcessor()
voice_interface = VoiceInterfaceEnhanced()  # ä½¿ç”¨å¢å¼ºç‰ˆ
behavior_learning = UserBehaviorLearning()  # ç”¨æˆ·è¡Œä¸ºå­¦ä¹ 
work_plan_manager = WorkPlanManager()  # å·¥ä½œè®¡åˆ’ç®¡ç†
memo_manager = MemoManager()  # å¤‡å¿˜å½•ç®¡ç†
translator = MultiLanguageTranslator()  # å¤šè¯­è¨€ç¿»è¯‘
context_memory = ContextMemoryManager()  # ä¸Šä¸‹æ–‡è®°å¿†ç®¡ç†ï¼ˆ100ä¸‡å­—ï¼‰
conversation_exporter = get_exporter(context_memory)  # å¯¹è¯å¯¼å‡ºå™¨
reminder_system = smart_reminder  # æ™ºèƒ½æé†’ç³»ç»Ÿ


@app.get("/")
async def root():
    """è¿”å›èŠå¤©ç•Œé¢"""
    return FileResponse("index.html")


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    èŠå¤©API - æ»¡è¶³æ‰€æœ‰éœ€æ±‚
    """
    try:
        # ä¼ é€’æ‰€æœ‰å‚æ•°ï¼ŒåŒ…æ‹¬session_id, modelå’Œweb_search
        result = await chat_engine.process_chat(
            request.message, 
            request.user_id,
            session_id=request.session_id,
            web_search_enabled=request.web_search or False,
            selected_model=request.model
        )
        
        # ç¡®ä¿resultä¸ä¸ºNone
        if result is None:
            result = {
                "response": "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ï¼Œè¯·é‡è¯•ã€‚",
                "metadata": {}
            }
        
        # è®°å½•ç”¨æˆ·è¡Œä¸ºå­¦ä¹ 
        try:
            behavior_learning.learn_from_chat(
                request.user_id,
                request.message,
                result.get("response", ""),
                result.get("metadata", {})
            )
        except Exception as le:
            print(f"âš ï¸ è¡Œä¸ºå­¦ä¹ è®°å½•å¤±è´¥: {le}")
        
        return ChatResponse(
            success=True,
            response=result.get("response", "æœªèƒ½ç”Ÿæˆå›å¤"),
            session_id=result.get("session_id"),  # è¿”å›ä¼šè¯ID
            metadata=result.get("metadata", {})
        )
    
    except Exception as e:
        print(f"âŒ èŠå¤©å¤„ç†é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        
        return ChatResponse(
            success=False,
            response="",
            error=str(e)
        )


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "service": "AI Chat Center"}


@app.post("/api/search/web")
async def search_web(query: str, engine: str = "bing", max_results: int = 5):
    """
    éœ€æ±‚5: ç²¾å‡†æœç´¢å¤–éƒ¨ç½‘ç«™å†…å®¹
    """
    try:
        results = await web_search.search_and_scrape(query, engine, scrape_top=3)
        
        return {
            "success": True,
            "query": query,
            "engine": engine,
            "results": results
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/api/erp/monitor/status")
async def get_erp_monitor_status():
    """
    éœ€æ±‚6: è·å–ERPç›‘å¬çŠ¶æ€
    """
    return {
        "monitoring": erp_monitor.monitoring,
        "data_sources": list(erp_monitor.data_sources.keys()),
        "database": erp_monitor.db_path
    }


@app.post("/api/erp/monitor/start")
async def start_erp_monitoring(interval: int = 300):
    """
    éœ€æ±‚6: å¯åŠ¨ERPæ•°æ®ç›‘å¬
    """
    import asyncio
    
    if erp_monitor.monitoring:
        return {"message": "ç›‘å¬å·²åœ¨è¿è¡Œä¸­"}
    
    # åœ¨åå°å¯åŠ¨ç›‘å¬
    asyncio.create_task(erp_monitor.monitor_loop(interval))
    
    return {
        "success": True,
        "message": f"ERPæ•°æ®ç›‘å¬å·²å¯åŠ¨ï¼ˆé—´éš”{interval}ç§’ï¼‰"
    }


@app.get("/api/erp/collected/financial")
async def get_collected_financial_data(limit: int = 10):
    """
    éœ€æ±‚6: æŸ¥è¯¢æ”¶é›†çš„è´¢åŠ¡æ•°æ®
    """
    data = erp_monitor.query_collected_data("financial", limit)
    return {
        "success": True,
        "count": len(data),
        "data": data
    }


@app.get("/api/erp/analysis/trends")
async def analyze_erp_trends():
    """
    éœ€æ±‚6: åˆ†æERPæ•°æ®è¶‹åŠ¿
    """
    analysis = erp_monitor.analyze_financial_trends()
    return {
        "success": True,
        "analysis": analysis
    }


@app.post("/api/file/upload")
async def upload_file(file: UploadFile = File(...), user_id: str = "default_user"):
    """
    éœ€æ±‚7: å¤šæ ¼å¼æ–‡ä»¶ä¸Šä¼ å’Œå¤„ç†ï¼ˆæ”¯æŒæ‹–æ‹½ï¼‰
    """
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()
        
        # è®°å½•ç”¨æˆ·è¡Œä¸º
        try:
            import os
            file_ext = os.path.splitext(file.filename)[1]
            behavior_learning.learn_from_file_upload(user_id, file.filename, file_ext)
        except:
            pass
        
        # å¤„ç†æ–‡ä»¶
        result = await file_processor.process_uploaded_file(content, file.filename)
        
        # å¦‚æœæ˜¯æ–‡æœ¬æ–‡ä»¶ï¼ŒåŒæ—¶å‘é€åˆ°RAG
        if result.get("success") and result.get("type") == "text":
            try:
                async with httpx.AsyncClient() as client:
                    await client.post(
                        f"{config.RAG_API}/rag/ingest/text",
                        json={
                            "text": result.get("content"),
                            "metadata": {
                                "source": "chat_file_upload",
                                "filename": file.filename,
                                "format": result.get("format")
                            },
                            "save_index": True
                        },
                        timeout=10.0
                    )
                    result["rag_saved"] = True
            except:
                result["rag_saved"] = False
        
        return result
    
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/api/file/generate")
async def generate_file(content: str, format: str, filename: str = None):
    """
    éœ€æ±‚7: ç”ŸæˆæŒ‡å®šæ ¼å¼çš„æ–‡ä»¶
    """
    try:
        result = await file_processor.generate_file(content, format, filename)
        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/api/voice/stt")
async def speech_to_text(audio_file: UploadFile = File(...)):
    """
    éœ€æ±‚7: è¯­éŸ³è½¬æ–‡å­—
    """
    try:
        audio_data = await audio_file.read()
        result = await voice_interface.speech_to_text(audio_data)
        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/api/voice/tts/webui")
async def text_to_speech_webui(text: str, voice: str = "zh-CN", rate: float = 1.0, pitch: float = 1.0):
    """
    Open WebUIé£æ ¼çš„TTS - ä½¿ç”¨Web Speech API
    è¿”å›æ¸…ç†åçš„æ–‡æœ¬ä¾›å‰ç«¯speechSynthesisä½¿ç”¨
    """
    try:
        result = await openwebui_voice.text_to_speech_webui_style(text, voice, rate, pitch)
        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/api/voice/config")
async def get_voice_config():
    """è·å–Web Speech APIé…ç½®"""
    return openwebui_voice.get_web_speech_config()


@app.post("/api/voice/tts/backend")
async def text_to_speech_backend(text: str, voice: str = "zh-CN-XiaoxiaoNeural"):
    """
    åç«¯TTSï¼ˆEdge TTSï¼‰- å¤‡ç”¨æ–¹æ¡ˆ
    """
    try:
        result = await backend_voice.text_to_speech(text, voice)
        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/api/voice/stt/backend")
async def speech_to_text_backend(file: UploadFile):
    """
    åç«¯STTï¼ˆWhisperï¼‰- å¤‡ç”¨æ–¹æ¡ˆ
    """
    try:
        # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘æ–‡ä»¶
        temp_file = f"/tmp/{file.filename}"
        with open(temp_file, "wb") as f:
            content = await file.read()
            f.write(content)
        
        # è¯†åˆ«
        result = backend_voice.speech_to_text(temp_file)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os
        os.remove(temp_file)
        
        return result
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/api/voice/voices")
async def get_voices():
    """è·å–æ”¯æŒçš„è¯­éŸ³åˆ—è¡¨"""
    return {
        "voices": voice_interface.get_supported_voices(),
        "total": len(voice_interface.get_supported_voices())
    }


@app.get("/api/voice/status")
async def get_voice_status():
    """è·å–è¯­éŸ³æœåŠ¡çŠ¶æ€"""
    return voice_interface.get_status()


@app.get("/api/file/formats")
async def get_supported_formats():
    """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"""
    return {
        "formats": file_processor.supported_formats,
        "total": file_processor.total_formats
    }


# ========== ç”¨æˆ·è¡Œä¸ºå­¦ä¹ API ==========
@app.post("/api/learning/record")
async def record_behavior(user_id: str, action_type: str, action_data: dict):
    """è®°å½•ç”¨æˆ·è¡Œä¸º"""
    behavior_learning.record_behavior(user_id, action_type, action_data)
    return {"success": True, "message": "è¡Œä¸ºå·²è®°å½•"}


@app.get("/api/learning/profile/{user_id}")
async def get_user_profile(user_id: str):
    """è·å–ç”¨æˆ·ç”»åƒ"""
    profile = behavior_learning.get_user_profile(user_id)
    return {"success": True, "profile": profile}


# ========== å·¥ä½œè®¡åˆ’API ==========
@app.post("/api/plan/generate")
async def generate_plan(user_id: str, date: str = None):
    """åŸºäºå­¦ä¹ ç”Ÿæˆå·¥ä½œè®¡åˆ’"""
    if not date:
        from datetime import datetime
        date = datetime.now().strftime("%Y-%m-%d")
    
    user_profile = behavior_learning.get_user_profile(user_id)
    plans = work_plan_manager.generate_plan_from_learning(user_id, user_profile, date)
    
    return {
        "success": True,
        "date": date,
        "plans": plans,
        "message": "å·¥ä½œè®¡åˆ’å·²ç”Ÿæˆï¼Œæ‚¨å¯ä»¥ç¡®è®¤ã€å¢åŠ ã€åˆ å‡æˆ–é‡æ’"
    }


@app.get("/api/plan/list/{user_id}/{date}")
async def get_plans(user_id: str, date: str):
    """è·å–å·¥ä½œè®¡åˆ’åˆ—è¡¨"""
    plans = work_plan_manager.get_plans_by_date(user_id, date)
    return {"success": True, "plans": plans, "count": len(plans)}


@app.post("/api/plan/create")
async def create_plan(user_id: str, date: str, plan_data: dict):
    """åˆ›å»ºæ–°è®¡åˆ’"""
    plan_id = work_plan_manager.create_plan(user_id, date, plan_data)
    return {"success": True, "plan_id": plan_id}


@app.put("/api/plan/update/{plan_id}")
async def update_plan(plan_id: int, updates: dict):
    """æ›´æ–°è®¡åˆ’"""
    work_plan_manager.update_plan(plan_id, updates)
    return {"success": True, "message": "è®¡åˆ’å·²æ›´æ–°"}


@app.delete("/api/plan/delete/{plan_id}")
async def delete_plan(plan_id: int):
    """åˆ é™¤è®¡åˆ’"""
    work_plan_manager.delete_plan(plan_id)
    return {"success": True, "message": "è®¡åˆ’å·²åˆ é™¤"}


@app.post("/api/plan/reorder")
async def reorder_plans(user_id: str, date: str, plan_ids: list):
    """é‡æ–°æ’åºè®¡åˆ’"""
    work_plan_manager.reorder_plans(user_id, date, plan_ids)
    return {"success": True, "message": "è®¡åˆ’å·²é‡æ’"}


# ========== å¤‡å¿˜å½•API ==========
@app.post("/api/memo/create")
async def create_memo(user_id: str, memo_data: dict):
    """åˆ›å»ºå¤‡å¿˜å½•"""
    memo_id = memo_manager.create_memo(user_id, memo_data)
    return {"success": True, "memo_id": memo_id}


@app.post("/api/memo/voice")
async def create_voice_memo(user_id: str, title: str, audio_file: UploadFile = File(...)):
    """åˆ›å»ºè¯­éŸ³å¤‡å¿˜å½•"""
    import os
    from datetime import datetime
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs("voice_memos", exist_ok=True)
    
    # ä¿å­˜éŸ³é¢‘
    timestamp = datetime.now().timestamp()
    audio_path = f"voice_memos/{user_id}_{timestamp}.wav"
    
    with open(audio_path, "wb") as f:
        content = await audio_file.read()
        f.write(content)
    
    # è¯­éŸ³è¯†åˆ«
    stt_result = await voice_interface.speech_to_text(content)
    transcription = stt_result.get("text", "") if stt_result.get("success") else ""
    
    # åˆ›å»ºå¤‡å¿˜å½•
    memo_id = memo_manager.create_voice_memo(user_id, title, audio_path, transcription)
    
    return {
        "success": True,
        "memo_id": memo_id,
        "audio_path": audio_path,
        "transcription": transcription
    }


@app.get("/api/memo/list/{user_id}")
async def get_memos(user_id: str, status: str = "active"):
    """è·å–å¤‡å¿˜å½•åˆ—è¡¨"""
    memos = memo_manager.get_memos(user_id, status)
    return {"success": True, "memos": memos, "count": len(memos)}


@app.get("/api/memo/{memo_id}")
async def get_memo(memo_id: int):
    """è·å–å•ä¸ªå¤‡å¿˜å½•"""
    memo = memo_manager.get_memo_by_id(memo_id)
    if memo:
        return {"success": True, "memo": memo}
    return {"success": False, "error": "å¤‡å¿˜å½•ä¸å­˜åœ¨"}


@app.put("/api/memo/update/{memo_id}")
async def update_memo(memo_id: int, updates: dict):
    """æ›´æ–°å¤‡å¿˜å½•"""
    memo_manager.update_memo(memo_id, updates)
    return {"success": True, "message": "å¤‡å¿˜å½•å·²æ›´æ–°"}


@app.post("/api/memo/link-plan")
async def link_memo_to_plan(memo_id: int, plan_id: int):
    """å…³è”å¤‡å¿˜å½•åˆ°è®¡åˆ’"""
    work_plan_manager.link_memo_to_plan(plan_id, memo_id)
    return {"success": True, "message": "å¤‡å¿˜å½•å·²å…³è”åˆ°è®¡åˆ’"}


@app.get("/api/memo/search/{user_id}")
async def search_memos(user_id: str, keyword: str):
    """æœç´¢å¤‡å¿˜å½•"""
    memos = memo_manager.search_memos(user_id, keyword)
    return {"success": True, "memos": memos, "count": len(memos)}


# ========== å¤šè¯­è¨€ç¿»è¯‘API ==========
@app.post("/api/translate")
async def translate_text(text: str, source_lang: str, target_lang: str):
    """ç¿»è¯‘æ–‡æœ¬"""
    result = await translator.translate(text, source_lang, target_lang)
    return result


@app.post("/api/translate/auto")
async def auto_translate(text: str, target_lang: str = "zh"):
    """è‡ªåŠ¨æ£€æµ‹å¹¶ç¿»è¯‘"""
    result = await translator.auto_detect_and_translate(text, target_lang)
    return result


@app.get("/api/translate/languages")
async def get_languages():
    """è·å–æ”¯æŒçš„è¯­è¨€"""
    languages = translator.get_supported_languages()
    return {"success": True, "languages": languages}


# ============================================================
# ğŸ“– ä¸Šä¸‹æ–‡è®°å¿†ç®¡ç†APIï¼ˆ100ä¸‡å­—è®°å¿†èƒ½åŠ›ï¼‰
# ============================================================

@app.get("/api/context/stats/{session_id}")
async def get_context_stats(session_id: str):
    """è·å–ä¸Šä¸‹æ–‡è®°å¿†ç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = context_memory.get_context_stats(session_id)
        return {"success": True, "stats": stats}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/context/history/{session_id}")
async def get_conversation_history(session_id: str, limit: int = 50, offset: int = 0):
    """è·å–ä¼šè¯å†å²"""
    try:
        history = context_memory.get_conversation_history(session_id, limit, offset)
        return {"success": True, "history": history, "count": len(history)}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/context/sessions/{user_id}")
async def get_user_sessions(user_id: str, limit: int = 20):
    """è·å–ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯"""
    try:
        sessions = context_memory.get_user_sessions(user_id, limit)
        return {"success": True, "sessions": sessions, "count": len(sessions)}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/context/summary/{session_id}")
async def get_session_summary_api(session_id: str):
    """è·å–ä¼šè¯æ‘˜è¦"""
    try:
        summary = context_memory.get_session_summary(session_id)
        if summary:
            return {"success": True, "summary": summary}
        else:
            return {"success": False, "error": "ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æ‘˜è¦"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.post("/api/context/summary/{session_id}/generate")
async def generate_session_summary_api(session_id: str, ai_summary: Optional[str] = None):
    """ç”Ÿæˆä¼šè¯æ‘˜è¦"""
    try:
        summary = context_memory.generate_session_summary(session_id, ai_summary)
        return {"success": True, "summary": summary}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/context/search/{session_id}")
async def search_context(session_id: str, query: str, top_k: int = 5):
    """æœç´¢ç›¸å…³å†å²å¯¹è¯"""
    try:
        results = context_memory.search_relevant_context(session_id, query, top_k)
        return {"success": True, "results": results, "count": len(results)}
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# ğŸ“¤ å¯¹è¯å¯¼å‡ºAPI
# ============================================================

@app.get("/api/export/{session_id}/markdown")
async def export_markdown(session_id: str, include_metadata: bool = False):
    """å¯¼å‡ºä¸ºMarkdownæ ¼å¼"""
    try:
        content = conversation_exporter.export_to_markdown(session_id, include_metadata)
        from fastapi.responses import Response
        return Response(
            content=content,
            media_type="text/markdown",
            headers={
                "Content-Disposition": f"attachment; filename=conversation_{session_id}.md"
            }
        )
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/export/{session_id}/json")
async def export_json(session_id: str, pretty: bool = True):
    """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
    try:
        content = conversation_exporter.export_to_json(session_id, pretty)
        from fastapi.responses import Response
        return Response(
            content=content,
            media_type="application/json",
            headers={
                "Content-Disposition": f"attachment; filename=conversation_{session_id}.json"
            }
        )
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/export/{session_id}/html")
async def export_html(session_id: str):
    """å¯¼å‡ºä¸ºHTMLæ ¼å¼"""
    try:
        content = conversation_exporter.export_to_html(session_id)
        from fastapi.responses import Response
        return Response(
            content=content,
            media_type="text/html",
            headers={
                "Content-Disposition": f"attachment; filename=conversation_{session_id}.html"
            }
        )
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/export/{session_id}/txt")
async def export_txt(session_id: str):
    """å¯¼å‡ºä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
    try:
        content = conversation_exporter.export_to_txt(session_id)
        from fastapi.responses import Response
        return Response(
            content=content,
            media_type="text/plain",
            headers={
                "Content-Disposition": f"attachment; filename=conversation_{session_id}.txt"
            }
        )
    except Exception as e:
        return {"success": False, "error": str(e)}


# ============================================================
# ğŸ”” æ™ºèƒ½æé†’API
# ============================================================

@app.post("/api/reminder/detect")
async def detect_reminder(message: str, user_id: str, session_id: str):
    """æ£€æµ‹æ¶ˆæ¯ä¸­çš„æé†’"""
    try:
        reminders = reminder_system.extract_reminders_from_message(user_id, session_id, message)
        
        # è‡ªåŠ¨ä¿å­˜æ£€æµ‹åˆ°çš„æé†’
        saved_ids = []
        for reminder in reminders:
            reminder_id = reminder_system.save_reminder(reminder)
            saved_ids.append(reminder_id)
        
        return {
            "success": True, 
            "reminders_detected": len(reminders),
            "reminders": reminders,
            "saved_ids": saved_ids
        }
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/reminder/active/{user_id}")
async def get_active_reminders(user_id: str, limit: int = 20):
    """è·å–æ´»è·ƒçš„æé†’"""
    try:
        reminders = reminder_system.get_active_reminders(user_id, limit)
        return {"success": True, "reminders": reminders, "count": len(reminders)}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/reminder/due/{user_id}")
async def get_due_reminders(user_id: str):
    """è·å–åˆ°æœŸçš„æé†’"""
    try:
        reminders = reminder_system.get_due_reminders(user_id)
        return {"success": True, "reminders": reminders, "count": len(reminders)}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.post("/api/reminder/{reminder_id}/complete")
async def complete_reminder(reminder_id: int):
    """æ ‡è®°æé†’ä¸ºå·²å®Œæˆ"""
    try:
        reminder_system.mark_as_completed(reminder_id)
        return {"success": True, "message": "æé†’å·²å®Œæˆ"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.post("/api/reminder/{reminder_id}/dismiss")
async def dismiss_reminder(reminder_id: int):
    """æ ‡è®°æé†’ä¸ºå·²å¿½ç•¥"""
    try:
        reminder_system.mark_as_dismissed(reminder_id)
        return {"success": True, "message": "æé†’å·²å¿½ç•¥"}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/reminder/stats/{user_id}")
async def get_reminder_stats(user_id: str):
    """è·å–æé†’ç»Ÿè®¡"""
    try:
        stats = reminder_system.get_reminder_statistics(user_id)
        return {"success": True, "stats": stats}
    except Exception as e:
        return {"success": False, "error": str(e)}


@app.get("/api/models")
async def get_available_models():
    """
    éœ€æ±‚8: è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨
    """
    try:
        # ä»Ollamaè·å–å·²å®‰è£…çš„æ¨¡å‹
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{config.OLLAMA_API}/api/tags", timeout=5.0)
            
            if response.status_code == 200:
                data = response.json()
                installed_models = [model.get("name") for model in data.get("models", [])]
                
                # æ ‡è®°å“ªäº›æ¨èæ¨¡å‹å·²å®‰è£…
                models_info = []
                for model in config.SUPPORTED_MODELS:
                    model_info = model.copy()
                    model_info["installed"] = model["id"] in installed_models
                    models_info.append(model_info)
                
                return {
                    "success": True,
                    "models": models_info,
                    "installed_count": len(installed_models),
                    "current_model": config.OLLAMA_MODEL
                }
    except Exception as e:
        # å¦‚æœOllamaä¸å¯ç”¨ï¼Œè¿”å›æ¨èåˆ—è¡¨
        return {
            "success": False,
            "models": config.SUPPORTED_MODELS,
            "error": "OllamaæœåŠ¡ä¸å¯ç”¨",
            "current_model": config.OLLAMA_MODEL
        }


# æä¾›é™æ€æ–‡ä»¶æœåŠ¡ï¼ˆå¿…é¡»åœ¨è·¯ç”±ä¹‹åï¼‰
try:
    app.mount("/static", StaticFiles(directory="static"), name="static")
except:
    print("âš ï¸ é™æ€æ–‡ä»¶ç›®å½•æœªæ‰¾åˆ°ï¼Œå°†è·³è¿‡")


if __name__ == "__main__":
    import uvicorn
    print("=" * 60)
    print("   ğŸ¤– AI Stack æ™ºèƒ½å¯¹è¯ä¸­å¿ƒå¯åŠ¨ä¸­...")
    print("=" * 60)
    print("")
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:8020")
    print("")
    print("âœ… æ»¡è¶³4ä¸ªæ ¸å¿ƒéœ€æ±‚:")
    print("  1. OpenWebUIè°ƒç”¨AI Stack + åé¦ˆç»“æœ")
    print("  2. RAGå…ˆè¡Œæ£€ç´¢ + å†å²ç»éªŒä½œä¸ºé™„åŠ æ¡ä»¶")
    print("  3. ç»“æœRAGéªŒè¯ + å·®å¼‚æ£€æµ‹è¯´æ˜")
    print("  4. ç›‘æ§å­¦ä¹  + ç»éªŒç§¯ç´¯åˆ°RAG")
    print("")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=8020)

