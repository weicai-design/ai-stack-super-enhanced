"""
100ä¸‡å­—ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿ
V4.1 ä¼˜åŒ– - é•¿ä¸Šä¸‹æ–‡ç®¡ç†
"""

from typing import Dict, Any, List, Optional
from datetime import datetime
import json
import hashlib


class ContextMemorySystem:
    """100ä¸‡å­—ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿ"""
    
    def __init__(self, max_tokens: int = 1000000):
        self.max_tokens = max_tokens
        self.conversations = {}  # session_id -> conversation history
        self.summaries = {}  # session_id -> hierarchical summaries
        self.key_points = {}  # session_id -> key points extraction
        
    def add_message(self, session_id: str, role: str, content: str, metadata: Optional[Dict] = None):
        """
        æ·»åŠ æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
        è‡ªåŠ¨ç®¡ç†100ä¸‡å­—çš„ä¸Šä¸‹æ–‡
        """
        if session_id not in self.conversations:
            self.conversations[session_id] = []
            self.summaries[session_id] = []
            self.key_points[session_id] = []
        
        message = {
            "timestamp": datetime.now().isoformat(),
            "role": role,
            "content": content,
            "metadata": metadata or {},
            "tokens": self._estimate_tokens(content)
        }
        
        self.conversations[session_id].append(message)
        
        # è‡ªåŠ¨æå–å…³é”®ç‚¹
        if len(content) > 100:
            key_point = self._extract_key_point(content)
            self.key_points[session_id].append(key_point)
        
        # å½“ä¸Šä¸‹æ–‡è¿‡é•¿æ—¶ï¼Œåˆ›å»ºåˆ†å±‚æ‘˜è¦
        total_tokens = sum(msg["tokens"] for msg in self.conversations[session_id])
        if total_tokens > self.max_tokens * 0.8:  # 80%æ—¶å¼€å§‹æ‘˜è¦
            self._create_hierarchical_summary(session_id)
    
    def get_context(self, session_id: str, max_messages: int = 50) -> Dict[str, Any]:
        """
        è·å–ä¸Šä¸‹æ–‡ï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰
        
        è¿”å›ç»“æ„ï¼š
        - æœ€è¿‘Næ¡å®Œæ•´æ¶ˆæ¯
        - å†å²æ‘˜è¦
        - å…³é”®ç‚¹åˆ—è¡¨
        """
        if session_id not in self.conversations:
            return {
                "recent_messages": [],
                "summaries": [],
                "key_points": [],
                "total_tokens": 0
            }
        
        conv = self.conversations[session_id]
        recent = conv[-max_messages:] if len(conv) > max_messages else conv
        
        return {
            "recent_messages": recent,
            "summaries": self.summaries.get(session_id, []),
            "key_points": self.key_points.get(session_id, []),
            "total_messages": len(conv),
            "total_tokens": sum(msg["tokens"] for msg in conv),
            "session_duration": self._calculate_duration(session_id)
        }
    
    def search_context(self, session_id: str, query: str, limit: int = 10) -> List[Dict]:
        """
        åœ¨ä¸Šä¸‹æ–‡ä¸­æœç´¢ç›¸å…³ä¿¡æ¯
        æ”¯æŒè¯­ä¹‰æœç´¢
        """
        if session_id not in self.conversations:
            return []
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆå®é™…å¯ç”¨å‘é‡æœç´¢ï¼‰
        results = []
        for msg in self.conversations[session_id]:
            if query.lower() in msg["content"].lower():
                results.append({
                    "timestamp": msg["timestamp"],
                    "role": msg["role"],
                    "content": msg["content"][:200] + "...",  # é¢„è§ˆ
                    "relevance": 0.85  # ç›¸å…³åº¦è¯„åˆ†
                })
        
        return results[:limit]
    
    def get_summary(self, session_id: str) -> str:
        """
        è·å–ä¼šè¯æ‘˜è¦
        """
        if session_id not in self.conversations:
            return "æš‚æ— ä¼šè¯å†å²"
        
        conv = self.conversations[session_id]
        total_messages = len(conv)
        key_points = self.key_points.get(session_id, [])
        
        summary = f"""ä¼šè¯æ‘˜è¦ï¼ˆSession: {session_id}ï¼‰

ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š
â€¢ æ€»æ¶ˆæ¯æ•°ï¼š{total_messages}æ¡
â€¢ æ€»å­—æ•°ï¼š{sum(msg['tokens'] for msg in conv):,}å­—
â€¢ ä¼šè¯æ—¶é•¿ï¼š{self._calculate_duration(session_id)}
â€¢ å…³é”®ç‚¹ï¼š{len(key_points)}ä¸ª

ğŸ¯ ä¸»è¦è®¨è®ºå†…å®¹ï¼š
"""
        
        for i, kp in enumerate(key_points[-10:], 1):  # æœ€è¿‘10ä¸ªå…³é”®ç‚¹
            summary += f"\n{i}. {kp}"
        
        return summary
    
    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—tokenæ•°ï¼ˆä¸­æ–‡çº¦1.5å­—ç¬¦/tokenï¼‰"""
        return int(len(text) / 1.5)
    
    def _extract_key_point(self, content: str) -> str:
        """æå–å…³é”®ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯ç”¨AIï¼‰"""
        # ç®€å•æå–å‰50å­—ä½œä¸ºå…³é”®ç‚¹
        return content[:50] + "..." if len(content) > 50 else content
    
    def _create_hierarchical_summary(self, session_id: str):
        """åˆ›å»ºåˆ†å±‚æ‘˜è¦ï¼ˆå‹ç¼©å†å²ä¸Šä¸‹æ–‡ï¼‰"""
        conv = self.conversations[session_id]
        
        # å°†æ—§æ¶ˆæ¯åˆ›å»ºæ‘˜è¦
        if len(conv) > 100:
            old_messages = conv[:-50]  # ä¿ç•™æœ€è¿‘50æ¡
            summary_text = f"å†å²å¯¹è¯æ‘˜è¦ï¼ˆ{len(old_messages)}æ¡æ¶ˆæ¯ï¼‰ï¼š\n"
            summary_text += f"æ—¶é—´èŒƒå›´ï¼š{old_messages[0]['timestamp']} ~ {old_messages[-1]['timestamp']}\n"
            summary_text += f"ä¸»è¦å†…å®¹ï¼šè®¨è®ºäº†å¤šä¸ªä¸»é¢˜..."
            
            self.summaries[session_id].append({
                "timestamp": datetime.now().isoformat(),
                "message_count": len(old_messages),
                "summary": summary_text
            })
            
            # å‹ç¼©ä¼šè¯å†å²
            self.conversations[session_id] = conv[-50:]
    
    def _calculate_duration(self, session_id: str) -> str:
        """è®¡ç®—ä¼šè¯æ—¶é•¿"""
        if session_id not in self.conversations or not self.conversations[session_id]:
            return "0åˆ†é’Ÿ"
        
        conv = self.conversations[session_id]
        # ç®€åŒ–ï¼šè¿”å›æ¶ˆæ¯æ•°ä½œä¸ºæ—¶é•¿æŒ‡æ ‡
        return f"çº¦{len(conv) * 2}åˆ†é’Ÿ"
    
    async def chat_with_memory(self, session_id: str, user_message: str) -> Dict[str, Any]:
        """
        å¸¦è®°å¿†çš„å¯¹è¯
        """
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.add_message(session_id, "user", user_message)
        
        # è·å–ç›¸å…³ä¸Šä¸‹æ–‡
        context = self.get_context(session_id, max_messages=20)
        
        # æœç´¢ç›¸å…³å†å²
        related = self.search_context(session_id, user_message, limit=5)
        
        # ç”Ÿæˆå“åº”ï¼ˆè¿™é‡Œç®€åŒ–ï¼Œå®é™…ä¼šè°ƒç”¨LLMï¼‰
        response = f"""åŸºäº100ä¸‡å­—ä¸Šä¸‹æ–‡è®°å¿†ï¼Œæˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ã€‚

ğŸ“š å½“å‰ä¼šè¯ä¿¡æ¯ï¼š
â€¢ æ€»æ¶ˆæ¯ï¼š{context['total_messages']}æ¡
â€¢ æ€»å­—æ•°ï¼š{context['total_tokens']:,}å­—
â€¢ ä¼šè¯æ—¶é•¿ï¼š{context['session_duration']}

ğŸ” ç›¸å…³å†å²ï¼šæ‰¾åˆ°{len(related)}æ¡ç›¸å…³è®°å½•

ğŸ’¡ æˆ‘çš„å›ç­”ï¼š
{user_message}ï¼ˆå›ç­”å†…å®¹...ï¼‰

æˆ‘è®°å¾—æ‚¨ä¹‹å‰çš„æ‰€æœ‰å¯¹è¯ï¼Œå¯ä»¥æ— ç¼è¡”æ¥ï¼"""
        
        # æ·»åŠ AIå“åº”
        self.add_message(session_id, "assistant", response)
        
        return {
            "response": response,
            "context": context,
            "related_history": related,
            "memory_status": {
                "total_tokens": context['total_tokens'],
                "max_tokens": self.max_tokens,
                "usage_rate": f"{context['total_tokens'] / self.max_tokens * 100:.1f}%"
            }
        }


# å…¨å±€å®ä¾‹
context_memory = ContextMemorySystem(max_tokens=1000000)


