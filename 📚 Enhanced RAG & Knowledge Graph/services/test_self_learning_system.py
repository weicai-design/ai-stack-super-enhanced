#!/usr/bin/env python3
"""
è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿå®Œæ•´æµ‹è¯•æ¨¡å—
æµ‹è¯•æ‰€æœ‰ç»„ä»¶çš„ç”Ÿäº§çº§å·¥ç¨‹åŒ–èƒ½åŠ›
"""

import sys
import os
import json
import time
from datetime import datetime, timedelta

# æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from self_learning_system import (
    SelfLearningSystem, SelfLearningConfig, WorkflowMonitor, 
    IssueAnalyzer, ExperienceSummarizer, Optimizer, RAGIntegration,
    IssueType, SeverityLevel, get_self_learning_system
)


def test_workflow_monitor():
    """æµ‹è¯•å·¥ä½œæµç›‘æ§å™¨"""
    print("\n=== æµ‹è¯•å·¥ä½œæµç›‘æ§å™¨ ===")
    
    monitor = WorkflowMonitor()
    
    # æ¨¡æ‹Ÿå·¥ä½œæµæ•°æ®
    test_workflows = [
        {
            "user_message": "æµ‹è¯•å·¥ä½œæµ1",
            "duration": 2.5,
            "success": True,
            "timestamp": datetime.now().isoformat(),
            "performance_metrics": {
                "performance_score": 85,
                "resource_usage": 0.3
            }
        },
        {
            "user_message": "æµ‹è¯•å·¥ä½œæµ2", 
            "duration": 8.2,
            "success": False,
            "timestamp": (datetime.now() - timedelta(hours=1)).isoformat(),
            "performance_metrics": {
                "performance_score": 45,
                "resource_usage": 0.8
            }
        }
    ]
    
    # æµ‹è¯•å·¥ä½œæµè®°å½•
    for workflow in test_workflows:
        monitor.record_workflow(workflow)
    
    # æµ‹è¯•ç»Ÿè®¡åˆ†æ
    stats = monitor.get_monitoring_statistics()
    print(f"ç›‘æ§ç»Ÿè®¡: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    # æµ‹è¯•å·¥ä½œæµæŸ¥è¯¢
    workflow = monitor.get_workflow_by_id("WF001")
    print(f"æŸ¥è¯¢å·¥ä½œæµ: {workflow}")
    
    # æµ‹è¯•æ€§èƒ½è¶‹åŠ¿
    trends = monitor._get_performance_trends()
    print(f"æ€§èƒ½è¶‹åŠ¿: {trends}")
    
    # æµ‹è¯•å‘Šè­¦ç”Ÿæˆ
    alert = monitor.generate_alert(test_workflows[1], IssueType.PERFORMANCE, SeverityLevel.HIGH)
    print(f"ç”Ÿæˆå‘Šè­¦: {alert}")
    
    print("âœ“ å·¥ä½œæµç›‘æ§å™¨æµ‹è¯•å®Œæˆ")


def test_issue_analyzer():
    """æµ‹è¯•é—®é¢˜åˆ†æå™¨"""
    print("\n=== æµ‹è¯•é—®é¢˜åˆ†æå™¨ ===")
    
    analyzer = IssueAnalyzer()
    
    # æµ‹è¯•å·¥ä½œæµåˆ†æ
    test_workflow = {
        "id": "TEST_WORKFLOW_001",
        "user_message": "æµ‹è¯•é—®é¢˜åˆ†æå·¥ä½œæµ",
        "duration": 12.5,  # è¶…è¿‡é˜ˆå€¼
        "success": True,
        "rag_retrieval_1": {"results_count": 0},  # æ£€ç´¢é—®é¢˜
        "function_execution": {"success": False, "error": "æ¨¡å—å¯¼å…¥é”™è¯¯"},
        "performance_metrics": {"resource_usage": 0.9}  # èµ„æºä½¿ç”¨è¿‡é«˜
    }
    
    analysis_result = analyzer.analyze_workflow(test_workflow)
    print(f"é—®é¢˜åˆ†æç»“æœ: {json.dumps(analysis_result, indent=2, ensure_ascii=False)}")
    
    # æµ‹è¯•ç»Ÿè®¡åˆ†æ
    stats = analyzer.get_analysis_statistics()
    print(f"åˆ†æç»Ÿè®¡: {stats}")
    
    # æµ‹è¯•å·²çŸ¥æ¨¡å¼åŒ¹é…
    test_issue = {
        "type": IssueType.PERFORMANCE.value,
        "description": "å“åº”æ—¶é—´è¿‡é•¿ï¼š12.5ç§’ (ç›®æ ‡<5.0ç§’)",
        "severity": SeverityLevel.HIGH.value
    }
    
    patterns = analyzer.match_known_patterns(test_issue)
    print(f"åŒ¹é…æ¨¡å¼: {patterns}")
    
    print("âœ“ é—®é¢˜åˆ†æå™¨æµ‹è¯•å®Œæˆ")


def test_experience_summarizer():
    """æµ‹è¯•ç»éªŒæ€»ç»“å™¨"""
    print("\n=== æµ‹è¯•ç»éªŒæ€»ç»“å™¨ ===")
    
    summarizer = ExperienceSummarizer()
    
    # æ¨¡æ‹Ÿé—®é¢˜åˆ†æç»“æœ - ä¿®æ­£æ ¼å¼ä»¥åŒ¹é…ç»éªŒæ€»ç»“å™¨æœŸæœ›çš„è¾“å…¥
    test_issues_list = [
        {
            "issues": [
                {
                    "type": IssueType.PERFORMANCE.value,
                    "severity": SeverityLevel.HIGH.value,
                    "description": "å“åº”æ—¶é—´è¿‡é•¿ï¼š15.2ç§’",
                    "suggestion": "ä¼˜åŒ–RAGæ£€ç´¢ç®—æ³•"
                },
                {
                    "type": IssueType.RAG_QUALITY.value,
                    "severity": SeverityLevel.MEDIUM.value,
                    "description": "RAGç¬¬ä¸€æ¬¡æ£€ç´¢æ— ç»“æœ",
                    "suggestion": "æ‰©å……çŸ¥è¯†åº“å†…å®¹"
                }
            ]
        }
    ]
    
    # æµ‹è¯•ç»éªŒæ€»ç»“
    try:
        summary = summarizer.summarize_issues(test_issues_list)
        print(f"ç»éªŒæ€»ç»“ID: {summary.get('id')}")
        print(f"å‘ç°é—®é¢˜æ•°: {summary.get('total_issues')}")
        print(f"è´¨é‡è¯„åˆ†: {summary.get('quality_score')}")
        
        # æµ‹è¯•RAGæ–‡æ¡£ç”Ÿæˆ
        rag_doc = summary.get('rag_document', '')
        print(f"RAGæ–‡æ¡£é•¿åº¦: {len(rag_doc)} å­—ç¬¦")
        
        print("âœ“ ç»éªŒæ€»ç»“å™¨æµ‹è¯•å®Œæˆ")
    except Exception as e:
        print(f"âŒ ç»éªŒæ€»ç»“å™¨æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def test_optimizer():
    """æµ‹è¯•ä¼˜åŒ–å™¨"""
    print("\n=== æµ‹è¯•ä¼˜åŒ–å™¨ ===")
    
    optimizer = Optimizer()
    
    # æ¨¡æ‹Ÿç»éªŒæ€»ç»“æ•°æ®
    test_experience = {
        "experiences": [
            {
                "issue_type": "performance",
                "severity": "medium",
                "occurrence_count": 5,
                "optimization_suggestions": ["è°ƒæ•´ç¼“å­˜ç­–ç•¥", "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢"]
            }
        ]
    }
    
    # åº”ç”¨ä¼˜åŒ–
    optimization_result = await optimizer.apply_optimization(test_experience)
    print(f"ä¼˜åŒ–ç»“æœ: {json.dumps(optimization_result, indent=2, ensure_ascii=False)}")
    
    # æµ‹è¯•ä¼˜åŒ–å†å²
    history = optimizer.get_optimization_history()
    print(f"ä¼˜åŒ–å†å²è®°å½•æ•°: {len(history)}")
    
    print("âœ“ ä¼˜åŒ–å™¨æµ‹è¯•å®Œæˆ")


async def test_rag_integration():
    """æµ‹è¯•RAGé›†æˆ"""
    print("\n=== æµ‹è¯•RAGé›†æˆ ===")
    
    rag_integration = RAGIntegration()
    
    # æ¨¡æ‹Ÿç»éªŒæ€»ç»“æ•°æ® - ä¿®æ­£æ ¼å¼ä»¥åŒ¹é…RAGé›†æˆå™¨æœŸæœ›çš„è¾“å…¥
    test_summary = {
        "id": "EXP001",
        "summary": "å‘ç°2ç±»é—®é¢˜ï¼Œå…±2ä¸ªå…·ä½“é—®é¢˜",
        "total_issues": 2,
        "issue_types": 2,
        "experiences": [
            {
                "issue_type": "performance",
                "severity": "high",
                "occurrence_count": 1,
                "optimization_suggestions": ["ä¼˜åŒ–RAGæ£€ç´¢ç®—æ³•"]
            },
            {
                "issue_type": "rag_quality",
                "severity": "medium",
                "occurrence_count": 1,
                "optimization_suggestions": ["æ‰©å……çŸ¥è¯†åº“å†…å®¹"]
            }
        ],
        "rag_document": "# AI-STACK ç³»ç»Ÿç»éªŒæ€»ç»“\n\n**æ€»ç»“ID**: EXP001\n**ç”Ÿæˆæ—¶é—´**: 2024-01-01 12:00:00\n\n## ç³»ç»ŸçŠ¶æ€\n\nç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œå‘ç°2ç±»éœ€è¦ä¼˜åŒ–çš„é—®é¢˜ã€‚\n\n## ç›‘æ§æŒ‡æ ‡\n\n- **å“åº”æ—¶é—´**: éœ€è¦ä¼˜åŒ–\n- **æˆåŠŸç‡**: 95%\n- **èµ„æºä½¿ç”¨ç‡**: æ­£å¸¸\n\n## é—®é¢˜åˆ†æ\n\n### 1. æ€§èƒ½é—®é¢˜\n- **ä¸¥é‡ç¨‹åº¦**: high\n- **ä¼˜å…ˆçº§**: high\n- **å‡ºç°æ¬¡æ•°**: 1\n- **å‘ç°æ—¶é—´**: 2024-01-01 12:00:00\n\n#### ä¼˜åŒ–å»ºè®®\n- ä¼˜åŒ–RAGæ£€ç´¢ç®—æ³•\n\n### 2. RAGè´¨é‡é—®é¢˜\n- **ä¸¥é‡ç¨‹åº¦**: medium\n- **ä¼˜å…ˆçº§**: medium\n- **å‡ºç°æ¬¡æ•°**: 1\n- **å‘ç°æ—¶é—´**: 2024-01-01 12:00:00\n\n#### ä¼˜åŒ–å»ºè®®\n- æ‰©å……çŸ¥è¯†åº“å†…å®¹\n\n---\n\n*æœ¬æ–‡æ¡£ç”±AI-STACKè‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*",
        "quality_score": 85.0,
        "priority_distribution": {"critical": 0, "high": 1, "medium": 1, "low": 0},
        "created_at": datetime.now().isoformat(),
        "metadata": {
            "version": "1.0",
            "generator": "AI-STACK Self Learning System",
            "quality_assurance": "enabled"
        }
    }
    
    # æµ‹è¯•RAGä¿å­˜
    try:
        save_result = await rag_integration.save_to_rag(test_summary)
        print(f"RAGä¿å­˜ç»“æœ: {save_result}")
        
        # æµ‹è¯•é›†æˆç»Ÿè®¡
        stats = rag_integration.get_integration_stats()
        print(f"é›†æˆç»Ÿè®¡: {stats}")
        
        print("âœ“ RAGé›†æˆæµ‹è¯•å®Œæˆ")
    except Exception as e:
        print(f"âŒ RAGé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def test_self_learning_system():
    """æµ‹è¯•å®Œæ•´çš„è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿ"""
    print("\n=== æµ‹è¯•å®Œæ•´çš„è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿ ===")
    
    # è·å–å…¨å±€å®ä¾‹
    system = get_self_learning_system()
    
    # æ¨¡æ‹Ÿå·¥ä½œæµå¤„ç† - ä¿®æ­£æ ¼å¼ä»¥åŒ¹é…process_workflowæœŸæœ›çš„è¾“å…¥
    test_workflow = {
        "workflow_id": "TEST_WORKFLOW_001",
        "user_message": "ç³»ç»Ÿæµ‹è¯•å·¥ä½œæµ",
        "duration": 3.2,
        "success": True,
        "timestamp": datetime.now().isoformat(),
        "steps": [
            {
                "name": "rag_retrieval_1",
                "results_count": 10,
                "success": True
            },
            {
                "name": "function_execution",
                "success": True
            }
        ],
        "performance_metrics": {
            "performance_score": 92,
            "resource_usage": 0.4
        }
    }
    
    # æµ‹è¯•å·¥ä½œæµå¤„ç† - ä½¿ç”¨awaitè°ƒç”¨å¼‚æ­¥æ–¹æ³•
    try:
        result = await system.process_workflow(test_workflow)
        print(f"ç³»ç»Ÿå¤„ç†ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")
        
        # æµ‹è¯•ç³»ç»ŸçŠ¶æ€
        status = system.get_learning_status()
        print(f"ç³»ç»Ÿå­¦ä¹ çŠ¶æ€: {status}")
        
        # æµ‹è¯•æ‰¹é‡å¤„ç†
        batch_workflows = [test_workflow] * 3
        batch_result = await system.batch_process_workflows(batch_workflows)
        print(f"æ‰¹é‡å¤„ç†ç»“æœæ•°: {len(batch_result.get('results', []))}")
        
        print("âœ“ è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
    except Exception as e:
        print(f"âŒ è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¼€å§‹è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿç”Ÿäº§çº§å·¥ç¨‹åŒ–èƒ½åŠ›æµ‹è¯•...")
    
    try:
        test_workflow_monitor()
        test_issue_analyzer()
        test_experience_summarizer()
        await test_optimizer()
        await test_rag_integration()
        await test_self_learning_system()
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼è‡ªæˆ‘å­¦ä¹ ç³»ç»Ÿç”Ÿäº§çº§å·¥ç¨‹åŒ–èƒ½åŠ›éªŒè¯æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


import asyncio

async def main():
    await run_all_tests()

if __name__ == "__main__":
    asyncio.run(main())