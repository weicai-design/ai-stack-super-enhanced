"""
çœŸå®æ€§éªŒè¯ç®¡é“
ç”¨äºéªŒè¯RAGæ£€ç´¢ç»“æœçš„çœŸå®æ€§å’Œå¯ä¿¡åº¦
"""
from typing import List, Dict, Any, Optional
from datetime import datetime
import re


class TruthVerificationPipeline:
    """çœŸå®æ€§éªŒè¯ç®¡é“"""
    
    def __init__(self, llm_client=None):
        """
        åˆå§‹åŒ–çœŸå®æ€§éªŒè¯ç®¡é“
        
        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œç”¨äºAIéªŒè¯ï¼‰
        """
        self.llm_client = llm_client
        self.verification_cache = {}
    
    def verify(self, text: str, sources: List[Dict] = None) -> Dict[str, Any]:
        """
        éªŒè¯æ–‡æœ¬çš„çœŸå®æ€§
        
        Args:
            text: è¦éªŒè¯çš„æ–‡æœ¬
            sources: æ¥æºä¿¡æ¯åˆ—è¡¨
        
        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        result = {
            "text": text,
            "verified": False,
            "confidence_score": 0.0,
            "verification_details": {},
            "sources": sources or [],
            "timestamp": datetime.now().isoformat()
        }
        
        # 1. åŸºç¡€éªŒè¯
        basic_score = self._basic_verification(text)
        result["verification_details"]["basic"] = basic_score
        
        # 2. æ¥æºéªŒè¯
        if sources:
            source_score = self._verify_sources(sources)
            result["verification_details"]["sources"] = source_score
        else:
            source_score = 0.5  # æ— æ¥æºæ—¶ä¸­ç­‰å¯ä¿¡åº¦
        
        # 3. ä¸€è‡´æ€§éªŒè¯
        consistency_score = self._check_consistency(text, sources)
        result["verification_details"]["consistency"] = consistency_score
        
        # 4. äº‹å®æ ¸æŸ¥
        fact_score = self._fact_check(text)
        result["verification_details"]["facts"] = fact_score
        
        # 5. æ—¶æ•ˆæ€§éªŒè¯
        timeliness_score = self._check_timeliness(text, sources)
        result["verification_details"]["timeliness"] = timeliness_score
        
        # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
        weights = {
            "basic": 0.2,
            "sources": 0.25,
            "consistency": 0.25,
            "facts": 0.2,
            "timeliness": 0.1
        }
        
        confidence = (
            basic_score * weights["basic"] +
            source_score * weights["sources"] +
            consistency_score * weights["consistency"] +
            fact_score * weights["facts"] +
            timeliness_score * weights["timeliness"]
        )
        
        result["confidence_score"] = round(confidence, 3)
        result["verified"] = confidence >= 0.7  # 70%ä»¥ä¸Šè®¤ä¸ºå¯ä¿¡
        
        # ç”ŸæˆéªŒè¯å»ºè®®
        result["suggestions"] = self._generate_suggestions(result)
        
        return result
    
    def _basic_verification(self, text: str) -> float:
        """åŸºç¡€éªŒè¯ï¼šæ£€æŸ¥æ–‡æœ¬è´¨é‡"""
        score = 1.0
        
        # æ£€æŸ¥é•¿åº¦ï¼ˆå¤ªçŸ­æˆ–å¤ªé•¿éƒ½é™ä½å¯ä¿¡åº¦ï¼‰
        length = len(text)
        if length < 10:
            score -= 0.3
        elif length > 10000:
            score -= 0.1
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¯ç–‘æ¨¡å¼
        suspicious_patterns = [
            r'\b(å‡çš„|è™šå‡|è°£è¨€|ä¸å®)\b',
            r'\b(æ®è¯´|å¬è¯´|å¯èƒ½)\b',
            r'\?\?\?',
            r'!!!+'
        ]
        
        for pattern in suspicious_patterns:
            if re.search(pattern, text):
                score -= 0.1
        
        return max(0.0, min(1.0, score))
    
    def _verify_sources(self, sources: List[Dict]) -> float:
        """éªŒè¯æ¥æºå¯ä¿¡åº¦"""
        if not sources:
            return 0.5
        
        total_score = 0.0
        
        for source in sources:
            source_score = 1.0
            
            # æ£€æŸ¥æ¥æºç±»å‹
            source_type = source.get("type", "unknown")
            if source_type in ["academic", "official", "verified"]:
                source_score = 1.0
            elif source_type in ["news", "media"]:
                source_score = 0.8
            elif source_type in ["blog", "forum"]:
                source_score = 0.6
            else:
                source_score = 0.5
            
            # æ£€æŸ¥æ˜¯å¦æœ‰URL
            if source.get("url"):
                source_score += 0.1
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä½œè€…
            if source.get("author"):
                source_score += 0.1
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å‘å¸ƒæ—¥æœŸ
            if source.get("published_date"):
                source_score += 0.1
            
            total_score += min(1.0, source_score)
        
        return total_score / len(sources)
    
    def _check_consistency(self, text: str, sources: List[Dict]) -> float:
        """æ£€æŸ¥æ–‡æœ¬ä¸æ¥æºçš„ä¸€è‡´æ€§"""
        if not sources:
            return 0.7  # æ— æ¥æºæ—¶å‡è®¾ä¸­ç­‰ä¸€è‡´æ€§
        
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥å…³é”®è¯åŒ¹é…
        text_keywords = set(self._extract_keywords(text))
        
        consistency_scores = []
        for source in sources:
            source_text = source.get("content", "")
            source_keywords = set(self._extract_keywords(source_text))
            
            if not source_keywords:
                continue
            
            # è®¡ç®—å…³é”®è¯é‡å ç‡
            overlap = len(text_keywords & source_keywords)
            total = len(text_keywords | source_keywords)
            
            if total > 0:
                consistency = overlap / total
                consistency_scores.append(consistency)
        
        if not consistency_scores:
            return 0.7
        
        return sum(consistency_scores) / len(consistency_scores)
    
    def _fact_check(self, text: str) -> float:
        """äº‹å®æ ¸æŸ¥"""
        score = 1.0
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—å’Œæ—¥æœŸï¼ˆå¯éªŒè¯çš„äº‹å®ï¼‰
        has_numbers = bool(re.search(r'\d+', text))
        has_dates = bool(re.search(r'\d{4}[-/å¹´]\d{1,2}[-/æœˆ]\d{1,2}[æ—¥]?', text))
        
        if has_numbers or has_dates:
            score += 0.1  # æœ‰å…·ä½“æ•°æ®ï¼Œæé«˜å¯ä¿¡åº¦
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸ç¡®å®šæ€§è¯æ±‡
        uncertain_words = ['å¯èƒ½', 'ä¹Ÿè®¸', 'å¤§æ¦‚', 'ä¼°è®¡', 'å¬è¯´', 'æ®è¯´']
        for word in uncertain_words:
            if word in text:
                score -= 0.05
        
        return max(0.0, min(1.0, score))
    
    def _check_timeliness(self, text: str, sources: List[Dict]) -> float:
        """æ£€æŸ¥æ—¶æ•ˆæ€§"""
        if not sources:
            return 0.7
        
        now = datetime.now()
        timeliness_scores = []
        
        for source in sources:
            published_date = source.get("published_date")
            if not published_date:
                continue
            
            try:
                if isinstance(published_date, str):
                    pub_date = datetime.fromisoformat(published_date.replace('Z', '+00:00'))
                else:
                    pub_date = published_date
                
                # è®¡ç®—æ—¶é—´å·®ï¼ˆå¤©ï¼‰
                days_diff = (now - pub_date).days
                
                # è¶Šæ–°è¶Šå¥½
                if days_diff < 7:
                    timeliness = 1.0
                elif days_diff < 30:
                    timeliness = 0.9
                elif days_diff < 90:
                    timeliness = 0.8
                elif days_diff < 365:
                    timeliness = 0.7
                else:
                    timeliness = 0.6
                
                timeliness_scores.append(timeliness)
            except:
                continue
        
        if not timeliness_scores:
            return 0.7
        
        return sum(timeliness_scores) / len(timeliness_scores)
    
    def _extract_keywords(self, text: str, top_k: int = 20) -> List[str]:
        """æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰"""
        # ç§»é™¤æ ‡ç‚¹å’Œç‰¹æ®Šå­—ç¬¦
        text_clean = re.sub(r'[^\w\s]', ' ', text)
        
        # åˆ†è¯ï¼ˆç®€å•æŒ‰ç©ºæ ¼åˆ†ï¼‰
        words = text_clean.split()
        
        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¸', 'ç­‰', 'åŠ', 'the', 'a', 'an', 'and', 'or', 'but'}
        keywords = [w for w in words if len(w) > 1 and w.lower() not in stop_words]
        
        # ç»Ÿè®¡é¢‘ç‡
        word_freq = {}
        for word in keywords:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # è¿”å›é«˜é¢‘è¯
        sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
        return [word for word, freq in sorted_words[:top_k]]
    
    def _generate_suggestions(self, result: Dict) -> List[str]:
        """ç”ŸæˆéªŒè¯å»ºè®®"""
        suggestions = []
        
        confidence = result["confidence_score"]
        details = result["verification_details"]
        
        if confidence < 0.5:
            suggestions.append("âš ï¸ å¯ä¿¡åº¦è¾ƒä½ï¼Œå»ºè®®è¿›ä¸€æ­¥æ ¸å®")
        
        if details.get("sources", 0) < 0.6:
            suggestions.append("ğŸ’¡ å»ºè®®æ·»åŠ æ›´å¤šæƒå¨æ¥æº")
        
        if details.get("consistency", 0) < 0.6:
            suggestions.append("âš ï¸ æ–‡æœ¬ä¸æ¥æºä¸€è‡´æ€§è¾ƒä½ï¼Œè¯·ä»”ç»†æ ¸å¯¹")
        
        if details.get("timeliness", 0) < 0.6:
            suggestions.append("ğŸ“… ä¿¡æ¯å¯èƒ½è¾ƒæ—§ï¼Œå»ºè®®æŸ¥æ‰¾æœ€æ–°èµ„æ–™")
        
        if not result.get("sources"):
            suggestions.append("ğŸ“š å»ºè®®æ·»åŠ æ¥æºä¿¡æ¯ä»¥æé«˜å¯ä¿¡åº¦")
        
        if confidence >= 0.9:
            suggestions.append("âœ… ä¿¡æ¯å¯ä¿¡åº¦å¾ˆé«˜")
        
        return suggestions
    
    def batch_verify(self, texts: List[str], sources_list: List[List[Dict]] = None) -> List[Dict]:
        """æ‰¹é‡éªŒè¯"""
        results = []
        
        for i, text in enumerate(texts):
            sources = sources_list[i] if sources_list and i < len(sources_list) else None
            result = self.verify(text, sources)
            results.append(result)
        
        return results
    
    def get_verification_report(self, results: List[Dict]) -> Dict[str, Any]:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        total = len(results)
        if total == 0:
            return {
                "total": 0,
                "verified": 0,
                "average_confidence": 0.0
            }
        
        verified_count = sum(1 for r in results if r["verified"])
        avg_confidence = sum(r["confidence_score"] for r in results) / total
        
        return {
            "total": total,
            "verified": verified_count,
            "unverified": total - verified_count,
            "verification_rate": round(verified_count / total, 3),
            "average_confidence": round(avg_confidence, 3),
            "high_confidence": sum(1 for r in results if r["confidence_score"] >= 0.9),
            "medium_confidence": sum(1 for r in results if 0.7 <= r["confidence_score"] < 0.9),
            "low_confidence": sum(1 for r in results if r["confidence_score"] < 0.7)
        }


# å…¨å±€å®ä¾‹
truth_verifier = TruthVerificationPipeline()
