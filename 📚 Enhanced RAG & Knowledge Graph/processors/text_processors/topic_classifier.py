"""
ä¸»é¢˜åˆ†ç±»å™¨
æ”¯æŒæ–‡æ¡£ä¸»é¢˜åˆ†ç±»ã€å¤šæ ‡ç­¾åˆ†ç±»ã€å±‚çº§åˆ†ç±»ç­‰åŠŸèƒ½
"""
from typing import List, Dict, Optional
import re
from collections import Counter


class TopicClassifier:
    """ä¸»é¢˜åˆ†ç±»å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¸»é¢˜åˆ†ç±»å™¨"""
        # é¢„å®šä¹‰ä¸»é¢˜å…³é”®è¯
        self.topic_keywords = {
            "æŠ€æœ¯": ["AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç®—æ³•", "ç¼–ç¨‹", "å¼€å‘", "æŠ€æœ¯", "ç§‘æŠ€"],
            "å•†ä¸š": ["å•†ä¸š", "ä¼ä¸š", "ç®¡ç†", "è¿è¥", "è¥é”€", "é”€å”®", "å¸‚åœº", "æˆ˜ç•¥"],
            "è´¢åŠ¡": ["è´¢åŠ¡", "ä¼šè®¡", "æˆæœ¬", "é¢„ç®—", "åˆ©æ¶¦", "æ”¶å…¥", "æ”¯å‡º", "æŠ•èµ„"],
            "ç”Ÿäº§": ["ç”Ÿäº§", "åˆ¶é€ ", "å·¥è‰º", "è´¨é‡", "è®¾å¤‡", "äº§èƒ½", "æ•ˆç‡"],
            "æ³•å¾‹": ["æ³•å¾‹", "åˆåŒ", "åè®®", "åˆè§„", "æ³•è§„", "æ¡æ¬¾"],
            "åŒ»ç–—": ["åŒ»ç–—", "å¥åº·", "åŒ»é™¢", "ç–¾ç—…", "æ²»ç–—", "è¯ç‰©"],
            "æ•™è‚²": ["æ•™è‚²", "å­¦ä¹ ", "åŸ¹è®­", "è¯¾ç¨‹", "æ•™å­¦", "å­¦ç”Ÿ"],
            "æ–°é—»": ["æ–°é—»", "æŠ¥é“", "äº‹ä»¶", "å‘ç”Ÿ", "æ®æ‚‰", "æ¶ˆæ¯"]
        }
    
    def classify(
        self,
        text: str,
        top_k: int = 3,
        multi_label: bool = True
    ) -> Dict:
        """
        åˆ†ç±»æ–‡æœ¬ä¸»é¢˜
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            top_k: è¿”å›top kä¸ªä¸»é¢˜
            multi_label: æ˜¯å¦æ”¯æŒå¤šæ ‡ç­¾
            
        Returns:
            åˆ†ç±»ç»“æœ
        """
        # åŸºäºå…³é”®è¯çš„ç®€å•åˆ†ç±»
        scores = self._calculate_topic_scores(text)
        
        # æ’åº
        sorted_topics = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        
        if multi_label:
            # å¤šæ ‡ç­¾ï¼šè¿”å›æ‰€æœ‰åˆ†æ•°>é˜ˆå€¼çš„ä¸»é¢˜
            threshold = 0.3
            predictions = [
                {
                    "topic": topic,
                    "confidence": score,
                    "label": topic
                }
                for topic, score in sorted_topics
                if score >= threshold
            ][:top_k]
        else:
            # å•æ ‡ç­¾ï¼šåªè¿”å›æœ€é«˜åˆ†
            predictions = [
                {
                    "topic": sorted_topics[0][0],
                    "confidence": sorted_topics[0][1],
                    "label": sorted_topics[0][0]
                }
            ]
        
        return {
            "success": True,
            "text": text[:100] + "..." if len(text) > 100 else text,
            "predictions": predictions,
            "all_scores": dict(sorted_topics),
            "multi_label": multi_label
        }
    
    def _calculate_topic_scores(self, text: str) -> Dict[str, float]:
        """è®¡ç®—å„ä¸»é¢˜çš„å¾—åˆ†"""
        scores = {}
        
        for topic, keywords in self.topic_keywords.items():
            score = 0
            for keyword in keywords:
                # ç»Ÿè®¡å…³é”®è¯å‡ºç°æ¬¡æ•°
                count = len(re.findall(keyword, text, re.IGNORECASE))
                score += count
            
            # å½’ä¸€åŒ–åˆ†æ•°
            if len(text) > 0:
                scores[topic] = min(1.0, score / (len(text) / 100))
            else:
                scores[topic] = 0.0
        
        return scores
    
    def classify_hierarchical(self, text: str) -> Dict:
        """
        å±‚çº§åˆ†ç±»
        
        æŒ‰ç…§é¢„å®šä¹‰çš„ä¸»é¢˜å±‚çº§è¿›è¡Œåˆ†ç±»
        
        Returns:
            å±‚çº§åˆ†ç±»ç»“æœ
        """
        # å®šä¹‰ä¸»é¢˜å±‚çº§
        hierarchy = {
            "ç§‘æŠ€": {
                "AI": ["æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "NLP"],
                "è½¯ä»¶": ["ç¼–ç¨‹", "å¼€å‘", "æµ‹è¯•"],
                "ç¡¬ä»¶": ["èŠ¯ç‰‡", "è®¾å¤‡", "ç¡¬ä»¶"]
            },
            "å•†ä¸š": {
                "ç®¡ç†": ["ä¼ä¸šç®¡ç†", "é¡¹ç›®ç®¡ç†", "äººåŠ›èµ„æº"],
                "è¥é”€": ["å¸‚åœºè¥é”€", "å“ç‰Œ", "æ¨å¹¿"],
                "è´¢åŠ¡": ["ä¼šè®¡", "æŠ•èµ„", "èèµ„"]
            }
        }
        
        # ä¸€çº§åˆ†ç±»
        level1 = self.classify(text, top_k=1, multi_label=False)
        primary_topic = level1["predictions"][0]["topic"] if level1["predictions"] else "å…¶ä»–"
        
        # äºŒçº§åˆ†ç±»ï¼ˆæ¨¡æ‹Ÿï¼‰
        return {
            "success": True,
            "primary_topic": primary_topic,
            "secondary_topic": "å­åˆ†ç±»1",
            "tertiary_topic": "ç»†åˆ†ä¸»é¢˜1",
            "hierarchy_path": f"{primary_topic} > å­åˆ†ç±»1 > ç»†åˆ†ä¸»é¢˜1",
            "confidence": 0.85
        }
    
    def extract_keywords(self, text: str, top_k: int = 10) -> List[Dict]:
        """
        æå–å…³é”®è¯
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            top_k: è¿”å›top kä¸ªå…³é”®è¯
            
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ä½¿ç”¨TF-IDFæˆ–TextRankï¼‰
        # ç§»é™¤æ ‡ç‚¹å’Œåœç”¨è¯
        words = re.findall(r'[\u4e00-\u9fa5]+', text)
        
        # è¿‡æ»¤åœç”¨è¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'æœ‰', 'ä¸', 'ç­‰', 'ä¸º', 'è¿™', 'å°†', 'å¯ä»¥', 'èƒ½å¤Ÿ'}
        words = [w for w in words if len(w) >= 2 and w not in stop_words]
        
        # ç»Ÿè®¡è¯é¢‘
        word_freq = Counter(words)
        
        # è¿”å›top k
        keywords = []
        for word, freq in word_freq.most_common(top_k):
            keywords.append({
                "keyword": word,
                "frequency": freq,
                "weight": freq / len(words) if words else 0
            })
        
        return keywords
    
    def batch_classify(self, texts: List[str]) -> Dict:
        """
        æ‰¹é‡åˆ†ç±»
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            æ‰¹é‡åˆ†ç±»ç»“æœ
        """
        results = []
        for text in texts:
            result = self.classify(text)
            results.append(result)
        
        # ç»Ÿè®¡ä¸»é¢˜åˆ†å¸ƒ
        topic_distribution = Counter()
        for result in results:
            for pred in result.get("predictions", []):
                topic_distribution[pred["topic"]] += 1
        
        return {
            "success": True,
            "total": len(texts),
            "results": results,
            "topic_distribution": dict(topic_distribution)
        }
    
    def get_topic_hierarchy(self) -> Dict:
        """è·å–ä¸»é¢˜å±‚çº§ç»“æ„"""
        return {
            "ç§‘æŠ€": ["AI", "è½¯ä»¶", "ç¡¬ä»¶"],
            "å•†ä¸š": ["ç®¡ç†", "è¥é”€", "è´¢åŠ¡"],
            "ç”Ÿäº§": ["åˆ¶é€ ", "è´¨é‡", "ç‰©æµ"],
            "å…¶ä»–": ["æ³•å¾‹", "åŒ»ç–—", "æ•™è‚²"]
        }


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    classifier = TopicClassifier()
    
    test_text = """
åä¸ºæŠ€æœ¯æœ‰é™å…¬å¸å‘å¸ƒäº†æœ€æ–°çš„AIèŠ¯ç‰‡ï¼Œé‡‡ç”¨å…ˆè¿›çš„æ·±åº¦å­¦ä¹ ç®—æ³•ã€‚
è¯¥äº§å“åœ¨æœºå™¨å­¦ä¹ ä»»åŠ¡ä¸Šæ€§èƒ½æå‡300%ï¼Œé¢„è®¡å°†æ¨åŠ¨äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨ä¼ä¸šä¸­çš„åº”ç”¨ã€‚
å…¬å¸è®¡åˆ’æŠ•èµ„50äº¿å…ƒç”¨äºæŠ€æœ¯ç ”å‘ã€‚
    """
    
    print("âœ… ä¸»é¢˜åˆ†ç±»å™¨å·²åŠ è½½\n")
    
    # åˆ†ç±»
    result = classifier.classify(test_text, top_k=3)
    
    print(f"ğŸ“Š åˆ†ç±»ç»“æœ:")
    for pred in result["predictions"]:
        print(f"  {pred['topic']}: {pred['confidence']:.2f}")
    
    # å…³é”®è¯æå–
    keywords = classifier.extract_keywords(test_text, top_k=5)
    print(f"\nğŸ”‘ å…³é”®è¯:")
    for kw in keywords:
        print(f"  {kw['keyword']} (é¢‘ç‡: {kw['frequency']})")
    
    print("\nğŸ’¡ å®é™…éƒ¨ç½²å»ºè®®:")
    print("  â€¢ ä½¿ç”¨transformersåŠ è½½åˆ†ç±»æ¨¡å‹ï¼ˆå¦‚BERT-classifierï¼‰")
    print("  â€¢ æˆ–ä½¿ç”¨ç™¾åº¦ã€è®¯é£ç­‰åˆ†ç±»API")
    print("  â€¢ æˆ–è®­ç»ƒè‡ªå®šä¹‰åˆ†ç±»æ¨¡å‹")


