"""
æ™ºèƒ½æ‘˜è¦å™¨
æ”¯æŒæŠ½å–å¼æ‘˜è¦ã€ç”Ÿæˆå¼æ‘˜è¦ã€å¤šæ–‡æ¡£æ‘˜è¦ç­‰åŠŸèƒ½
"""
from typing import List, Dict, Optional
import re
from collections import Counter


class IntelligentSummarizer:
    """æ™ºèƒ½æ‘˜è¦ç”Ÿæˆå™¨"""
    
    def __init__(self, language: str = "zh"):
        """
        åˆå§‹åŒ–æ‘˜è¦å™¨
        
        Args:
            language: è¯­è¨€ï¼ˆzh, enï¼‰
        """
        self.language = language
        
        # ä¸­æ–‡åœç”¨è¯
        self.stop_words_zh = {
            'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'æœ‰', 'ä¸', 'ç­‰', 'ä¸º', 'è¿™', 'å°†', 'å¯ä»¥',
            'èƒ½å¤Ÿ', 'è¿›è¡Œ', 'é€šè¿‡', 'ä½¿ç”¨', 'æˆ‘ä»¬', 'ä»–ä»¬', 'å…¶ä¸­', 'å› æ­¤', 'å¦‚æœ',
            'ä½†æ˜¯', 'æ‰€ä»¥', 'ç„¶è€Œ', 'å¹¶ä¸”', 'æˆ–è€…', 'è™½ç„¶', 'ä¸è¿‡', 'è€Œä¸”'
        }
    
    def summarize(
        self,
        text: str,
        method: str = "extractive",
        max_length: int = 200,
        num_sentences: int = 3
    ) -> Dict:
        """
        ç”Ÿæˆæ‘˜è¦
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            method: æ‘˜è¦æ–¹æ³•ï¼ˆextractive, abstractive, hybridï¼‰
            max_length: æœ€å¤§é•¿åº¦
            num_sentences: æå–çš„å¥å­æ•°ï¼ˆæŠ½å–å¼ï¼‰
            
        Returns:
            æ‘˜è¦ç»“æœ
        """
        if method == "extractive":
            summary = self._extractive_summary(text, num_sentences)
        elif method == "abstractive":
            summary = self._abstractive_summary(text, max_length)
        elif method == "hybrid":
            # æ··åˆï¼šå…ˆæŠ½å–å†ç”Ÿæˆ
            extracted = self._extractive_summary(text, num_sentences)
            summary = self._abstractive_summary(extracted, max_length)
        else:
            summary = text[:max_length]
        
        return {
            "success": True,
            "original_length": len(text),
            "summary": summary,
            "summary_length": len(summary),
            "compression_ratio": f"{(1 - len(summary)/len(text))*100:.1f}%",
            "method": method
        }
    
    def _extractive_summary(self, text: str, num_sentences: int) -> str:
        """
        æŠ½å–å¼æ‘˜è¦
        
        ä»åŸæ–‡ä¸­æŠ½å–æœ€é‡è¦çš„å¥å­
        
        ä½¿ç”¨TextRankç®—æ³•æˆ–åŸºäºTF-IDF
        """
        # åˆ†å¥
        sentences = self._split_sentences(text)
        
        if len(sentences) <= num_sentences:
            return text
        
        # è®¡ç®—å¥å­é‡è¦æ€§å¾—åˆ†
        sentence_scores = self._score_sentences(sentences, text)
        
        # æ’åºå¹¶é€‰æ‹©top kå¥å­
        sorted_sentences = sorted(
            enumerate(sentences),
            key=lambda x: sentence_scores[x[0]],
            reverse=True
        )
        
        # é€‰æ‹©top kï¼Œä½†æŒ‰åŸæ–‡é¡ºåºæ’åˆ—
        selected_indices = sorted([idx for idx, _ in sorted_sentences[:num_sentences]])
        selected_sentences = [sentences[i] for i in selected_indices]
        
        return ''.join(selected_sentences)
    
    def _split_sentences(self, text: str) -> List[str]:
        """åˆ†å‰²å¥å­"""
        # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿ.!?]+)', text)
        
        # é‡æ–°ç»„åˆï¼ˆä¿ç•™æ ‡ç‚¹ï¼‰
        result = []
        for i in range(0, len(sentences)-1, 2):
            if i+1 < len(sentences):
                sent = sentences[i] + sentences[i+1]
                if sent.strip():
                    result.append(sent)
        
        return result
    
    def _score_sentences(self, sentences: List[str], full_text: str) -> List[float]:
        """
        è®¡ç®—å¥å­é‡è¦æ€§å¾—åˆ†
        
        åŸºäºï¼š
        - å…³é”®è¯é¢‘ç‡
        - å¥å­ä½ç½®
        - å¥å­é•¿åº¦
        """
        scores = []
        
        # æå–å…³é”®è¯
        keywords = self._extract_keywords(full_text, top_k=20)
        keyword_set = set(kw["word"] for kw in keywords)
        
        for i, sent in enumerate(sentences):
            score = 0.0
            
            # 1. å…³é”®è¯å¾—åˆ†
            words = re.findall(r'[\u4e00-\u9fa5]+', sent)
            keyword_count = sum(1 for w in words if w in keyword_set)
            score += keyword_count * 2
            
            # 2. ä½ç½®å¾—åˆ†ï¼ˆé¦–å°¾å¥å­æ›´é‡è¦ï¼‰
            position_score = 0
            if i < 2:  # å¼€å¤´
                position_score = 2
            elif i >= len(sentences) - 2:  # ç»“å°¾
                position_score = 1.5
            score += position_score
            
            # 3. é•¿åº¦å¾—åˆ†ï¼ˆé¿å…å¤ªçŸ­çš„å¥å­ï¼‰
            if len(sent) > 20:
                score += 1
            
            scores.append(score)
        
        return scores
    
    def _abstractive_summary(self, text: str, max_length: int) -> str:
        """
        ç”Ÿæˆå¼æ‘˜è¦
        
        ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆæ–°çš„æ‘˜è¦æ–‡æœ¬
        
        å®é™…å®ç°éœ€è¦ä½¿ç”¨ï¼š
        - GPT-3/GPT-4
        - BART
        - T5
        - æˆ–ä¸­æ–‡æ¨¡å‹ï¼ˆå¦‚CPMã€ChatGLMï¼‰
        """
        # æ¨¡æ‹Ÿç”Ÿæˆå¼æ‘˜è¦
        # å®é™…åº”è°ƒç”¨LLM API
        
        if len(text) <= max_length:
            return text
        
        # ç®€åŒ–ç‰ˆï¼šæå–å…³é”®ä¿¡æ¯
        summary = f"æœ¬æ–‡ä¸»è¦è®¨è®ºäº†...ï¼ˆå®é™…ä½¿ç”¨ä¸­ä¼šè°ƒç”¨GPT-4æˆ–å…¶ä»–LLMç”Ÿæˆæµç•…çš„æ‘˜è¦ï¼‰"
        
        return summary[:max_length]
    
    def _extract_keywords(self, text: str, top_k: int = 10) -> List[Dict]:
        """æå–å…³é”®è¯ï¼ˆç”¨äºé‡è¦æ€§è¯„åˆ†ï¼‰"""
        words = re.findall(r'[\u4e00-\u9fa5]+', text)
        words = [w for w in words if len(w) >= 2 and w not in self.stop_words_zh]
        
        word_freq = Counter(words)
        
        keywords = []
        for word, freq in word_freq.most_common(top_k):
            keywords.append({
                "word": word,
                "frequency": freq,
                "score": freq / len(words) if words else 0
            })
        
        return keywords
    
    def multi_document_summary(
        self,
        documents: List[str],
        max_length: int = 500
    ) -> Dict:
        """
        å¤šæ–‡æ¡£æ‘˜è¦
        
        å¯¹å¤šä¸ªæ–‡æ¡£ç”Ÿæˆç»Ÿä¸€çš„æ‘˜è¦
        
        Args:
            documents: æ–‡æ¡£åˆ—è¡¨
            max_length: æœ€å¤§é•¿åº¦
            
        Returns:
            å¤šæ–‡æ¡£æ‘˜è¦
        """
        # åˆå¹¶æ–‡æ¡£
        combined_text = "\n\n".join(documents)
        
        # ç”Ÿæˆæ‘˜è¦
        summary_result = self.summarize(combined_text, method="extractive", max_length=max_length)
        
        return {
            "success": True,
            "document_count": len(documents),
            "total_length": len(combined_text),
            "summary": summary_result["summary"],
            "compression_ratio": summary_result["compression_ratio"]
        }
    
    def query_focused_summary(
        self,
        text: str,
        query: str,
        max_length: int = 200
    ) -> Dict:
        """
        é—®é¢˜å¯¼å‘æ‘˜è¦
        
        ç”Ÿæˆé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„æ‘˜è¦
        
        Args:
            text: æ–‡æœ¬
            query: é—®é¢˜/æŸ¥è¯¢
            max_length: æœ€å¤§é•¿åº¦
            
        Returns:
            é’ˆå¯¹é—®é¢˜çš„æ‘˜è¦
        """
        # æå–æŸ¥è¯¢å…³é”®è¯
        query_keywords = set(re.findall(r'[\u4e00-\u9fa5]+', query))
        query_keywords = {w for w in query_keywords if len(w) >= 2}
        
        # æ‰¾åˆ°ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„å¥å­
        sentences = self._split_sentences(text)
        
        # è®¡ç®—ç›¸å…³æ€§å¾—åˆ†
        relevant_sentences = []
        for sent in sentences:
            sent_words = set(re.findall(r'[\u4e00-\u9fa5]+', sent))
            overlap = query_keywords & sent_words
            if overlap:
                relevant_sentences.append((sent, len(overlap)))
        
        # æ’åºå¹¶é€‰æ‹©
        relevant_sentences.sort(key=lambda x: x[1], reverse=True)
        
        summary = ''.join(s[0] for s in relevant_sentences[:3])
        
        if len(summary) > max_length:
            summary = summary[:max_length] + "..."
        
        return {
            "success": True,
            "query": query,
            "summary": summary,
            "relevance_score": len(relevant_sentences)
        }
    
    def bullet_point_summary(self, text: str, num_points: int = 5) -> List[str]:
        """
        è¦ç‚¹å¼æ‘˜è¦
        
        ç”Ÿæˆbullet pointæ ¼å¼çš„æ‘˜è¦
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            num_points: è¦ç‚¹æ•°é‡
            
        Returns:
            è¦ç‚¹åˆ—è¡¨
        """
        sentences = self._split_sentences(text)
        scores = self._score_sentences(sentences, text)
        
        # é€‰æ‹©é‡è¦å¥å­
        sorted_sentences = sorted(
            zip(sentences, scores),
            key=lambda x: x[1],
            reverse=True
        )
        
        # æå–è¦ç‚¹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        bullet_points = []
        for sent, score in sorted_sentences[:num_points]:
            # ç®€åŒ–å¥å­ï¼Œç§»é™¤ä»å¥
            point = sent.strip()
            if len(point) > 50:
                point = point[:50] + "..."
            bullet_points.append(point)
        
        return bullet_points


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    summarizer = IntelligentSummarizer()
    
    test_text = """
äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è¿‡å»åå¹´å–å¾—äº†å·¨å¤§è¿›å±•ã€‚æ·±åº¦å­¦ä¹ çš„çªç ´ä½¿å¾—è®¡ç®—æœºåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ç­‰ä»»åŠ¡ä¸Šè¾¾åˆ°ç”šè‡³è¶…è¿‡äººç±»æ°´å¹³ã€‚
å¤§è¯­è¨€æ¨¡å‹çš„å‡ºç°æ›´æ˜¯å¼€å¯äº†AIçš„æ–°æ—¶ä»£ã€‚GPTã€BERTç­‰æ¨¡å‹å±•ç¤ºäº†å¼ºå¤§çš„è¯­è¨€ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚
åœ¨ä¼ä¸šåº”ç”¨æ–¹é¢ï¼ŒAIå·²ç»æ·±å…¥åˆ°å®¢æˆ·æœåŠ¡ã€æ•°æ®åˆ†æã€æµç¨‹ä¼˜åŒ–ç­‰å¤šä¸ªé¢†åŸŸã€‚è®¸å¤šä¼ä¸šé€šè¿‡éƒ¨ç½²AIç³»ç»Ÿï¼Œå®ç°äº†æ•ˆç‡æå‡å’Œæˆæœ¬é™ä½ã€‚
æœªæ¥ï¼ŒAIå°†ç»§ç»­å¿«é€Ÿå‘å±•ï¼Œä¸æ›´å¤šä¼ ç»Ÿè¡Œä¸šæ·±åº¦èåˆï¼Œä¸ºç¤¾ä¼šå¸¦æ¥æ·±åˆ»å˜é©ã€‚
    """
    
    print("âœ… æ™ºèƒ½æ‘˜è¦å™¨å·²åŠ è½½\n")
    
    # æŠ½å–å¼æ‘˜è¦
    result1 = summarizer.summarize(test_text, method="extractive", num_sentences=2)
    print(f"ğŸ“Š æŠ½å–å¼æ‘˜è¦ ({result1['compression_ratio']}å‹ç¼©):")
    print(f"  {result1['summary']}\n")
    
    # è¦ç‚¹å¼æ‘˜è¦
    bullets = summarizer.bullet_point_summary(test_text, num_points=3)
    print(f"ğŸ“‹ è¦ç‚¹å¼æ‘˜è¦:")
    for i, point in enumerate(bullets, 1):
        print(f"  {i}. {point}")
    
    print("\nğŸ’¡ å®é™…éƒ¨ç½²å»ºè®®:")
    print("  â€¢ ä½¿ç”¨transformersåŠ è½½BARTæˆ–T5æ¨¡å‹")
    print("  â€¢ æˆ–è°ƒç”¨GPT-4 APIç”Ÿæˆé«˜è´¨é‡æ‘˜è¦")
    print("  â€¢ æˆ–ä½¿ç”¨ä¸­æ–‡æ¨¡å‹ï¼ˆå¦‚ChatGLMï¼‰")


