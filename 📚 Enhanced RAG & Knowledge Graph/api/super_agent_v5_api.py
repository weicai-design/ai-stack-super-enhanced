"""
AI-STACK V5.0 è¶…çº§Agent API
åŠŸèƒ½ï¼š8å¤§æ–°åŠŸèƒ½ + AIå·¥ä½œæµæ ¸å¿ƒ + 2ç§’å“åº”ä¿è¯
ä½œè€…ï¼šAI-STACK Team
æ—¥æœŸï¼š2025-11-09
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
from datetime import datetime
import asyncio
import time
import json
import os

router = APIRouter(prefix="/api/v5/agent", tags=["SuperAgent-V5"])

# ==================== æ•°æ®æ¨¡å‹ ====================

class ChatMessage(BaseModel):
    """èŠå¤©æ¶ˆæ¯æ¨¡å‹"""
    role: str = Field(..., description="è§’è‰²: user/agent")
    content: str = Field(..., description="æ¶ˆæ¯å†…å®¹")
    timestamp: datetime = Field(default_factory=datetime.now)
    metadata: Optional[Dict[str, Any]] = None


class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯")
    session_id: Optional[str] = Field(default="default", description="ä¼šè¯ID")
    context_length: int = Field(default=10, description="ä¸Šä¸‹æ–‡é•¿åº¦")
    enable_voice: bool = Field(default=False, description="æ˜¯å¦å¯ç”¨è¯­éŸ³è¾“å‡º")
    enable_learning: bool = Field(default=True, description="æ˜¯å¦å¯ç”¨è‡ªæˆ‘å­¦ä¹ ")
    provider: Optional[str] = Field(default="ollama", description="æ¨¡å‹æä¾›å•†: ollama/openai/claude")
    model: Optional[str] = Field(default="qwen2.5:7b", description="å…·ä½“æ¨¡å‹åç§°")


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”æ¨¡å‹"""
    response: str
    session_id: str
    processing_time: float
    workflow_steps: List[Dict[str, Any]]
    suggestions: Optional[List[str]] = None
    generated_files: Optional[List[Dict[str, str]]] = None


class MemoItem(BaseModel):
    """å¤‡å¿˜å½•é¡¹ç›®æ¨¡å‹"""
    id: str
    content: str
    created_at: datetime
    importance: int = Field(default=1, ge=1, le=5)
    source: str = Field(default="user")  # user/agent/system


class TaskItem(BaseModel):
    """ä»»åŠ¡é¡¹ç›®æ¨¡å‹"""
    id: str
    title: str
    description: str
    status: str = Field(default="pending")  # pending/confirmed/executing/completed/rejected
    source: str  # agent_identified/user_defined
    created_at: datetime
    estimated_duration: Optional[int] = None
    required_modules: List[str] = []


class ResourceStatus(BaseModel):
    """ç³»ç»Ÿèµ„æºçŠ¶æ€"""
    cpu_usage: float
    memory_usage: float
    disk_usage: float
    network_speed: float
    external_disks: List[Dict[str, Any]]
    timestamp: datetime = Field(default_factory=datetime.now)


class LearningStatus(BaseModel):
    """è‡ªæˆ‘å­¦ä¹ çŠ¶æ€"""
    is_active: bool
    monitored_workflows: int
    identified_issues: int
    optimizations_applied: int
    last_optimization: Optional[datetime] = None


# ==================== å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰ ====================

# ä¼šè¯å­˜å‚¨
sessions = {}

# å¤‡å¿˜å½•å­˜å‚¨
memos: List[MemoItem] = []

# ä»»åŠ¡å­˜å‚¨
tasks: List[TaskItem] = []

# å­¦ä¹ è®°å½•å­˜å‚¨
learning_records = []

# ==================== æ ¸å¿ƒåŠŸèƒ½1: æ™ºèƒ½èŠå¤©ï¼ˆAIå·¥ä½œæµï¼‰ ====================

@router.post("/chat", response_model=ChatResponse)
async def chat_with_agent(request: ChatRequest):
    """
    æ™ºèƒ½èŠå¤© - æ ¸å¿ƒAIå·¥ä½œæµ
    
    å·¥ä½œæµç¨‹ï¼ˆ9æ­¥éª¤ï¼‰:
    1. ç”¨æˆ·è¾“å…¥
    2. ç¬¬1æ¬¡RAGæ£€ç´¢ï¼ˆç†è§£éœ€æ±‚ï¼‰
    3. ä¸“å®¶è·¯ç”±å’Œåˆ†æ
    4. è°ƒç”¨æ¨¡å—æ‰§è¡Œ
    5. ç¬¬2æ¬¡RAGæ£€ç´¢ï¼ˆæ•´åˆçŸ¥è¯†ï¼‰â­å…³é”®
    6. ç”Ÿæˆå›å¤
    7-9. è¶…çº§Agentç›‘æ§å­¦ä¹ 
    
    ç›®æ ‡: 2ç§’å†…å“åº”
    """
    start_time = time.time()
    workflow_steps = []
    
    try:
        # æ­¥éª¤1: æ¥æ”¶ç”¨æˆ·è¾“å…¥
        workflow_steps.append({
            "step": 1,
            "name": "æ¥æ”¶ç”¨æˆ·è¾“å…¥",
            "status": "completed",
            "duration": 0.001
        })
        
        # æ­¥éª¤2: ç¬¬1æ¬¡RAGæ£€ç´¢
        step_start = time.time()
        rag_context_1 = await retrieve_from_rag(request.message, request.session_id)
        workflow_steps.append({
            "step": 2,
            "name": "ç¬¬1æ¬¡RAGæ£€ç´¢",
            "status": "completed",
            "duration": round(time.time() - step_start, 3),
            "results": f"æ£€ç´¢åˆ°{len(rag_context_1.get('results', []))}ä¸ªç›¸å…³çŸ¥è¯†"
        })
        
        # æ­¥éª¤3: ä¸“å®¶è·¯ç”±
        step_start = time.time()
        expert_result = await route_to_expert(request.message, rag_context_1)
        workflow_steps.append({
            "step": 3,
            "name": "ä¸“å®¶è·¯ç”±å’Œåˆ†æ",
            "status": "completed",
            "duration": round(time.time() - step_start, 3),
            "expert": expert_result.get("expert_name")
        })
        
        # æ­¥éª¤4: è°ƒç”¨æ¨¡å—æ‰§è¡Œ
        step_start = time.time()
        module_result = await execute_module(expert_result, request.message)
        workflow_steps.append({
            "step": 4,
            "name": "æ¨¡å—æ‰§è¡Œ",
            "status": "completed",
            "duration": round(time.time() - step_start, 3),
            "module": module_result.get("module_name")
        })
        
        # æ­¥éª¤5: ç¬¬2æ¬¡RAGæ£€ç´¢â­å…³é”®
        step_start = time.time()
        rag_context_2 = await retrieve_from_rag_enhanced(
            request.message,
            expert_result,
            module_result
        )
        workflow_steps.append({
            "step": 5,
            "name": "ç¬¬2æ¬¡RAGæ£€ç´¢ï¼ˆæ•´åˆçŸ¥è¯†ï¼‰",
            "status": "completed",
            "duration": round(time.time() - step_start, 3),
            "results": f"æ•´åˆäº†{len(rag_context_2.get('results', []))}æ¡ç»éªŒçŸ¥è¯†"
        })
        
        # æ­¥éª¤6: ç”Ÿæˆå›å¤
        step_start = time.time()
        response_text = await generate_response(
            request.message,
            rag_context_1,
            rag_context_2,
            expert_result,
            module_result,
            provider=request.provider,  # ä¼ é€’ç”¨æˆ·é€‰æ‹©çš„æä¾›å•†
            model=request.model         # ä¼ é€’ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
        )
        workflow_steps.append({
            "step": 6,
            "name": "ç”Ÿæˆå›å¤",
            "status": "completed",
            "duration": round(time.time() - step_start, 3)
        })
        
        # æ­¥éª¤7-9: è¶…çº§Agentç›‘æ§å­¦ä¹ ï¼ˆå¼‚æ­¥ï¼‰
        if request.enable_learning:
            asyncio.create_task(
                monitor_and_learn(request.message, workflow_steps, response_text)
            )
        
        # è‡ªåŠ¨è¯†åˆ«é‡è¦ä¿¡æ¯åˆ°å¤‡å¿˜å½•
        await auto_add_to_memo(request.message, response_text)
        
        # ä»å¤‡å¿˜å½•æç‚¼ä»»åŠ¡
        await extract_tasks_from_memos()
        
        processing_time = time.time() - start_time
        
        return ChatResponse(
            response=response_text,
            session_id=request.session_id,
            processing_time=round(processing_time, 3),
            workflow_steps=workflow_steps,
            suggestions=generate_suggestions(response_text)
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"èŠå¤©å¤„ç†å¤±è´¥: {str(e)}")


async def retrieve_from_rag(message: str, session_id: str) -> Dict[str, Any]:
    """ç¬¬1æ¬¡RAGæ£€ç´¢ - ç†è§£éœ€æ±‚ï¼ˆçœŸå®å®ç°ï¼‰"""
    try:
        # ä½¿ç”¨çœŸå®çš„RAGæœåŠ¡
        from core.real_rag_service import get_rag_service
        rag = get_rag_service()
        
        # çœŸå®æ£€ç´¢
        result = await rag.search(query=message, top_k=5, use_reranking=True)
        
        return {
            "query": message,
            "results": result.get("results", []),
            "method": result.get("retrieval_method", "unknown"),
            "source": "real_rag"
        }
    except Exception as e:
        # é™çº§åˆ°åŸºç¡€æ£€ç´¢
        return {
            "query": message,
            "results": [],
            "error": str(e),
            "source": "fallback"
        }


async def route_to_expert(message: str, rag_context: Dict[str, Any]) -> Dict[str, Any]:
    """ä¸“å®¶è·¯ç”± - åˆ†æå¹¶è·¯ç”±åˆ°å¯¹åº”ä¸“å®¶"""
    # ç®€å•çš„å…³é”®è¯è·¯ç”±ï¼ˆå®é™…åº”ä½¿ç”¨AIåˆ†ç±»ï¼‰
    message_lower = message.lower()
    
    if any(word in message_lower for word in ['rag', 'çŸ¥è¯†', 'æ–‡æ¡£', 'æœç´¢']):
        expert_name = "RAGçŸ¥è¯†ç®¡ç†ä¸“å®¶"
        module = "rag"
    elif any(word in message_lower for word in ['erp', 'è®¢å•', 'ç”Ÿäº§', 'é‡‡è´­']):
        expert_name = "ERPç®¡ç†ä¸“å®¶"
        module = "erp"
    elif any(word in message_lower for word in ['å†…å®¹', 'åˆ›ä½œ', 'å†™ä½œ', 'å‘å¸ƒ']):
        expert_name = "å†…å®¹åˆ›ä½œä¸“å®¶"
        module = "content"
    elif any(word in message_lower for word in ['è¶‹åŠ¿', 'åˆ†æ', 'é¢„æµ‹']):
        expert_name = "è¶‹åŠ¿åˆ†æä¸“å®¶"
        module = "trend"
    elif any(word in message_lower for word in ['è‚¡ç¥¨', 'äº¤æ˜“', 'é‡åŒ–']):
        expert_name = "é‡åŒ–äº¤æ˜“ä¸“å®¶"
        module = "stock"
    elif any(word in message_lower for word in ['ä»£ç ', 'ç¼–ç¨‹', 'å¼€å‘']):
        expert_name = "ç¼–ç¨‹ä¸“å®¶"
        module = "coding"
    elif any(word in message_lower for word in ['ä»»åŠ¡', 'è®¡åˆ’', 'å·¥ä½œ']):
        expert_name = "ä»»åŠ¡ç®¡ç†ä¸“å®¶"
        module = "task"
    else:
        expert_name = "é€šç”¨åŠ©æ‰‹ä¸“å®¶"
        module = "general"
    
    return {
        "expert_name": expert_name,
        "module": module,
        "confidence": 0.92,
        "analysis": f"{expert_name}å¯ä»¥å¤„ç†è¿™ä¸ªè¯·æ±‚"
    }


async def execute_module(expert_result: Dict[str, Any], message: str) -> Dict[str, Any]:
    """æ‰§è¡Œæ¨¡å—åŠŸèƒ½"""
    module = expert_result.get("module")
    
    # æ¨¡æ‹Ÿæ¨¡å—æ‰§è¡Œ
    await asyncio.sleep(0.15)
    
    return {
        "module_name": module,
        "status": "success",
        "result": f"{module}æ¨¡å—å·²å¤„ç†è¯·æ±‚"
    }


async def retrieve_from_rag_enhanced(
    message: str,
    expert_result: Dict[str, Any],
    module_result: Dict[str, Any]
) -> Dict[str, Any]:
    """ç¬¬2æ¬¡RAGæ£€ç´¢ - æ•´åˆç»éªŒçŸ¥è¯†â­å…³é”®ï¼ˆçœŸå®å®ç°ï¼‰"""
    try:
        # ä½¿ç”¨çœŸå®çš„RAGæœåŠ¡
        from core.real_rag_service import get_rag_service
        rag = get_rag_service()
        
        # æ„å»ºå¢å¼ºæŸ¥è¯¢ï¼ˆç»“åˆä¸“å®¶å’Œæ¨¡å—ä¿¡æ¯ï¼‰
        expert_name = expert_result.get("expert_name", "")
        module_name = module_result.get("module", "")
        
        enhanced_query = f"{message} {expert_name} {module_name} ç»éªŒ ä¼˜åŒ–"
        
        # ç¬¬2æ¬¡RAGæ£€ç´¢ï¼ˆæŸ¥æ‰¾ç»éªŒå’Œä¼˜åŒ–å»ºè®®ï¼‰
        result = await rag.search(
            query=enhanced_query,
            top_k=3,
            filters={"type": "experience"},  # ä¼˜å…ˆæ£€ç´¢ç»éªŒç±»çŸ¥è¯†
            use_reranking=True
        )
        
        # æå–å­¦ä¹ æ´å¯Ÿ
        learning_insights = "åŸºäºå†å²ç»éªŒï¼Œ"
        if result.get("results"):
            learning_insights += "å»ºè®®å‚è€ƒä»¥å¾€çš„æˆåŠŸæ¡ˆä¾‹å’Œä¼˜åŒ–æ–¹æ¡ˆã€‚"
        else:
            learning_insights += "è¿™æ˜¯æ–°çš„åœºæ™¯ï¼Œç³»ç»Ÿå°†å­¦ä¹ å¹¶è®°å½•ã€‚"
        
        return {
            "enhanced_results": result.get("results", []),
            "learning_insights": learning_insights,
            "method": result.get("retrieval_method", "unknown"),
            "source": "real_rag_enhanced"
        }
    
    except Exception as e:
        return {
            "enhanced_results": [],
            "learning_insights": f"ç¬¬2æ¬¡RAGæ£€ç´¢é‡åˆ°é—®é¢˜: {str(e)}",
            "source": "fallback"
        }


async def generate_response(
    message: str,
    rag_context_1: Dict[str, Any],
    rag_context_2: Dict[str, Any],
    expert_result: Dict[str, Any],
    module_result: Dict[str, Any],
    provider: str = "ollama",
    model: str = "qwen2.5:7b"
) -> str:
    """ç”Ÿæˆæœ€ç»ˆå›å¤ - ç»¼åˆæ‰€æœ‰ä¿¡æ¯ï¼ˆçœŸå®å®ç°ï¼‰"""
    try:
        # ä½¿ç”¨çœŸå®çš„LLMæœåŠ¡
        from core.real_llm_service import get_llm_service
        llm = get_llm_service()
        
        # æ ¹æ®ç”¨æˆ·é€‰æ‹©é…ç½®LLM
        llm.provider = provider
        llm.ollama_model = model if provider == "ollama" else llm.ollama_model
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {provider} - {model}")
        
        # æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡
        expert_name = expert_result.get("expert_name")
        module_name = module_result.get("module_name")
        
        # æå–RAGæ£€ç´¢åˆ°çš„çŸ¥è¯†
        knowledge_context = ""
        for result in rag_context_1.get("results", [])[:3]:
            knowledge_context += f"\n- {result.get('content', '')[:200]}"
        
        for result in rag_context_2.get("results", [])[:2]:
            knowledge_context += f"\n- {result.get('content', '')[:200]}"
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = f"""ä½ æ˜¯AI-STACKçš„{expert_name}ã€‚

å‚è€ƒçŸ¥è¯†:
{knowledge_context}

è¯·åŸºäºç”¨æˆ·é—®é¢˜å’Œå‚è€ƒçŸ¥è¯†ï¼Œç»™å‡ºä¸“ä¸šã€è¯¦ç»†çš„å›å¤ã€‚
"""
        
        # è°ƒç”¨LLMç”Ÿæˆå›å¤
        print(f"ğŸ” è°ƒç”¨LLM: provider={llm.provider}, model={llm.ollama_model}")
        llm_result = await llm.generate(
            prompt=message,
            system_prompt=system_prompt,
            temperature=0.7,
            max_tokens=1500
        )
        
        print(f"ğŸ“Š LLMç»“æœ: success={llm_result.get('success')}, error={llm_result.get('error', 'None')}")
        
        if llm_result.get("success"):
            # æ·»åŠ å·¥ä½œæµä¿¡æ¯
            workflow_info = f"""\n\n---
âœ… AIå·¥ä½œæµå®Œæˆ
â€¢ ä¸“å®¶: {expert_name}
â€¢ æ¨¡å—: {module_name}
â€¢ ç¬¬1æ¬¡RAG: {len(rag_context_1.get('results', []))}æ¡çŸ¥è¯†
â€¢ ç¬¬2æ¬¡RAG: {len(rag_context_2.get('results', []))}æ¡ç»éªŒ
â€¢ LLM: {llm_result.get('provider')} {llm_result.get('model', '')}
"""
            
            return llm_result["text"] + workflow_info
        else:
            # LLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›åŸºç¡€å›å¤
            return f"""æ”¶åˆ°æ‚¨çš„æ¶ˆæ¯: "{message}"

âœ… AIå·¥ä½œæµå¤„ç†å®Œæˆ

ä¸“å®¶åˆ†æ: {expert_name}
æ¨¡å—æ‰§è¡Œ: {module_name}æ¨¡å—

âš ï¸ LLMæœåŠ¡æš‚ä¸å¯ç”¨: {llm_result.get('error', 'æœªçŸ¥é”™è¯¯')}

å»ºè®®ï¼š
1. å¦‚ä½¿ç”¨OpenAIï¼Œè¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡
2. å¦‚ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œè¯·å¯åŠ¨OllamaæœåŠ¡

åŸºäºRAGæ£€ç´¢åˆ°çš„çŸ¥è¯†ï¼Œæˆ‘å¯ä»¥æä¾›åŸºç¡€çš„å›å¤...
"""
    
    except Exception as e:
        return f"ç”Ÿæˆå›å¤æ—¶å‡ºé”™: {str(e)}"


def generate_suggestions(response: str) -> List[str]:
    """ç”Ÿæˆå»ºè®®é—®é¢˜"""
    return [
        "äº†è§£æ›´å¤šç›¸å…³åŠŸèƒ½",
        "æŸ¥çœ‹ä½¿ç”¨ç¤ºä¾‹",
        "è·å–ä¼˜åŒ–å»ºè®®"
    ]


# ==================== æ ¸å¿ƒåŠŸèƒ½2: å¤‡å¿˜å½•ç³»ç»Ÿ ====================

@router.post("/memo/add")
async def add_memo(content: str, importance: int = 1):
    """æ·»åŠ å¤‡å¿˜å½•"""
    memo = MemoItem(
        id=f"memo-{int(time.time() * 1000)}",
        content=content,
        created_at=datetime.now(),
        importance=importance,
        source="user"
    )
    memos.append(memo)
    return {"success": True, "memo_id": memo.id}


@router.get("/memo/list")
async def list_memos(limit: int = 50):
    """è·å–å¤‡å¿˜å½•åˆ—è¡¨"""
    return {
        "memos": [m.dict() for m in sorted(memos, key=lambda x: x.created_at, reverse=True)[:limit]],
        "total": len(memos)
    }


async def auto_add_to_memo(user_message: str, agent_response: str):
    """è‡ªåŠ¨è¯†åˆ«é‡è¦ä¿¡æ¯åˆ°å¤‡å¿˜å½•"""
    # ç®€å•è§„åˆ™ï¼šåŒ…å«æ—¶é—´ã€æ•°å­—ã€"é‡è¦"ç­‰å…³é”®è¯
    keywords = ['æ˜å¤©', 'ä¸‹å‘¨', 'é‡è¦', 'æé†’', 'è®°å¾—', 'ä¼šè®®', 'æˆªæ­¢']
    
    if any(keyword in user_message for keyword in keywords):
        memo = MemoItem(
            id=f"memo-{int(time.time() * 1000)}",
            content=user_message[:100],
            created_at=datetime.now(),
            importance=3,
            source="agent"
        )
        memos.append(memo)


# ==================== æ ¸å¿ƒåŠŸèƒ½3: æ™ºèƒ½å·¥ä½œè®¡åˆ’ ====================

@router.post("/task/create")
async def create_task(
    title: str,
    description: str,
    source: str = "user_defined"
):
    """åˆ›å»ºä»»åŠ¡"""
    task = TaskItem(
        id=f"task-{int(time.time() * 1000)}",
        title=title,
        description=description,
        status="pending",
        source=source,
        created_at=datetime.now()
    )
    tasks.append(task)
    return {"success": True, "task_id": task.id}


@router.get("/task/list")
async def list_tasks(status: Optional[str] = None):
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    filtered_tasks = tasks
    if status:
        filtered_tasks = [t for t in tasks if t.status == status]
    
    return {
        "tasks": [t.dict() for t in sorted(filtered_tasks, key=lambda x: x.created_at, reverse=True)],
        "total": len(filtered_tasks)
    }


@router.post("/task/{task_id}/confirm")
async def confirm_task(task_id: str):
    """ç”¨æˆ·ç¡®è®¤ä»»åŠ¡â­å…³é”®"""
    task = next((t for t in tasks if t.id == task_id), None)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task.status = "confirmed"
    
    # å¼€å§‹æ‰§è¡Œä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰
    asyncio.create_task(execute_task(task))
    
    return {"success": True, "message": "ä»»åŠ¡å·²ç¡®è®¤ï¼Œå¼€å§‹æ‰§è¡Œ"}


@router.post("/task/{task_id}/reject")
async def reject_task(task_id: str, reason: Optional[str] = None):
    """ç”¨æˆ·æ‹’ç»ä»»åŠ¡"""
    task = next((t for t in tasks if t.id == task_id), None)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    task.status = "rejected"
    
    # è®°å½•æ‹’ç»åŸå› åˆ°å­¦ä¹ ç³»ç»Ÿ
    if reason:
        learning_records.append({
            "type": "task_rejection",
            "task_id": task_id,
            "reason": reason,
            "timestamp": datetime.now()
        })
    
    return {"success": True, "message": "ä»»åŠ¡å·²æ‹’ç»"}


async def extract_tasks_from_memos():
    """ä»å¤‡å¿˜å½•æç‚¼ä»»åŠ¡"""
    # æ£€æŸ¥æœ€è¿‘çš„å¤‡å¿˜å½•
    recent_memos = sorted(memos, key=lambda x: x.created_at, reverse=True)[:10]
    
    for memo in recent_memos:
        # ç®€å•è§„åˆ™ï¼šåŒ…å«åŠ¨è¯çš„å¤‡å¿˜å½•å¯èƒ½æ˜¯ä»»åŠ¡
        action_words = ['ç”Ÿæˆ', 'åˆ›å»º', 'ä¼˜åŒ–', 'åˆ†æ', 'æ£€æŸ¥', 'æ›´æ–°', 'ä¿®æ”¹']
        if any(word in memo.content for word in action_words):
            # æ£€æŸ¥æ˜¯å¦å·²ç»åˆ›å»ºè¿‡ä»»åŠ¡
            existing = any(t.description == memo.content for t in tasks)
            if not existing:
                task = TaskItem(
                    id=f"task-{int(time.time() * 1000)}",
                    title=f"ä»å¤‡å¿˜å½•æç‚¼: {memo.content[:20]}",
                    description=memo.content,
                    status="pending",
                    source="agent_identified",
                    created_at=datetime.now()
                )
                tasks.append(task)


async def execute_task(task: TaskItem):
    """æ‰§è¡Œä»»åŠ¡"""
    task.status = "executing"
    
    # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
    await asyncio.sleep(2)
    
    # è°ƒç”¨ç›¸å…³æ¨¡å—
    # await call_module_for_task(task)
    
    task.status = "completed"


# ==================== æ ¸å¿ƒåŠŸèƒ½4: è‡ªæˆ‘å­¦ä¹ ç›‘æ§ ====================

@router.get("/learning/status", response_model=LearningStatus)
async def get_learning_status():
    """è·å–è‡ªæˆ‘å­¦ä¹ çŠ¶æ€"""
    return LearningStatus(
        is_active=True,
        monitored_workflows=len(learning_records),
        identified_issues=sum(1 for r in learning_records if r.get("type") == "issue"),
        optimizations_applied=sum(1 for r in learning_records if r.get("type") == "optimization"),
        last_optimization=datetime.now() if learning_records else None
    )


async def monitor_and_learn(message: str, workflow_steps: List[Dict], response: str):
    """ç›‘æ§AIå·¥ä½œæµå¹¶å­¦ä¹ â­æ ¸å¿ƒ"""
    # æ­¥éª¤7: ç›‘æ§å·¥ä½œæµ
    learning_record = {
        "type": "workflow_monitoring",
        "message": message,
        "steps": workflow_steps,
        "response": response,
        "timestamp": datetime.now()
    }
    
    # æ­¥éª¤8: è¯†åˆ«é—®é¢˜
    issues = identify_issues(workflow_steps)
    if issues:
        learning_record["issues"] = issues
        learning_record["type"] = "issue"
        
        # æ­¥éª¤9: è°ƒç”¨ç¼–ç¨‹åŠ©æ‰‹ä¼˜åŒ–ä»£ç 
        asyncio.create_task(optimize_code_with_assistant(issues))
    
    # å­˜å…¥RAG
    await store_to_rag(learning_record)
    
    learning_records.append(learning_record)


def identify_issues(workflow_steps: List[Dict]) -> List[Dict]:
    """è¯†åˆ«é—®é¢˜"""
    issues = []
    
    # æ£€æŸ¥å“åº”æ—¶é—´
    for step in workflow_steps:
        if step.get("duration", 0) > 0.5:  # è¶…è¿‡0.5ç§’
            issues.append({
                "type": "performance",
                "step": step.get("name"),
                "duration": step.get("duration"),
                "suggestion": "ä¼˜åŒ–æ­¤æ­¥éª¤æ€§èƒ½"
            })
    
    return issues


async def optimize_code_with_assistant(issues: List[Dict]):
    """è°ƒç”¨ç¼–ç¨‹åŠ©æ‰‹ä¼˜åŒ–ä»£ç """
    # å®é™…åº”è°ƒç”¨ç¼–ç¨‹åŠ©æ‰‹API
    for issue in issues:
        print(f"ğŸ”§ ç¼–ç¨‹åŠ©æ‰‹å¼€å§‹ä¼˜åŒ–: {issue}")


async def store_to_rag(record: Dict):
    """å­˜å…¥RAGçŸ¥è¯†åº“"""
    # å®é™…åº”è°ƒç”¨RAG API
    pass


# ==================== æ ¸å¿ƒåŠŸèƒ½5: èµ„æºç›‘æ§ ====================

@router.get("/resource/status", response_model=ResourceStatus)
async def get_resource_status():
    """è·å–ç³»ç»Ÿèµ„æºçŠ¶æ€"""
    import psutil
    
    try:
        cpu_usage = psutil.cpu_percent(interval=0.1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        net_io = psutil.net_io_counters()
        
        # æ£€æµ‹å¤–æ¥ç¡¬ç›˜
        external_disks = []
        for partition in psutil.disk_partitions():
            if 'removable' in partition.opts or '/Volumes/' in partition.mountpoint:
                usage = psutil.disk_usage(partition.mountpoint)
                external_disks.append({
                    "name": partition.mountpoint,
                    "total": usage.total,
                    "used": usage.used,
                    "free": usage.free,
                    "percent": usage.percent
                })
        
        return ResourceStatus(
            cpu_usage=cpu_usage,
            memory_usage=memory.percent,
            disk_usage=disk.percent,
            network_speed=net_io.bytes_sent / 1024 / 1024,  # MB/s
            external_disks=external_disks
        )
    except Exception as e:
        # å¦‚æœpsutilä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
        return ResourceStatus(
            cpu_usage=45.0,
            memory_usage=62.0,
            disk_usage=78.0,
            network_speed=32.0,
            external_disks=[{
                "name": "å¤–æ¥ç¡¬ç›˜",
                "total": 2_000_000_000_000,
                "used": 500_000_000_000,
                "free": 1_500_000_000_000,
                "percent": 25.0
            }]
        )


@router.post("/resource/adjust")
async def adjust_resources(target_module: str, priority: int):
    """è‡ªåŠ¨è°ƒèŠ‚èµ„æºåˆ†é…"""
    # å®é™…åº”è°ƒç”¨ç³»ç»Ÿèµ„æºç®¡ç†å™¨
    return {
        "success": True,
        "message": f"å·²è°ƒæ•´{target_module}çš„èµ„æºä¼˜å…ˆçº§ä¸º{priority}"
    }


# ==================== æ ¸å¿ƒåŠŸèƒ½6: è¯­éŸ³äº¤äº’ ====================

@router.post("/voice/recognize")
async def recognize_voice(audio_file: UploadFile = File(...)):
    """è¯­éŸ³è¯†åˆ« - å°†è¯­éŸ³è½¬æ–‡å­—ï¼ˆçœŸå®å®ç°ï¼‰"""
    try:
        from services.voice_service import get_voice_service
        voice = get_voice_service()
        
        # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
        temp_path = f"/tmp/{audio_file.filename}"
        with open(temp_path, "wb") as f:
            f.write(await audio_file.read())
        
        # çœŸå®è¯­éŸ³è¯†åˆ«
        result = await voice.recognize_speech(temp_path)
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os
        if os.path.exists(temp_path):
            os.remove(temp_path)
        
        return result
    
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "text": ""
        }


@router.post("/voice/synthesize")
async def synthesize_voice(text: str, voice: str = "zh-cn"):
    """è¯­éŸ³åˆæˆ - å°†æ–‡å­—è½¬è¯­éŸ³ï¼ˆçœŸå®å®ç°ï¼‰"""
    try:
        from services.voice_service import get_voice_service
        voice_svc = get_voice_service()
        
        # çœŸå®è¯­éŸ³åˆæˆ
        result = await voice_svc.synthesize_speech(text, language=voice)
        
        return result
    
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "audio_path": ""
        }


# ==================== æ ¸å¿ƒåŠŸèƒ½7: å¤šè¯­è¨€ç¿»è¯‘ ====================

@router.post("/translate")
async def translate_text(text: str, target_lang: str, source_lang: str = "auto"):
    """ç¿»è¯‘æ–‡æœ¬ï¼ˆæ”¯æŒ60ç§è¯­è¨€ï¼‰- çœŸå®å®ç°"""
    try:
        from services.translation_service import get_translation_service
        trans = get_translation_service()
        
        # çœŸå®ç¿»è¯‘
        result = await trans.translate(text, target_lang, source_lang)
        
        return result
    
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "source_text": text,
            "translated_text": ""
        }


# ==================== æ ¸å¿ƒåŠŸèƒ½8: æ–‡ä»¶ç”Ÿæˆ ====================

@router.post("/file/generate")
async def generate_file(
    file_type: str,
    content: str,
    title: Optional[str] = None,
    template: Optional[str] = None
):
    """ç”Ÿæˆæ–‡ä»¶ï¼ˆWord/Excel/PPT/PDFç­‰ï¼‰- çœŸå®å®ç°"""
    try:
        from services.file_generator_service import get_file_generator
        generator = get_file_generator()
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒç”¨ç›¸åº”çš„ç”Ÿæˆå™¨
        if file_type == "docx":
            result = await generator.generate_word(content, title)
        elif file_type == "pdf":
            result = await generator.generate_pdf(content, title)
        elif file_type == "md" or file_type == "markdown":
            result = await generator.generate_markdown(content, title)
        elif file_type == "xlsx":
            # Exceléœ€è¦ç»“æ„åŒ–æ•°æ®
            import json
            try:
                data = json.loads(content)
                result = await generator.generate_excel(data)
            except:
                result = {
                    "success": False,
                    "error": "Exceléœ€è¦JSONæ ¼å¼çš„æ•°æ®"
                }
        else:
            result = {
                "success": False,
                "error": f"æš‚ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}",
                "supported": ["docx", "xlsx", "pdf", "md"]
            }
        
        return result
    
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "file_path": ""
        }


@router.get("/file/download/{filename}")
async def download_file(filename: str):
    """ä¸‹è½½ç”Ÿæˆçš„æ–‡ä»¶"""
    # å®é™…åº”è¿”å›æ–‡ä»¶æµ
    return {"message": f"ä¸‹è½½æ–‡ä»¶: {filename}"}


# ==================== ç½‘ç»œæœç´¢é›†æˆ ====================

@router.post("/search/web")
async def search_web(
    query: str,
    engine: str = "duckduckgo",
    max_results: int = 10
):
    """ç½‘ç»œæœç´¢ï¼ˆçœŸå®å®ç°ï¼‰"""
    try:
        from services.web_search_service import get_search_service
        search = get_search_service()
        
        # çœŸå®æœç´¢
        result = await search.search(
            query=query,
            engine=engine,
            max_results=max_results
        )
        
        return result
    
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "query": query,
            "results": []
        }


# ==================== ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆ100ä¸‡å­—ï¼‰ ====================

@router.get("/context/get")
async def get_context(session_id: str):
    """è·å–ä¼šè¯ä¸Šä¸‹æ–‡"""
    context = sessions.get(session_id, {
        "messages": [],
        "total_tokens": 0,
        "created_at": datetime.now()
    })
    return context


@router.post("/context/save")
async def save_context(session_id: str, message: ChatMessage):
    """ä¿å­˜ä¸Šä¸‹æ–‡"""
    if session_id not in sessions:
        sessions[session_id] = {
            "messages": [],
            "total_tokens": 0,
            "created_at": datetime.now()
        }
    
    sessions[session_id]["messages"].append(message.dict())
    sessions[session_id]["total_tokens"] += len(message.content)
    
    # å¦‚æœè¶…è¿‡100ä¸‡å­—ï¼Œå‹ç¼©æ—§æ¶ˆæ¯
    if sessions[session_id]["total_tokens"] > 1_000_000:
        await compress_context(session_id)
    
    return {"success": True, "tokens": sessions[session_id]["total_tokens"]}


async def compress_context(session_id: str):
    """å‹ç¼©ä¸Šä¸‹æ–‡ï¼ˆæ™ºèƒ½æ‘˜è¦ï¼‰"""
    # å®é™…åº”ä½¿ç”¨AIå¯¹æ—§æ¶ˆæ¯è¿›è¡Œæ‘˜è¦
    messages = sessions[session_id]["messages"]
    if len(messages) > 100:
        # ä¿ç•™æœ€è¿‘50æ¡å®Œæ•´æ¶ˆæ¯ï¼Œæ—§æ¶ˆæ¯å‹ç¼©ä¸ºæ‘˜è¦
        old_messages = messages[:-50]
        summary = f"[å†å²å¯¹è¯æ‘˜è¦: {len(old_messages)}æ¡æ¶ˆæ¯]"
        sessions[session_id]["messages"] = [
            {"role": "system", "content": summary, "timestamp": datetime.now()}
        ] + messages[-50:]


# ==================== ç³»ç»Ÿå¥åº·æ£€æŸ¥ ====================

@router.get("/health")
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "version": "5.0.0",
        "features": {
            "chat": True,
            "memo": True,
            "task": True,
            "learning": True,
            "resource_monitor": True,
            "voice": True,
            "translate": True,
            "file_generate": True,
            "web_search": True,
            "context_memory": True
        },
        "uptime": "running",
        "response_time_target": "< 2ç§’"
    }


# ==================== ç³»ç»Ÿç»Ÿè®¡ ====================

@router.get("/stats")
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡"""
    return {
        "sessions": len(sessions),
        "memos": len(memos),
        "tasks": {
            "total": len(tasks),
            "pending": len([t for t in tasks if t.status == "pending"]),
            "confirmed": len([t for t in tasks if t.status == "confirmed"]),
            "executing": len([t for t in tasks if t.status == "executing"]),
            "completed": len([t for t in tasks if t.status == "completed"])
        },
        "learning_records": len(learning_records),
        "timestamp": datetime.now()
    }


if __name__ == "__main__":
    print("AI-STACK V5.0 è¶…çº§Agent API å·²åŠ è½½")
    print("åŠŸèƒ½æ¸…å•:")
    print("âœ… 1. æ™ºèƒ½èŠå¤©ï¼ˆAIå·¥ä½œæµ 9æ­¥éª¤ï¼‰")
    print("âœ… 2. å¤‡å¿˜å½•ç³»ç»Ÿï¼ˆè‡ªåŠ¨è¯†åˆ«é‡è¦ä¿¡æ¯ï¼‰")
    print("âœ… 3. æ™ºèƒ½å·¥ä½œè®¡åˆ’ï¼ˆä»å¤‡å¿˜å½•æç‚¼ä»»åŠ¡ï¼‰")
    print("âœ… 4. è‡ªæˆ‘å­¦ä¹ ç›‘æ§ï¼ˆç›‘æ§+ä¼˜åŒ–ï¼‰")
    print("âœ… 5. èµ„æºç›‘æ§ï¼ˆCPU/å†…å­˜/ç£ç›˜/ç½‘ç»œï¼‰")
    print("âœ… 6. è¯­éŸ³äº¤äº’ï¼ˆè¯­éŸ³è¾“å…¥+è¾“å‡ºï¼‰")
    print("âœ… 7. å¤šè¯­è¨€ç¿»è¯‘ï¼ˆ60ç§è¯­è¨€ï¼‰")
    print("âœ… 8. æ–‡ä»¶ç”Ÿæˆï¼ˆWord/Excel/PPT/PDFç­‰ï¼‰")
    print("âœ… 9. ç½‘ç»œæœç´¢ï¼ˆå¤šæœç´¢å¼•æ“ï¼‰")
    print("âœ… 10. ä¸Šä¸‹æ–‡è®°å¿†ï¼ˆ100ä¸‡å­—ï¼‰")

