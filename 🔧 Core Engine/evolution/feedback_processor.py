# ai-stack-super-enhanced/ğŸ”§ Core Engine/evolution/feedback_processor.py
"""
åé¦ˆå¤„ç†å™¨ - è´Ÿè´£å¤„ç†å„ç§åé¦ˆä¿¡å·å¹¶è½¬åŒ–ä¸ºè¿›åŒ–æŒ‡å¯¼
å¯¹åº”å¼€å‘è®¡åˆ’ï¼šé˜¶æ®µ1 - Core Engine ä¸­çš„è¿›åŒ–å¼•æ“åŸºç¡€
å¯¹åº”å¼€å‘è§„åˆ™ï¼š9.1/9.2 è‡ªæˆ‘å­¦ä¹ å’Œè‡ªæˆ‘è¿›åŒ–åŠŸèƒ½éœ€æ±‚
"""

import asyncio
import logging
import re
import uuid
from collections import Counter, defaultdict
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)


class FeedbackSource(Enum):
    """åé¦ˆæ¥æºæšä¸¾"""

    SYSTEM_MONITORING = "system_monitoring"
    USER_INTERACTION = "user_interaction"
    PERFORMANCE_METRICS = "performance_metrics"
    ERROR_REPORTS = "error_reports"
    SECURITY_EVENTS = "security_events"
    EXTERNAL_SOURCES = "external_sources"
    SELF_EVALUATION = "self_evaluation"


class FeedbackType(Enum):
    """åé¦ˆç±»å‹æšä¸¾"""

    POSITIVE = "positive"
    NEGATIVE = "negative"
    NEUTRAL = "neutral"
    CORRECTIVE = "corrective"
    SUGGESTIVE = "suggestive"
    CRITICAL = "critical"


class FeedbackPriority(Enum):
    """åé¦ˆä¼˜å…ˆçº§æšä¸¾"""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"
    EMERGENCY = "emergency"


class FeedbackProcessor:
    """
    åé¦ˆå¤„ç†å™¨ - ç³»ç»Ÿåé¦ˆä¿¡å·å¤„ç†å’Œåˆ†ææ ¸å¿ƒç»„ä»¶

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å¤šæºåé¦ˆæ•°æ®æ”¶é›†å’Œæ ‡å‡†åŒ–
    2. åé¦ˆä¿¡å·åˆ†ç±»å’Œä¼˜å…ˆçº§è¯„ä¼°
    3. æƒ…æ„Ÿåˆ†æå’Œæ„å›¾è¯†åˆ«
    4. åé¦ˆèšåˆå’Œæ¨¡å¼å‘ç°
    5. è¿›åŒ–æŒ‡å¯¼ç”Ÿæˆå’Œä¼ é€’
    """

    def __init__(self):
        # åé¦ˆæ•°æ®å­˜å‚¨
        self.feedback_queue = asyncio.Queue()
        self.processed_feedback = []
        self.feedback_patterns = {}

        # å¤„ç†é…ç½®
        self.processing_config = {}
        self.source_weights = {}

        # åˆ†æç»„ä»¶
        self.sentiment_analyzer = None
        self.pattern_miner = None
        self.correlation_engine = None

        # çŠ¶æ€ä¿¡æ¯
        self.is_initialized = False
        self.processing_task = None
        self.running = False
        self.feedback_count = 0

        # ç¼“å­˜å’Œä¼˜åŒ–
        self.feedback_cache = {}
        self.learning_model = {}

        logger.info("åé¦ˆå¤„ç†å™¨å®ä¾‹åˆ›å»º")

    async def initialize(self, config: Dict[str, Any] = None) -> bool:
        """
        åˆå§‹åŒ–åé¦ˆå¤„ç†å™¨

        Args:
            config: å¤„ç†é…ç½®å‚æ•°

        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–åé¦ˆå¤„ç†å™¨")

            # è®¾ç½®é…ç½®
            self.processing_config = config or {}
            await self._setup_default_config()

            # åˆå§‹åŒ–åˆ†æç»„ä»¶
            await self._initialize_analyzers()

            # è®¾ç½®æºæƒé‡
            await self._setup_source_weights()

            # å¯åŠ¨å¤„ç†ä»»åŠ¡
            self.running = True
            self.processing_task = asyncio.create_task(self._processing_loop())

            self.is_initialized = True
            logger.info("åé¦ˆå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"åé¦ˆå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}", exc_info=True)
            self.is_initialized = False
            return False

    async def _setup_default_config(self):
        """è®¾ç½®é»˜è®¤é…ç½®"""
        default_config = {
            "processing_batch_size": 10,
            "max_queue_size": 1000,
            "retention_days": 90,
            "real_time_processing": True,
            "sentiment_analysis_enabled": True,
            "pattern_detection_enabled": True,
            "correlation_analysis_enabled": True,
            "auto_learning_enabled": True,
            "emergency_threshold": 0.9,
            "feedback_aggregation_window": 300,  # 5åˆ†é’Ÿ
        }

        # åˆå¹¶é…ç½®
        for key, value in default_config.items():
            if key not in self.processing_config:
                self.processing_config[key] = value

    async def _initialize_analyzers(self):
        """åˆå§‹åŒ–åˆ†æç»„ä»¶"""
        try:
            # åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æå™¨
            self.sentiment_analyzer = SentimentAnalyzer()

            # åˆå§‹åŒ–æ¨¡å¼æŒ–æ˜å™¨
            self.pattern_miner = PatternMiner()

            # åˆå§‹åŒ–å…³è”å¼•æ“
            self.correlation_engine = CorrelationEngine()

            logger.debug("åé¦ˆåˆ†æç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            logger.error(f"åˆ†æç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {str(e)}")

    async def _setup_source_weights(self):
        """è®¾ç½®æºæƒé‡"""
        # é»˜è®¤æºæƒé‡é…ç½®
        self.source_weights = {
            FeedbackSource.SYSTEM_MONITORING: 0.9,
            FeedbackSource.PERFORMANCE_METRICS: 0.8,
            FeedbackSource.ERROR_REPORTS: 0.7,
            FeedbackSource.SECURITY_EVENTS: 0.95,
            FeedbackSource.USER_INTERACTION: 0.6,
            FeedbackSource.EXTERNAL_SOURCES: 0.5,
            FeedbackSource.SELF_EVALUATION: 0.85,
        }

        # ä»é…ç½®ä¸­æ›´æ–°æƒé‡
        if "source_weights" in self.processing_config:
            for source, weight in self.processing_config["source_weights"].items():
                try:
                    source_enum = FeedbackSource(source)
                    self.source_weights[source_enum] = weight
                except ValueError:
                    logger.warning(f"æœªçŸ¥åé¦ˆæ¥æº: {source}")

    async def _processing_loop(self):
        """åé¦ˆå¤„ç†å¾ªç¯"""
        logger.info("å¯åŠ¨åé¦ˆå¤„ç†å¾ªç¯")

        batch_size = self.processing_config.get("processing_batch_size", 10)

        while self.running:
            try:
                # æ‰¹é‡å¤„ç†åé¦ˆ
                batch = await self._collect_feedback_batch(batch_size)

                if batch:
                    # å¤„ç†æ‰¹é‡åé¦ˆ
                    processed_batch = await self._process_feedback_batch(batch)

                    # å­¦ä¹ å¤„ç†ç»“æœ
                    if self.processing_config.get("auto_learning_enabled", True):
                        await self._learn_from_processed_feedback(processed_batch)

                    # æ›´æ–°åé¦ˆæ¨¡å¼
                    if self.processing_config.get("pattern_detection_enabled", True):
                        await self._update_feedback_patterns(processed_batch)

                # çŸ­æš‚ç­‰å¾…ä»¥é¿å…è¿‡åº¦æ¶ˆè€—CPU
                await asyncio.sleep(0.1)

            except asyncio.CancelledError:
                logger.info("åé¦ˆå¤„ç†å¾ªç¯è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"åé¦ˆå¤„ç†å¾ªç¯å¼‚å¸¸: {str(e)}", exc_info=True)
                await asyncio.sleep(1)  # å¼‚å¸¸åç­‰å¾…1ç§’

    async def _collect_feedback_batch(self, batch_size: int) -> List[Dict[str, Any]]:
        """æ”¶é›†åé¦ˆæ‰¹æ¬¡"""
        batch = []

        try:
            # ä»é˜Ÿåˆ—ä¸­è·å–åé¦ˆ
            while len(batch) < batch_size and not self.feedback_queue.empty():
                try:
                    feedback = await asyncio.wait_for(
                        self.feedback_queue.get(), timeout=0.1
                    )
                    batch.append(feedback)
                    self.feedback_queue.task_done()
                except asyncio.TimeoutError:
                    break

            return batch

        except Exception as e:
            logger.error(f"åé¦ˆæ‰¹æ¬¡æ”¶é›†å¤±è´¥: {str(e)}")
            return []

    async def submit_feedback(self, feedback_data: Dict[str, Any]) -> str:
        """
        æäº¤åé¦ˆæ•°æ®

        Args:
            feedback_data: åé¦ˆæ•°æ®

        Returns:
            str: åé¦ˆID
        """
        try:
            # ç”Ÿæˆåé¦ˆID
            feedback_id = str(uuid.uuid4())

            # æ ‡å‡†åŒ–åé¦ˆæ•°æ®
            standardized_feedback = await self._standardize_feedback(
                feedback_data, feedback_id
            )

            # æ£€æŸ¥é˜Ÿåˆ—å¤§å°
            max_queue_size = self.processing_config.get("max_queue_size", 1000)
            if self.feedback_queue.qsize() >= max_queue_size:
                logger.warning("åé¦ˆé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæœ€æ—§çš„åé¦ˆ")
                try:
                    self.feedback_queue.get_nowait()
                    self.feedback_queue.task_done()
                except asyncio.QueueEmpty:
                    pass

            # æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—
            await self.feedback_queue.put(standardized_feedback)

            logger.debug(f"åé¦ˆæäº¤æˆåŠŸ: {feedback_id}")
            return feedback_id

        except Exception as e:
            logger.error(f"åé¦ˆæäº¤å¤±è´¥: {str(e)}")
            return f"error_{int(datetime.utcnow().timestamp())}"

    async def _standardize_feedback(
        self, raw_feedback: Dict[str, Any], feedback_id: str
    ) -> Dict[str, Any]:
        """æ ‡å‡†åŒ–åé¦ˆæ•°æ®"""
        try:
            standardized = {
                "feedback_id": feedback_id,
                "timestamp": datetime.utcnow().isoformat(),
                "received_at": datetime.utcnow().isoformat(),
                "raw_data": raw_feedback,
            }

            # æå–æ¥æº
            source = await self._extract_feedback_source(raw_feedback)
            standardized["source"] = source.value

            # æå–ç±»å‹
            feedback_type = await self._classify_feedback_type(raw_feedback, source)
            standardized["type"] = feedback_type.value

            # è¯„ä¼°ä¼˜å…ˆçº§
            priority = await self._assess_feedback_priority(
                raw_feedback, source, feedback_type
            )
            standardized["priority"] = priority.value

            # æå–å†…å®¹
            content = await self._extract_feedback_content(raw_feedback)
            standardized["content"] = content

            # æ·»åŠ å…ƒæ•°æ®
            standardized["metadata"] = {
                "source_confidence": await self._calculate_source_confidence(source),
                "processing_stage": "standardized",
                "standardization_version": "1.0",
            }

            return standardized

        except Exception as e:
            logger.error(f"åé¦ˆæ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
            # è¿”å›æœ€å°æ ‡å‡†åŒ–æ•°æ®
            return {
                "feedback_id": feedback_id,
                "timestamp": datetime.utcnow().isoformat(),
                "source": "unknown",
                "type": "neutral",
                "priority": "medium",
                "content": {"raw": raw_feedback},
                "metadata": {"error": str(e)},
            }

    async def _extract_feedback_source(
        self, raw_feedback: Dict[str, Any]
    ) -> FeedbackSource:
        """æå–åé¦ˆæ¥æº"""
        try:
            # æ ¹æ®æ•°æ®ç‰¹å¾åˆ¤æ–­æ¥æº
            if "system_metrics" in raw_feedback or "performance_data" in raw_feedback:
                return FeedbackSource.SYSTEM_MONITORING

            elif "user_id" in raw_feedback or "user_action" in raw_feedback:
                return FeedbackSource.USER_INTERACTION

            elif "error_code" in raw_feedback or "exception" in raw_feedback:
                return FeedbackSource.ERROR_REPORTS

            elif "security_level" in raw_feedback or "threat_indicator" in raw_feedback:
                return FeedbackSource.SECURITY_EVENTS

            elif "external_api" in raw_feedback or "third_party" in raw_feedback:
                return FeedbackSource.EXTERNAL_SOURCES

            elif "self_assessment" in raw_feedback or "introspection" in raw_feedback:
                return FeedbackSource.SELF_EVALUATION

            else:
                # é»˜è®¤ä¸ºæ€§èƒ½æŒ‡æ ‡
                return FeedbackSource.PERFORMANCE_METRICS

        except Exception as e:
            logger.error(f"åé¦ˆæ¥æºæå–å¤±è´¥: {str(e)}")
            return FeedbackSource.PERFORMANCE_METRICS

    async def _classify_feedback_type(
        self, raw_feedback: Dict[str, Any], source: FeedbackSource
    ) -> FeedbackType:
        """åˆ†ç±»åé¦ˆç±»å‹"""
        try:
            # åŸºäºæ¥æºå’Œå†…å®¹çš„ç±»å‹åˆ†ç±»
            content_str = str(raw_feedback).lower()

            # å…³é”®äº‹ä»¶æ£€æµ‹
            critical_indicators = [
                "error",
                "failure",
                "crash",
                "panic",
                "emergency",
                "critical",
            ]
            if any(indicator in content_str for indicator in critical_indicators):
                return FeedbackType.CRITICAL

            # çº æ­£æ€§åé¦ˆæ£€æµ‹
            corrective_indicators = [
                "fix",
                "correct",
                "repair",
                "resolve",
                "should",
                "must",
            ]
            if any(indicator in content_str for indicator in corrective_indicators):
                return FeedbackType.CORRECTIVE

            # å»ºè®®æ€§åé¦ˆæ£€æµ‹
            suggestive_indicators = [
                "suggest",
                "recommend",
                "improve",
                "enhance",
                "better",
            ]
            if any(indicator in content_str for indicator in suggestive_indicators):
                return FeedbackType.SUGGESTIVE

            # æƒ…æ„Ÿåˆ†æ
            if self.processing_config.get("sentiment_analysis_enabled", True):
                sentiment = await self.sentiment_analyzer.analyze(raw_feedback)
                if sentiment > 0.1:
                    return FeedbackType.POSITIVE
                elif sentiment < -0.1:
                    return FeedbackType.NEGATIVE
                else:
                    return FeedbackType.NEUTRAL
            else:
                return FeedbackType.NEUTRAL

        except Exception as e:
            logger.error(f"åé¦ˆç±»å‹åˆ†ç±»å¤±è´¥: {str(e)}")
            return FeedbackType.NEUTRAL

    async def _assess_feedback_priority(
        self,
        raw_feedback: Dict[str, Any],
        source: FeedbackSource,
        feedback_type: FeedbackType,
    ) -> FeedbackPriority:
        """è¯„ä¼°åé¦ˆä¼˜å…ˆçº§"""
        try:
            base_priority_scores = {
                FeedbackPriority.LOW: 1,
                FeedbackPriority.MEDIUM: 2,
                FeedbackPriority.HIGH: 3,
                FeedbackPriority.CRITICAL: 4,
                FeedbackPriority.EMERGENCY: 5,
            }

            # åŸºç¡€åˆ†æ•°åŸºäºæ¥æºå’Œç±»å‹
            source_weight = self.source_weights.get(source, 0.5)
            type_multiplier = self._get_type_multiplier(feedback_type)

            base_score = source_weight * type_multiplier

            # å†…å®¹ç´§æ€¥åº¦åˆ†æ
            urgency_indicators = {
                "immediately": 2.0,
                "urgent": 1.8,
                "asap": 1.7,
                "critical": 1.9,
                "emergency": 2.0,
                "now": 1.6,
            }

            content_str = str(raw_feedback).lower()
            urgency_boost = 1.0
            for indicator, boost in urgency_indicators.items():
                if indicator in content_str:
                    urgency_boost = max(urgency_boost, boost)

            final_score = base_score * urgency_boost

            # æ˜ å°„åˆ°ä¼˜å…ˆçº§
            if final_score >= 1.8:
                return FeedbackPriority.EMERGENCY
            elif final_score >= 1.5:
                return FeedbackPriority.CRITICAL
            elif final_score >= 1.2:
                return FeedbackPriority.HIGH
            elif final_score >= 0.8:
                return FeedbackPriority.MEDIUM
            else:
                return FeedbackPriority.LOW

        except Exception as e:
            logger.error(f"åé¦ˆä¼˜å…ˆçº§è¯„ä¼°å¤±è´¥: {str(e)}")
            return FeedbackPriority.MEDIUM

    def _get_type_multiplier(self, feedback_type: FeedbackType) -> float:
        """è·å–ç±»å‹ä¹˜æ•°"""
        multipliers = {
            FeedbackType.CRITICAL: 2.0,
            FeedbackType.NEGATIVE: 1.5,
            FeedbackType.CORRECTIVE: 1.3,
            FeedbackType.SUGGESTIVE: 1.1,
            FeedbackType.POSITIVE: 0.8,
            FeedbackType.NEUTRAL: 0.7,
        }
        return multipliers.get(feedback_type, 1.0)

    async def _extract_feedback_content(
        self, raw_feedback: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æå–åé¦ˆå†…å®¹"""
        try:
            content = {
                "raw": raw_feedback,
                "structured": {},
                "keywords": [],
                "sentiment": 0.0,
            }

            # æå–ç»“æ„åŒ–ä¿¡æ¯
            if isinstance(raw_feedback, dict):
                for key, value in raw_feedback.items():
                    if isinstance(value, (str, int, float, bool)):
                        content["structured"][key] = value

            # æå–å…³é”®è¯
            content["keywords"] = await self._extract_keywords(raw_feedback)

            # æƒ…æ„Ÿåˆ†æ
            if self.processing_config.get("sentiment_analysis_enabled", True):
                content["sentiment"] = await self.sentiment_analyzer.analyze(
                    raw_feedback
                )

            return content

        except Exception as e:
            logger.error(f"åé¦ˆå†…å®¹æå–å¤±è´¥: {str(e)}")
            return {"raw": raw_feedback, "error": str(e)}

    async def _extract_keywords(self, raw_feedback: Dict[str, Any]) -> List[str]:
        """æå–å…³é”®è¯"""
        try:
            text_content = str(raw_feedback)

            # ç®€å•çš„å…³é”®è¯æå–
            words = re.findall(r"\b[a-zA-Z]{3,}\b", text_content.lower())

            # è¿‡æ»¤å¸¸è§è¯
            stop_words = {
                "the",
                "and",
                "for",
                "are",
                "but",
                "not",
                "you",
                "all",
                "can",
                "your",
                "has",
                "had",
                "was",
                "were",
                "will",
                "with",
                "have",
                "this",
                "that",
                "from",
            }
            filtered_words = [word for word in words if word not in stop_words]

            # ç»Ÿè®¡è¯é¢‘
            word_freq = Counter(filtered_words)

            # è¿”å›é«˜é¢‘è¯
            return [word for word, count in word_freq.most_common(10)]

        except Exception as e:
            logger.error(f"å…³é”®è¯æå–å¤±è´¥: {str(e)}")
            return []

    async def _calculate_source_confidence(self, source: FeedbackSource) -> float:
        """è®¡ç®—æ¥æºç½®ä¿¡åº¦"""
        # åŸºäºæ¥æºå¯é æ€§çš„ç½®ä¿¡åº¦è®¡ç®—
        confidence_scores = {
            FeedbackSource.SYSTEM_MONITORING: 0.95,
            FeedbackSource.PERFORMANCE_METRICS: 0.9,
            FeedbackSource.SELF_EVALUATION: 0.85,
            FeedbackSource.SECURITY_EVENTS: 0.8,
            FeedbackSource.ERROR_REPORTS: 0.75,
            FeedbackSource.USER_INTERACTION: 0.7,
            FeedbackSource.EXTERNAL_SOURCES: 0.6,
        }

        return confidence_scores.get(source, 0.5)

    async def _process_feedback_batch(
        self, batch: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """å¤„ç†åé¦ˆæ‰¹æ¬¡"""
        processed_batch = []

        try:
            for feedback in batch:
                processed_feedback = await self._process_single_feedback(feedback)
                processed_batch.append(processed_feedback)

                # å­˜å‚¨å¤„ç†ç»“æœ
                self.processed_feedback.append(processed_feedback)
                self.feedback_count += 1

            # é™åˆ¶å­˜å‚¨å¤§å°
            max_storage = self.processing_config.get("max_storage_size", 10000)
            if len(self.processed_feedback) > max_storage:
                self.processed_feedback = self.processed_feedback[-max_storage:]

            logger.debug(f"åé¦ˆæ‰¹æ¬¡å¤„ç†å®Œæˆ: {len(processed_batch)}æ¡åé¦ˆ")
            return processed_batch

        except Exception as e:
            logger.error(f"åé¦ˆæ‰¹æ¬¡å¤„ç†å¤±è´¥: {str(e)}")
            return []

    async def _process_single_feedback(
        self, feedback: Dict[str, Any]
    ) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªåé¦ˆ"""
        try:
            processed = feedback.copy()

            # æƒ…æ„Ÿåˆ†æ
            if self.processing_config.get("sentiment_analysis_enabled", True):
                sentiment_result = await self.sentiment_analyzer.analyze_detailed(
                    feedback
                )
                processed["sentiment_analysis"] = sentiment_result

            # æ¨¡å¼åŒ¹é…
            if self.processing_config.get("pattern_detection_enabled", True):
                pattern_match = await self.pattern_miner.match_patterns(feedback)
                processed["pattern_matches"] = pattern_match

            # å…³è”åˆ†æ
            if self.processing_config.get("correlation_analysis_enabled", True):
                correlations = await self.correlation_engine.find_correlations(
                    feedback, self.processed_feedback
                )
                processed["correlations"] = correlations

            # ç”Ÿæˆè¿›åŒ–æŒ‡å¯¼
            evolution_guidance = await self._generate_evolution_guidance(processed)
            processed["evolution_guidance"] = evolution_guidance

            # æ›´æ–°å¤„ç†çŠ¶æ€
            processed["metadata"]["processed_at"] = datetime.utcnow().isoformat()
            processed["metadata"]["processing_version"] = "1.0"

            return processed

        except Exception as e:
            logger.error(
                f"å•ä¸ªåé¦ˆå¤„ç†å¤±è´¥: {feedback.get('feedback_id', 'unknown')} - {str(e)}"
            )
            feedback["metadata"]["processing_error"] = str(e)
            return feedback

    async def _generate_evolution_guidance(
        self, processed_feedback: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆè¿›åŒ–æŒ‡å¯¼"""
        try:
            guidance = {
                "guidance_id": str(uuid.uuid4()),
                "generated_at": datetime.utcnow().isoformat(),
                "confidence": 0.0,
                "recommendations": [],
                "warnings": [],
                "opportunities": [],
            }

            # åŸºäºåé¦ˆç±»å‹ç”ŸæˆæŒ‡å¯¼
            feedback_type = processed_feedback.get("type", "")
            feedback_priority = processed_feedback.get("priority", "")
            feedback_content = processed_feedback.get("content", {})

            # è´Ÿé¢åé¦ˆ -> çº æ­£æ€§æŒ‡å¯¼
            if feedback_type in ["negative", "critical", "corrective"]:
                corrective_actions = await self._generate_corrective_guidance(
                    processed_feedback
                )
                guidance["recommendations"].extend(corrective_actions)
                guidance["confidence"] += 0.3

            # å»ºè®®æ€§åé¦ˆ -> æ”¹è¿›æŒ‡å¯¼
            if feedback_type == "suggestive":
                improvement_actions = await self._generate_improvement_guidance(
                    processed_feedback
                )
                guidance["recommendations"].extend(improvement_actions)
                guidance["confidence"] += 0.2

            # æ­£é¢åé¦ˆ -> å¼ºåŒ–æŒ‡å¯¼
            if feedback_type == "positive":
                reinforcement_actions = await self._generate_reinforcement_guidance(
                    processed_feedback
                )
                guidance["recommendations"].extend(reinforcement_actions)
                guidance["confidence"] += 0.1

            # åŸºäºä¼˜å…ˆçº§è°ƒæ•´ç½®ä¿¡åº¦
            priority_boost = {
                "emergency": 0.4,
                "critical": 0.3,
                "high": 0.2,
                "medium": 0.1,
                "low": 0.0,
            }
            guidance["confidence"] += priority_boost.get(feedback_priority, 0.0)

            # é™åˆ¶ç½®ä¿¡åº¦èŒƒå›´
            guidance["confidence"] = max(0.0, min(1.0, guidance["confidence"]))

            # ç”Ÿæˆè­¦å‘Šå’Œæœºä¼š
            if feedback_priority in ["critical", "emergency"]:
                guidance["warnings"].append(
                    {
                        "level": "high",
                        "message": "æ£€æµ‹åˆ°é«˜ä¼˜å…ˆçº§åé¦ˆï¼Œå»ºè®®ç«‹å³å¤„ç†",
                        "related_feedback": processed_feedback["feedback_id"],
                    }
                )

            if feedback_type == "positive" and guidance["confidence"] > 0.7:
                guidance["opportunities"].append(
                    {
                        "type": "optimization",
                        "message": "æ­£é¢åé¦ˆæŒ‡ç¤ºå½“å‰ç­–ç•¥æœ‰æ•ˆï¼Œå¯è€ƒè™‘æ‰©å¤§åº”ç”¨",
                        "confidence": guidance["confidence"],
                    }
                )

            return guidance

        except Exception as e:
            logger.error(f"è¿›åŒ–æŒ‡å¯¼ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "guidance_id": str(uuid.uuid4()),
                "error": str(e),
                "confidence": 0.0,
                "recommendations": [],
            }

    async def _generate_corrective_guidance(
        self, feedback: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆçº æ­£æ€§æŒ‡å¯¼"""
        recommendations = []

        try:
            content = feedback.get("content", {})
            keywords = content.get("keywords", [])
            structured_data = content.get("structured", {})

            # åŸºäºå…³é”®è¯çš„æ¨¡å¼åŒ¹é…
            issue_patterns = {
                "slow": ["æ€§èƒ½ä¼˜åŒ–", "ç¼“å­˜ç­–ç•¥", "æŸ¥è¯¢ä¼˜åŒ–"],
                "error": ["é”™è¯¯å¤„ç†", "è¾“å…¥éªŒè¯", "å¼‚å¸¸æ•è·"],
                "memory": ["å†…å­˜ç®¡ç†", "èµ„æºæ¸…ç†", "æ³„æ¼æ£€æµ‹"],
                "crash": ["ç¨³å®šæ€§æ”¹è¿›", "å®¹é”™æœºåˆ¶", "çŠ¶æ€æ¢å¤"],
                "security": ["å®‰å…¨æ£€æŸ¥", "æƒé™éªŒè¯", "æ•°æ®åŠ å¯†"],
            }

            for keyword in keywords:
                for pattern, actions in issue_patterns.items():
                    if pattern in keyword:
                        for action in actions:
                            recommendations.append(
                                {
                                    "type": "corrective",
                                    "action": action,
                                    "reason": f"æ£€æµ‹åˆ°'{keyword}'ç›¸å…³é—®é¢˜",
                                    "priority": feedback.get("priority", "medium"),
                                    "source_feedback": feedback["feedback_id"],
                                }
                            )

            # åŸºäºç»“æ„åŒ–æ•°æ®çš„å»ºè®®
            if "error_code" in structured_data:
                recommendations.append(
                    {
                        "type": "corrective",
                        "action": "åˆ†æé”™è¯¯ä»£ç æ ¹æœ¬åŸå› ",
                        "reason": f"æ£€æµ‹åˆ°é”™è¯¯ä»£ç : {structured_data['error_code']}",
                        "priority": "high",
                        "source_feedback": feedback["feedback_id"],
                    }
                )

            return recommendations[:5]  # è¿”å›å‰5ä¸ªå»ºè®®

        except Exception as e:
            logger.error(f"çº æ­£æ€§æŒ‡å¯¼ç”Ÿæˆå¤±è´¥: {str(e)}")
            return [
                {
                    "type": "corrective",
                    "action": "è°ƒæŸ¥åé¦ˆæ ¹æœ¬åŸå› ",
                    "reason": "åé¦ˆå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯",
                    "priority": "medium",
                    "source_feedback": feedback["feedback_id"],
                }
            ]

    async def _generate_improvement_guidance(
        self, feedback: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ”¹è¿›æŒ‡å¯¼"""
        recommendations = []

        try:
            content = feedback.get("content", {})
            keywords = content.get("keywords", [])

            improvement_patterns = {
                "better": ["æ€§èƒ½è°ƒä¼˜", "ç”¨æˆ·ä½“éªŒæ”¹è¿›"],
                "faster": ["ç®—æ³•ä¼˜åŒ–", "å¹¶å‘å¤„ç†"],
                "easier": ["ç•Œé¢ç®€åŒ–", "æµç¨‹ä¼˜åŒ–"],
                "more": ["åŠŸèƒ½æ‰©å±•", "å®¹é‡å¢åŠ "],
                "improve": ["è´¨é‡æå‡", "æµç¨‹æ”¹è¿›"],
            }

            for keyword in keywords:
                for pattern, actions in improvement_patterns.items():
                    if pattern in keyword:
                        for action in actions:
                            recommendations.append(
                                {
                                    "type": "improvement",
                                    "action": action,
                                    "reason": f"ç”¨æˆ·å»ºè®®'{keyword}'ç›¸å…³æ”¹è¿›",
                                    "priority": "medium",
                                    "source_feedback": feedback["feedback_id"],
                                }
                            )

            return recommendations[:3]  # è¿”å›å‰3ä¸ªå»ºè®®

        except Exception as e:
            logger.error(f"æ”¹è¿›æŒ‡å¯¼ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []

    async def _generate_reinforcement_guidance(
        self, feedback: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå¼ºåŒ–æŒ‡å¯¼"""
        recommendations = []

        try:
            content = feedback.get("content", {})
            sentiment = content.get("sentiment", 0)

            # é«˜æ­£é¢æƒ…æ„Ÿ -> å¼ºåŒ–å½“å‰ç­–ç•¥
            if sentiment > 0.5:
                recommendations.append(
                    {
                        "type": "reinforcement",
                        "action": "ç»´æŒå½“å‰ä¼˜åŒ–ç­–ç•¥",
                        "reason": "æ”¶åˆ°å¼ºçƒˆæ­£é¢åé¦ˆï¼Œå½“å‰ç­–ç•¥æ•ˆæœè‰¯å¥½",
                        "priority": "low",
                        "source_feedback": feedback["feedback_id"],
                    }
                )

            return recommendations

        except Exception as e:
            logger.error(f"å¼ºåŒ–æŒ‡å¯¼ç”Ÿæˆå¤±è´¥: {str(e)}")
            return []

    async def _learn_from_processed_feedback(
        self, processed_batch: List[Dict[str, Any]]
    ):
        """ä»å¤„ç†è¿‡çš„åé¦ˆä¸­å­¦ä¹ """
        try:
            for feedback in processed_batch:
                # å­¦ä¹ åé¦ˆæ¨¡å¼
                await self._update_learning_model(feedback)

                # è°ƒæ•´å¤„ç†ç­–ç•¥
                await self._adapt_processing_strategy(feedback)

            logger.debug(f"ä»{len(processed_batch)}æ¡åé¦ˆä¸­å­¦ä¹ å®Œæˆ")

        except Exception as e:
            logger.error(f"åé¦ˆå­¦ä¹ å¤±è´¥: {str(e)}")

    async def _update_learning_model(self, feedback: Dict[str, Any]):
        """æ›´æ–°å­¦ä¹ æ¨¡å‹"""
        try:
            feedback_type = feedback.get("type")
            source = feedback.get("source")
            priority = feedback.get("priority")

            # æ›´æ–°ç±»å‹åˆ†å¸ƒ
            if "type_distribution" not in self.learning_model:
                self.learning_model["type_distribution"] = defaultdict(int)
            self.learning_model["type_distribution"][feedback_type] += 1

            # æ›´æ–°æºåˆ†å¸ƒ
            if "source_distribution" not in self.learning_model:
                self.learning_model["source_distribution"] = defaultdict(int)
            self.learning_model["source_distribution"][source] += 1

            # æ›´æ–°ä¼˜å…ˆçº§åˆ†å¸ƒ
            if "priority_distribution" not in self.learning_model:
                self.learning_model["priority_distribution"] = defaultdict(int)
            self.learning_model["priority_distribution"][priority] += 1

            # é™åˆ¶å­¦ä¹ æ¨¡å‹å¤§å°
            for distribution in [
                "type_distribution",
                "source_distribution",
                "priority_distribution",
            ]:
                if distribution in self.learning_model:
                    # ä¿æŒæœ€è¿‘1000æ¡è®°å½•çš„åˆ†å¸ƒ
                    total = sum(self.learning_model[distribution].values())
                    if total > 1000:
                        scale_factor = 1000 / total
                        for key in list(self.learning_model[distribution].keys()):
                            self.learning_model[distribution][key] = int(
                                self.learning_model[distribution][key] * scale_factor
                            )
                            if self.learning_model[distribution][key] == 0:
                                del self.learning_model[distribution][key]

        except Exception as e:
            logger.error(f"å­¦ä¹ æ¨¡å‹æ›´æ–°å¤±è´¥: {str(e)}")

    async def _adapt_processing_strategy(self, feedback: Dict[str, Any]):
        """è°ƒæ•´å¤„ç†ç­–ç•¥"""
        try:
            # åŸºäºåé¦ˆç‰¹å¾è°ƒæ•´æºæƒé‡
            source = feedback.get("source")
            guidance_confidence = feedback.get("evolution_guidance", {}).get(
                "confidence", 0
            )

            if guidance_confidence > 0.7:
                # é«˜ç½®ä¿¡åº¦æŒ‡å¯¼ -> æé«˜è¯¥æºæƒé‡
                current_weight = self.source_weights.get(FeedbackSource(source), 0.5)
                new_weight = min(1.0, current_weight + 0.05)
                self.source_weights[FeedbackSource(source)] = new_weight
                logger.debug(f"æé«˜æºæƒé‡: {source} -> {new_weight}")

            elif guidance_confidence < 0.3:
                # ä½ç½®ä¿¡åº¦æŒ‡å¯¼ -> é™ä½è¯¥æºæƒé‡
                current_weight = self.source_weights.get(FeedbackSource(source), 0.5)
                new_weight = max(0.1, current_weight - 0.03)
                self.source_weights[FeedbackSource(source)] = new_weight
                logger.debug(f"é™ä½æºæƒé‡: {source} -> {new_weight}")

        except Exception as e:
            logger.error(f"å¤„ç†ç­–ç•¥è°ƒæ•´å¤±è´¥: {str(e)}")

    async def _update_feedback_patterns(self, processed_batch: List[Dict[str, Any]]):
        """æ›´æ–°åé¦ˆæ¨¡å¼"""
        try:
            for feedback in processed_batch:
                pattern_key = await self._generate_pattern_key(feedback)

                if pattern_key not in self.feedback_patterns:
                    self.feedback_patterns[pattern_key] = {
                        "pattern": pattern_key,
                        "first_seen": datetime.utcnow(),
                        "last_seen": datetime.utcnow(),
                        "occurrence_count": 1,
                        "sources": set([feedback.get("source")]),
                        "types": set([feedback.get("type")]),
                        "priorities": set([feedback.get("priority")]),
                    }
                else:
                    pattern = self.feedback_patterns[pattern_key]
                    pattern["last_seen"] = datetime.utcnow()
                    pattern["occurrence_count"] += 1
                    pattern["sources"].add(feedback.get("source"))
                    pattern["types"].add(feedback.get("type"))
                    pattern["priorities"].add(feedback.get("priority"))

            # æ¸…ç†æ—§æ¨¡å¼
            cutoff_time = datetime.utcnow() - timedelta(days=7)
            expired_patterns = [
                key
                for key, pattern in self.feedback_patterns.items()
                if pattern["last_seen"] < cutoff_time
                and pattern["occurrence_count"] < 3
            ]

            for key in expired_patterns:
                del self.feedback_patterns[key]

        except Exception as e:
            logger.error(f"åé¦ˆæ¨¡å¼æ›´æ–°å¤±è´¥: {str(e)}")

    async def _generate_pattern_key(self, feedback: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¨¡å¼é”®"""
        try:
            content = feedback.get("content", {})
            keywords = content.get("keywords", [])
            structured = content.get("structured", {})

            # åŸºäºå…³é”®è¯å’Œå…³é”®å­—æ®µç”Ÿæˆæ¨¡å¼é”®
            key_parts = []

            # æ·»åŠ å‰3ä¸ªå…³é”®è¯
            key_parts.extend(keywords[:3])

            # æ·»åŠ å…³é”®å­—æ®µ
            key_fields = ["error_code", "module", "component", "operation"]
            for field in key_fields:
                if field in structured:
                    key_parts.append(f"{field}:{structured[field]}")

            return "_".join(sorted(key_parts)) if key_parts else "default_pattern"

        except Exception as e:
            logger.error(f"æ¨¡å¼é”®ç”Ÿæˆå¤±è´¥: {str(e)}")
            return "error_pattern"

    async def process_feedback(
        self, performance_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å¤„ç†æ€§èƒ½æ•°æ®å¹¶ç”Ÿæˆåé¦ˆ

        Args:
            performance_data: æ€§èƒ½æ•°æ®

        Returns:
            Dict: å¤„ç†åçš„åé¦ˆç»“æœ
        """
        try:
            logger.info("å¼€å§‹å¤„ç†æ€§èƒ½åé¦ˆ")

            # åˆ›å»ºåé¦ˆæ•°æ®
            feedback_data = {
                "performance_data": performance_data,
                "analysis_timestamp": datetime.utcnow().isoformat(),
                "feedback_type": "performance_analysis",
            }

            # æäº¤åé¦ˆ
            feedback_id = await self.submit_feedback(feedback_data)

            # ç­‰å¾…å¤„ç†å®Œæˆï¼ˆç®€åŒ–å®ç°ï¼‰
            await asyncio.sleep(0.1)

            # æŸ¥æ‰¾å¤„ç†ç»“æœ
            processed_feedback = await self._find_processed_feedback(feedback_id)

            if processed_feedback:
                evolution_guidance = processed_feedback.get("evolution_guidance", {})
                logger.info(
                    f"æ€§èƒ½åé¦ˆå¤„ç†å®Œæˆï¼Œç”Ÿæˆ{len(evolution_guidance.get('recommendations', []))}æ¡æŒ‡å¯¼"
                )
                return evolution_guidance
            else:
                logger.warning("æœªæ‰¾åˆ°å¤„ç†åçš„åé¦ˆ")
                return {
                    "guidance_id": str(uuid.uuid4()),
                    "confidence": 0.0,
                    "recommendations": [],
                    "warnings": ["åé¦ˆå¤„ç†ç»“æœæœªæ‰¾åˆ°"],
                }

        except Exception as e:
            logger.error(f"æ€§èƒ½åé¦ˆå¤„ç†å¤±è´¥: {str(e)}", exc_info=True)
            return {
                "guidance_id": str(uuid.uuid4()),
                "error": str(e),
                "confidence": 0.0,
                "recommendations": [],
            }

    async def _find_processed_feedback(
        self, feedback_id: str
    ) -> Optional[Dict[str, Any]]:
        """æŸ¥æ‰¾å¤„ç†åçš„åé¦ˆ"""
        for feedback in reversed(self.processed_feedback):
            if feedback.get("feedback_id") == feedback_id:
                return feedback
        return None

    async def get_feedback_insights(self, time_range_hours: int = 24) -> Dict[str, Any]:
        """
        è·å–åé¦ˆæ´å¯Ÿ

        Args:
            time_range_hours: æ—¶é—´èŒƒå›´(å°æ—¶)

        Returns:
            Dict: åé¦ˆæ´å¯Ÿ
        """
        try:
            cutoff_time = datetime.utcnow() - timedelta(hours=time_range_hours)

            recent_feedback = [
                fb
                for fb in self.processed_feedback
                if datetime.fromisoformat(fb["timestamp"].replace("Z", "+00:00"))
                >= cutoff_time
            ]

            insights = {
                "time_range": f"last_{time_range_hours}_hours",
                "total_feedback": len(recent_feedback),
                "summary": await self._generate_insights_summary(recent_feedback),
                "patterns": await self._analyze_feedback_patterns(recent_feedback),
                "trends": await self._analyze_feedback_trends(recent_feedback),
                "recommendations": await self._generate_insights_recommendations(
                    recent_feedback
                ),
            }

            return insights

        except Exception as e:
            logger.error(f"åé¦ˆæ´å¯Ÿç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "error": str(e),
                "time_range": f"last_{time_range_hours}_hours",
                "total_feedback": 0,
            }

    async def _generate_insights_summary(
        self, feedback_list: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæ´å¯Ÿæ‘˜è¦"""
        try:
            if not feedback_list:
                return {"message": "æ— è¿‘æœŸåé¦ˆæ•°æ®"}

            # ç»Ÿè®¡åŸºæœ¬ä¿¡æ¯
            type_distribution = Counter(
                fb.get("type", "unknown") for fb in feedback_list
            )
            source_distribution = Counter(
                fb.get("source", "unknown") for fb in feedback_list
            )
            priority_distribution = Counter(
                fb.get("priority", "medium") for fb in feedback_list
            )

            # è®¡ç®—å¹³å‡æƒ…æ„Ÿ
            sentiments = [
                fb.get("content", {}).get("sentiment", 0) for fb in feedback_list
            ]
            avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0

            # è®¡ç®—æŒ‡å¯¼ç½®ä¿¡åº¦
            confidences = [
                fb.get("evolution_guidance", {}).get("confidence", 0)
                for fb in feedback_list
            ]
            avg_confidence = sum(confidences) / len(confidences) if confidences else 0

            return {
                "feedback_count": len(feedback_list),
                "type_distribution": dict(type_distribution),
                "source_distribution": dict(source_distribution),
                "priority_distribution": dict(priority_distribution),
                "average_sentiment": avg_sentiment,
                "average_confidence": avg_confidence,
                "time_period": f"{len(feedback_list)}æ¡åé¦ˆ",
            }

        except Exception as e:
            logger.error(f"æ´å¯Ÿæ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _analyze_feedback_patterns(
        self, feedback_list: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """åˆ†æåé¦ˆæ¨¡å¼"""
        try:
            patterns = []

            # åˆ†æé«˜é¢‘å…³é”®è¯
            all_keywords = []
            for fb in feedback_list:
                keywords = fb.get("content", {}).get("keywords", [])
                all_keywords.extend(keywords)

            keyword_freq = Counter(all_keywords)
            top_keywords = keyword_freq.most_common(5)

            for keyword, count in top_keywords:
                patterns.append(
                    {
                        "type": "keyword_pattern",
                        "pattern": keyword,
                        "frequency": count,
                        "description": f"é«˜é¢‘å…³é”®è¯: {keyword}",
                        "confidence": min(1.0, count / len(feedback_list)),
                    }
                )

            # åˆ†æç±»å‹-æ¥æºå…³è”
            type_source_pairs = [
                (fb.get("type"), fb.get("source")) for fb in feedback_list
            ]
            pair_freq = Counter(type_source_pairs)

            for (fb_type, source), count in pair_freq.most_common(3):
                patterns.append(
                    {
                        "type": "type_source_correlation",
                        "pattern": f"{fb_type}_{source}",
                        "frequency": count,
                        "description": f"{source}æ¥æºçš„{fb_type}åé¦ˆé¢‘ç¹",
                        "confidence": min(1.0, count / len(feedback_list)),
                    }
                )

            return patterns

        except Exception as e:
            logger.error(f"åé¦ˆæ¨¡å¼åˆ†æå¤±è´¥: {str(e)}")
            return [{"type": "analysis_error", "error": str(e)}]

    async def _analyze_feedback_trends(
        self, feedback_list: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """åˆ†æåé¦ˆè¶‹åŠ¿"""
        try:
            if len(feedback_list) < 10:
                return {"message": "æ•°æ®ä¸è¶³è¿›è¡Œè¶‹åŠ¿åˆ†æ"}

            # æŒ‰æ—¶é—´çª—å£åˆ†æ
            hourly_feedback = defaultdict(list)
            for fb in feedback_list:
                timestamp = datetime.fromisoformat(
                    fb["timestamp"].replace("Z", "+00:00")
                )
                hour_key = timestamp.replace(minute=0, second=0, microsecond=0)
                hourly_feedback[hour_key].append(fb)

            # è®¡ç®—æ¯å°æ—¶æŒ‡æ ‡
            hours = sorted(hourly_feedback.keys())
            sentiment_trend = []
            volume_trend = []

            for hour in hours[-24:]:  # æœ€è¿‘24å°æ—¶
                hour_feedback = hourly_feedback[hour]
                sentiments = [
                    fb.get("content", {}).get("sentiment", 0) for fb in hour_feedback
                ]
                avg_sentiment = sum(sentiments) / len(sentiments) if sentiments else 0

                sentiment_trend.append(avg_sentiment)
                volume_trend.append(len(hour_feedback))

            # åˆ†æè¶‹åŠ¿
            sentiment_slope = await self._calculate_trend_slope(sentiment_trend)
            volume_slope = await self._calculate_trend_slope(volume_trend)

            return {
                "sentiment_trend": (
                    "improving"
                    if sentiment_slope > 0.01
                    else "declining" if sentiment_slope < -0.01 else "stable"
                ),
                "volume_trend": (
                    "increasing"
                    if volume_slope > 0.1
                    else "decreasing" if volume_slope < -0.1 else "stable"
                ),
                "sentiment_slope": sentiment_slope,
                "volume_slope": volume_slope,
                "analysis_period": f"{len(hours)}å°æ—¶",
            }

        except Exception as e:
            logger.error(f"åé¦ˆè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
            return {"error": str(e)}

    async def _calculate_trend_slope(self, values: List[float]) -> float:
        """è®¡ç®—è¶‹åŠ¿æ–œç‡"""
        if len(values) < 2:
            return 0.0

        x = list(range(len(values)))
        y = values

        n = len(x)
        sum_x = sum(x)
        sum_y = sum(y)
        sum_xy = sum(x[i] * y[i] for i in range(n))
        sum_x2 = sum(x_i * x_i for x_i in x)

        numerator = n * sum_xy - sum_x * sum_y
        denominator = n * sum_x2 - sum_x * sum_x

        return numerator / denominator if denominator != 0 else 0.0

    async def _generate_insights_recommendations(
        self, feedback_list: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæ´å¯Ÿå»ºè®®"""
        recommendations = []

        try:
            insights = await self._generate_insights_summary(feedback_list)
            trends = await self._analyze_feedback_trends(feedback_list)

            # åŸºäºè´Ÿé¢åé¦ˆæ¯”ä¾‹çš„å»ºè®®
            type_dist = insights.get("type_distribution", {})
            negative_count = type_dist.get("negative", 0) + type_dist.get("critical", 0)
            total_count = insights.get("feedback_count", 1)
            negative_ratio = negative_count / total_count

            if negative_ratio > 0.3:
                recommendations.append(
                    {
                        "type": "process_improvement",
                        "priority": "high",
                        "description": f"è´Ÿé¢åé¦ˆæ¯”ä¾‹è¾ƒé«˜({negative_ratio:.1%})ï¼Œå»ºè®®é‡ç‚¹æ”¹è¿›",
                        "action": "åˆ†æè´Ÿé¢åé¦ˆæ ¹æœ¬åŸå› å¹¶å®æ–½çº æ­£æªæ–½",
                    }
                )

            # åŸºäºæƒ…æ„Ÿè¶‹åŠ¿çš„å»ºè®®
            sentiment_trend = trends.get("sentiment_trend", "stable")
            if sentiment_trend == "declining":
                recommendations.append(
                    {
                        "type": "proactive_measure",
                        "priority": "medium",
                        "description": "æ£€æµ‹åˆ°ç”¨æˆ·æƒ…æ„Ÿä¸‹é™è¶‹åŠ¿",
                        "action": "å®æ–½é¢„é˜²æ€§æ”¹è¿›æªæ–½é˜»æ­¢è¶‹åŠ¿æ¶åŒ–",
                    }
                )

            # åŸºäºåé¦ˆæ¥æºçš„å»ºè®®
            source_dist = insights.get("source_distribution", {})
            if source_dist.get("error_reports", 0) > total_count * 0.2:
                recommendations.append(
                    {
                        "type": "quality_assurance",
                        "priority": "high",
                        "description": "é”™è¯¯æŠ¥å‘Šæ¯”ä¾‹è¾ƒé«˜ï¼Œè¡¨æ˜ç³»ç»Ÿç¨³å®šæ€§é—®é¢˜",
                        "action": "åŠ å¼ºé”™è¯¯å¤„ç†å’Œç³»ç»Ÿç¨³å®šæ€§æµ‹è¯•",
                    }
                )

            return recommendations[:5]  # è¿”å›å‰5ä¸ªå»ºè®®

        except Exception as e:
            logger.error(f"æ´å¯Ÿå»ºè®®ç”Ÿæˆå¤±è´¥: {str(e)}")
            return [
                {
                    "type": "analysis_error",
                    "priority": "medium",
                    "description": f"æ´å¯Ÿåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}",
                }
            ]

    async def get_health_status(self) -> Dict[str, Any]:
        """è·å–å¥åº·çŠ¶æ€"""
        try:
            # æ£€æŸ¥å¤„ç†çŠ¶æ€
            queue_size = self.feedback_queue.qsize()
            processed_count = len(self.processed_feedback)

            # è¯„ä¼°å¤„ç†æ•ˆç‡
            processing_efficiency = min(
                1.0, processed_count / (processed_count + queue_size + 1)
            )

            # æ£€æŸ¥ç»„ä»¶çŠ¶æ€
            components_healthy = all(
                [
                    self.sentiment_analyzer is not None,
                    self.pattern_miner is not None,
                    self.correlation_engine is not None,
                ]
            )

            # è¯„ä¼°æ•´ä½“å¥åº·çŠ¶æ€
            if components_healthy and processing_efficiency > 0.7:
                status = "healthy"
            elif components_healthy and processing_efficiency > 0.3:
                status = "degraded"
            else:
                status = "unhealthy"

            return {
                "status": status,
                "initialized": self.is_initialized,
                "running": self.running,
                "queue_size": queue_size,
                "processed_count": processed_count,
                "processing_efficiency": processing_efficiency,
                "components_healthy": components_healthy,
                "learning_model_size": len(self.learning_model),
                "pattern_count": len(self.feedback_patterns),
            }

        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "initialized": self.is_initialized,
                "running": self.running,
            }

    async def stop(self):
        """åœæ­¢åé¦ˆå¤„ç†å™¨"""
        logger.info("æ­£åœ¨åœæ­¢åé¦ˆå¤„ç†å™¨...")

        self.running = False

        if self.processing_task:
            self.processing_task.cancel()

        # ç­‰å¾…å¤„ç†å®Œæˆ
        await asyncio.sleep(1)

        logger.info("åé¦ˆå¤„ç†å™¨å·²åœæ­¢")


# è¾…åŠ©åˆ†æç»„ä»¶ç±»
class SentimentAnalyzer:
    """æƒ…æ„Ÿåˆ†æå™¨"""

    async def analyze(self, data: Any) -> float:
        """åˆ†ææƒ…æ„Ÿ"""
        try:
            text = str(data)

            # ç®€å•çš„æƒ…æ„Ÿè¯åˆ†æ
            positive_words = {
                "good",
                "great",
                "excellent",
                "fast",
                "smooth",
                "reliable",
                "stable",
                "efficient",
            }
            negative_words = {
                "bad",
                "poor",
                "slow",
                "error",
                "crash",
                "fail",
                "broken",
                "unstable",
            }

            words = set(re.findall(r"\b[a-zA-Z]+\b", text.lower()))

            positive_count = len(words & positive_words)
            negative_count = len(words & negative_words)

            total = positive_count + negative_count
            if total == 0:
                return 0.0

            sentiment = (positive_count - negative_count) / total
            return max(-1.0, min(1.0, sentiment))

        except Exception as e:
            logger.error(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {str(e)}")
            return 0.0

    async def analyze_detailed(self, feedback: Dict[str, Any]) -> Dict[str, Any]:
        """è¯¦ç»†æƒ…æ„Ÿåˆ†æ"""
        base_sentiment = await self.analyze(feedback)

        return {
            "score": base_sentiment,
            "magnitude": abs(base_sentiment),
            "category": (
                "positive"
                if base_sentiment > 0.1
                else "negative" if base_sentiment < -0.1 else "neutral"
            ),
            "confidence": min(1.0, abs(base_sentiment) * 2),  # åŸºäºå¼ºåº¦çš„ç½®ä¿¡åº¦
        }


class PatternMiner:
    """æ¨¡å¼æŒ–æ˜å™¨"""

    async def match_patterns(self, feedback: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åŒ¹é…æ¨¡å¼"""
        # ç®€åŒ–å®ç° - å®é™…ä¸­ä¼šä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å¼åŒ¹é…ç®—æ³•
        return [
            {"pattern_type": "basic", "confidence": 0.5, "description": "åŸºç¡€æ¨¡å¼åŒ¹é…"}
        ]


class CorrelationEngine:
    """å…³è”å¼•æ“"""

    async def find_correlations(
        self,
        current_feedback: Dict[str, Any],
        historical_feedback: List[Dict[str, Any]],
    ) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾å…³è”"""
        # ç®€åŒ–å®ç° - å®é™…ä¸­ä¼šä½¿ç”¨å…³è”åˆ†æç®—æ³•
        if len(historical_feedback) < 5:
            return []

        return [
            {
                "type": "temporal",
                "confidence": 0.3,
                "description": "æ—¶é—´å…³è”æ¨¡å¼",
                "related_count": min(5, len(historical_feedback)),
            }
        ]
