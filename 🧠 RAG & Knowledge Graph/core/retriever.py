"""
æ£€ç´¢å™¨ - çŸ¥è¯†æ£€ç´¢åŠŸèƒ½

å®ç°å¤šç§æ£€ç´¢ç­–ç•¥ï¼š
1. å‘é‡æ£€ç´¢ï¼ˆè¯­ä¹‰æ£€ç´¢ï¼‰
2. å…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰
3. æ··åˆæ£€ç´¢
4. é‡æ’åº
"""

from typing import List, Dict, Any, Optional
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Retriever:
    """
    æ£€ç´¢å™¨
    
    è´Ÿè´£ï¼š
    1. å‘é‡æ£€ç´¢
    2. å…³é”®è¯æ£€ç´¢  
    3. æ··åˆæ£€ç´¢
    4. ç»“æœé‡æ’åº
    """
    
    def __init__(self, vector_store=None, config: Optional[Dict] = None):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        self.vector_store = vector_store
        self.config = config or self._get_default_config()
        
        logger.info("ğŸ” æ£€ç´¢å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   æ£€ç´¢æ¨¡å¼: {self.config['retrieval_mode']}")
    
    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "retrieval_mode": "hybrid",  # vector, keyword, hybrid
            "top_k": 5,
            "similarity_threshold": 0.7,
            "enable_rerank": True,
            "rerank_top_k": 10,
            "keyword_weight": 0.3,  # æ··åˆæ£€ç´¢æ—¶å…³é”®è¯æƒé‡
            "vector_weight": 0.7    # æ··åˆæ£€ç´¢æ—¶å‘é‡æƒé‡
        }
    
    def retrieve(
        self,
        query: str,
        query_embedding: Optional[List[float]] = None,
        top_k: Optional[int] = None,
        mode: Optional[str] = None,
        filters: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            query_embedding: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›ç»“æœæ•°é‡
            mode: æ£€ç´¢æ¨¡å¼ (vector, keyword, hybrid)
            filters: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            æ£€ç´¢ç»“æœ
        """
        top_k = top_k or self.config["top_k"]
        mode = mode or self.config["retrieval_mode"]
        
        logger.info(f"\nğŸ” å¼€å§‹æ£€ç´¢")
        logger.info(f"   æŸ¥è¯¢: {query[:50]}...")
        logger.info(f"   æ¨¡å¼: {mode}")
        logger.info(f"   è¿”å›: top-{top_k}")
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©æ£€ç´¢æ–¹æ³•
        if mode == "vector":
            results = self._vector_retrieve(query_embedding, top_k, filters)
        elif mode == "keyword":
            results = self._keyword_retrieve(query, top_k, filters)
        elif mode == "hybrid":
            results = self._hybrid_retrieve(query, query_embedding, top_k, filters)
        else:
            logger.warning(f"âš ï¸  æœªçŸ¥æ£€ç´¢æ¨¡å¼: {mode}ï¼Œä½¿ç”¨å‘é‡æ£€ç´¢")
            results = self._vector_retrieve(query_embedding, top_k, filters)
        
        # é‡æ’åºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config["enable_rerank"] and len(results) > 0:
            results = self._rerank(query, results)
        
        # è¿‡æ»¤ä½åˆ†ç»“æœ
        threshold = self.config["similarity_threshold"]
        results = [r for r in results if r.get("score", 0) >= threshold]
        
        logger.info(f"âœ… æ£€ç´¢å®Œæˆ: æ‰¾åˆ°{len(results)}ä¸ªç»“æœ")
        
        return {
            "success": True,
            "query": query,
            "mode": mode,
            "results": results[:top_k],
            "total_results": len(results)
        }
    
    def _vector_retrieve(
        self,
        query_embedding: List[float],
        top_k: int,
        filters: Optional[Dict] = None
    ) -> List[Dict]:
        """å‘é‡æ£€ç´¢"""
        logger.info("   æ‰§è¡Œå‘é‡æ£€ç´¢...")
        
        if not self.vector_store:
            logger.warning("   âš ï¸  æœªé…ç½®å‘é‡å­˜å‚¨ï¼Œè¿”å›ç©ºç»“æœ")
            return []
        
        if not query_embedding:
            logger.warning("   âš ï¸  æœªæä¾›æŸ¥è¯¢å‘é‡ï¼Œè¿”å›ç©ºç»“æœ")
            return []
        
        # æŸ¥è¯¢å‘é‡åº“
        query_result = self.vector_store.query(
            query_embedding=query_embedding,
            n_results=top_k * 2,  # å¤šå–ä¸€äº›ï¼Œç”¨äºåç»­é‡æ’åº
            where=filters
        )
        
        if not query_result.get("success"):
            return []
        
        return query_result.get("results", [])
    
    def _keyword_retrieve(
        self,
        query: str,
        top_k: int,
        filters: Optional[Dict] = None
    ) -> List[Dict]:
        """å…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰"""
        logger.info("   æ‰§è¡Œå…³é”®è¯æ£€ç´¢...")
        
        # TODO: å®ç°BM25æ£€ç´¢
        # éœ€è¦ï¼š
        # 1. åˆ†è¯
        # 2. è®¡ç®—TF-IDF
        # 3. BM25è¯„åˆ†
        
        logger.warning("   âš ï¸  å…³é”®è¯æ£€ç´¢åŠŸèƒ½å¾…å®ç°")
        return []
    
    def _hybrid_retrieve(
        self,
        query: str,
        query_embedding: Optional[List[float]],
        top_k: int,
        filters: Optional[Dict] = None
    ) -> List[Dict]:
        """æ··åˆæ£€ç´¢"""
        logger.info("   æ‰§è¡Œæ··åˆæ£€ç´¢...")
        
        # 1. å‘é‡æ£€ç´¢
        vector_results = self._vector_retrieve(query_embedding, top_k * 2, filters)
        
        # 2. å…³é”®è¯æ£€ç´¢
        keyword_results = self._keyword_retrieve(query, top_k * 2, filters)
        
        # 3. åˆå¹¶ç»“æœ
        if not keyword_results:
            # å¦‚æœå…³é”®è¯æ£€ç´¢æ²¡æœ‰ç»“æœï¼Œåªç”¨å‘é‡æ£€ç´¢
            return vector_results
        
        # èåˆä¸¤ç§æ£€ç´¢ç»“æœï¼ˆç®€å•å®ç°ï¼šåŠ æƒå¹³å‡ï¼‰
        vector_weight = self.config["vector_weight"]
        keyword_weight = self.config["keyword_weight"]
        
        # æ„å»ºæ–‡æ¡£IDåˆ°åˆ†æ•°çš„æ˜ å°„
        scores = {}
        
        # å‘é‡æ£€ç´¢åˆ†æ•°
        for result in vector_results:
            doc_id = result["id"]
            scores[doc_id] = {
                "vector_score": result.get("score", 0),
                "keyword_score": 0,
                "result": result
            }
        
        # å…³é”®è¯æ£€ç´¢åˆ†æ•°
        for result in keyword_results:
            doc_id = result["id"]
            if doc_id in scores:
                scores[doc_id]["keyword_score"] = result.get("score", 0)
            else:
                scores[doc_id] = {
                    "vector_score": 0,
                    "keyword_score": result.get("score", 0),
                    "result": result
                }
        
        # è®¡ç®—ç»¼åˆåˆ†æ•°
        hybrid_results = []
        for doc_id, score_data in scores.items():
            final_score = (
                score_data["vector_score"] * vector_weight +
                score_data["keyword_score"] * keyword_weight
            )
            
            result = score_data["result"].copy()
            result["score"] = final_score
            result["vector_score"] = score_data["vector_score"]
            result["keyword_score"] = score_data["keyword_score"]
            hybrid_results.append(result)
        
        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        hybrid_results.sort(key=lambda x: x["score"], reverse=True)
        
        logger.info(f"   æ··åˆäº†{len(vector_results)}ä¸ªå‘é‡ç»“æœå’Œ{len(keyword_results)}ä¸ªå…³é”®è¯ç»“æœ")
        
        return hybrid_results
    
    def _rerank(self, query: str, results: List[Dict]) -> List[Dict]:
        """
        é‡æ’åº
        
        ä½¿ç”¨æ›´ç²¾ç¡®çš„æ–¹æ³•é‡æ–°æ’åºç»“æœ
        """
        logger.info("   æ‰§è¡Œç»“æœé‡æ’åº...")
        
        # TODO: å®ç°é‡æ’åº
        # å¯ä»¥ä½¿ç”¨ï¼š
        # 1. äº¤å‰ç¼–ç å™¨ï¼ˆCross-encoderï¼‰
        # 2. åŸºäºè§„åˆ™çš„é‡æ’åº
        # 3. å¤šå› ç´ ç»¼åˆè¯„åˆ†
        
        # ç®€å•å®ç°ï¼šåŸºäºæŸ¥è¯¢é•¿åº¦å’Œæ–‡æ¡£é•¿åº¦çš„è°ƒæ•´
        for result in results:
            doc_text = result.get("document", "")
            
            # è€ƒè™‘æ–‡æ¡£é•¿åº¦ï¼ˆä¸è¦å¤ªçŸ­ä¹Ÿä¸è¦å¤ªé•¿ï¼‰
            ideal_length = 500
            length_score = 1 - abs(len(doc_text) - ideal_length) / ideal_length
            length_score = max(0, min(1, length_score))
            
            # è°ƒæ•´åˆ†æ•°
            original_score = result.get("score", 0)
            result["score"] = original_score * 0.8 + length_score * 0.2
            result["reranked"] = True
        
        # é‡æ–°æ’åº
        results.sort(key=lambda x: x.get("score", 0), reverse=True)
        
        return results
    
    def get_context(
        self,
        query: str,
        query_embedding: Optional[List[float]] = None,
        max_length: int = 2000
    ) -> str:
        """
        è·å–æ£€ç´¢ä¸Šä¸‹æ–‡ï¼ˆç”¨äºRAGï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            query_embedding: æŸ¥è¯¢å‘é‡
            max_length: æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
            
        Returns:
            ç»„åˆçš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£
        retrieval_result = self.retrieve(
            query=query,
            query_embedding=query_embedding
        )
        
        if not retrieval_result.get("success"):
            return ""
        
        # ç»„åˆä¸Šä¸‹æ–‡
        context_parts = []
        current_length = 0
        
        for result in retrieval_result.get("results", []):
            doc_text = result.get("document", "")
            
            if current_length + len(doc_text) > max_length:
                # æˆªæ–­
                remaining = max_length - current_length
                if remaining > 100:  # è‡³å°‘ä¿ç•™100å­—ç¬¦
                    context_parts.append(doc_text[:remaining])
                break
            
            context_parts.append(doc_text)
            current_length += len(doc_text)
        
        context = "\n\n".join(context_parts)
        
        logger.info(f"   ç”Ÿæˆä¸Šä¸‹æ–‡: {len(context)}å­—ç¬¦")
        
        return context


def test_retriever():
    """æµ‹è¯•æ£€ç´¢å™¨"""
    print("="*70)
    print("  æ£€ç´¢å™¨æµ‹è¯•")
    print("="*70)
    
    # æ¨¡æ‹Ÿå‘é‡å­˜å‚¨
    class MockVectorStore:
        def query(self, query_embedding, n_results, where=None):
            # è¿”å›æ¨¡æ‹Ÿç»“æœ
            return {
                "success": True,
                "results": [
                    {
                        "id": "doc_1",
                        "document": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºæ™ºèƒ½æœºå™¨ã€‚",
                        "metadata": {"topic": "AI"},
                        "score": 0.95
                    },
                    {
                        "id": "doc_2",
                        "document": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„å­é›†ï¼Œä¸“æ³¨äºè®©æœºå™¨ä»æ•°æ®ä¸­å­¦ä¹ ã€‚",
                        "metadata": {"topic": "ML"},
                        "score": 0.88
                    },
                    {
                        "id": "doc_3",
                        "document": "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ã€‚",
                        "metadata": {"topic": "DL"},
                        "score": 0.82
                    }
                ]
            }
    
    # åˆ›å»ºæ¨¡æ‹Ÿå‘é‡
    def create_mock_embedding():
        import random
        return [random.random() for _ in range(384)]
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    mock_store = MockVectorStore()
    retriever = Retriever(vector_store=mock_store)
    
    # æµ‹è¯•å‘é‡æ£€ç´¢
    print("\n1. æµ‹è¯•å‘é‡æ£€ç´¢:")
    query_embedding = create_mock_embedding()
    
    result = retriever.retrieve(
        query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        query_embedding=query_embedding,
        mode="vector",
        top_k=3
    )
    
    print(f"   æ£€ç´¢æˆåŠŸ: {result['success']}")
    print(f"   æ‰¾åˆ°ç»“æœ: {result['total_results']}ä¸ª")
    
    for i, res in enumerate(result['results'], 1):
        print(f"\n   ç»“æœ{i}:")
        print(f"     æ–‡æ¡£: {res['document']}")
        print(f"     åˆ†æ•°: {res['score']:.3f}")
    
    # æµ‹è¯•è·å–ä¸Šä¸‹æ–‡
    print("\n2. æµ‹è¯•è·å–ä¸Šä¸‹æ–‡:")
    context = retriever.get_context(
        query="ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        query_embedding=query_embedding,
        max_length=500
    )
    
    print(f"   ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)}å­—ç¬¦")
    print(f"   ä¸Šä¸‹æ–‡é¢„è§ˆ: {context[:100]}...")
    
    print("\nâœ… æ£€ç´¢å™¨æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    test_retriever()



