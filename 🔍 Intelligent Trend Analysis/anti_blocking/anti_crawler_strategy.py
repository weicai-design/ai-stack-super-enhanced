"""
åçˆ¬è™«ç­–ç•¥
- User-Agentè½®æ¢
- IPä»£ç†æ± 
- è¯·æ±‚é¢‘ç‡æ§åˆ¶
- éªŒè¯ç å¤„ç†
"""
from typing import Dict, Any, List
import random
import time
from datetime import datetime, timedelta


class AntiCrawlerStrategy:
    """åçˆ¬è™«ç­–ç•¥ç®¡ç†"""
    
    def __init__(self):
        # User-Agentæ± 
        self.user_agents = [
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36",
            "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15",
            "Mozilla/5.0 (iPad; CPU OS 14_0 like Mac OS X) AppleWebKit/605.1.15"
        ]
        
        # IPä»£ç†æ± ï¼ˆç¤ºä¾‹ï¼‰
        self.proxy_pool = []
        
        # è¯·æ±‚é¢‘ç‡æ§åˆ¶
        self.request_intervals = {
            "default": (2, 5),      # 2-5ç§’
            "conservative": (5, 10), # 5-10ç§’
            "aggressive": (1, 3)     # 1-3ç§’
        }
        
        # è¯·æ±‚å†å²
        self.request_history = []
        
        # é»‘åå•ï¼ˆè¢«å°çš„åŸŸå/IPï¼‰
        self.blacklist = []
    
    # ============ è¯·æ±‚ç­–ç•¥ ============
    
    def get_request_headers(self, strategy: str = "default") -> Dict[str, str]:
        """
        è·å–è¯·æ±‚å¤´
        
        Args:
            strategy: ç­–ç•¥ç±»å‹ï¼ˆdefault/conservative/aggressiveï¼‰
        
        Returns:
            è¯·æ±‚å¤´
        """
        # éšæœºUser-Agent
        user_agent = random.choice(self.user_agents)
        
        headers = {
            "User-Agent": user_agent,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Cache-Control": "max-age=0"
        }
        
        # éšæœºæ·»åŠ Referer
        if random.random() > 0.5:
            headers["Referer"] = "https://www.google.com/"
        
        return headers
    
    def get_request_delay(self, strategy: str = "default") -> float:
        """
        è·å–è¯·æ±‚å»¶è¿Ÿ
        
        Args:
            strategy: ç­–ç•¥ç±»å‹
        
        Returns:
            å»¶è¿Ÿç§’æ•°
        """
        interval = self.request_intervals.get(strategy, self.request_intervals["default"])
        min_delay, max_delay = interval
        
        # éšæœºå»¶è¿Ÿ
        delay = random.uniform(min_delay, max_delay)
        
        return delay
    
    def get_proxy(self) -> Optional[str]:
        """
        è·å–ä»£ç†
        
        Returns:
            ä»£ç†åœ°å€æˆ–None
        """
        if not self.proxy_pool:
            return None
        
        # éšæœºé€‰æ‹©ä¸€ä¸ªå¯ç”¨ä»£ç†
        available_proxies = [p for p in self.proxy_pool if p not in self.blacklist]
        
        if not available_proxies:
            return None
        
        return random.choice(available_proxies)
    
    # ============ è¯·æ±‚é¢‘ç‡æ§åˆ¶ ============
    
    def should_wait(self, domain: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…
        
        Args:
            domain: ç›®æ ‡åŸŸå
        
        Returns:
            æ˜¯å¦éœ€è¦ç­‰å¾…
        """
        # æ£€æŸ¥æœ€è¿‘å¯¹è¯¥åŸŸåçš„è¯·æ±‚
        recent_requests = [
            r for r in self.request_history
            if r['domain'] == domain and
            datetime.fromisoformat(r['timestamp']) > datetime.utcnow() - timedelta(minutes=1)
        ]
        
        # å¦‚æœ1åˆ†é’Ÿå†…è¯·æ±‚è¶…è¿‡10æ¬¡ï¼Œéœ€è¦ç­‰å¾…
        return len(recent_requests) > 10
    
    def record_request(
        self,
        domain: str,
        success: bool,
        response_code: Optional[int] = None
    ):
        """
        è®°å½•è¯·æ±‚
        
        Args:
            domain: åŸŸå
            success: æ˜¯å¦æˆåŠŸ
            response_code: å“åº”ä»£ç 
        """
        self.request_history.append({
            "domain": domain,
            "success": success,
            "response_code": response_code,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        # åªä¿ç•™æœ€è¿‘1000æ¡
        if len(self.request_history) > 1000:
            self.request_history = self.request_history[-1000:]
        
        # æ£€æŸ¥æ˜¯å¦è¢«å°
        if response_code in [403, 429]:  # 403 Forbidden, 429 Too Many Requests
            self._handle_blocked(domain)
    
    def _handle_blocked(self, domain: str):
        """å¤„ç†è¢«å°æƒ…å†µ"""
        print(f"âš ï¸ åŸŸå {domain} å¯èƒ½è¢«å°é”ï¼Œå“åº”ç 403/429")
        
        # æ·»åŠ åˆ°é»‘åå•ï¼ˆä¸´æ—¶ï¼‰
        if domain not in self.blacklist:
            self.blacklist.append(domain)
        
        # è‡ªåŠ¨åˆ‡æ¢ç­–ç•¥ä¸ºä¿å®ˆæ¨¡å¼
        print(f"ğŸ“‹ è‡ªåŠ¨åˆ‡æ¢ä¸ºä¿å®ˆçˆ¬å–æ¨¡å¼")
    
    # ============ ç»Ÿè®¡åˆ†æ ============
    
    def get_request_statistics(self) -> Dict[str, Any]:
        """è·å–è¯·æ±‚ç»Ÿè®¡"""
        try:
            total = len(self.request_history)
            
            if total == 0:
                return {
                    "success": True,
                    "statistics": {
                        "total_requests": 0
                    }
                }
            
            successful = sum(1 for r in self.request_history if r['success'])
            success_rate = (successful / total * 100) if total > 0 else 0
            
            # æŒ‰åŸŸåç»Ÿè®¡
            domain_stats = defaultdict(lambda: {"total": 0, "success": 0})
            for req in self.request_history:
                domain = req['domain']
                domain_stats[domain]["total"] += 1
                if req['success']:
                    domain_stats[domain]["success"] += 1
            
            # è¢«å°åŸŸå
            blocked_domains = [
                d for d, stats in domain_stats.items()
                if stats['success'] / stats['total'] < 0.5  # æˆåŠŸç‡ä½äº50%
            ]
            
            return {
                "success": True,
                "statistics": {
                    "total_requests": total,
                    "successful_requests": successful,
                    "success_rate": float(success_rate),
                    "blacklisted_domains": len(self.blacklist),
                    "potentially_blocked": blocked_domains,
                    "domain_stats": dict(domain_stats)
                }
            }
        
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def add_proxy(self, proxy_url: str):
        """æ·»åŠ ä»£ç†åˆ°ä»£ç†æ± """
        if proxy_url not in self.proxy_pool:
            self.proxy_pool.append(proxy_url)
    
    def remove_proxy(self, proxy_url: str):
        """ä»ä»£ç†æ± ç§»é™¤ä»£ç†"""
        if proxy_url in self.proxy_pool:
            self.proxy_pool.remove(proxy_url)


# å…¨å±€å®ä¾‹
anti_crawler = AntiCrawlerStrategy()

