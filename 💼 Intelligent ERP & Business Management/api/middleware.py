"""
ERP API Middleware and Error Handling
ERP APIä¸­é—´ä»¶å’Œé”™è¯¯å¤„ç†

ç”Ÿäº§çº§APIæ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†æœºåˆ¶ - T0006-3å¢å¼ºç‰ˆ + T0006-4æ€§èƒ½ç›‘æ§é›†æˆ
"""

import time
import logging
import traceback
import asyncio
import redis
from typing import Callable, Dict, Any, Optional
from fastapi import Request, Response, HTTPException
from fastapi.responses import JSONResponse
from starlette.middleware.base import BaseHTTPMiddleware
from contextlib import contextmanager
from functools import wraps
import json

# å¯¼å…¥æ€§èƒ½ç›‘æ§ç³»ç»Ÿ - T0006-4
from .performance_monitor import record_api_performance, get_performance_monitor

# é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger("erp_api")

# Redisç¼“å­˜å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
redis_client: Optional[redis.Redis] = None

try:
    redis_client = redis.Redis(
        host='localhost', 
        port=6379, 
        db=0, 
        decode_responses=True,
        socket_connect_timeout=5,
        socket_timeout=5
    )
    # æµ‹è¯•è¿æ¥
    redis_client.ping()
    logger.info("âœ… Redisç¼“å­˜å·²è¿æ¥")
except Exception as e:
    logger.warning(f"âŒ Redisè¿æ¥å¤±è´¥: {e}, å°†ä½¿ç”¨å†…å­˜ç¼“å­˜")
    redis_client = None


class PerformanceMiddleware(BaseHTTPMiddleware):
    """å¢å¼ºç‰ˆæ€§èƒ½ç›‘æ§ä¸­é—´ä»¶ - T0006-3ä¼˜åŒ– + T0006-4æ€§èƒ½ç›‘æ§é›†æˆ"""
    
    def __init__(self, app, enable_metrics: bool = True, enable_cache: bool = True, redis_client: Optional[redis.Redis] = None):
        super().__init__(app)
        self.enable_metrics = enable_metrics
        self.enable_cache = enable_cache
        self.redis_client = redis_client
        
        # åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨ - T0006-4
        self.performance_monitor = get_performance_monitor(redis_client)
        
        # ä¼ ç»Ÿç»Ÿè®¡ä¿¡æ¯ï¼ˆå‘åå…¼å®¹ï¼‰
        self.request_stats = {
            "total_requests": 0,
            "slow_requests": 0,
            "error_requests": 0,
            "avg_response_time": 0.0
        }
    
    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        """å¤„ç†è¯·æ±‚å¹¶è®°å½•æ€§èƒ½æŒ‡æ ‡ - T0006-4é›†æˆç‰ˆæœ¬"""
        start_time = time.time()
        
        # è¯·æ±‚æ ‡è¯†
        request_id = f"{int(start_time * 1000)}_{request.method}_{request.url.path}"
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        cache_key = None
        if self.enable_cache and self.redis_client and request.method == "GET":
            cache_key = f"api_cache:{request_id}"
            try:
                cached_response = self.redis_client.get(cache_key)
                if cached_response:
                    logger.info(f"ğŸ“¦ ç¼“å­˜å‘½ä¸­: {request.url.path}")
                    
                    # è®°å½•ç¼“å­˜å‘½ä¸­æ€§èƒ½æŒ‡æ ‡ - T0006-4
                    if self.enable_metrics:
                        record_api_performance(
                            endpoint=request.url.path,
                            method=request.method,
                            response_time=0.001,  # ç¼“å­˜å‘½ä¸­å“åº”æ—¶é—´æçŸ­
                            status_code=200,
                            cache_hit=True
                        )
                    
                    return JSONResponse(content=json.loads(cached_response))
            except Exception as e:
                logger.warning(f"ç¼“å­˜è¯»å–å¤±è´¥: {e}")
        
        # å¤„ç†è¯·æ±‚
        try:
            response = await call_next(request)
            
            # è®°å½•å“åº”æ—¶é—´
            response_time = time.time() - start_time
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.request_stats["total_requests"] += 1
            self.request_stats["avg_response_time"] = (
                (self.request_stats["avg_response_time"] * (self.request_stats["total_requests"] - 1) + response_time) / 
                self.request_stats["total_requests"]
            )
            
            # è®°å½•æ…¢è¯·æ±‚
            if response_time > 2.0:  # è¶…è¿‡2ç§’è§†ä¸ºæ…¢è¯·æ±‚
                self.request_stats["slow_requests"] += 1
                logger.warning(f"ğŸŒ æ…¢è¯·æ±‚: {request.url.path} - {response_time:.2f}s")
            
            # ç¼“å­˜å“åº”ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.enable_cache and cache_key and self.redis_client and response.status_code == 200:
                try:
                    # åªç¼“å­˜æˆåŠŸçš„GETè¯·æ±‚
                    if hasattr(response, 'body'):
                        self.redis_client.setex(cache_key, 300, response.body.decode())  # ç¼“å­˜5åˆ†é’Ÿ
                        logger.info(f"ğŸ’¾ ç¼“å­˜å†™å…¥: {request.url.path}")
                except Exception as e:
                    logger.warning(f"ç¼“å­˜å†™å…¥å¤±è´¥: {e}")
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡ - T0006-4é›†æˆ
            if self.enable_metrics:
                logger.info(f"ğŸ“Š è¯·æ±‚å®Œæˆ: {request.url.path} - {response_time:.3f}s")
                
                # ä½¿ç”¨æ–°çš„æ€§èƒ½ç›‘æ§ç³»ç»Ÿè®°å½•æŒ‡æ ‡
                record_api_performance(
                    endpoint=request.url.path,
                    method=request.method,
                    response_time=response_time,
                    status_code=response.status_code,
                    cache_hit=False
                )
            
            return response
            
        except Exception as e:
            # è®°å½•é”™è¯¯
            response_time = time.time() - start_time
            self.request_stats["error_requests"] += 1
            
            logger.error(f"âŒ è¯·æ±‚é”™è¯¯: {request.url.path} - {str(e)}")
            logger.error(traceback.format_exc())
            
            # è®°å½•é”™è¯¯æ€§èƒ½æŒ‡æ ‡ - T0006-4
            if self.enable_metrics:
                record_api_performance(
                    endpoint=request.url.path,
                    method=request.method,
                    response_time=response_time,
                    status_code=500,
                    cache_hit=False,
                    error_type=type(e).__name__
                )
            
            # è¿”å›é”™è¯¯å“åº”
            return JSONResponse(
                status_code=500,
                content={
                    "error": "Internal Server Error",
                    "message": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
                    "request_id": request_id
                }
            )


class ErrorHandlingMiddleware(BaseHTTPMiddleware):
    """å¢å¼ºç‰ˆå…¨å±€é”™è¯¯å¤„ç†ä¸­é—´ä»¶ - T0006-3ä¼˜åŒ–"""
    
    def __init__(self, app, enable_recovery: bool = True, retry_count: int = 0):
        super().__init__(app)
        self.enable_recovery = enable_recovery
        self.retry_count = retry_count
    
    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        # é”™è¯¯åˆ†ç±»å’Œæ¢å¤æœºåˆ¶
        retry_attempts = 0
        
        while retry_attempts <= self.retry_count:
            try:
                response = await call_next(request)
                return response
            except HTTPException as e:
                # FastAPIçš„HTTPå¼‚å¸¸ç›´æ¥æŠ›å‡º
                logger.warning(
                    f"HTTP Exception - Method: {request.method}, Path: {request.url.path}, "
                    f"Status: {e.status_code}, Detail: {e.detail}"
                )
                raise
            except ConnectionError as e:
                # è¿æ¥é”™è¯¯ï¼ˆæ•°æ®åº“ã€å¤–éƒ¨APIç­‰ï¼‰
                error_id = f"CONN-{int(time.time())}"
                logger.error(
                    f"Connection Error - ID: {error_id}, Method: {request.method}, "
                    f"Path: {request.url.path}, Error: {str(e)}, Attempt: {retry_attempts}"
                )
                
                if retry_attempts < self.retry_count and self.enable_recovery:
                    retry_attempts += 1
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue
                
                return JSONResponse(
                    status_code=503,
                    content={
                        "error": "Service Unavailable",
                        "error_id": error_id,
                        "message": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•",
                        "retry_after": 30,
                        "timestamp": time.time()
                    }
                )
            except TimeoutError as e:
                # è¶…æ—¶é”™è¯¯
                error_id = f"TIMEOUT-{int(time.time())}"
                logger.error(
                    f"Timeout Error - ID: {error_id}, Method: {request.method}, "
                    f"Path: {request.url.path}, Error: {str(e)}, Attempt: {retry_attempts}"
                )
                
                if retry_attempts < self.retry_count and self.enable_recovery:
                    retry_attempts += 1
                    await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
                    continue
                
                return JSONResponse(
                    status_code=504,
                    content={
                        "error": "Gateway Timeout",
                        "error_id": error_id,
                        "message": "è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
                        "timeout": 30,
                        "timestamp": time.time()
                    }
                )
            except ValueError as e:
                # æ•°æ®éªŒè¯é”™è¯¯
                error_id = f"VALIDATION-{int(time.time())}"
                logger.warning(
                    f"Validation Error - ID: {error_id}, Method: {request.method}, "
                    f"Path: {request.url.path}, Error: {str(e)}"
                )
                
                return JSONResponse(
                    status_code=400,
                    content={
                        "error": "Bad Request",
                        "error_id": error_id,
                        "message": "è¾“å…¥æ•°æ®æ ¼å¼é”™è¯¯",
                        "details": str(e),
                        "timestamp": time.time()
                    }
                )
            except Exception as e:
                # å…¶ä»–æœªå¤„ç†å¼‚å¸¸
                error_id = f"UNHANDLED-{int(time.time())}"
                logger.error(
                    f"Unhandled API Error - ID: {error_id}, Method: {request.method}, "
                    f"Path: {request.url.path}, Error: {str(e)}, Traceback: {traceback.format_exc()}"
                )
                
                if retry_attempts < self.retry_count and self.enable_recovery:
                    retry_attempts += 1
                    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                    continue
                
                # è¿”å›æ ‡å‡†åŒ–çš„é”™è¯¯å“åº”
                return JSONResponse(
                    status_code=500,
                    content={
                        "error": "Internal Server Error",
                        "error_id": error_id,
                        "message": "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•",
                        "timestamp": time.time()
                    }
                )
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        error_id = f"FATAL-{int(time.time())}"
        logger.critical(
            f"Fatal API Error - ID: {error_id}, Method: {request.method}, "
            f"Path: {request.url.path}, All retry attempts failed"
        )
        
        return JSONResponse(
            status_code=500,
            content={
                "error": "Service Unavailable",
                "error_id": error_id,
                "message": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åè”ç³»ç®¡ç†å‘˜",
                "timestamp": time.time()
            }
        )


class RateLimitingMiddleware(BaseHTTPMiddleware):
    """å¢å¼ºç‰ˆæ™ºèƒ½é€Ÿç‡é™åˆ¶ä¸­é—´ä»¶ - T0006-3ä¼˜åŒ–"""
    
    def __init__(self, app, 
                 max_requests: int = 100, 
                 window_seconds: int = 60,
                 burst_limit: int = 20,
                 enable_redis: bool = False,
                 redis_client = None):
        super().__init__(app)
        self.max_requests = max_requests
        self.window_seconds = window_seconds
        self.burst_limit = burst_limit
        self.enable_redis = enable_redis
        self.redis_client = redis_client
        
        # æœ¬åœ°å†…å­˜å­˜å‚¨ï¼ˆç”¨äºå•æœºæ¨¡å¼ï¼‰
        self.request_counts = {}
        self.burst_counts = {}
        
        # æ™ºèƒ½é™æµç­–ç•¥ï¼šä¸åŒAPIè·¯å¾„çš„ä¸åŒé™åˆ¶
        self.api_limits = {
            "/api/customer/": {"max_requests": 200, "window_seconds": 60},
            "/api/order/": {"max_requests": 150, "window_seconds": 60},
            "/api/inventory/": {"max_requests": 100, "window_seconds": 60},
            "/api/finance/": {"max_requests": 50, "window_seconds": 60},
            "/api/production/": {"max_requests": 80, "window_seconds": 60},
            "/api/quality/": {"max_requests": 120, "window_seconds": 60}
        }
    
    async def dispatch(self, request: Request, call_next: Callable) -> Response:
        client_ip = request.client.host if request.client else "unknown"
        current_time = time.time()
        api_path = request.url.path
        
        # è·å–ç‰¹å®šAPIè·¯å¾„çš„é™åˆ¶é…ç½®
        api_limit = self._get_api_limit(api_path)
        max_requests = api_limit.get("max_requests", self.max_requests)
        window_seconds = api_limit.get("window_seconds", self.window_seconds)
        
        # åˆ†å¸ƒå¼é™æµï¼ˆå¦‚æœå¯ç”¨Redisï¼‰
        if self.enable_redis and self.redis_client:
            return await self._distributed_rate_limit(
                client_ip, api_path, max_requests, window_seconds, request, call_next
            )
        else:
            # æœ¬åœ°å†…å­˜é™æµ
            return await self._local_rate_limit(
                client_ip, api_path, max_requests, window_seconds, request, call_next
            )
    
    async def _distributed_rate_limit(self, client_ip: str, api_path: str, 
                                     max_requests: int, window_seconds: int,
                                     request: Request, call_next: Callable) -> Response:
        """åˆ†å¸ƒå¼é€Ÿç‡é™åˆ¶ï¼ˆRedisæ”¯æŒï¼‰"""
        current_time = time.time()
        redis_key = f"rate_limit:{client_ip}:{api_path}"
        
        try:
            # ä½¿ç”¨Redisæœ‰åºé›†åˆå®ç°æ»‘åŠ¨çª—å£
            pipeline = self.redis_client.pipeline()
            pipeline.zadd(redis_key, {str(current_time): current_time})
            pipeline.zremrangebyscore(redis_key, 0, current_time - window_seconds)
            pipeline.zcard(redis_key)
            pipeline.expire(redis_key, window_seconds)
            
            results = pipeline.execute()
            request_count = results[2]
            
            if request_count > max_requests:
                # è®¡ç®—å‰©ä½™æ—¶é—´
                oldest_request = self.redis_client.zrange(redis_key, 0, 0, withscores=True)
                if oldest_request:
                    oldest_time = oldest_request[0][1]
                    retry_after = int(window_seconds - (current_time - oldest_time))
                else:
                    retry_after = window_seconds
                
                return JSONResponse(
                    status_code=429,
                    content={
                        "error": "Too Many Requests",
                        "message": f"è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{retry_after}ç§’åå†è¯•",
                        "retry_after": retry_after,
                        "current_requests": request_count,
                        "max_requests": max_requests
                    }
                )
            
            # ç»§ç»­å¤„ç†è¯·æ±‚
            response = await call_next(request)
            return response
            
        except Exception as e:
            logger.error(f"Redis rate limiting failed: {str(e)}")
            # Rediså¤±è´¥æ—¶é™çº§åˆ°æœ¬åœ°é™æµ
            return await self._local_rate_limit(
                client_ip, api_path, max_requests, window_seconds, request, call_next
            )
    
    async def _local_rate_limit(self, client_ip: str, api_path: str,
                               max_requests: int, window_seconds: int,
                               request: Request, call_next: Callable) -> Response:
        """æœ¬åœ°å†…å­˜é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        client_key = f"{client_ip}:{api_path}"
        
        # æ¸…ç†è¿‡æœŸè®°å½•
        self._cleanup_expired_records(current_time, window_seconds)
        
        # è·å–æˆ–åˆå§‹åŒ–å®¢æˆ·ç«¯è¯·æ±‚è®¡æ•°
        if client_key not in self.request_counts:
            self.request_counts[client_key] = []
        
        # æ£€æŸ¥çªå‘æµé‡é™åˆ¶
        if client_key not in self.burst_counts:
            self.burst_counts[client_key] = {"count": 0, "last_reset": current_time}
        
        burst_info = self.burst_counts[client_key]
        
        # æ¯5ç§’é‡ç½®çªå‘è®¡æ•°
        if current_time - burst_info["last_reset"] > 5:
            burst_info["count"] = 0
            burst_info["last_reset"] = current_time
        
        # æ£€æŸ¥çªå‘é™åˆ¶
        burst_info["count"] += 1
        if burst_info["count"] > self.burst_limit:
            return JSONResponse(
                status_code=429,
                content={
                    "error": "Burst Limit Exceeded",
                    "message": "çªå‘æµé‡è¶…è¿‡é™åˆ¶ï¼Œè¯·ç¨åé‡è¯•",
                    "retry_after": 5
                }
            )
        
        # æ·»åŠ å½“å‰è¯·æ±‚æ—¶é—´
        self.request_counts[client_key].append(current_time)
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        recent_requests = [t for t in self.request_counts[client_key] 
                          if current_time - t <= window_seconds]
        
        if len(recent_requests) > max_requests:
            # è®¡ç®—æœ€æ—©çš„æœ‰æ•ˆè¯·æ±‚æ—¶é—´
            oldest_valid_time = current_time - window_seconds
            valid_requests = [t for t in recent_requests if t > oldest_valid_time]
            
            if valid_requests:
                oldest_request = min(valid_requests)
                retry_after = int(window_seconds - (current_time - oldest_request))
            else:
                retry_after = window_seconds
            
            return JSONResponse(
                status_code=429,
                content={
                    "error": "Too Many Requests",
                    "message": f"è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·{retry_after}ç§’åå†è¯•",
                    "retry_after": retry_after,
                    "current_requests": len(recent_requests),
                    "max_requests": max_requests
                }
            )
        
        # æ›´æ–°è¯·æ±‚è®¡æ•°
        self.request_counts[client_key] = recent_requests
        
        # ç»§ç»­å¤„ç†è¯·æ±‚
        response = await call_next(request)
        
        # æ·»åŠ é€Ÿç‡é™åˆ¶å¤´ä¿¡æ¯
        response.headers["X-RateLimit-Limit"] = str(max_requests)
        response.headers["X-RateLimit-Remaining"] = str(max_requests - len(recent_requests))
        response.headers["X-RateLimit-Reset"] = str(int(current_time + window_seconds))
        
        return response
    
    def _get_api_limit(self, api_path: str) -> dict:
        """è·å–ç‰¹å®šAPIè·¯å¾„çš„é™åˆ¶é…ç½®"""
        for path_prefix, limit_config in self.api_limits.items():
            if api_path.startswith(path_prefix):
                return limit_config
        return {"max_requests": self.max_requests, "window_seconds": self.window_seconds}
    
    def _cleanup_expired_records(self, current_time: float, window_seconds: int):
        """æ¸…ç†è¿‡æœŸè®°å½•"""
        expired_keys = []
        for key, timestamps in self.request_counts.items():
            valid_timestamps = [t for t in timestamps 
                               if current_time - t <= window_seconds]
            if not valid_timestamps:
                expired_keys.append(key)
            else:
                self.request_counts[key] = valid_timestamps
        
        for key in expired_keys:
            del self.request_counts[key]
            if key in self.burst_counts:
                del self.burst_counts[key]


@contextmanager
def api_performance_monitor(endpoint_name: str):
    """APIæ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start_time = time.time()
    try:
        yield
    finally:
        process_time = time.time() - start_time
        if process_time > 1.0:
            logger.warning(f"Slow API Endpoint - {endpoint_name}: {process_time:.3f}s")
        elif process_time > 0.5:
            logger.info(f"API Endpoint - {endpoint_name}: {process_time:.3f}s")


def create_error_response(
    status_code: int, 
    message: str, 
    error_type: str = None,
    details: Dict[str, Any] = None
) -> JSONResponse:
    """åˆ›å»ºæ ‡å‡†åŒ–çš„é”™è¯¯å“åº”"""
    error_id = f"ERR-{int(time.time())}"
    
    response_content = {
        "error": error_type or "API Error",
        "error_id": error_id,
        "message": message,
        "timestamp": time.time()
    }
    
    if details:
        response_content["details"] = details
    
    return JSONResponse(
        status_code=status_code,
        content=response_content
    )


def validate_api_input(data: Any, validation_rules: Dict[str, Callable]) -> Dict[str, Any]:
    """APIè¾“å…¥éªŒè¯å·¥å…·"""
    errors = {}
    
    for field, validator in validation_rules.items():
        try:
            if hasattr(data, field):
                value = getattr(data, field)
                validator(value)
        except Exception as e:
            errors[field] = str(e)
    
    if errors:
        raise HTTPException(
            status_code=400,
            detail={
                "error": "Validation Error",
                "message": "è¾“å…¥æ•°æ®éªŒè¯å¤±è´¥",
                "validation_errors": errors
            }
        )
    
    return data


# å¸¸ç”¨çš„éªŒè¯è§„åˆ™
VALIDATION_RULES = {
    "positive_number": lambda x: x > 0 or ValueError("å¿…é¡»ä¸ºæ­£æ•°"),
    "non_empty_string": lambda x: len(str(x).strip()) > 0 or ValueError("ä¸èƒ½ä¸ºç©º"),
    "valid_date": lambda x: isinstance(x, str) and len(x) == 10 or ValueError("æ—¥æœŸæ ¼å¼æ— æ•ˆ"),
    "valid_email": lambda x: "@" in str(x) or ValueError("é‚®ç®±æ ¼å¼æ— æ•ˆ"),
}