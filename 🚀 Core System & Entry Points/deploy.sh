#!/bin/bash
#
# AI-STACK-SUPER-ENHANCED ç¯å¢ƒæ„ŸçŸ¥éƒ¨ç½²è„šæœ¬
# å¯¹åº”éœ€æ±‚: 8.3/8.4/8.5/8.6/8.8 - ç¯å¢ƒéƒ¨ç½²ã€æœåŠ¡ç¼–æ’ã€èµ„æºæ„ŸçŸ¥
#

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# è„šæœ¬ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
BASE_DIR="$(dirname "$SCRIPT_DIR")"

# æ—¥å¿—å‡½æ•°
log() {
    echo -e "${GREEN}[$(date '+%Y-%m-%d %H:%M:%S')] $1${NC}"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$SCRIPT_DIR/logs/system.log"
}

warn() {
    echo -e "${YELLOW}[$(date '+%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] WARNING: $1" >> "$SCRIPT_DIR/logs/system.log"
}

error() {
    echo -e "${RED}[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}" >&2
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: $1" >> "$SCRIPT_DIR/logs/system.log"
}

info() {
    echo -e "${BLUE}[$(date '+%Y-%m-%d %H:%M:%S')] INFO: $1${NC}"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] INFO: $1" >> "$SCRIPT_DIR/logs/system.log"
}

# ç¯å¢ƒæ£€æµ‹å‡½æ•°
detect_environment() {
    log "æ£€æµ‹éƒ¨ç½²ç¯å¢ƒ..."

    # æ£€æµ‹ç½‘ç»œè¿æ¥
    if ping -c 1 -W 1000 8.8.8.8 &> /dev/null; then
        info "ç½‘ç»œè¿æ¥æ­£å¸¸"
    else
        warn "ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œå¯èƒ½å½±å“åœ¨çº¿æœåŠ¡"
    fi

    # æ£€æµ‹ Docker èµ„æº
    local docker_info=$(docker info 2>/dev/null)
    if [[ $? -eq 0 ]]; then
        local docker_driver=$(echo "$docker_info" | grep "Storage Driver" | cut -d: -f2 | sed 's/^ *//')
        local docker_root_dir=$(echo "$docker_info" | grep "Docker Root Dir" | cut -d: -f2 | sed 's/^ *//')
        info "Docker å­˜å‚¨é©±åŠ¨: $docker_driver"
        info "Docker æ ¹ç›®å½•: $docker_root_dir"
    fi

    # æ£€æµ‹å¯ç”¨ç£ç›˜ç©ºé—´
    check_disk_space
}

# ç£ç›˜ç©ºé—´æ£€æŸ¥
check_disk_space() {
    local critical_paths=("/" "/Volumes/Huawei-1" "/Volumes/Huawei-2" "/Users/ywc")

    for path in "${critical_paths[@]}"; do
        if [[ -d "$path" ]]; then
            local available_mb=$(df -m "$path" | awk 'NR==2 {print $4}')
            local total_mb=$(df -m "$path" | awk 'NR==2 {print $2}')
            local usage_percent=$((100 - (available_mb * 100 / total_mb)))

            info "è·¯å¾„ $path: ä½¿ç”¨ç‡ ${usage_percent}%, å¯ç”¨ ${available_mb}MB"

            if [[ $available_mb -lt 1024 ]]; then
                warn "è·¯å¾„ $path å¯ç”¨ç©ºé—´ä¸è¶³1GB"
            fi
        else
            warn "è·¯å¾„ $path ä¸å­˜åœ¨"
        fi
    done
}

# èµ„æºé…ç½®å‡½æ•°
configure_resources() {
    log "é…ç½®ç³»ç»Ÿèµ„æº..."

    # æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€é…ç½®
    local total_memory_gb=$(sysctl -n hw.memsize | awk '{print int($0/1024/1024/1024)}')
    local cpu_cores=$(sysctl -n hw.physicalcpu)

    info "ç³»ç»Ÿæ€»å†…å­˜: ${total_memory_gb}GB"
    info "ç‰©ç†æ ¸å¿ƒæ•°: ${cpu_cores}"

    # è®¡ç®—åˆç†çš„èµ„æºåˆ†é…
    local docker_memory=$((total_memory_gb * 70 / 100))  # 70% ç»™ Docker
    local docker_cpus=$((cpu_cores * 80 / 100))         # 80% ç»™ Docker

    # ç¡®ä¿æœ€å°å€¼
    if [[ $docker_memory -lt 8 ]]; then
        docker_memory=8
        warn "å†…å­˜åˆ†é…è°ƒæ•´åˆ°æœ€å°å€¼ 8GB"
    fi

    if [[ $docker_cpus -lt 4 ]]; then
        docker_cpus=4
        warn "CPU åˆ†é…è°ƒæ•´åˆ°æœ€å°å€¼ 4æ ¸å¿ƒ"
    fi

    info "Docker èµ„æºåˆ†é…: ${docker_memory}GB å†…å­˜, ${docker_cpus} æ ¸å¿ƒ"

    # ç”Ÿæˆèµ„æºé…ç½®æ–‡ä»¶
    cat > "$SCRIPT_DIR/cache/resource_cache/docker_resources.conf" << EOF
# AI-STACK åŠ¨æ€èµ„æºåˆ†é…é…ç½®
# ç”Ÿæˆæ—¶é—´: $(date)

DOCKER_MEMORY_LIMIT=${docker_memory}G
DOCKER_CPU_LIMIT=${docker_cpus}.0
DOCKER_MEMORY_RESERVATION=$((docker_memory * 60 / 100))G

# æœåŠ¡ç‰¹å®šèµ„æºåˆ†é…
OLLAMA_MEMORY=$((docker_memory * 30 / 100))G
OPENWEBUI_MEMORY=$((docker_memory * 15 / 100))G
RAG_SERVICE_MEMORY=$((docker_memory * 20 / 100))G
ERP_SERVICE_MEMORY=$((docker_memory * 15 / 100))G

# å­˜å‚¨é…ç½®
PRIMARY_STORAGE="/Volumes/Huawei-1/ai-stack-data"
BACKUP_STORAGE="/Volumes/Huawei-2/ai-stack-backup"
EOF

    log "èµ„æºé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ"
}

# æœåŠ¡ä¾èµ–æ£€æŸ¥
check_dependencies() {
    log "æ£€æŸ¥æœåŠ¡ä¾èµ–..."

    local missing_deps=0

    # æ£€æŸ¥ Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        error "Docker Compose æœªå®‰è£…"
        missing_deps=1
    else
        local compose_version=$(docker-compose --version)
        info "Docker Compose: $compose_version"
    fi

    # æ£€æŸ¥ Ollama
    if ! docker images | grep -q "ollama/ollama"; then
        warn "Ollama é•œåƒæœªæ‰¾åˆ°ï¼Œå°†åœ¨éƒ¨ç½²æ—¶ä¸‹è½½"
    else
        info "Ollama é•œåƒå·²å°±ç»ª"
    fi

    # æ£€æŸ¥ Python ä¾èµ–
    if [[ -f "$BASE_DIR/requirements.txt" ]]; then
        info "Python ä¾èµ–æ–‡ä»¶å­˜åœ¨"
    else
        warn "æœªæ‰¾åˆ° Python ä¾èµ–æ–‡ä»¶"
    fi

    return $missing_deps
}

# éƒ¨ç½²é…ç½®ç”Ÿæˆ
generate_deployment_config() {
    log "ç”Ÿæˆéƒ¨ç½²é…ç½®æ–‡ä»¶..."

    # åˆ›å»º docker-compose åŸºç¡€é…ç½®
    cat > "$BASE_DIR/ğŸ³ Intelligent Docker Containerization/docker-compose/base.yml" << 'EOF'
version: '3.8'

services:
  # Ollama æœåŠ¡ - å¿…é¡»é¦–å…ˆå¯åŠ¨
  ollama:
    image: ollama/ollama:latest
    container_name: ai-stack-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    deploy:
      resources:
        limits:
          memory: ${OLLAMA_MEMORY:-8G}
          cpus: '${OLLAMA_CPUS:-4.0}'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  # OpenWebUI æœåŠ¡ - ä¾èµ– Ollama
  openwebui:
    image: openwebui/openwebui:latest
    container_name: ai-stack-openwebui
    ports:
      - "3000:3000"
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_NAME="AI-STACK Super Enhanced"
      - ENABLE_SIGNUP=false
    depends_on:
      ollama:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: ${OPENWEBUI_MEMORY:-4G}
          cpus: '${OPENWEBUI_CPUS:-2.0}'
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

volumes:
  ollama_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${PRIMARY_STORAGE:-./data}/ollama

networks:
  default:
    name: ai-stack-network
    driver: bridge
EOF

    info "Docker Compose åŸºç¡€é…ç½®å·²ç”Ÿæˆ"

    # ç”Ÿæˆç¯å¢ƒå˜é‡æ–‡ä»¶
    cat > "$BASE_DIR/.env" << EOF
# AI-STACK ç¯å¢ƒé…ç½®
# è‡ªåŠ¨ç”Ÿæˆäº: $(date)

# è·¯å¾„é…ç½®
PRIMARY_STORAGE=/Volumes/Huawei-1/ai-stack-data
BACKUP_STORAGE=/Volumes/Huawei-2/ai-stack-backup
LOG_PATH=$SCRIPT_DIR/logs

# èµ„æºé™åˆ¶
OLLAMA_MEMORY=${docker_memory}G
OLLAMA_CPUS=${docker_cpus}.0
OPENWEBUI_MEMORY=4G
OPENWEBUI_CPUS=2.0

# ç½‘ç»œé…ç½®
WEBUI_PORT=3000
OLLAMA_PORT=11434
API_PORT=8000

# åŠŸèƒ½å¼€å…³
ENABLE_RAG=true
ENABLE_ERP=true
ENABLE_STOCK=true
ENABLE_CONTENT=true
EOF

    log "ç¯å¢ƒé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ"
}

# æœåŠ¡å¯åŠ¨å‡½æ•°
start_services() {
    log "å¯åŠ¨æ ¸å¿ƒæœåŠ¡..."

    # åˆ‡æ¢åˆ° Docker ç›®å½•
    cd "$BASE_DIR/ğŸ³ Intelligent Docker Containerization/docker-compose"

    # å¯åŠ¨åŸºç¡€æœåŠ¡
    info "å¯åŠ¨ Ollama å’Œ OpenWebUI æœåŠ¡..."
    if docker-compose -f base.yml up -d; then
        log "åŸºç¡€æœåŠ¡å¯åŠ¨æˆåŠŸ"
    else
        error "åŸºç¡€æœåŠ¡å¯åŠ¨å¤±è´¥"
        return 1
    fi

    # ç­‰å¾…æœåŠ¡å°±ç»ª
    wait_for_services
}

# ç­‰å¾…æœåŠ¡å°±ç»ª
wait_for_services() {
    log "ç­‰å¾…æœåŠ¡å°±ç»ª..."

    local max_wait=180
    local wait_interval=5
    local current_wait=0

    info "ç­‰å¾… Ollama æœåŠ¡å¯åŠ¨..."
    while [[ $current_wait -lt $max_wait ]]; do
        if curl -s http://localhost:11434/api/tags &> /dev/null; then
            info "Ollama æœåŠ¡å·²å°±ç»ª"
            break
        fi

        sleep $wait_interval
        current_wait=$((current_wait + wait_interval))
        info "ç­‰å¾…ä¸­... ${current_wait}ç§’"
    done

    if [[ $current_wait -ge $max_wait ]]; then
        warn "Ollama æœåŠ¡å¯åŠ¨è¶…æ—¶"
    fi

    info "ç­‰å¾… OpenWebUI æœåŠ¡å¯åŠ¨..."
    current_wait=0
    while [[ $current_wait -lt $max_wait ]]; do
        if curl -s http://localhost:3000 &> /dev/null; then
            info "OpenWebUI æœåŠ¡å·²å°±ç»ª"
            break
        fi

        sleep $wait_interval
        current_wait=$((current_wait + wait_interval))
        info "ç­‰å¾…ä¸­... ${current_wait}ç§’"
    done

    if [[ $current_wait -ge $max_wait ]]; then
        warn "OpenWebUI æœåŠ¡å¯åŠ¨è¶…æ—¶"
    fi
}

# éƒ¨ç½²åæ£€æŸ¥
post_deployment_check() {
    log "æ‰§è¡Œéƒ¨ç½²åæ£€æŸ¥..."

    local health_status=0

    # æ£€æŸ¥å®¹å™¨çŠ¶æ€
    info "æ£€æŸ¥å®¹å™¨è¿è¡ŒçŠ¶æ€..."
    local container_status=$(docker ps --format "table {{.Names}}\t{{.Status}}")
    info "å®¹å™¨çŠ¶æ€:\n$container_status"

    # æ£€æŸ¥æœåŠ¡ç«¯ç‚¹
    check_service_endpoints

    # ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š
    generate_deployment_report

    if [[ $health_status -eq 0 ]]; then
        log "ğŸ‰ éƒ¨ç½²å®Œæˆï¼AI-STACK ç³»ç»Ÿå·²æˆåŠŸå¯åŠ¨"
        info "ğŸ“Š OpenWebUI ç•Œé¢: http://localhost:3000"
        info "ğŸ¤– Ollama API: http://localhost:11434"
        info "ğŸ“ ç³»ç»Ÿæ—¥å¿—: $SCRIPT_DIR/logs/system.log"
    else
        warn "éƒ¨ç½²å®Œæˆï¼Œä½†å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"
    fi
}

# æ£€æŸ¥æœåŠ¡ç«¯ç‚¹
check_service_endpoints() {
    local endpoints=(
        "http://localhost:3000"
        "http://localhost:11434/api/tags"
    )

    for endpoint in "${endpoints[@]}"; do
        if curl -s --head "$endpoint" | grep -q "200"; then
            info "âœ… æœåŠ¡ç«¯ç‚¹å¯ç”¨: $endpoint"
        else
            warn "âš ï¸  æœåŠ¡ç«¯ç‚¹ä¸å¯ç”¨: $endpoint"
        fi
    done
}

# ç”Ÿæˆéƒ¨ç½²æŠ¥å‘Š
generate_deployment_report() {
    local report_file="$SCRIPT_DIR/logs/deployment_report_$(date +%Y%m%d_%H%M%S).log"

    cat > "$report_file" << EOF
AI-STACK SUPER ENHANCED éƒ¨ç½²æŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: $(date)

=== ç³»ç»Ÿä¿¡æ¯ ===
ä¸»æœºå: $(hostname)
æ“ä½œç³»ç»Ÿ: $(sw_vers -productName) $(sw_vers -productVersion)
å¤„ç†å™¨: $(sysctl -n machdep.cpu.brand_string)
å†…å­˜: $(sysctl -n hw.memsize | awk '{print int($0/1024/1024/1024)}') GB

=== éƒ¨ç½²é…ç½® ===
Docker å†…å­˜é™åˆ¶: ${docker_memory}GB
Docker CPU é™åˆ¶: ${docker_cpus} æ ¸å¿ƒ
ä¸»å­˜å‚¨: /Volumes/Huawei-1/ai-stack-data
å¤‡ä»½å­˜å‚¨: /Volumes/Huawei-2/ai-stack-backup

=== æœåŠ¡çŠ¶æ€ ===
$(docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}")

=== æœåŠ¡ç«¯ç‚¹ ===
OpenWebUI: http://localhost:3000
Ollama API: http://localhost:11434

=== ä¸‹ä¸€æ­¥ ===
1. è®¿é—® http://localhost:3000 é…ç½® OpenWebUI
2. åœ¨ Ollama ä¸­ä¸‹è½½æ‰€éœ€æ¨¡å‹
3. è¿è¡Œå¥åº·æ£€æŸ¥è„šæœ¬éªŒè¯ç³»ç»ŸçŠ¶æ€

EOF

    info "éƒ¨ç½²æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# ä¸»éƒ¨ç½²å‡½æ•°
main() {
    log "å¼€å§‹ AI-STACK-SUPER-ENHANCED éƒ¨ç½²æµç¨‹"

    # ç¯å¢ƒæ£€æµ‹
    detect_environment

    # ä¾èµ–æ£€æŸ¥
    if ! check_dependencies; then
        error "ä¾èµ–æ£€æŸ¥å¤±è´¥ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•"
        exit 1
    fi

    # èµ„æºé…ç½®
    configure_resources

    # ç”Ÿæˆéƒ¨ç½²é…ç½®
    generate_deployment_config

    # å¯åŠ¨æœåŠ¡
    if start_services; then
        # éƒ¨ç½²åæ£€æŸ¥
        post_deployment_check
    else
        error "æœåŠ¡å¯åŠ¨å¤±è´¥"
        exit 1
    fi

    log "éƒ¨ç½²æµç¨‹å®Œæˆ"
}

# ä¿¡å·å¤„ç†
trap 'error "éƒ¨ç½²è¿‡ç¨‹è¢«ä¸­æ–­"; exit 130' INT TERM

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"