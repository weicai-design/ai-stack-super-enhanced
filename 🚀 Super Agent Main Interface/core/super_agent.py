"""
è¶…çº§Agentæ ¸å¿ƒå¼•æ“
å®ç°AIå·¥ä½œæµ9æ­¥éª¤ï¼ŒåŒ…æ‹¬2æ¬¡RAGæ£€ç´¢
"""

import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime
import json
import time

from .workflow_monitor import WorkflowMonitor
from .learning_events import LearningEventBus
from .task_orchestrator import TaskOrchestrator
from .closure_recorder import ClosureRecorder
from .context_compressor import ContextCompressor
from .unified_event_bus import UnifiedEventBus, get_unified_event_bus
from .closed_loop_engine import ClosedLoopEngine
from .execution_checker import ExecutionChecker
from .feedback_handler import FeedbackHandler
from .evidence_recorder import EvidenceRecorder
from .dual_rag_engine import DualRAGEngine
from .enhanced_expert_router import EnhancedExpertRouter
from .enhanced_workflow_monitor import EnhancedWorkflowMonitor, WorkflowStepType

class SuperAgent:
    """
    è¶…çº§Agentæ ¸å¿ƒå¼•æ“
    
    å®ç°AIå·¥ä½œæµ9æ­¥éª¤ï¼š
    1. ç”¨æˆ·è¾“å…¥
    2. è¯†åˆ«é‡è¦ä¿¡æ¯â†’å¤‡å¿˜å½•
    3. ç¬¬1æ¬¡RAGæ£€ç´¢ï¼ˆç†è§£éœ€æ±‚ï¼‰
    4. è·¯ç”±åˆ°å¯¹åº”ä¸“å®¶
    5. ä¸“å®¶åˆ†æå¹¶è°ƒç”¨æ¨¡å—åŠŸèƒ½
    6. åŠŸèƒ½æ¨¡å—æ‰§è¡Œä»»åŠ¡
    7. ç¬¬2æ¬¡RAGæ£€ç´¢ï¼ˆæ•´åˆç»éªŒçŸ¥è¯†ï¼‰â­çµé­‚
    8. ä¸“å®¶ç»¼åˆç”Ÿæˆå›å¤
    9. è¿”å›ç»™ç”¨æˆ·
    """
    
    def __init__(self):
        self.memo_system = None  # å°†åœ¨åˆå§‹åŒ–æ—¶æ³¨å…¥
        self.rag_service = None  # RAGæœåŠ¡
        self.expert_router = None  # ä¸“å®¶è·¯ç”±
        self.module_executor = None  # æ¨¡å—æ‰§è¡Œå™¨
        self.learning_monitor = None  # å­¦ä¹ ç›‘æ§
        self.resource_monitor = None  # èµ„æºç›‘æ§
        self.task_planning = None  # ä»»åŠ¡è§„åˆ’ç³»ç»Ÿ
        self.workflow_monitor = None  # å·¥ä½œæµç›‘æ§å™¨
        self.event_bus = LearningEventBus()
        self.closure_recorder = ClosureRecorder()
        self.closure_recorder.attach_to_event_bus(self.event_bus)
        self.task_orchestrator: Optional[TaskOrchestrator] = None
        
        # P0-001: é—­ç¯ç³»ç»Ÿç»„ä»¶
        self.unified_event_bus = get_unified_event_bus()
        self.execution_checker = ExecutionChecker(self.unified_event_bus)
        self.feedback_handler = FeedbackHandler(self.unified_event_bus)
        self.evidence_recorder = EvidenceRecorder(self.unified_event_bus)
        self.closed_loop_engine = ClosedLoopEngine(
            event_bus=self.unified_event_bus,
            execution_checker=self.execution_checker,
            feedback_handler=self.feedback_handler,
            evidence_recorder=self.evidence_recorder,
            closure_recorder=self.closure_recorder,
        )
        
        # P0-002: åŒRAGæ£€ç´¢å’Œå¢å¼ºä¸“å®¶è·¯ç”±
        self.dual_rag_engine = DualRAGEngine(rag_service=None, cache_enabled=True)
        self.enhanced_expert_router = EnhancedExpertRouter()
        self.enhanced_workflow_monitor = EnhancedWorkflowMonitor()
        
        # è‡ªåŠ¨åˆå§‹åŒ–ä¾èµ–
        self._initialize_dependencies()
        
        # åˆå§‹åŒ–å·¥ä½œæµç›‘æ§å™¨
        self.workflow_monitor = WorkflowMonitor()
        
        # åˆå§‹åŒ–ç¼“å­˜
        self.response_cache = {}
        self.rag_cache = {}
        self.expert_cache = {}
        self.rag2_cache = {}
        self.max_cache_size = 1000
        self.cache_ttl = 300  # 5åˆ†é’Ÿ
        self.timeout_config = {
            "memo_extraction": 0.3,  # ä¼˜åŒ–ï¼šå‡å°‘åˆ°0.3ç§’
            "rag_retrieval": 2.0,  # ä¼˜åŒ–ï¼šå‡å°‘åˆ°2ç§’
            "expert_routing": 0.3,  # ä¼˜åŒ–ï¼šå‡å°‘åˆ°0.3ç§’
            "module_execution": 2.5,  # ä¼˜åŒ–ï¼šå‡å°‘åˆ°2.5ç§’
            "rag2_retrieval": 1.0  # ä¼˜åŒ–ï¼šå‡å°‘åˆ°1ç§’
        }
        self.context_compressor = ContextCompressor()
    
    def _initialize_dependencies(self):
        """åˆå§‹åŒ–ä¾èµ–ç»„ä»¶"""
        from .rag_service_adapter import RAGServiceAdapter
        from .expert_router import ExpertRouter
        from .module_executor import ModuleExecutor
        
        # åˆå§‹åŒ–RAGæœåŠ¡é€‚é…å™¨
        self.rag_service = RAGServiceAdapter()
        
        # åˆå§‹åŒ–ä¸“å®¶è·¯ç”±
        self.expert_router = ExpertRouter()
        
        # åˆå§‹åŒ–æ¨¡å—æ‰§è¡Œå™¨
        self.module_executor = ModuleExecutor()
        
        # è®¾ç½®æ¨¡å—æ‰§è¡Œå™¨åˆ°å­¦ä¹ ç›‘æ§ï¼ˆç”¨äºè‡ªåŠ¨ä¼˜åŒ–ï¼‰
        if self.learning_monitor:
            self.learning_monitor.coding_assistant = f"{self.module_executor.module_apis.get('coding', 'http://localhost:8000')}/api/coding-assistant"
        
    async def process_user_input(
        self,
        user_input: str,
        input_type: str = "text",  # text, voice, file, search
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œæ‰§è¡Œå®Œæ•´çš„AIå·¥ä½œæµâ­ä¼˜åŒ–ç‰ˆï¼ˆ2ç§’å“åº”ç›®æ ‡ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
            input_type: è¾“å…¥ç±»å‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å¤„ç†ç»“æœ
        """
        start_time = datetime.now()
        
        # è§„èŒƒåŒ–ä¸Šä¸‹æ–‡ï¼ˆå«å¤–éƒ¨æœç´¢ç»“æœï¼‰
        context = context or {}
        external_search_context = self._prepare_external_search_context(context.get("external_search"))
        if external_search_context:
            context["external_search"] = external_search_context
        elif "external_search" in context:
            context.pop("external_search", None)
        slo_context = context.get("slo", {})
        
        # å¼€å§‹å·¥ä½œæµç›‘æ§
        workflow_id = None
        if self.workflow_monitor:
            workflow_id = await self.workflow_monitor.start_workflow(user_input, context)
            await self.workflow_monitor.record_step("user_input", "user_input", success=True, data={"input": user_input})
        
        # P0-002: å¢å¼ºå·¥ä½œæµç›‘æ§
        enhanced_workflow_id = None
        if self.enhanced_workflow_monitor:
            enhanced_workflow_id = await self.enhanced_workflow_monitor.start_workflow(user_input, context)
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆç®€å•æŸ¥è¯¢å¯ä»¥ç¼“å­˜ï¼‰
        cache_key = f"{user_input}:{input_type}"
        if cache_key in self.response_cache:
            cached_result = self.response_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached_result["cached_at"])).total_seconds() < self.cache_ttl:
                return {
                    **cached_result["result"],
                    "from_cache": True,
                    "response_time": (datetime.now() - start_time).total_seconds()
                }
        
        try:
            # æ­¥éª¤1: ç”¨æˆ·è¾“å…¥
            input_data = {
                "content": user_input,
                "type": input_type,
                "timestamp": datetime.now().isoformat(),
                "context": context or {}
            }
            
            # æ­¥éª¤2: è¯†åˆ«é‡è¦ä¿¡æ¯â†’å¤‡å¿˜å½•â­ä¼˜åŒ–ç‰ˆï¼ˆå¼‚æ­¥+è¶…æ—¶ï¼‰
            memo_task = asyncio.create_task(
                asyncio.wait_for(
                    self._extract_important_info(input_data),
                    timeout=self.timeout_config["memo_extraction"]
                )
            ) if self.memo_system else None
            
            # æ­¥éª¤3: ç¬¬1æ¬¡RAGæ£€ç´¢ï¼ˆç†è§£éœ€æ±‚ + æ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼‰â­å¹¶è¡Œ
            if self.workflow_monitor:
                await self.workflow_monitor.record_step("rag_retrieval_1", "rag_retrieval")
            
            # P0-002: ä½¿ç”¨åŒRAGå¼•æ“è¿›è¡Œç¬¬1æ¬¡æ£€ç´¢
            if self.dual_rag_engine:
                rag1_result = await self.dual_rag_engine.first_rag_retrieval(
                    user_input=user_input,
                    context=context,
                    top_k=3,
                    timeout=2.0,
                )
                rag_result_1 = rag1_result.to_dict() if hasattr(rag1_result, 'to_dict') else {
                    "knowledge": rag1_result.knowledge_items if hasattr(rag1_result, 'knowledge_items') else [],
                    "understanding": rag1_result.understanding if hasattr(rag1_result, 'understanding') else {},
                    "query": user_input,
                }
                
                # P0-002: è®°å½•åˆ°å¢å¼ºå·¥ä½œæµç›‘æ§
                if self.enhanced_workflow_monitor:
                    await self.enhanced_workflow_monitor.record_step(
                        step_name="rag_retrieval_1",
                        step_type=WorkflowStepType.RAG_RETRIEVAL_1,
                        data=rag_result_1,
                    )
            else:
                rag_result_1 = await self._first_rag_retrieval(user_input, context)
            
            if self.workflow_monitor:
                await self.workflow_monitor.complete_step("rag_retrieval_1", success=True, result=rag_result_1)
            
            if self.enhanced_workflow_monitor:
                await self.enhanced_workflow_monitor.complete_step("rag_retrieval_1", success=True, result=rag_result_1)
            
            if external_search_context:
                self._augment_rag_with_search(rag_result_1, external_search_context)
            
            # æ­¥éª¤4: è·¯ç”±åˆ°å¯¹åº”ä¸“å®¶
            if self.workflow_monitor:
                await self.workflow_monitor.record_step("expert_routing", "expert_routing")
            
            # P0-002: ä½¿ç”¨å¢å¼ºä¸“å®¶è·¯ç”±
            if self.enhanced_expert_router:
                expert_result = await self.enhanced_expert_router.route(
                    user_input=user_input,
                    rag_result=rag_result_1,
                    timeout=0.5,
                )
                expert = expert_result.to_dict() if hasattr(expert_result, 'to_dict') else {
                    "expert": expert_result.expert if hasattr(expert_result, 'expert') else "default",
                    "domain": expert_result.domain if hasattr(expert_result, 'domain') else "general",
                    "module": expert_result.module if hasattr(expert_result, 'module') else "rag",
                    "confidence": expert_result.confidence if hasattr(expert_result, 'confidence') else 0.7,
                    "intent": expert_result.intent if hasattr(expert_result, 'intent') else {},
                }
                
                # P0-002: è®°å½•åˆ°å¢å¼ºå·¥ä½œæµç›‘æ§
                if self.enhanced_workflow_monitor:
                    await self.enhanced_workflow_monitor.record_step(
                        step_name="expert_routing",
                        step_type=WorkflowStepType.EXPERT_ROUTING,
                        data=expert,
                    )
            else:
                expert = await self._route_to_expert(user_input, rag_result_1)
            
            if self.workflow_monitor:
                await self.workflow_monitor.complete_step("expert_routing", success=True, result=expert)
            
            if self.enhanced_workflow_monitor:
                await self.enhanced_workflow_monitor.complete_step("expert_routing", success=True, result=expert)
            
            # æ­¥éª¤5: ä¸“å®¶åˆ†æå¹¶è°ƒç”¨æ¨¡å—åŠŸèƒ½æ‰§è¡Œ
            if self.workflow_monitor:
                await self.workflow_monitor.record_step("module_execution", "module_execution")
            module_result = await self._execute_module_function(expert, user_input, rag_result_1, slo_context)
            if self.workflow_monitor:
                await self.workflow_monitor.complete_step("module_execution", success=True, result=module_result)
            
            # æ­¥éª¤6: åŠŸèƒ½æ¨¡å—æ‰§è¡Œä»»åŠ¡ï¼Œè¿”å›ç»“æœ
            execution_result = await self._get_execution_result(module_result)
            
            # æ­¥éª¤7: ä¸“å®¶æ¥æ”¶ç»“æœï¼Œç¬¬2æ¬¡RAGæ£€ç´¢ï¼ˆæ•´åˆç»éªŒçŸ¥è¯†ï¼‰â­ä¼˜åŒ–ç‰ˆï¼ˆç¼“å­˜+è¶…æ—¶ï¼‰
            if self.workflow_monitor:
                await self.workflow_monitor.record_step("rag_retrieval_2", "rag_retrieval")
            
            # P0-002: ä½¿ç”¨åŒRAGå¼•æ“è¿›è¡Œç¬¬2æ¬¡æ£€ç´¢
            if self.dual_rag_engine:
                rag1_result_obj = None
                if hasattr(rag_result_1, 'knowledge_items'):
                    rag1_result_obj = rag_result_1
                elif isinstance(rag_result_1, dict):
                    # è½¬æ¢ä¸ºRAGRetrievalResultå¯¹è±¡ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                    from .dual_rag_engine import RAGRetrievalResult
                    rag1_result_obj = RAGRetrievalResult(
                        retrieval_id=f"rag1_{uuid4()}",
                        query=user_input,
                        knowledge_items=rag_result_1.get("knowledge", []),
                        understanding=rag_result_1.get("understanding", {}),
                        retrieval_time=0.0,
                    )
                
                rag2_result = await self.dual_rag_engine.second_rag_retrieval(
                    user_input=user_input,
                    execution_result=execution_result,
                    rag1_result=rag1_result_obj,
                    top_k=3,
                    timeout=1.0,
                )
                rag_result_2 = rag2_result.to_dict() if hasattr(rag2_result, 'to_dict') else {
                    "experience": rag2_result.knowledge_items if hasattr(rag2_result, 'knowledge_items') else [],
                    "understanding": rag2_result.understanding if hasattr(rag2_result, 'understanding') else {},
                }
                
                # P0-002: è®°å½•åˆ°å¢å¼ºå·¥ä½œæµç›‘æ§
                if self.enhanced_workflow_monitor:
                    await self.enhanced_workflow_monitor.record_step(
                        step_name="rag_retrieval_2",
                        step_type=WorkflowStepType.RAG_RETRIEVAL_2,
                        data=rag_result_2,
                    )
            else:
                rag_result_2 = await self._second_rag_retrieval(
                    user_input, execution_result, rag_result_1
                )
            
            if self.workflow_monitor:
                await self.workflow_monitor.complete_step("rag_retrieval_2", success=True, result=rag_result_2)
            
            if self.enhanced_workflow_monitor:
                await self.enhanced_workflow_monitor.complete_step("rag_retrieval_2", success=True, result=rag_result_2)
            
            # æ­¥éª¤8: ä¸“å®¶ç»¼åˆç”Ÿæˆæœ€ç»ˆå›å¤
            if self.workflow_monitor:
                await self.workflow_monitor.record_step("response_generation", "response_generation")
            
            # P0-002: è®°å½•åˆ°å¢å¼ºå·¥ä½œæµç›‘æ§
            if self.enhanced_workflow_monitor:
                await self.enhanced_workflow_monitor.record_step(
                    step_name="response_generation",
                    step_type=WorkflowStepType.RESPONSE_GENERATION,
                )
            
            final_response = await self._generate_final_response(
                expert, execution_result, rag_result_2, external_search_context, slo_context
            )
            
            if self.workflow_monitor:
                await self.workflow_monitor.complete_step("response_generation", success=True, result=final_response)
            
            if self.enhanced_workflow_monitor:
                await self.enhanced_workflow_monitor.complete_step("response_generation", success=True, result=final_response)
            
            # æ­¥éª¤2å®Œæˆï¼šå¤„ç†å¤‡å¿˜å½•ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰â­å¢å¼ºç‰ˆ
            memo_created = False
            memo_info = None
            if memo_task:
                try:
                    important_info = await memo_task
                    if important_info and self.memo_system:
                        memo = await self.memo_system.add_memo(important_info)
                        memo_created = True
                        memo_info = {
                            "memo_id": memo.get("id") if isinstance(memo, dict) else None,
                            "title": important_info.get("title"),
                            "type": important_info.get("type"),
                            "importance": important_info.get("importance")
                        }
                        
                        # å¦‚æœæ˜¯ä»»åŠ¡ç±»å‹ï¼Œå¼‚æ­¥æç‚¼åˆ°ä»»åŠ¡è§„åˆ’ç³»ç»Ÿâ­å¢å¼ºç‰ˆ
                        if important_info.get("type") == "task" and self.task_planning:
                            asyncio.create_task(
                                self._extract_and_plan_tasks(important_info)
                            )
                except asyncio.TimeoutError:
                    pass  # è¶…æ—¶ä¸å½±å“ä¸»æµç¨‹
                except Exception as e:
                    logger.warning(f"å¤‡å¿˜å½•åˆ›å»ºå¤±è´¥: {e}")  # è®°å½•é”™è¯¯ä½†ä¸å½±å“ä¸»æµç¨‹
            
            # æ­¥éª¤9: è¿”å›ç»™ç”¨æˆ·
            response_time = (datetime.now() - start_time).total_seconds()
            
            # å®Œæˆå·¥ä½œæµç›‘æ§
            if self.workflow_monitor and workflow_id:
                workflow_result = await self.workflow_monitor.complete_workflow(final_response, response_time)
            
            # P0-002: å®Œæˆå¢å¼ºå·¥ä½œæµç›‘æ§
            if self.enhanced_workflow_monitor and enhanced_workflow_id:
                enhanced_workflow_result = await self.enhanced_workflow_monitor.complete_workflow(final_response, response_time)
            
            # å¹¶è¡Œï¼šè‡ªæˆ‘å­¦ä¹ ç›‘æ§
            if self.learning_monitor:
                asyncio.create_task(self.learning_monitor.monitor_workflow({
                    "input": input_data,
                    "rag_1": rag_result_1,
                    "expert": expert,
                    "execution": execution_result,
                    "rag_2": rag_result_2,
                    "response": final_response,
                    "response_time": response_time
                }))
            
            result = {
                "success": True,
                "response": final_response,
                "response_time": response_time,
                "rag_retrievals": {
                    "first": rag_result_1,
                    "second": rag_result_2
                },
                "execution": execution_result,
                "timestamp": datetime.now().isoformat(),
                "memo_created": memo_created,
                "memo_info": memo_info,  # æ·»åŠ å¤‡å¿˜å½•ä¿¡æ¯ï¼Œä¾›å‰ç«¯æ˜¾ç¤º
                "task_plan_created": False,  # ä»»åŠ¡è®¡åˆ’åˆ›å»ºæ ‡å¿—
                "task_plan": None,  # ä»»åŠ¡è®¡åˆ’æ•°æ®
                "slo": slo_context
            }
            
            if external_search_context:
                result["search_context"] = external_search_context
            
            # æ£€æŸ¥æ˜¯å¦åˆ›å»ºäº†ä»»åŠ¡è®¡åˆ’
            if memo_info and memo_info.get("type") == "task" and self.task_planning:
                try:
                    extracted_tasks = await self.task_planning.extract_tasks_from_memos()
                    if extracted_tasks:
                        plan = await self.task_planning.create_plan(extracted_tasks)
                        result["task_plan_created"] = True
                        result["task_plan"] = plan
                except Exception as e:
                    logger.warning(f"ä»»åŠ¡è®¡åˆ’åˆ›å»ºå¤±è´¥: {e}")
            
            # ç¼“å­˜ç»“æœï¼ˆä¼˜åŒ–ç­–ç•¥ï¼šç¼“å­˜æ›´å¤šæŸ¥è¯¢ï¼‰
            should_cache = (
                input_type == "text" and 
                len(user_input) < 200 and
                response_time < 1.5 and
                not result.get("execution", {}).get("type") in ["complex", "long_running"]
            )
            
            if should_cache:
                self.response_cache[cache_key] = {
                    "result": result,
                    "cached_at": datetime.now().isoformat()
                }
                # é™åˆ¶ç¼“å­˜å¤§å°
                self._cleanup_cache("response_cache", self.max_cache_size)
            
            return result
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            error_info = {
                "error": str(e),
                "input": user_input,
                "timestamp": datetime.now().isoformat()
            }
            
            # è®°å½•é”™è¯¯åˆ°RAG
            if self.learning_monitor:
                await self.learning_monitor.record_error(error_info)
            
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _extract_and_plan_tasks(self, memo_info: Dict):
        """
        ä»å¤‡å¿˜å½•æç‚¼ä»»åŠ¡å¹¶åˆ›å»ºè®¡åˆ’â­å¢å¼ºç‰ˆ
        
        Args:
            memo_info: å¤‡å¿˜å½•ä¿¡æ¯
        """
        try:
            # æç‚¼ä»»åŠ¡
            extracted_tasks = await self.task_planning.extract_tasks_from_memos()
            
            if extracted_tasks:
                # åˆ›å»ºå·¥ä½œè®¡åˆ’
                plan = await self.task_planning.create_plan(extracted_tasks)
                
                # è®°å½•åˆ°å·¥ä½œæµç›‘æ§
                if self.workflow_monitor:
                    await self.workflow_monitor.record_step(
                        "task_extraction",
                        "task_planning",
                        success=True,
                        data={
                            "tasks_count": len(extracted_tasks),
                            "plan_id": plan.get("id")
                        }
                    )
                
                logger.info(f"å·²ä»å¤‡å¿˜å½•æç‚¼ {len(extracted_tasks)} ä¸ªä»»åŠ¡ï¼Œåˆ›å»ºè®¡åˆ’ {plan.get('id')}")
        except Exception as e:
            logger.warning(f"ä»»åŠ¡æç‚¼å¤±è´¥: {e}")
    
    async def _extract_important_info(self, input_data: Dict) -> Optional[Dict]:
        """æå–é‡è¦ä¿¡æ¯åˆ°å¤‡å¿˜å½•â­å¢å¼ºç‰ˆ"""
        import re
        from datetime import datetime, timedelta
        
        content = input_data.get("content", "")
        if not content or len(content.strip()) < 3:
            return None
        
        # å¢å¼ºçš„ä»»åŠ¡å…³é”®è¯è¯†åˆ«
        task_keywords = [
            "éœ€è¦", "åº”è¯¥", "è®°å¾—", "è¦", "å¿…é¡»", "å®Œæˆ", "å¤„ç†", "æ‰§è¡Œ",
            "è®¡åˆ’", "å®‰æ’", "å‡†å¤‡", "æ£€æŸ¥", "å®¡æ ¸", "ç¡®è®¤", "æé†’", "é€šçŸ¥",
            "å¼€ä¼š", "ä¼šè®®", "è®¨è®º", "æ±‡æŠ¥", "æäº¤", "äº¤ä»˜", "æˆªæ­¢", "deadline"
        ]
        has_task = any(keyword in content for keyword in task_keywords)
        
        # å¢å¼ºçš„æ—¥æœŸè¯†åˆ«
        date_patterns = [
            r"(\d{4}[-/]\d{1,2}[-/]\d{1,2})",  # 2024-01-15
            r"(\d{1,2}[-/]\d{1,2})",  # 01-15
            r"(\d{1,2}æœˆ\d{1,2}æ—¥)",  # 1æœˆ15æ—¥
            r"(æ˜å¤©|åå¤©|å¤§åå¤©|ä¸‹å‘¨|ä¸‹å‘¨ä¸€|ä¸‹å‘¨äºŒ|ä¸‹å‘¨ä¸‰|ä¸‹å‘¨å››|ä¸‹å‘¨äº”|ä¸‹å‘¨å…­|ä¸‹å‘¨æ—¥)",
            r"(ä»Šå¤©|æ˜å¤©|åå¤©|æœ¬å‘¨|ä¸‹å‘¨|æœ¬æœˆ|ä¸‹æœˆ)",
            r"(\d+å¤©å|\d+å‘¨å|\d+ä¸ªæœˆå)"
        ]
        dates = []
        for pattern in date_patterns:
            matches = re.findall(pattern, content)
            dates.extend(matches)
        
        # è¯†åˆ«æ—¶é—´ç‚¹
        time_patterns = [
            r"(\d{1,2}:\d{2})",  # 14:30
            r"(\d{1,2}ç‚¹\d{0,2}åˆ†?)",  # ä¸‹åˆ2ç‚¹30åˆ†
            r"(ä¸Šåˆ|ä¸‹åˆ|æ™šä¸Š|å‡Œæ™¨)(\d{1,2}ç‚¹)"
        ]
        times = []
        for pattern in time_patterns:
            matches = re.findall(pattern, content)
            times.extend(matches)
        
        # è¯†åˆ«è”ç³»äºº
        contact_patterns = [
            r"@(\w+)",
            r"è”ç³»(\w+)",
            r"é€šçŸ¥(\w+)",
            r"å‘Šè¯‰(\w+)",
            r"å’Œ(\w+)(ä¸€èµ·|è®¨è®º|å¼€ä¼š)"
        ]
        contacts = []
        for pattern in contact_patterns:
            matches = re.findall(pattern, content)
            if isinstance(matches[0], tuple):
                contacts.extend([m for m in matches[0] if m])
            else:
                contacts.extend(matches)
        
        # è¯†åˆ«é‡è¦ç¨‹åº¦ï¼ˆé€šè¿‡å…³é”®è¯ï¼‰
        importance_keywords = {
            5: ["ç´§æ€¥", "é‡è¦", "å¿…é¡»", "ç«‹å³", "é©¬ä¸Š", "å°½å¿«"],
            4: ["éœ€è¦", "åº”è¯¥", "è®°å¾—", "è¦"],
            3: ["å¯ä»¥", "å»ºè®®", "è€ƒè™‘", "å¦‚æœ"],
            2: ["å¯èƒ½", "ä¹Ÿè®¸", "æˆ–è€…"]
        }
        importance = 2  # é»˜è®¤
        for level, keywords in importance_keywords.items():
            if any(keyword in content for keyword in keywords):
                importance = max(importance, level)
                break
        
        # è¯†åˆ«æ ‡ç­¾
        tags = []
        if has_task:
            tags.append("ä»»åŠ¡")
        if dates:
            tags.append("æœ‰æ—¥æœŸ")
        if times:
            tags.append("æœ‰æ—¶é—´")
        if contacts:
            tags.append("æ¶‰åŠäººå‘˜")
        
        # æå–æ ‡é¢˜ï¼ˆå‰30ä¸ªå­—ç¬¦æˆ–ç¬¬ä¸€å¥è¯ï¼‰
        title = content[:30] if len(content) <= 30 else content.split("ã€‚")[0][:30]
        if not title:
            title = content[:30]
        
        # åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ›å»ºå¤‡å¿˜å½•ï¼ˆæé«˜è¯†åˆ«å‡†ç¡®ç‡ï¼‰â­å¢å¼ºç‰ˆ
        should_create = (
            has_task or  # åŒ…å«ä»»åŠ¡å…³é”®è¯
            len(dates) > 0 or  # åŒ…å«æ—¥æœŸ
            len(times) > 0 or  # åŒ…å«æ—¶é—´
            len(contacts) > 0 or  # åŒ…å«è”ç³»äºº
            importance >= 4 or  # é‡è¦æ€§é«˜
            len(content) > 50 or  # å†…å®¹è¾ƒé•¿ï¼ˆå¯èƒ½æ˜¯é‡è¦ä¿¡æ¯ï¼‰
            any(keyword in content for keyword in ["é‡è¦", "è®°ä½", "å¤‡å¿˜", "è®°å½•", "ä¿å­˜", "æé†’"])  # æ˜ç¡®è¦æ±‚è®°å½•
        )
        
        # å¦‚æœåŒ…å«æ˜ç¡®çš„è®°å½•è¦æ±‚ï¼Œæé«˜é‡è¦æ€§
        if any(keyword in content for keyword in ["é‡è¦", "è®°ä½", "å¤‡å¿˜", "è®°å½•"]):
            importance = max(importance, 4)
        
        if should_create:
            return {
                "title": title,
                "content": content,
                "type": "task" if has_task else "note",
                "importance": importance,
                "tags": tags,
                "dates": dates,
                "times": times,
                "contacts": contacts,
                "metadata": {
                    "source": "chat",
                    "input_type": input_data.get("type", "text"),
                    "timestamp": datetime.now().isoformat()
                }
            }
        
        return None
    
    async def _first_rag_retrieval(
        self,
        user_input: str,
        context: Optional[Dict]
    ) -> Dict[str, Any]:
        """
        ç¬¬1æ¬¡RAGæ£€ç´¢ï¼šç†è§£éœ€æ±‚ + æ£€ç´¢ç›¸å…³çŸ¥è¯†â­ä¼˜åŒ–ç‰ˆï¼ˆ1.5ç§’è¶…æ—¶ï¼‰
        
        è¿™æ˜¯AIå·¥ä½œæµçš„å…³é”®æ­¥éª¤ä¹‹ä¸€
        """
        slo_config = context.get("slo", {}) if context else {}
        rag_top_k = slo_config.get("rag_top_k", 3)

        if not self.rag_service:
            return {"knowledge": [], "understanding": {"intent": "query", "confidence": 0.5}}
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"rag1:{user_input[:50]}"
        if cache_key in self.rag_cache:
            cached = self.rag_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached["cached_at"])).total_seconds() < 300:
                return cached["result"]
        
        try:
            # å¹¶è¡Œæ‰§è¡Œï¼šæ£€ç´¢çŸ¥è¯† + ç†è§£æ„å›¾ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
            knowledge_task = self.rag_service.retrieve(
                query=user_input,
                top_k=rag_top_k,
                context=context
            )
            understanding_task = self.rag_service.understand_intent(user_input)
            
            # è®¾ç½®è¶…æ—¶
            knowledge, understanding = await asyncio.wait_for(
                asyncio.gather(knowledge_task, understanding_task),
                timeout=self.timeout_config["rag_retrieval"]
            )
            
            # ç¡®ä¿understandingä¸ä¸ºNone
            if understanding is None:
                understanding = {"intent": "query", "domain": "general", "confidence": 0.5}
            
            # ç¡®ä¿knowledgeæ˜¯åˆ—è¡¨
            if knowledge is None:
                knowledge = []
            elif not isinstance(knowledge, list):
                knowledge = []
            
            result = {
                "knowledge": knowledge,
                "understanding": understanding,
                "query": user_input,
                "timestamp": datetime.now().isoformat()
            }
            
            # ç¼“å­˜ç»“æœ
            self._cache_rag_result(cache_key, result)
            
            return result
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›å¿«é€Ÿç»“æœ
            return {
                "knowledge": [],
                "understanding": {"intent": "query", "domain": "general", "confidence": 0.5},
                "query": user_input,
                "timeout": True,
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            # å¼‚å¸¸æ—¶è¿”å›é»˜è®¤ç»“æœ
            import logging
            logger = logging.getLogger(__name__)
            logger.warning(f"RAGæ£€ç´¢å¼‚å¸¸: {e}")
            return {
                "knowledge": [],
                "understanding": {"intent": "query", "domain": "general", "confidence": 0.5},
                "query": user_input,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _route_to_expert(
        self,
        user_input: str,
        rag_result: Dict
    ) -> Dict[str, Any]:
        """è·¯ç”±åˆ°å¯¹åº”ä¸“å®¶â­ä¼˜åŒ–ç‰ˆï¼ˆ0.5ç§’è¶…æ—¶ï¼‰"""
        # ç¡®ä¿rag_resultä¸ä¸ºNone
        if rag_result is None:
            rag_result = {"knowledge": [], "understanding": {"intent": "query", "domain": "general", "confidence": 0.5}}
        
        if not self.expert_router:
            return {"expert": "default", "domain": "general", "confidence": 0.5}
        
        # æ£€æŸ¥ç¼“å­˜
        understanding = rag_result.get("understanding", {}) if rag_result else {}
        intent = understanding.get("intent", "") if isinstance(understanding, dict) else ""
        cache_key = f"expert:{user_input[:50]}:{intent}"
        if cache_key in self.expert_cache:
            cached = self.expert_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached["cached_at"])).total_seconds() < 300:
                return cached["result"]
        
        try:
            # å¸¦è¶…æ—¶æ§åˆ¶
            expert = await asyncio.wait_for(
                self.expert_router.route(user_input, rag_result),
                timeout=self.timeout_config["expert_routing"]
            )
            
            # ç¼“å­˜ç»“æœ
            self._cache_expert_result(cache_key, expert)
            
            return expert
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›é»˜è®¤ä¸“å®¶
            return {"expert": "default", "confidence": 0.5, "timeout": True}
    
    async def _execute_module_function(
        self,
        expert: Dict,
        user_input: str,
        rag_result: Dict,
        slo_config: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ¨¡å—åŠŸèƒ½â­ä¼˜åŒ–ç‰ˆï¼ˆ3ç§’è¶…æ—¶ï¼‰"""
        if not self.module_executor:
            return {"result": "åŠŸèƒ½æœªå®ç°", "type": "error"}
        
        try:
            slo_timeout = (slo_config or {}).get("module_timeout")
            module_timeout = slo_timeout or self.timeout_config["module_execution"]
            # å¸¦è¶…æ—¶æ§åˆ¶
            result = await asyncio.wait_for(
                self.module_executor.execute(
                    expert=expert,
                    input=user_input,
                    context=rag_result
                ),
                timeout=module_timeout
            )
            return result
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›å¿«é€Ÿå“åº”
            return {
                "result": "æ‰§è¡Œè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–ç®€åŒ–è¯·æ±‚",
                "type": "timeout",
                "expert": expert.get("expert", "unknown")
            }
    
    async def _get_execution_result(self, module_result: Dict) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»“æœ"""
        return module_result
    
    async def _second_rag_retrieval(
        self,
        user_input: str,
        execution_result: Dict,
        rag_result_1: Dict
    ) -> Dict[str, Any]:
        """
        ç¬¬2æ¬¡RAGæ£€ç´¢ï¼šæ•´åˆç»éªŒçŸ¥è¯†â­ä¼˜åŒ–ç‰ˆï¼ˆç¼“å­˜+è¶…æ—¶ï¼‰
        
        è¿™æ˜¯AIå·¥ä½œæµæœ€å…³é”®çš„æ­¥éª¤ï¼
        é€šè¿‡æ£€ç´¢å†å²ç»éªŒå’Œæœ€ä½³å®è·µï¼Œæå‡å›ç­”è´¨é‡
        """
        # ç¡®ä¿execution_resultå’Œrag_result_1ä¸ä¸ºNone
        if execution_result is None:
            execution_result = {"module": "default", "type": "unknown", "result": {}}
        if rag_result_1 is None:
            rag_result_1 = {"knowledge": [], "understanding": {"intent": "query"}}
        
        if not self.rag_service:
            return {
                "experience": [],
                "best_practices": [],
                "similar_cases": [],
                "integrated_knowledge": "",
                "recommendations": []
            }
        
        # æ£€æŸ¥ç¼“å­˜â­æ–°å¢
        module = execution_result.get("module", "") if execution_result else ""
        result_type = execution_result.get("type", "") if execution_result else ""
        cache_key = f"rag2:{user_input[:50]}:{module}:{result_type}"
        if cache_key in self.rag2_cache:
            cached = self.rag2_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached["cached_at"])).total_seconds() < 300:
                return cached["result"]
        
        # moduleå’Œresult_typeå·²åœ¨ä¸Šé¢å®šä¹‰
        
        # æ„å»ºæ›´ç²¾å‡†çš„æŸ¥è¯¢è¯­å¥
        execution_summary = self._summarize_execution_result(execution_result)
        experience_query = f"{user_input} {execution_summary} å†å²ç»éªŒ æœ€ä½³å®è·µ è§£å†³æ–¹æ¡ˆ æˆåŠŸæ¡ˆä¾‹"
        
        try:
            # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ£€ç´¢ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰â­ä¼˜åŒ–
            experience_task = self.rag_service.retrieve(
                query=experience_query,
                top_k=3,  # å‡å°‘æ£€ç´¢æ•°é‡ä»¥æå‡é€Ÿåº¦
                filter_type="experience",
                context={
                    "module": module,
                    "result_type": result_type,
                    "first_rag_result": rag_result_1
                }
            )
            
            similar_cases_task = self.rag_service.find_similar_cases(
                execution_result,
                top_k=3  # å‡å°‘æ¡ˆä¾‹æ•°é‡
            )
            
            best_practices_task = self.rag_service.get_best_practices(
                module,
                top_k=3  # å‡å°‘æœ€ä½³å®è·µæ•°é‡
            )
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ£€ç´¢ï¼ˆå¸¦è¶…æ—¶ï¼‰
            experience, similar_cases, best_practices = await asyncio.wait_for(
                asyncio.gather(
                    experience_task,
                    similar_cases_task,
                    best_practices_task,
                    return_exceptions=True
                ),
                timeout=self.timeout_config["rag2_retrieval"]
            )
            
            # å¤„ç†å¼‚å¸¸
            if isinstance(experience, Exception):
                experience = []
            if isinstance(similar_cases, Exception):
                similar_cases = []
            if isinstance(best_practices, Exception):
                best_practices = []
            
            # æ•´åˆæ‰€æœ‰çŸ¥è¯†ï¼Œå½¢æˆç»¼åˆå»ºè®®ï¼ˆè¿™æ˜¯"çµé­‚"çš„æ ¸å¿ƒï¼‰
            integrated_knowledge = self._integrate_knowledge(
                experience, similar_cases, best_practices, [], execution_result
            )
            
            # ç”Ÿæˆæ¨èå»ºè®®
            recommendations = self._generate_recommendations(
                experience, similar_cases, best_practices, execution_result
            )
            
            result = {
                "experience": experience,
                "similar_cases": similar_cases,
                "best_practices": best_practices,
                "solutions": [],
                "integrated_knowledge": integrated_knowledge,
                "recommendations": recommendations,
                "module": module,
                "retrieval_count": {
                    "experience": len(experience) if isinstance(experience, list) else 0,
                    "cases": len(similar_cases) if isinstance(similar_cases, list) else 0,
                    "practices": len(best_practices) if isinstance(best_practices, list) else 0,
                    "solutions": 0
                },
                "timestamp": datetime.now().isoformat()
            }
            
            # ç¼“å­˜ç»“æœâ­æ–°å¢
            self._cache_rag2_result(cache_key, result)
            
            return result
            
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›å¿«é€Ÿç»“æœ
            return {
                "experience": [],
                "similar_cases": [],
                "best_practices": [],
                "solutions": [],
                "integrated_knowledge": "",
                "recommendations": [],
                "module": module,
                "timeout": True,
                "timestamp": datetime.now().isoformat()
            }
    
    def _summarize_execution_result(self, execution_result: Dict) -> str:
        """æ€»ç»“æ‰§è¡Œç»“æœï¼Œç”¨äºæ„å»ºæŸ¥è¯¢"""
        summary_parts = []
        
        module = execution_result.get("module", "")
        if module:
            summary_parts.append(f"æ¨¡å—ï¼š{module}")
        
        result_type = execution_result.get("type", "")
        if result_type:
            summary_parts.append(f"ç±»å‹ï¼š{result_type}")
        
        result_data = execution_result.get("result", {})
        if isinstance(result_data, dict):
            status = result_data.get("status", "")
            if status:
                summary_parts.append(f"çŠ¶æ€ï¼š{status}")
        
        return " ".join(summary_parts)
    
    def _integrate_knowledge(
        self,
        experience: List[Dict],
        similar_cases: List[Dict],
        best_practices: List[str],
        solutions: List[Dict],
        execution_result: Dict
    ) -> str:
        """
        æ•´åˆæ‰€æœ‰çŸ¥è¯†ï¼Œå½¢æˆç»¼åˆçŸ¥è¯†æ‘˜è¦â­çµé­‚çš„æ ¸å¿ƒ
        
        è¿™æ˜¯ç¬¬2æ¬¡RAGæ£€ç´¢çš„"çµé­‚"æ‰€åœ¨ï¼š
        ä¸æ˜¯ç®€å•è¿”å›æ£€ç´¢ç»“æœï¼Œè€Œæ˜¯æ™ºèƒ½æ•´åˆæ‰€æœ‰çŸ¥è¯†
        """
        knowledge_parts = []
        
        # æ•´åˆæœ€ä½³å®è·µ
        if best_practices:
            knowledge_parts.append("ğŸ’¡ æœ€ä½³å®è·µï¼š")
            for i, practice in enumerate(best_practices[:3], 1):
                knowledge_parts.append(f"  {i}. {practice}")
        
        # æ•´åˆç±»ä¼¼æ¡ˆä¾‹
        if similar_cases:
            knowledge_parts.append("\nğŸ“š ç±»ä¼¼æ¡ˆä¾‹ï¼š")
            for i, case in enumerate(similar_cases[:3], 1):
                title = case.get("title") or case.get("content", "æ¡ˆä¾‹")[:60]
                knowledge_parts.append(f"  {i}. {title}")
        
        # æ•´åˆå†å²ç»éªŒ
        if experience:
            knowledge_parts.append("\nğŸ” å†å²ç»éªŒï¼š")
            for i, exp in enumerate(experience[:3], 1):
                content = exp.get("content", "")[:80]
                if content:
                    knowledge_parts.append(f"  {i}. {content}...")
        
        # æ•´åˆè§£å†³æ–¹æ¡ˆ
        if solutions:
            knowledge_parts.append("\nâœ… è§£å†³æ–¹æ¡ˆï¼š")
            for i, solution in enumerate(solutions[:2], 1):
                content = solution.get("content", "")[:80]
                if content:
                    knowledge_parts.append(f"  {i}. {content}...")
        
        return "\n".join(knowledge_parts) if knowledge_parts else "æš‚æ— ç›¸å…³ç»éªŒçŸ¥è¯†"
    
    def _generate_recommendations(
        self,
        experience: List[Dict],
        similar_cases: List[Dict],
        best_practices: List[str],
        execution_result: Dict
    ) -> List[str]:
        """
        åŸºäºæ£€ç´¢åˆ°çš„çŸ¥è¯†ç”Ÿæˆæ¨èå»ºè®®â­
        
        è¿™æ˜¯ç¬¬2æ¬¡RAGæ£€ç´¢çš„å¦ä¸€ä¸ª"çµé­‚"åŠŸèƒ½ï¼š
        ä¸ä»…æ£€ç´¢çŸ¥è¯†ï¼Œè¿˜è¦åŸºäºçŸ¥è¯†ç”Ÿæˆæ™ºèƒ½å»ºè®®
        """
        recommendations = []
        
        # åŸºäºæœ€ä½³å®è·µç”Ÿæˆå»ºè®®
        if best_practices:
            recommendations.extend([
                f"å»ºè®®éµå¾ªæœ€ä½³å®è·µï¼š{practice}"
                for practice in best_practices[:2]
            ])
        
        # åŸºäºç±»ä¼¼æ¡ˆä¾‹ç”Ÿæˆå»ºè®®
        if similar_cases:
            for case in similar_cases[:2]:
                if case.get("metadata", {}).get("success", False):
                    recommendations.append(
                        f"å‚è€ƒæˆåŠŸæ¡ˆä¾‹ï¼š{case.get('title', 'æ¡ˆä¾‹')}"
                    )
        
        # åŸºäºå†å²ç»éªŒç”Ÿæˆå»ºè®®
        if experience:
            for exp in experience[:2]:
                content = exp.get("content", "")
                if "ä¼˜åŒ–" in content or "æ”¹è¿›" in content:
                    recommendations.append(f"å†å²ç»éªŒæç¤ºï¼š{content[:50]}...")
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5æ¡å»ºè®®
    
    async def _generate_final_response(
        self,
        expert: Dict,
        execution_result: Dict,
        rag_result_2: Dict,
        search_context: Optional[Dict] = None,
        slo_context: Optional[Dict] = None
    ) -> str:
        """ç”Ÿæˆæœ€ç»ˆå›å¤â­ä½¿ç”¨çœŸå®LLMç”Ÿæˆ"""
        # ç¡®ä¿å‚æ•°ä¸ä¸ºNone
        if expert is None:
            expert = {"expert": "default", "domain": "general", "confidence": 0.5}
        if execution_result is None:
            execution_result = {"module": "default", "type": "unknown", "result": {}}
        if rag_result_2 is None:
            rag_result_2 = {
                "experience": [],
                "best_practices": [],
                "similar_cases": [],
                "integrated_knowledge": "",
                "recommendations": []
            }
        
        try:
            # å¯¼å…¥LLMæœåŠ¡
            from .llm_service import get_llm_service
            
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            context_parts = []
            
            # æ·»åŠ æ‰§è¡Œç»“æœ
            result_data = execution_result.get("result", {}) if execution_result else {}
            if isinstance(result_data, dict):
                if result_data.get("message"):
                    context_parts.append(f"æ‰§è¡Œç»“æœ: {result_data['message']}")
                elif result_data.get("type"):
                    context_parts.append(f"æ¨¡å—ç±»å‹: {result_data['type']}")
            elif isinstance(result_data, str):
                context_parts.append(f"æ‰§è¡Œç»“æœ: {result_data}")
            
            # æ·»åŠ RAGæ£€ç´¢çš„çŸ¥è¯†
            integrated_knowledge = rag_result_2.get("integrated_knowledge", "") if rag_result_2 else ""
            if integrated_knowledge and integrated_knowledge != "æš‚æ— ç›¸å…³ç»éªŒçŸ¥è¯†":
                context_parts.append(f"ç›¸å…³çŸ¥è¯†: {integrated_knowledge}")
            
            best_practices = rag_result_2.get("best_practices", []) if rag_result_2 else []
            if best_practices:
                context_parts.append(f"æœ€ä½³å®è·µ: {', '.join(best_practices[:3])}")
            
            similar_cases = rag_result_2.get("similar_cases", []) if rag_result_2 else []
            if similar_cases:
                case_summaries = []
                for case in similar_cases[:2]:
                    title = case.get("title") or case.get("content", "æ¡ˆä¾‹")[:50] if isinstance(case, dict) else str(case)[:50]
                    case_summaries.append(title)
                context_parts.append(f"ç±»ä¼¼æ¡ˆä¾‹: {', '.join(case_summaries)}")
            
            recommendations = rag_result_2.get("recommendations", []) if rag_result_2 else []
            if recommendations:
                context_parts.append(f"æ¨èå»ºè®®: {', '.join(recommendations[:3])}")
            
            if search_context and search_context.get("results"):
                search_lines = []
                for idx, item in enumerate(search_context.get("results", [])[:3], 1):
                    title = item.get("title") or "å¤–éƒ¨ç»“æœ"
                    snippet = item.get("snippet") or ""
                    url = item.get("url") or ""
                    search_lines.append(f"  {idx}. {title} - {snippet[:80]} ({url})")
                if search_lines:
                    engine = search_context.get("engine", "external")
                    context_parts.append(f"å¤–éƒ¨æœç´¢ï¼ˆ{engine}ï¼‰ï¼š\n" + "\n".join(search_lines))
            
            if self.context_compressor:
                context_parts = self.context_compressor.compress_sections(context_parts)
            
            # æ„å»ºæç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œèƒ½å¤Ÿæ ¹æ®æ‰§è¡Œç»“æœã€RAGæ£€ç´¢çš„çŸ¥è¯†å’Œå†å²ç»éªŒï¼Œç”Ÿæˆä¸“ä¸šã€å‡†ç¡®ã€æœ‰ç”¨çš„å›å¤ã€‚
è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­è¨€è‡ªç„¶æµç•…ï¼Œé€»è¾‘æ¸…æ™°ã€‚"""
            
            user_prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆå›å¤ï¼š

{chr(10).join(context_parts) if context_parts else 'ä»»åŠ¡æ‰§è¡Œå®Œæˆ'}

è¯·ç»¼åˆä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªä¸“ä¸šã€æœ‰ç”¨çš„å›å¤ã€‚"""
            
            # è°ƒç”¨çœŸå®LLMç”Ÿæˆå›å¤ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨æ›´å¿«æ¨¡å‹å’Œæ›´å°‘tokenï¼‰
            llm_service = get_llm_service()
            temperature = 0.3
            max_tokens = 256
            if slo_context and slo_context.get("use_fast_model"):
                temperature = 0.2
                max_tokens = 200
            response = await llm_service.generate(
                prompt=user_prompt,
                system_prompt=system_prompt,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            return response
            
        except Exception as e:
            # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿å›å¤ï¼ˆä½†æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ï¼‰
            import logging
            logger = logging.getLogger(__name__)
            logger.warning(f"LLMç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿å›å¤: {e}")
            
            # é™çº§åˆ°æ¨¡æ¿å›å¤
            response_parts = []
            result_data = execution_result.get("result", {})
            if isinstance(result_data, dict):
                if result_data.get("message"):
                    response_parts.append(result_data["message"])
                elif result_data.get("type"):
                    response_parts.append(f"âœ… {result_data['type']}æ¨¡å—æ‰§è¡Œå®Œæˆ")
            elif isinstance(result_data, str):
                response_parts.append(result_data)
            
            integrated_knowledge = rag_result_2.get("integrated_knowledge", "")
            if integrated_knowledge and integrated_knowledge != "æš‚æ— ç›¸å…³ç»éªŒçŸ¥è¯†":
                response_parts.append(f"\n\nğŸ§  ç›¸å…³çŸ¥è¯†:\n{integrated_knowledge}")
            
            if rag_result_2.get("recommendations"):
                recommendations_text = "\n".join([
                    f"- {rec}" for rec in rag_result_2["recommendations"][:3]
                ])
                response_parts.append(f"\nğŸ” æ¨èå»ºè®®:\n{recommendations_text}")
            
            if search_context and search_context.get("results"):
                external_text = "\n".join([
                    f"- {item.get('title', 'ç»“æœ')} ({item.get('url', '')})"
                    for item in search_context["results"][:3]
                ])
                response_parts.append(f"\nğŸŒ å¤–éƒ¨æœç´¢å‚è€ƒ:\n{external_text}")
            
            if slo_context and slo_context.get("enable_streaming"):
                response_parts.append("\nâ±ï¸ ç³»ç»Ÿé‡‡ç”¨æµå¼é™çº§ç­–ç•¥ï¼Œä¼˜å…ˆè¿”å›æ¦‚è¦ç»“æœã€‚")
            
            if not response_parts:
                response_parts.append("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
            
            return "\n".join(response_parts) + f"\n\nâš ï¸ æ³¨æ„: LLMæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿™æ˜¯æ¨¡æ¿å›å¤ã€‚é”™è¯¯: {str(e)}"

    def _prepare_external_search_context(self, search_context: Optional[Dict]) -> Optional[Dict]:
        """è§„èŒƒåŒ–å¤–éƒ¨æœç´¢ä¸Šä¸‹æ–‡"""
        if not search_context or not isinstance(search_context, dict):
            return None
        
        results = search_context.get("results") or []
        normalized_results = []
        for item in results[:5]:
            if not isinstance(item, dict):
                continue
            title = item.get("title") or item.get("name") or "å¤–éƒ¨æœç´¢ç»“æœ"
            snippet = item.get("snippet") or item.get("description") or item.get("content") or ""
            url = item.get("url") or item.get("link") or ""
            if not snippet and not url:
                continue
            normalized_results.append({
                "title": title[:120],
                "snippet": snippet[:300],
                "url": url,
                "source": item.get("source") or search_context.get("engine") or "external",
                "score": item.get("score"),
            })
        
        if not normalized_results:
            return None
        
        return {
            "query": search_context.get("query", ""),
            "engine": search_context.get("engine", "auto"),
            "search_type": search_context.get("search_type", "web"),
            "fetched_at": search_context.get("fetched_at", datetime.now().isoformat()),
            "results": normalized_results
        }
    
    def _augment_rag_with_search(self, rag_result: Optional[Dict], search_context: Dict):
        """å°†å¤–éƒ¨æœç´¢ç»“æœæ³¨å…¥RAGæ£€ç´¢çŸ¥è¯†ä¸­"""
        if not rag_result or not search_context:
            return
        
        results = search_context.get("results") or []
        if not results:
            return
        
        knowledge = rag_result.setdefault("knowledge", [])
        for item in results[:3]:
            knowledge.append({
                "title": item.get("title", "å¤–éƒ¨æœç´¢"),
                "content": item.get("snippet", ""),
                "source": item.get("url"),
                "type": "external_search",
                "engine": search_context.get("engine"),
                "search_type": search_context.get("search_type")
            })
    
    def set_memo_system(self, memo_system):
        """è®¾ç½®å¤‡å¿˜å½•ç³»ç»Ÿ"""
        self.memo_system = memo_system
    
    def set_rag_service(self, rag_service):
        """è®¾ç½®RAGæœåŠ¡"""
        self.rag_service = rag_service
    
    def set_expert_router(self, expert_router):
        """è®¾ç½®ä¸“å®¶è·¯ç”±"""
        self.expert_router = expert_router
    
    def set_module_executor(self, module_executor):
        """è®¾ç½®æ¨¡å—æ‰§è¡Œå™¨"""
        self.module_executor = module_executor
    
    def set_learning_monitor(self, learning_monitor):
        """è®¾ç½®å­¦ä¹ ç›‘æ§"""
        self.learning_monitor = learning_monitor
        if self.learning_monitor and hasattr(self.learning_monitor, "set_event_bus"):
            self.learning_monitor.set_event_bus(self.event_bus)
    
    def set_resource_monitor(self, resource_monitor):
        """è®¾ç½®èµ„æºç›‘æ§"""
        self.resource_monitor = resource_monitor
    
    def set_task_planning(self, task_planning):
        """è®¾ç½®ä»»åŠ¡è§„åˆ’ç³»ç»Ÿ"""
        self.task_planning = task_planning
        self._initialize_task_orchestrator()

    def _initialize_task_orchestrator(self):
        if self.task_planning:
            self.task_orchestrator = TaskOrchestrator(
                task_planning=self.task_planning,
                event_bus=self.event_bus,
                closure_recorder=self.closure_recorder
            )
    
    def _cache_rag_result(self, cache_key: str, result: Dict):
        """ç¼“å­˜RAGæ£€ç´¢ç»“æœ"""
        self.rag_cache[cache_key] = {
            "result": result,
            "cached_at": datetime.now().isoformat()
        }
        self._cleanup_cache("rag_cache", self.max_cache_size)
    
    def _cache_expert_result(self, cache_key: str, result: Dict):
        """ç¼“å­˜ä¸“å®¶è·¯ç”±ç»“æœ"""
        self.expert_cache[cache_key] = {
            "result": result,
            "cached_at": datetime.now().isoformat()
        }
        self._cleanup_cache("expert_cache", self.max_cache_size)
    
    def _cache_rag2_result(self, cache_key: str, result: Dict):
        """ç¼“å­˜ç¬¬2æ¬¡RAGæ£€ç´¢ç»“æœ"""
        self.rag2_cache[cache_key] = {
            "result": result,
            "cached_at": datetime.now().isoformat()
        }
        self._cleanup_cache("rag2_cache", self.max_cache_size)
    
    def _cleanup_cache(self, cache_name: str, max_size: int):
        """æ¸…ç†ç¼“å­˜ï¼ˆLRUç­–ç•¥ï¼‰"""
        cache = getattr(self, cache_name, {})
        if len(cache) > max_size:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = min(cache.keys(), 
                           key=lambda k: cache[k]["cached_at"])
            del cache[oldest_key]

