"""
è¶…çº§Agentæ ¸å¿ƒå¼•æ“
å®ç°AIå·¥ä½œæµ9æ­¥éª¤ï¼ŒåŒ…æ‹¬2æ¬¡RAGæ£€ç´¢
"""

import asyncio
from typing import Dict, List, Optional, Any
from datetime import datetime
import json

class SuperAgent:
    """
    è¶…çº§Agentæ ¸å¿ƒå¼•æ“
    
    å®ç°AIå·¥ä½œæµ9æ­¥éª¤ï¼š
    1. ç”¨æˆ·è¾“å…¥
    2. è¯†åˆ«é‡è¦ä¿¡æ¯â†’å¤‡å¿˜å½•
    3. ç¬¬1æ¬¡RAGæ£€ç´¢ï¼ˆç†è§£éœ€æ±‚ï¼‰
    4. è·¯ç”±åˆ°å¯¹åº”ä¸“å®¶
    5. ä¸“å®¶åˆ†æå¹¶è°ƒç”¨æ¨¡å—åŠŸèƒ½
    6. åŠŸèƒ½æ¨¡å—æ‰§è¡Œä»»åŠ¡
    7. ç¬¬2æ¬¡RAGæ£€ç´¢ï¼ˆæ•´åˆç»éªŒçŸ¥è¯†ï¼‰â­çµé­‚
    8. ä¸“å®¶ç»¼åˆç”Ÿæˆå›å¤
    9. è¿”å›ç»™ç”¨æˆ·
    """
    
    def __init__(self):
        self.memo_system = None  # å°†åœ¨åˆå§‹åŒ–æ—¶æ³¨å…¥
        self.rag_service = None  # RAGæœåŠ¡
        self.expert_router = None  # ä¸“å®¶è·¯ç”±
        self.module_executor = None  # æ¨¡å—æ‰§è¡Œå™¨
        self.learning_monitor = None  # å­¦ä¹ ç›‘æ§
        self.resource_monitor = None  # èµ„æºç›‘æ§
        self.task_planning = None  # ä»»åŠ¡è§„åˆ’ç³»ç»Ÿ
        
        # è‡ªåŠ¨åˆå§‹åŒ–ä¾èµ–
        self._initialize_dependencies()
    
    def _initialize_dependencies(self):
        """åˆå§‹åŒ–ä¾èµ–ç»„ä»¶"""
        from .rag_service_adapter import RAGServiceAdapter
        from .expert_router import ExpertRouter
        from .module_executor import ModuleExecutor
        
        # åˆå§‹åŒ–RAGæœåŠ¡é€‚é…å™¨
        self.rag_service = RAGServiceAdapter()
        
        # åˆå§‹åŒ–ä¸“å®¶è·¯ç”±
        self.expert_router = ExpertRouter()
        
        # åˆå§‹åŒ–æ¨¡å—æ‰§è¡Œå™¨
        self.module_executor = ModuleExecutor()
        
        # è®¾ç½®æ¨¡å—æ‰§è¡Œå™¨åˆ°å­¦ä¹ ç›‘æ§ï¼ˆç”¨äºè‡ªåŠ¨ä¼˜åŒ–ï¼‰
        if self.learning_monitor:
            self.learning_monitor.coding_assistant = f"{self.module_executor.module_apis.get('coding', 'http://localhost:8000')}/api/coding-assistant"
        
    async def process_user_input(
        self,
        user_input: str,
        input_type: str = "text",  # text, voice, file, search
        context: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œæ‰§è¡Œå®Œæ•´çš„AIå·¥ä½œæµâ­ä¼˜åŒ–ç‰ˆï¼ˆ2ç§’å“åº”ç›®æ ‡ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥å†…å®¹
            input_type: è¾“å…¥ç±»å‹
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            å¤„ç†ç»“æœ
        """
        start_time = datetime.now()
        
        # æ£€æŸ¥ç¼“å­˜ï¼ˆç®€å•æŸ¥è¯¢å¯ä»¥ç¼“å­˜ï¼‰
        cache_key = f"{user_input}:{input_type}"
        if cache_key in self.response_cache:
            cached_result = self.response_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached_result["cached_at"])).total_seconds() < self.cache_ttl:
                return {
                    **cached_result["result"],
                    "from_cache": True,
                    "response_time": (datetime.now() - start_time).total_seconds()
                }
        
        try:
            # æ­¥éª¤1: ç”¨æˆ·è¾“å…¥
            input_data = {
                "content": user_input,
                "type": input_type,
                "timestamp": datetime.now().isoformat(),
                "context": context or {}
            }
            
            # æ­¥éª¤2: è¯†åˆ«é‡è¦ä¿¡æ¯â†’å¤‡å¿˜å½•â­ä¼˜åŒ–ç‰ˆï¼ˆå¼‚æ­¥+è¶…æ—¶ï¼‰
            memo_task = asyncio.create_task(
                asyncio.wait_for(
                    self._extract_important_info(input_data),
                    timeout=self.timeout_config["memo_extraction"]
                )
            ) if self.memo_system else None
            
            # æ­¥éª¤3: ç¬¬1æ¬¡RAGæ£€ç´¢ï¼ˆç†è§£éœ€æ±‚ + æ£€ç´¢ç›¸å…³çŸ¥è¯†ï¼‰â­å¹¶è¡Œ
            rag_result_1 = await self._first_rag_retrieval(user_input, context)
            
            # æ­¥éª¤4: è·¯ç”±åˆ°å¯¹åº”ä¸“å®¶
            expert = await self._route_to_expert(user_input, rag_result_1)
            
            # æ­¥éª¤5: ä¸“å®¶åˆ†æå¹¶è°ƒç”¨æ¨¡å—åŠŸèƒ½æ‰§è¡Œ
            module_result = await self._execute_module_function(expert, user_input, rag_result_1)
            
            # æ­¥éª¤6: åŠŸèƒ½æ¨¡å—æ‰§è¡Œä»»åŠ¡ï¼Œè¿”å›ç»“æœ
            execution_result = await self._get_execution_result(module_result)
            
            # æ­¥éª¤7: ä¸“å®¶æ¥æ”¶ç»“æœï¼Œç¬¬2æ¬¡RAGæ£€ç´¢ï¼ˆæ•´åˆç»éªŒçŸ¥è¯†ï¼‰â­ä¼˜åŒ–ç‰ˆï¼ˆç¼“å­˜+è¶…æ—¶ï¼‰
            rag_result_2 = await self._second_rag_retrieval(
                user_input, execution_result, rag_result_1
            )
            
            # æ­¥éª¤8: ä¸“å®¶ç»¼åˆç”Ÿæˆæœ€ç»ˆå›å¤
            final_response = await self._generate_final_response(
                expert, execution_result, rag_result_2
            )
            
            # æ­¥éª¤2å®Œæˆï¼šå¤„ç†å¤‡å¿˜å½•ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡ä¸»æµç¨‹ï¼‰
            memo_created = False
            if memo_task:
                try:
                    important_info = await memo_task
                    if important_info and self.memo_system:
                        memo = await self.memo_system.add_memo(important_info)
                        memo_created = True
                        
                        # å¦‚æœæ˜¯ä»»åŠ¡ç±»å‹ï¼Œå¼‚æ­¥æç‚¼åˆ°ä»»åŠ¡è§„åˆ’ç³»ç»Ÿ
                        if important_info.get("type") == "task" and self.task_planning:
                            asyncio.create_task(
                                self.task_planning.extract_tasks_from_memos()
                            )
                except asyncio.TimeoutError:
                    pass  # è¶…æ—¶ä¸å½±å“ä¸»æµç¨‹
                except Exception:
                    pass  # é”™è¯¯ä¸å½±å“ä¸»æµç¨‹
            
            # æ­¥éª¤9: è¿”å›ç»™ç”¨æˆ·
            response_time = (datetime.now() - start_time).total_seconds()
            
            # å¹¶è¡Œï¼šè‡ªæˆ‘å­¦ä¹ ç›‘æ§
            if self.learning_monitor:
                asyncio.create_task(self.learning_monitor.monitor_workflow({
                    "input": input_data,
                    "rag_1": rag_result_1,
                    "expert": expert,
                    "execution": execution_result,
                    "rag_2": rag_result_2,
                    "response": final_response,
                    "response_time": response_time
                }))
            
            result = {
                "success": True,
                "response": final_response,
                "response_time": response_time,
                "rag_retrievals": {
                    "first": rag_result_1,
                    "second": rag_result_2
                },
                "execution": execution_result,
                "timestamp": datetime.now().isoformat(),
                "memo_created": memo_created
            }
            
            # ç¼“å­˜ç»“æœï¼ˆä¼˜åŒ–ç­–ç•¥ï¼šç¼“å­˜æ›´å¤šæŸ¥è¯¢ï¼‰
            should_cache = (
                input_type == "text" and 
                len(user_input) < 200 and
                response_time < 1.5 and
                not result.get("execution", {}).get("type") in ["complex", "long_running"]
            )
            
            if should_cache:
                self.response_cache[cache_key] = {
                    "result": result,
                    "cached_at": datetime.now().isoformat()
                }
                # é™åˆ¶ç¼“å­˜å¤§å°
                self._cleanup_cache("response_cache", self.max_cache_size)
            
            return result
            
        except Exception as e:
            # é”™è¯¯å¤„ç†
            error_info = {
                "error": str(e),
                "input": user_input,
                "timestamp": datetime.now().isoformat()
            }
            
            # è®°å½•é”™è¯¯åˆ°RAG
            if self.learning_monitor:
                await self.learning_monitor.record_error(error_info)
            
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    async def _extract_important_info(self, input_data: Dict) -> Optional[Dict]:
        """æå–é‡è¦ä¿¡æ¯åˆ°å¤‡å¿˜å½•â­å¢å¼ºç‰ˆ"""
        import re
        from datetime import datetime, timedelta
        
        content = input_data.get("content", "")
        if not content or len(content.strip()) < 3:
            return None
        
        # å¢å¼ºçš„ä»»åŠ¡å…³é”®è¯è¯†åˆ«
        task_keywords = [
            "éœ€è¦", "åº”è¯¥", "è®°å¾—", "è¦", "å¿…é¡»", "å®Œæˆ", "å¤„ç†", "æ‰§è¡Œ",
            "è®¡åˆ’", "å®‰æ’", "å‡†å¤‡", "æ£€æŸ¥", "å®¡æ ¸", "ç¡®è®¤", "æé†’", "é€šçŸ¥",
            "å¼€ä¼š", "ä¼šè®®", "è®¨è®º", "æ±‡æŠ¥", "æäº¤", "äº¤ä»˜", "æˆªæ­¢", "deadline"
        ]
        has_task = any(keyword in content for keyword in task_keywords)
        
        # å¢å¼ºçš„æ—¥æœŸè¯†åˆ«
        date_patterns = [
            r"(\d{4}[-/]\d{1,2}[-/]\d{1,2})",  # 2024-01-15
            r"(\d{1,2}[-/]\d{1,2})",  # 01-15
            r"(\d{1,2}æœˆ\d{1,2}æ—¥)",  # 1æœˆ15æ—¥
            r"(æ˜å¤©|åå¤©|å¤§åå¤©|ä¸‹å‘¨|ä¸‹å‘¨ä¸€|ä¸‹å‘¨äºŒ|ä¸‹å‘¨ä¸‰|ä¸‹å‘¨å››|ä¸‹å‘¨äº”|ä¸‹å‘¨å…­|ä¸‹å‘¨æ—¥)",
            r"(ä»Šå¤©|æ˜å¤©|åå¤©|æœ¬å‘¨|ä¸‹å‘¨|æœ¬æœˆ|ä¸‹æœˆ)",
            r"(\d+å¤©å|\d+å‘¨å|\d+ä¸ªæœˆå)"
        ]
        dates = []
        for pattern in date_patterns:
            matches = re.findall(pattern, content)
            dates.extend(matches)
        
        # è¯†åˆ«æ—¶é—´ç‚¹
        time_patterns = [
            r"(\d{1,2}:\d{2})",  # 14:30
            r"(\d{1,2}ç‚¹\d{0,2}åˆ†?)",  # ä¸‹åˆ2ç‚¹30åˆ†
            r"(ä¸Šåˆ|ä¸‹åˆ|æ™šä¸Š|å‡Œæ™¨)(\d{1,2}ç‚¹)"
        ]
        times = []
        for pattern in time_patterns:
            matches = re.findall(pattern, content)
            times.extend(matches)
        
        # è¯†åˆ«è”ç³»äºº
        contact_patterns = [
            r"@(\w+)",
            r"è”ç³»(\w+)",
            r"é€šçŸ¥(\w+)",
            r"å‘Šè¯‰(\w+)",
            r"å’Œ(\w+)(ä¸€èµ·|è®¨è®º|å¼€ä¼š)"
        ]
        contacts = []
        for pattern in contact_patterns:
            matches = re.findall(pattern, content)
            if isinstance(matches[0], tuple):
                contacts.extend([m for m in matches[0] if m])
            else:
                contacts.extend(matches)
        
        # è¯†åˆ«é‡è¦ç¨‹åº¦ï¼ˆé€šè¿‡å…³é”®è¯ï¼‰
        importance_keywords = {
            5: ["ç´§æ€¥", "é‡è¦", "å¿…é¡»", "ç«‹å³", "é©¬ä¸Š", "å°½å¿«"],
            4: ["éœ€è¦", "åº”è¯¥", "è®°å¾—", "è¦"],
            3: ["å¯ä»¥", "å»ºè®®", "è€ƒè™‘", "å¦‚æœ"],
            2: ["å¯èƒ½", "ä¹Ÿè®¸", "æˆ–è€…"]
        }
        importance = 2  # é»˜è®¤
        for level, keywords in importance_keywords.items():
            if any(keyword in content for keyword in keywords):
                importance = max(importance, level)
                break
        
        # è¯†åˆ«æ ‡ç­¾
        tags = []
        if has_task:
            tags.append("ä»»åŠ¡")
        if dates:
            tags.append("æœ‰æ—¥æœŸ")
        if times:
            tags.append("æœ‰æ—¶é—´")
        if contacts:
            tags.append("æ¶‰åŠäººå‘˜")
        
        # æå–æ ‡é¢˜ï¼ˆå‰30ä¸ªå­—ç¬¦æˆ–ç¬¬ä¸€å¥è¯ï¼‰
        title = content[:30] if len(content) <= 30 else content.split("ã€‚")[0][:30]
        if not title:
            title = content[:30]
        
        # åˆ¤æ–­æ˜¯å¦åº”è¯¥åˆ›å»ºå¤‡å¿˜å½•ï¼ˆæé«˜è¯†åˆ«å‡†ç¡®ç‡ï¼‰
        should_create = (
            has_task or  # åŒ…å«ä»»åŠ¡å…³é”®è¯
            len(dates) > 0 or  # åŒ…å«æ—¥æœŸ
            len(times) > 0 or  # åŒ…å«æ—¶é—´
            len(contacts) > 0 or  # åŒ…å«è”ç³»äºº
            importance >= 4 or  # é‡è¦æ€§é«˜
            len(content) > 50  # å†…å®¹è¾ƒé•¿ï¼ˆå¯èƒ½æ˜¯é‡è¦ä¿¡æ¯ï¼‰
        )
        
        if should_create:
            return {
                "title": title,
                "content": content,
                "type": "task" if has_task else "note",
                "importance": importance,
                "tags": tags,
                "dates": dates,
                "times": times,
                "contacts": contacts,
                "metadata": {
                    "source": "chat",
                    "input_type": input_data.get("type", "text"),
                    "timestamp": datetime.now().isoformat()
                }
            }
        
        return None
    
    async def _first_rag_retrieval(
        self,
        user_input: str,
        context: Optional[Dict]
    ) -> Dict[str, Any]:
        """
        ç¬¬1æ¬¡RAGæ£€ç´¢ï¼šç†è§£éœ€æ±‚ + æ£€ç´¢ç›¸å…³çŸ¥è¯†â­ä¼˜åŒ–ç‰ˆï¼ˆ1.5ç§’è¶…æ—¶ï¼‰
        
        è¿™æ˜¯AIå·¥ä½œæµçš„å…³é”®æ­¥éª¤ä¹‹ä¸€
        """
        if not self.rag_service:
            return {"knowledge": [], "understanding": {"intent": "query", "confidence": 0.5}}
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"rag1:{user_input[:50]}"
        if cache_key in self.rag_cache:
            cached = self.rag_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached["cached_at"])).total_seconds() < 300:
                return cached["result"]
        
        try:
            # å¹¶è¡Œæ‰§è¡Œï¼šæ£€ç´¢çŸ¥è¯† + ç†è§£æ„å›¾ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
            knowledge_task = self.rag_service.retrieve(
                query=user_input,
                top_k=5,
                context=context
            )
            understanding_task = self.rag_service.understand_intent(user_input)
            
            # è®¾ç½®è¶…æ—¶
            knowledge, understanding = await asyncio.wait_for(
                asyncio.gather(knowledge_task, understanding_task),
                timeout=self.timeout_config["rag_retrieval"]
            )
            
            result = {
                "knowledge": knowledge,
                "understanding": understanding,
                "query": user_input,
                "timestamp": datetime.now().isoformat()
            }
            
            # ç¼“å­˜ç»“æœ
            self._cache_rag_result(cache_key, result)
            
            return result
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›å¿«é€Ÿç»“æœ
            return {
                "knowledge": [],
                "understanding": {"intent": "query", "confidence": 0.5},
                "query": user_input,
                "timeout": True,
                "timestamp": datetime.now().isoformat()
            }
    
    async def _route_to_expert(
        self,
        user_input: str,
        rag_result: Dict
    ) -> Dict[str, Any]:
        """è·¯ç”±åˆ°å¯¹åº”ä¸“å®¶â­ä¼˜åŒ–ç‰ˆï¼ˆ0.5ç§’è¶…æ—¶ï¼‰"""
        if not self.expert_router:
            return {"expert": "default", "confidence": 0.5}
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"expert:{user_input[:50]}:{rag_result.get('understanding', {}).get('intent', '')}"
        if cache_key in self.expert_cache:
            cached = self.expert_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached["cached_at"])).total_seconds() < 300:
                return cached["result"]
        
        try:
            # å¸¦è¶…æ—¶æ§åˆ¶
            expert = await asyncio.wait_for(
                self.expert_router.route(user_input, rag_result),
                timeout=self.timeout_config["expert_routing"]
            )
            
            # ç¼“å­˜ç»“æœ
            self._cache_expert_result(cache_key, expert)
            
            return expert
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›é»˜è®¤ä¸“å®¶
            return {"expert": "default", "confidence": 0.5, "timeout": True}
    
    async def _execute_module_function(
        self,
        expert: Dict,
        user_input: str,
        rag_result: Dict
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ¨¡å—åŠŸèƒ½â­ä¼˜åŒ–ç‰ˆï¼ˆ3ç§’è¶…æ—¶ï¼‰"""
        if not self.module_executor:
            return {"result": "åŠŸèƒ½æœªå®ç°", "type": "error"}
        
        try:
            # å¸¦è¶…æ—¶æ§åˆ¶
            result = await asyncio.wait_for(
                self.module_executor.execute(
                    expert=expert,
                    input=user_input,
                    context=rag_result
                ),
                timeout=self.timeout_config["module_execution"]
            )
            return result
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›å¿«é€Ÿå“åº”
            return {
                "result": "æ‰§è¡Œè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–ç®€åŒ–è¯·æ±‚",
                "type": "timeout",
                "expert": expert.get("expert", "unknown")
            }
    
    async def _get_execution_result(self, module_result: Dict) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»“æœ"""
        return module_result
    
    async def _second_rag_retrieval(
        self,
        user_input: str,
        execution_result: Dict,
        rag_result_1: Dict
    ) -> Dict[str, Any]:
        """
        ç¬¬2æ¬¡RAGæ£€ç´¢ï¼šæ•´åˆç»éªŒçŸ¥è¯†â­ä¼˜åŒ–ç‰ˆï¼ˆç¼“å­˜+è¶…æ—¶ï¼‰
        
        è¿™æ˜¯AIå·¥ä½œæµæœ€å…³é”®çš„æ­¥éª¤ï¼
        é€šè¿‡æ£€ç´¢å†å²ç»éªŒå’Œæœ€ä½³å®è·µï¼Œæå‡å›ç­”è´¨é‡
        """
        if not self.rag_service:
            return {
                "experience": [],
                "best_practices": [],
                "similar_cases": [],
                "integrated_knowledge": "",
                "recommendations": []
            }
        
        # æ£€æŸ¥ç¼“å­˜â­æ–°å¢
        cache_key = f"rag2:{user_input[:50]}:{execution_result.get('module', '')}:{execution_result.get('type', '')}"
        if cache_key in self.rag2_cache:
            cached = self.rag2_cache[cache_key]
            if (datetime.now() - datetime.fromisoformat(cached["cached_at"])).total_seconds() < 300:
                return cached["result"]
        
        module = execution_result.get("module", "default")
        result_type = execution_result.get("type", "unknown")
        
        # æ„å»ºæ›´ç²¾å‡†çš„æŸ¥è¯¢è¯­å¥
        execution_summary = self._summarize_execution_result(execution_result)
        experience_query = f"{user_input} {execution_summary} å†å²ç»éªŒ æœ€ä½³å®è·µ è§£å†³æ–¹æ¡ˆ æˆåŠŸæ¡ˆä¾‹"
        
        try:
            # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ£€ç´¢ä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰â­ä¼˜åŒ–
            experience_task = self.rag_service.retrieve(
                query=experience_query,
                top_k=3,  # å‡å°‘æ£€ç´¢æ•°é‡ä»¥æå‡é€Ÿåº¦
                filter_type="experience",
                context={
                    "module": module,
                    "result_type": result_type,
                    "first_rag_result": rag_result_1
                }
            )
            
            similar_cases_task = self.rag_service.find_similar_cases(
                execution_result,
                top_k=3  # å‡å°‘æ¡ˆä¾‹æ•°é‡
            )
            
            best_practices_task = self.rag_service.get_best_practices(
                module,
                top_k=3  # å‡å°‘æœ€ä½³å®è·µæ•°é‡
            )
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æ£€ç´¢ï¼ˆå¸¦è¶…æ—¶ï¼‰
            experience, similar_cases, best_practices = await asyncio.wait_for(
                asyncio.gather(
                    experience_task,
                    similar_cases_task,
                    best_practices_task,
                    return_exceptions=True
                ),
                timeout=self.timeout_config["rag2_retrieval"]
            )
            
            # å¤„ç†å¼‚å¸¸
            if isinstance(experience, Exception):
                experience = []
            if isinstance(similar_cases, Exception):
                similar_cases = []
            if isinstance(best_practices, Exception):
                best_practices = []
            
            # æ•´åˆæ‰€æœ‰çŸ¥è¯†ï¼Œå½¢æˆç»¼åˆå»ºè®®ï¼ˆè¿™æ˜¯"çµé­‚"çš„æ ¸å¿ƒï¼‰
            integrated_knowledge = self._integrate_knowledge(
                experience, similar_cases, best_practices, [], execution_result
            )
            
            # ç”Ÿæˆæ¨èå»ºè®®
            recommendations = self._generate_recommendations(
                experience, similar_cases, best_practices, execution_result
            )
            
            result = {
                "experience": experience,
                "similar_cases": similar_cases,
                "best_practices": best_practices,
                "solutions": [],
                "integrated_knowledge": integrated_knowledge,
                "recommendations": recommendations,
                "module": module,
                "retrieval_count": {
                    "experience": len(experience) if isinstance(experience, list) else 0,
                    "cases": len(similar_cases) if isinstance(similar_cases, list) else 0,
                    "practices": len(best_practices) if isinstance(best_practices, list) else 0,
                    "solutions": 0
                },
                "timestamp": datetime.now().isoformat()
            }
            
            # ç¼“å­˜ç»“æœâ­æ–°å¢
            self._cache_rag2_result(cache_key, result)
            
            return result
            
        except asyncio.TimeoutError:
            # è¶…æ—¶è¿”å›å¿«é€Ÿç»“æœ
            return {
                "experience": [],
                "similar_cases": [],
                "best_practices": [],
                "solutions": [],
                "integrated_knowledge": "",
                "recommendations": [],
                "module": module,
                "timeout": True,
                "timestamp": datetime.now().isoformat()
            }
    
    def _summarize_execution_result(self, execution_result: Dict) -> str:
        """æ€»ç»“æ‰§è¡Œç»“æœï¼Œç”¨äºæ„å»ºæŸ¥è¯¢"""
        summary_parts = []
        
        module = execution_result.get("module", "")
        if module:
            summary_parts.append(f"æ¨¡å—ï¼š{module}")
        
        result_type = execution_result.get("type", "")
        if result_type:
            summary_parts.append(f"ç±»å‹ï¼š{result_type}")
        
        result_data = execution_result.get("result", {})
        if isinstance(result_data, dict):
            status = result_data.get("status", "")
            if status:
                summary_parts.append(f"çŠ¶æ€ï¼š{status}")
        
        return " ".join(summary_parts)
    
    def _integrate_knowledge(
        self,
        experience: List[Dict],
        similar_cases: List[Dict],
        best_practices: List[str],
        solutions: List[Dict],
        execution_result: Dict
    ) -> str:
        """
        æ•´åˆæ‰€æœ‰çŸ¥è¯†ï¼Œå½¢æˆç»¼åˆçŸ¥è¯†æ‘˜è¦â­çµé­‚çš„æ ¸å¿ƒ
        
        è¿™æ˜¯ç¬¬2æ¬¡RAGæ£€ç´¢çš„"çµé­‚"æ‰€åœ¨ï¼š
        ä¸æ˜¯ç®€å•è¿”å›æ£€ç´¢ç»“æœï¼Œè€Œæ˜¯æ™ºèƒ½æ•´åˆæ‰€æœ‰çŸ¥è¯†
        """
        knowledge_parts = []
        
        # æ•´åˆæœ€ä½³å®è·µ
        if best_practices:
            knowledge_parts.append("ğŸ’¡ æœ€ä½³å®è·µï¼š")
            for i, practice in enumerate(best_practices[:3], 1):
                knowledge_parts.append(f"  {i}. {practice}")
        
        # æ•´åˆç±»ä¼¼æ¡ˆä¾‹
        if similar_cases:
            knowledge_parts.append("\nğŸ“š ç±»ä¼¼æ¡ˆä¾‹ï¼š")
            for i, case in enumerate(similar_cases[:3], 1):
                title = case.get("title") or case.get("content", "æ¡ˆä¾‹")[:60]
                knowledge_parts.append(f"  {i}. {title}")
        
        # æ•´åˆå†å²ç»éªŒ
        if experience:
            knowledge_parts.append("\nğŸ” å†å²ç»éªŒï¼š")
            for i, exp in enumerate(experience[:3], 1):
                content = exp.get("content", "")[:80]
                if content:
                    knowledge_parts.append(f"  {i}. {content}...")
        
        # æ•´åˆè§£å†³æ–¹æ¡ˆ
        if solutions:
            knowledge_parts.append("\nâœ… è§£å†³æ–¹æ¡ˆï¼š")
            for i, solution in enumerate(solutions[:2], 1):
                content = solution.get("content", "")[:80]
                if content:
                    knowledge_parts.append(f"  {i}. {content}...")
        
        return "\n".join(knowledge_parts) if knowledge_parts else "æš‚æ— ç›¸å…³ç»éªŒçŸ¥è¯†"
    
    def _generate_recommendations(
        self,
        experience: List[Dict],
        similar_cases: List[Dict],
        best_practices: List[str],
        execution_result: Dict
    ) -> List[str]:
        """
        åŸºäºæ£€ç´¢åˆ°çš„çŸ¥è¯†ç”Ÿæˆæ¨èå»ºè®®â­
        
        è¿™æ˜¯ç¬¬2æ¬¡RAGæ£€ç´¢çš„å¦ä¸€ä¸ª"çµé­‚"åŠŸèƒ½ï¼š
        ä¸ä»…æ£€ç´¢çŸ¥è¯†ï¼Œè¿˜è¦åŸºäºçŸ¥è¯†ç”Ÿæˆæ™ºèƒ½å»ºè®®
        """
        recommendations = []
        
        # åŸºäºæœ€ä½³å®è·µç”Ÿæˆå»ºè®®
        if best_practices:
            recommendations.extend([
                f"å»ºè®®éµå¾ªæœ€ä½³å®è·µï¼š{practice}"
                for practice in best_practices[:2]
            ])
        
        # åŸºäºç±»ä¼¼æ¡ˆä¾‹ç”Ÿæˆå»ºè®®
        if similar_cases:
            for case in similar_cases[:2]:
                if case.get("metadata", {}).get("success", False):
                    recommendations.append(
                        f"å‚è€ƒæˆåŠŸæ¡ˆä¾‹ï¼š{case.get('title', 'æ¡ˆä¾‹')}"
                    )
        
        # åŸºäºå†å²ç»éªŒç”Ÿæˆå»ºè®®
        if experience:
            for exp in experience[:2]:
                content = exp.get("content", "")
                if "ä¼˜åŒ–" in content or "æ”¹è¿›" in content:
                    recommendations.append(f"å†å²ç»éªŒæç¤ºï¼š{content[:50]}...")
        
        return recommendations[:5]  # æœ€å¤šè¿”å›5æ¡å»ºè®®
    
    async def _generate_final_response(
        self,
        expert: Dict,
        execution_result: Dict,
        rag_result_2: Dict
    ) -> str:
        """ç”Ÿæˆæœ€ç»ˆå›å¤"""
        # ç»¼åˆä¸“å®¶åˆ†æã€æ‰§è¡Œç»“æœå’Œç»éªŒçŸ¥è¯†
        response_parts = []
        
        # æ·»åŠ æ‰§è¡Œç»“æœ
        result_data = execution_result.get("result", {})
        if isinstance(result_data, dict):
            if result_data.get("message"):
                response_parts.append(result_data["message"])
            elif result_data.get("type"):
                response_parts.append(f"âœ… {result_data['type']}æ¨¡å—æ‰§è¡Œå®Œæˆ")
        elif isinstance(result_data, str):
            response_parts.append(result_data)
        
        # â­ç¬¬2æ¬¡RAGæ£€ç´¢çš„çµé­‚ï¼šä¼˜å…ˆä½¿ç”¨æ•´åˆåçš„çŸ¥è¯†
        integrated_knowledge = rag_result_2.get("integrated_knowledge", "")
        if integrated_knowledge and integrated_knowledge != "æš‚æ— ç›¸å…³ç»éªŒçŸ¥è¯†":
            response_parts.append("\n\n" + "="*50)
            response_parts.append("ğŸ§  åŸºäºå†å²ç»éªŒå’Œæœ€ä½³å®è·µçš„ç»¼åˆçŸ¥è¯†ï¼ˆç¬¬2æ¬¡RAGæ£€ç´¢ï¼‰ï¼š")
            response_parts.append("="*50)
            response_parts.append(integrated_knowledge)
        
        # æ·»åŠ æ™ºèƒ½æ¨èå»ºè®®ï¼ˆç¬¬2æ¬¡RAGæ£€ç´¢çš„å¦ä¸€ä¸ªçµé­‚åŠŸèƒ½ï¼‰
        recommendations = rag_result_2.get("recommendations", [])
        if recommendations:
            response_parts.append("\n\nğŸ’¡ æ™ºèƒ½æ¨èå»ºè®®ï¼š")
            for i, rec in enumerate(recommendations, 1):
                response_parts.append(f"{i}. {rec}")
        
        # å¦‚æœæ•´åˆçŸ¥è¯†ä¸ºç©ºï¼Œåˆ™ä½¿ç”¨åŸå§‹æ•°æ®ï¼ˆå‘åå…¼å®¹ï¼‰
        if not integrated_knowledge or integrated_knowledge == "æš‚æ— ç›¸å…³ç»éªŒçŸ¥è¯†":
            best_practices = rag_result_2.get("best_practices", [])
            if best_practices:
                response_parts.append("\n\nğŸ’¡ åŸºäºå†å²ç»éªŒçš„æœ€ä½³å®è·µï¼š")
                for i, practice in enumerate(best_practices[:3], 1):
                    response_parts.append(f"{i}. {practice}")
            
            similar_cases = rag_result_2.get("similar_cases", [])
            if similar_cases:
                response_parts.append("\n\nğŸ“š å‚è€ƒç±»ä¼¼æ¡ˆä¾‹ï¼š")
                for i, case in enumerate(similar_cases[:2], 1):
                    title = case.get("title") or case.get("content", "æ¡ˆä¾‹")[:50]
                    response_parts.append(f"{i}. {title}")
            
            experience = rag_result_2.get("experience", [])
            if experience:
                response_parts.append("\n\nğŸ” ç›¸å…³å†å²ç»éªŒï¼š")
                for i, exp in enumerate(experience[:2], 1):
                    content = exp.get("content", "")[:100]
                    if content:
                        response_parts.append(f"{i}. {content}...")
        
        # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œè¿”å›é»˜è®¤å›å¤
        if not response_parts:
            response_parts.append("âœ… ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
        
        return "\n".join(response_parts)
    
    def set_memo_system(self, memo_system):
        """è®¾ç½®å¤‡å¿˜å½•ç³»ç»Ÿ"""
        self.memo_system = memo_system
    
    def set_rag_service(self, rag_service):
        """è®¾ç½®RAGæœåŠ¡"""
        self.rag_service = rag_service
    
    def set_expert_router(self, expert_router):
        """è®¾ç½®ä¸“å®¶è·¯ç”±"""
        self.expert_router = expert_router
    
    def set_module_executor(self, module_executor):
        """è®¾ç½®æ¨¡å—æ‰§è¡Œå™¨"""
        self.module_executor = module_executor
    
    def set_learning_monitor(self, learning_monitor):
        """è®¾ç½®å­¦ä¹ ç›‘æ§"""
        self.learning_monitor = learning_monitor
    
    def set_resource_monitor(self, resource_monitor):
        """è®¾ç½®èµ„æºç›‘æ§"""
        self.resource_monitor = resource_monitor
    
    def set_task_planning(self, task_planning):
        """è®¾ç½®ä»»åŠ¡è§„åˆ’ç³»ç»Ÿ"""
        self.task_planning = task_planning
    
    def _cache_rag_result(self, cache_key: str, result: Dict):
        """ç¼“å­˜RAGæ£€ç´¢ç»“æœ"""
        self.rag_cache[cache_key] = {
            "result": result,
            "cached_at": datetime.now().isoformat()
        }
        self._cleanup_cache("rag_cache", self.max_cache_size)
    
    def _cache_expert_result(self, cache_key: str, result: Dict):
        """ç¼“å­˜ä¸“å®¶è·¯ç”±ç»“æœ"""
        self.expert_cache[cache_key] = {
            "result": result,
            "cached_at": datetime.now().isoformat()
        }
        self._cleanup_cache("expert_cache", self.max_cache_size)
    
    def _cache_rag2_result(self, cache_key: str, result: Dict):
        """ç¼“å­˜ç¬¬2æ¬¡RAGæ£€ç´¢ç»“æœ"""
        self.rag2_cache[cache_key] = {
            "result": result,
            "cached_at": datetime.now().isoformat()
        }
        self._cleanup_cache("rag2_cache", self.max_cache_size)
    
    def _cleanup_cache(self, cache_name: str, max_size: int):
        """æ¸…ç†ç¼“å­˜ï¼ˆLRUç­–ç•¥ï¼‰"""
        cache = getattr(self, cache_name, {})
        if len(cache) > max_size:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = min(cache.keys(), 
                           key=lambda k: cache[k]["cached_at"])
            del cache[oldest_key]

