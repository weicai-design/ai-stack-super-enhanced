#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
2ç§’SLOæ€§èƒ½éªŒè¯æµ‹è¯•è„šæœ¬ï¼ˆT003ï¼‰

éªŒè¯æ‰€æœ‰APIç«¯ç‚¹çš„å“åº”æ—¶é—´æ˜¯å¦æ»¡è¶³2ç§’SLOè¦æ±‚
"""

import asyncio
import time
import httpx
import statistics
from typing import Dict, List, Tuple
from dataclasses import dataclass


@dataclass
class PerformanceResult:
    """æ€§èƒ½æµ‹è¯•ç»“æœ"""
    endpoint: str
    response_time: float
    status_code: int
    success: bool
    error: str = ""


class SLOPerformanceTester:
    """2ç§’SLOæ€§èƒ½éªŒè¯å™¨"""
    
    def __init__(self, base_url: str = "http://127.0.0.1:8001"):
        self.base_url = base_url
        self.slo_threshold = 2.0  # 2ç§’SLOé˜ˆå€¼
        self.client = httpx.AsyncClient(timeout=10.0)
        
        # å®šä¹‰è¦æµ‹è¯•çš„APIç«¯ç‚¹
        self.endpoints = [
            "/docs",  # APIæ–‡æ¡£
            "/api/experts/",  # ä¸“å®¶åˆ—è¡¨
            "/api/experts/count",  # ä¸“å®¶ç»Ÿè®¡
            "/api/metrics/health",  # å¥åº·æ£€æŸ¥
            "/api/metrics/performance",  # æ€§èƒ½æŒ‡æ ‡
            "/api/metrics/analysis/summary",  # åˆ†ææ‘˜è¦
            "/api/metrics/experts/ranking",  # ä¸“å®¶æ’å
            "/api/metrics/comparison?experts=rag_knowledge_expert,erp_quality_expert",  # ä¸“å®¶å¯¹æ¯”
        ]
    
    async def test_endpoint(self, endpoint: str) -> PerformanceResult:
        """æµ‹è¯•å•ä¸ªç«¯ç‚¹æ€§èƒ½"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        try:
            response = await self.client.get(url)
            response_time = time.time() - start_time
            
            return PerformanceResult(
                endpoint=endpoint,
                response_time=response_time,
                status_code=response.status_code,
                success=response.status_code == 200 and response_time <= self.slo_threshold
            )
        except Exception as e:
            response_time = time.time() - start_time
            return PerformanceResult(
                endpoint=endpoint,
                response_time=response_time,
                status_code=0,
                success=False,
                error=str(e)
            )
    
    async def run_concurrent_tests(self, concurrent_requests: int = 10) -> List[PerformanceResult]:
        """è¿è¡Œå¹¶å‘æ€§èƒ½æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹å¹¶å‘æ€§èƒ½æµ‹è¯• ({concurrent_requests}ä¸ªå¹¶å‘è¯·æ±‚)...")
        
        # ä¸ºæ¯ä¸ªç«¯ç‚¹åˆ›å»ºå¹¶å‘è¯·æ±‚
        tasks = []
        for endpoint in self.endpoints:
            for i in range(concurrent_requests):
                tasks.append(self.test_endpoint(endpoint))
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
        results = await asyncio.gather(*tasks)
        
        print(f"âœ… å¹¶å‘æµ‹è¯•å®Œæˆï¼Œå…±æµ‹è¯• {len(results)} ä¸ªè¯·æ±‚")
        return results
    
    async def run_sequential_tests(self) -> List[PerformanceResult]:
        """è¿è¡Œé¡ºåºæ€§èƒ½æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹é¡ºåºæ€§èƒ½æµ‹è¯•...")
        
        results = []
        for endpoint in self.endpoints:
            result = await self.test_endpoint(endpoint)
            results.append(result)
            
            status_icon = "âœ…" if result.success else "âŒ"
            print(f"{status_icon} {endpoint}: {result.response_time:.3f}s (çŠ¶æ€ç : {result.status_code})")
        
        print("âœ… é¡ºåºæµ‹è¯•å®Œæˆ")
        return results
    
    def analyze_results(self, results: List[PerformanceResult]) -> Dict[str, any]:
        """åˆ†ææ€§èƒ½æµ‹è¯•ç»“æœ"""
        # æŒ‰ç«¯ç‚¹åˆ†ç»„ç»“æœ
        endpoint_results: Dict[str, List[float]] = {}
        for result in results:
            if result.endpoint not in endpoint_results:
                endpoint_results[result.endpoint] = []
            endpoint_results[result.endpoint].append(result.response_time)
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        analysis = {
            "total_requests": len(results),
            "successful_requests": sum(1 for r in results if r.success),
            "failed_requests": sum(1 for r in results if not r.success),
            "slo_compliance_rate": 0.0,
            "average_response_time": 0.0,
            "p95_response_time": 0.0,
            "p99_response_time": 0.0,
            "endpoint_analysis": {},
            "slo_violations": []
        }
        
        # è®¡ç®—æ€»ä½“æŒ‡æ ‡
        if results:
            response_times = [r.response_time for r in results]
            analysis["average_response_time"] = statistics.mean(response_times)
            analysis["slo_compliance_rate"] = sum(1 for r in results if r.success) / len(results)
            
            # è®¡ç®—ç™¾åˆ†ä½æ•°
            sorted_times = sorted(response_times)
            analysis["p95_response_time"] = sorted_times[int(len(sorted_times) * 0.95)]
            analysis["p99_response_time"] = sorted_times[int(len(sorted_times) * 0.99)]
        
        # åˆ†ææ¯ä¸ªç«¯ç‚¹
        for endpoint, times in endpoint_results.items():
            if times:
                avg_time = statistics.mean(times)
                p95_time = sorted(times)[int(len(times) * 0.95)]
                success_rate = sum(1 for r in results if r.endpoint == endpoint and r.success) / len(times)
                
                analysis["endpoint_analysis"][endpoint] = {
                    "average_time": avg_time,
                    "p95_time": p95_time,
                    "success_rate": success_rate,
                    "request_count": len(times),
                    "slo_compliant": avg_time <= self.slo_threshold
                }
                
                if avg_time > self.slo_threshold:
                    analysis["slo_violations"].append({
                        "endpoint": endpoint,
                        "average_time": avg_time,
                        "threshold": self.slo_threshold
                    })
        
        return analysis
    
    def print_report(self, analysis: Dict[str, any]):
        """æ‰“å°æ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š 2ç§’SLOæ€§èƒ½éªŒè¯æŠ¥å‘Š")
        print("="*80)
        
        print(f"\nğŸ“ˆ æ€»ä½“æ€§èƒ½æŒ‡æ ‡:")
        print(f"   â€¢ æ€»è¯·æ±‚æ•°: {analysis['total_requests']}")
        print(f"   â€¢ æˆåŠŸè¯·æ±‚æ•°: {analysis['successful_requests']}")
        print(f"   â€¢ SLOåˆè§„ç‡: {analysis['slo_compliance_rate']:.1%}")
        print(f"   â€¢ å¹³å‡å“åº”æ—¶é—´: {analysis['average_response_time']:.3f}s")
        print(f"   â€¢ P95å“åº”æ—¶é—´: {analysis['p95_response_time']:.3f}s")
        print(f"   â€¢ P99å“åº”æ—¶é—´: {analysis['p99_response_time']:.3f}s")
        
        print(f"\nğŸ” ç«¯ç‚¹æ€§èƒ½åˆ†æ:")
        for endpoint, metrics in analysis["endpoint_analysis"].items():
            status_icon = "âœ…" if metrics["slo_compliant"] else "âŒ"
            print(f"   {status_icon} {endpoint}")
            print(f"     å¹³å‡æ—¶é—´: {metrics['average_time']:.3f}s, P95: {metrics['p95_time']:.3f}s")
            print(f"     æˆåŠŸç‡: {metrics['success_rate']:.1%}, è¯·æ±‚æ•°: {metrics['request_count']}")
        
        if analysis["slo_violations"]:
            print(f"\nâš ï¸  SLOè¿è§„ç«¯ç‚¹:")
            for violation in analysis["slo_violations"]:
                print(f"   âŒ {violation['endpoint']}: {violation['average_time']:.3f}s > {violation['threshold']}s")
        
        # æ€»ä½“è¯„ä¼°
        print(f"\nğŸ¯ SLOåˆè§„è¯„ä¼°:")
        if analysis["slo_compliance_rate"] >= 0.95:
            print("   âœ… ä¼˜ç§€ - ç³»ç»Ÿæ»¡è¶³2ç§’SLOè¦æ±‚ (åˆè§„ç‡ â‰¥ 95%)")
        elif analysis["slo_compliance_rate"] >= 0.90:
            print("   âš ï¸  è‰¯å¥½ - ç³»ç»ŸåŸºæœ¬æ»¡è¶³SLOè¦æ±‚ (åˆè§„ç‡ â‰¥ 90%)")
        else:
            print("   âŒ éœ€è¦æ”¹è¿› - ç³»ç»Ÿæœªæ»¡è¶³SLOè¦æ±‚ (åˆè§„ç‡ < 90%)")
        
        print("="*80)
    
    async def run_comprehensive_test(self):
        """è¿è¡Œå…¨é¢çš„æ€§èƒ½æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹2ç§’SLOæ€§èƒ½éªŒè¯æµ‹è¯•...")
        print(f"ğŸ“Š æµ‹è¯•ç›®æ ‡: éªŒè¯æ‰€æœ‰APIç«¯ç‚¹æ˜¯å¦æ»¡è¶³2ç§’å“åº”æ—¶é—´è¦æ±‚")
        print(f"ğŸ”— æµ‹è¯•åœ°å€: {self.base_url}")
        
        try:
            # 1. è¿è¡Œé¡ºåºæµ‹è¯•
            sequential_results = await self.run_sequential_tests()
            
            # 2. è¿è¡Œå¹¶å‘æµ‹è¯•
            concurrent_results = await self.run_concurrent_tests(concurrent_requests=5)
            
            # 3. åˆå¹¶ç»“æœå¹¶åˆ†æ
            all_results = sequential_results + concurrent_results
            analysis = self.analyze_results(all_results)
            
            # 4. ç”ŸæˆæŠ¥å‘Š
            self.print_report(analysis)
            
            # 5. è¿”å›æµ‹è¯•ç»“æœ
            return {
                "success": analysis["slo_compliance_rate"] >= 0.90,
                "analysis": analysis,
                "slo_compliant": analysis["slo_compliance_rate"] >= 0.90
            }
            
        except Exception as e:
            print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "slo_compliant": False
            }
        finally:
            await self.client.aclose()


async def main():
    """ä¸»å‡½æ•°"""
    tester = SLOPerformanceTester()
    
    # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
    print("â³ ç­‰å¾…APIæœåŠ¡å™¨å¯åŠ¨...")
    await asyncio.sleep(5)
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    result = await tester.run_comprehensive_test()
    
    # è¿”å›é€€å‡ºç 
    exit_code = 0 if result["slo_compliant"] else 1
    return exit_code


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)