class StoryboardRequest(BaseModel):
    concept: str
    template: Optional[str] = "fast_promo"
    duration: Optional[int] = Field(None, description="è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰")
    style: Optional[str] = Field("modern", description="é£æ ¼ï¼ˆmodern/classic/creativeï¼‰")


class StoryboardResponse(BaseModel):
    concept: str
    template: str
    shots: List[Dict[str, Any]]


class ResourceRollbackRequest(BaseModel):
    suggestion_id: str
    reason: Optional[str] = None


class ResourceRollbackResponse(BaseModel):
    suggestion_id: str
    description: str
    plan: str
    requested_by: str
    reason: Optional[str] = None
    rolled_back_at: str
    status: str


class TrendScenarioRequest(BaseModel):
    indicator: str = "EV_DEMAND"
    scenario_name: Optional[str] = "æ”¿ç­–åˆºæ¿€ + éœ€æ±‚èµ°å¼º"
    demand_shift: float = 0.05
    policy_intensity: float = 0.08
    supply_shift: float = 0.02


class TrendScenarioResponse(BaseModel):
    indicator: str
    scenario: str
    assumptions: Dict[str, float]
    forecast: Dict[str, Any]
    timeline: List[Dict[str, Any]]
    recommendations: List[str]


class TrendBacktestResponse(BaseModel):
    indicator: str
    window: int
    metrics: Dict[str, Any]
    series: List[Dict[str, Any]]
    events: List[Dict[str, Any]]


class ExpertRouteSimulationRequest(BaseModel):
    query: str
    knowledge_hints: Optional[List[str]] = None
    expected_domain: Optional[str] = None


class ExpertParticipant(BaseModel):
    expert_id: str
    name: str
    domain: str
    role: Optional[str] = None


class CollaborationSessionCreateRequest(BaseModel):
    topic: str
    initiator: str
    goals: List[str] = Field(default_factory=list)
    channel: Optional[str] = "multi"
    experts: List[ExpertParticipant]


class CollaborationContributionRequest(BaseModel):
    expert_id: str
    expert_name: str
    channel: str
    summary: str
    action_items: List[str] = Field(default_factory=list)
    impact_score: float = Field(0.5, ge=0.0, le=1.0)
    references: List[str] = Field(default_factory=list)


class CollaborationDecisionRequest(BaseModel):
    owner: str
    summary: str
    kpis: List[str] = Field(default_factory=list)
    followups: List[str] = Field(default_factory=list)


class ConfigApplyRequest(BaseModel):
    profile: str
    overrides: Dict[str, str] = Field(default_factory=dict)


class DeploymentRunRequest(BaseModel):
    profile: str
    dry_run: bool = True
    steps: Optional[List[str]] = None
    overrides: Dict[str, str] = Field(default_factory=dict)


class ServiceRegisterRequest(BaseModel):
    service: str
    endpoint: str
    version: str = "v1"
    protocol: str = "http"
    deployment_target: str = "monolith"
    metadata: Dict[str, Any] = Field(default_factory=dict)


class ServiceHeartbeatRequest(BaseModel):
    service: str
    instance_id: str
    status: str = "healthy"


class ServiceCallRequest(BaseModel):
    service: str
    operation: str
    payload: Dict[str, Any] = Field(default_factory=dict)
    prefer_internal: bool = True


class CollaborationEventStreamManager:
    """SSE æ¨é€ï¼šç›‘å¬ç»Ÿä¸€äº‹ä»¶æ€»çº¿çš„ä¸“å®¶ååŒäº‹ä»¶"""

    def __init__(self):
        self._queues: set[asyncio.Queue] = set()
        self._bus = get_unified_event_bus()
        self._subscriber_id = self._bus.subscribe(
            self._handle_event,
            EventFilter(category=EventCategory.WORKFLOW, source="expert_collaboration"),
        )

    async def register(self) -> asyncio.Queue:
        queue: asyncio.Queue = asyncio.Queue(maxsize=100)
        self._queues.add(queue)
        return queue

    def unregister(self, queue: asyncio.Queue) -> None:
        self._queues.discard(queue)

    async def _handle_event(self, event) -> None:
        payload = event.to_dict()
        for queue in list(self._queues):
            try:
                queue.put_nowait(payload)
            except asyncio.QueueFull:
                try:
                    queue.get_nowait()
                except asyncio.QueueEmpty:
                    pass
                queue.put_nowait(payload)
class CopyrightCheckRequest(BaseModel):
    text: str
    sources: Optional[List[str]] = None
    platforms: Optional[List[str]] = None
    threshold: float = 0.75


class CopyrightCheckResponse(BaseModel):
    matches: List[Dict[str, Any]]
    summary: Dict[str, Any]
    workflow: Dict[str, Any]
"""
è¶…çº§Agentä¸»ç•Œé¢API
æä¾›RESTful APIæ¥å£
"""

from fastapi import (
    APIRouter,
    HTTPException,
    UploadFile,
    File,
    Body,
    Query,
    Depends,
    Request,
    Response,
    status,
)
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Any
import asyncio
import time
from datetime import datetime
from uuid import uuid4

import sys
from pathlib import Path
import json
import os
import logging
import random
import math
import re
from collections import deque, Counter
import itertools
import yaml
import httpx

logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from core.super_agent import SuperAgent
from core.memo_system import MemoSystem
from core.task_planning import TaskPlanning
from core.self_learning import SelfLearningMonitor
from core.resource_monitor import ResourceMonitor
from core.resource_auto_adjuster import ResourceAutoAdjuster
from core.voice_interaction import VoiceInteraction
from core.translation import TranslationService
from core.file_generation import FileGenerationService
from core.web_search import WebSearchService
from core.file_format_handler import FileFormatHandler
from core.terminal_executor import TerminalExecutor
from core.terminal_audit import TerminalAuditLogger
from core.performance_monitor import performance_monitor, response_time_optimizer
from core.llm_service import get_llm_service, LLMProvider
from core.task_orchestrator import TaskStatus
from core.learning_events import LearningEventType
from core.data_sources.factory_data_source import FactoryDataSource
from core.integrations.external_status import ExternalIntegrationStatus
from core.workflow_causal_analyzer import WorkflowCausalAnalyzer
from core.resource_diagnostic import ResourceDiagnosticEngine
from core.resource_authorization import ResourceAuthorizationManager
from core.resource_strategy_engine import ResourceStrategyEngine, ResourceStrategy, StrategyContext
from core.resource_conflict_scheduler import ResourceConflictScheduler, ConflictType, ResolutionStrategy
from core.security_compliance_baseline import SecurityComplianceBaseline, ComplianceCategory, SecurityLevel, ViolationType
from core.observability_system import ObservabilitySystem, SpanType, SpanStatus
from core.observability_middleware import ObservabilityMiddleware
from core.observability_persistence import ObservabilityPersistence
from core.observability_alerts import ObservabilityAlertSystem, AlertRule, AlertSeverity, AlertCondition
from core.observability_export import ObservabilityExporter
from core.knowledge_template import KnowledgeTemplateManager, KnowledgeType, KnowledgePriority
from core.knowledge_ingestion_strategy import KnowledgeIngestionStrategy, IngestionTrigger, IngestionPriority
from core.security.config import get_security_settings
from core.security.auth import require_api_token
from core.security.sensitive_policy import SensitiveContentFilter
from core.security.audit_pipeline import get_audit_pipeline
from core.security.permission_guard import get_permission_guard
from core.security.risk_engine import get_risk_engine
from core.security.crawler_compliance import get_crawler_compliance_service
from core.security.approval_workflow import (
    get_approval_manager,
    ApprovalStatus,
)
ERP_MODULE_ROOT = project_root / "ğŸ’¼ Intelligent ERP & Business Management"
if ERP_MODULE_ROOT.exists() and str(ERP_MODULE_ROOT) not in sys.path:
    sys.path.insert(0, str(ERP_MODULE_ROOT))
try:
    from core.trial_data_source import DemoFactoryTrialDataSource
    from core.erp_8d_analysis import analyze_8d
except ModuleNotFoundError as exc:
    DemoFactoryTrialDataSource = None
    analyze_8d = None
    print(f"[SuperAgentAPI] ERP modulesæœªåŠ è½½: {exc}")
from core.strategy_engine import StrategyEngine
from core.content_compliance import ContentComplianceService
from core.copyright_inspector import CopyrightInspector, PlatformSourceComparison
from core.stock_gateway import StockGateway
from core.stock_simulator import StockSimulator
from core.stock_backtest import BacktestEngine
from core.integrations.douyin import DouyinIntegration
from core.integrations.api_monitor import APIMonitor
from core.stock_factor_engine import StockFactorEngine, stock_factor_engine
from core.stock_execution_analyzer import execution_analyzer
from core.broker_adapter import broker_manager
from core.storyboard_generator import StoryboardGenerator
from core.trend_scenario_engine import trend_scenario_engine, ScenarioInput
from core.trend_data_collector import trend_data_collector
from core.trend_rag_output import trend_rag_output
from core.operations_finance_expert import chart_expert, finance_expert
from core.operations_finance_strategy import operations_finance_strategy
from core.erp_data_sync import erp_data_sync
from core.expert_standardization import expert_standardization
from core.expert_collaboration import expert_collaboration_hub
from core.config_automation import (
    get_env_manager,
    get_deployment_manager,
)
from core.service_registry import get_service_registry, ServiceContract
from core.service_gateway import get_service_gateway, ServiceCallResult
from core.coding_assistant_enhanced import documentation_generator, command_replay, cursor_ide_integration
from core.multitenant_microservice_evolution import multitenant_evolution
from core.slo_performance_reporter import slo_performance_reporter, VectorIndexBenchmark, StreamingBenchmark, ContextCompressionBenchmark
from core.acceptance_matrix_generator import acceptance_matrix_generator
from core.acceptance_recording import acceptance_recording
from core.ci_evidence_uploader import ci_evidence_uploader
from core.closed_loop_engine import ClosedLoopEngine, ExecutionStatus
from core.unified_event_bus import UnifiedEventBus, EventCategory, EventSeverity, get_unified_event_bus, EventFilter
from core.execution_checker import ExecutionChecker, CheckType, CheckResult
from core.feedback_handler import FeedbackHandler, FeedbackType, FeedbackStatus
from core.evidence_recorder import EvidenceRecorder, EvidenceType
from core.content_deai_pipeline import deai_pipeline
from core.content_analytics import content_analytics
from core.database_persistence import DatabasePersistence, get_persistence
from core.data_sync_manager import DataSyncManager, get_sync_manager
from core.data_service import DataService, get_data_service
from core.persistence_seed import PersistenceSeeder
from core.tenant_manager import tenant_manager
from core.tenant_context import get_current_tenant
from core.module_registry import ModuleRegistry
from core.module_chain import ModuleChainManager
from core.function_hierarchy import FOUR_LEVEL_FUNCTIONS

RAG_MODULE_ROOT = project_root / "ğŸ“š Enhanced RAG & Knowledge Graph"
if RAG_MODULE_ROOT.exists() and str(RAG_MODULE_ROOT) not in sys.path:
    sys.path.insert(0, str(RAG_MODULE_ROOT))
try:
    from core.rag_tools import (
        clean_text as rag_clean,
        standardize_text as rag_standardize,
        deduplicate as rag_dedup,
        validate as rag_validate,
        authenticity_score as rag_auth_score,
    )
except ModuleNotFoundError as exc:
    rag_clean = rag_standardize = rag_dedup = rag_validate = rag_auth_score = None
    print(f"[SuperAgentAPI] RAG modulesæœªåŠ è½½: {exc}")

from AI_Programming_Assistant.core import (
    CursorAuthorization,
    CursorBridge,
    CursorLocalBridge,
    CursorPluginSystem,
    CursorProtocol,
    AuthorizationLevel,
    AccessScope,
    PluginPermission,
    PluginStatus,
    ProtocolCommand,
)
from datetime import timedelta
from dataclasses import dataclass, asdict

security_settings = get_security_settings()
sensitive_filter = SensitiveContentFilter()
router_dependencies = [Depends(require_api_token)] if security_settings.api_token else []

router = APIRouter(prefix="/api/super-agent", tags=["Super Agent"], dependencies=router_dependencies)
collaboration_event_stream = CollaborationEventStreamManager()
env_config_manager = get_env_manager()
deployment_manager = get_deployment_manager()
service_registry = get_service_registry()
service_gateway = get_service_gateway()


def _bootstrap_service_contracts():
    services_dir = project_root.parent / "config/services"
    if not services_dir.exists():
        return
    for path in services_dir.glob("*.yaml"):
        try:
            data = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
        except Exception as exc:
            logger.warning("è¯»å–æœåŠ¡å¥‘çº¦å¤±è´¥ %s: %s", path, exc)
            continue
        service = data.get("service")
        if not service:
            continue
        for operation in data.get("operations", []):
            contract = ServiceContract(
                service=service,
                operation=operation.get("operation"),
                method=operation.get("method", "POST"),
                path=operation.get("path", "/"),
                version=data.get("version", "v1"),
                timeout=operation.get("timeout", 2.0),
                description=data.get("description", ""),
                schema=operation.get("schema", {}),
            )
            service_registry.register_contract(contract)


_bootstrap_service_contracts()

# åˆå§‹åŒ–æœåŠ¡
super_agent = SuperAgent()
memo_system = MemoSystem()
task_planning = TaskPlanning(memo_system)

# P0-003: åˆå§‹åŒ–æ•°æ®æŒä¹…åŒ–å’ŒåŒæ­¥æœåŠ¡
data_persistence = get_persistence()
data_sync_manager = get_sync_manager()
data_service = get_data_service()

# P1-003: æ•°æ®æŒä¹…åŒ–ç§å­ç®¡ç†
persistence_seeder = PersistenceSeeder(data_service)

# P1-002: API è°ƒç”¨ç›‘æ§
api_monitor = APIMonitor()


def _register_default_service_handlers():
    async def rag_search(payload: Dict[str, Any]):
        query = payload.get("query") or payload.get("text") or ""
        top_k = max(1, min(int(payload.get("top_k", 5)), 10))
        result = await super_agent.dual_rag_engine.first_rag_retrieval(user_input=query, top_k=top_k)
        return result.to_dict()

    async def rag_experience(payload: Dict[str, Any]):
        query = payload.get("query") or ""
        execution = payload.get("execution_result") or {"module": "rag", "result": {}}
        rag1 = await super_agent.dual_rag_engine.first_rag_retrieval(user_input=query)
        rag2 = await super_agent.dual_rag_engine.second_rag_retrieval(
            user_input=query,
            execution_result=execution,
            rag1_result=rag1,
        )
        return {"rag1": rag1.to_dict(), "rag2": rag2.to_dict()}

    async def trend_backtest(payload: Dict[str, Any]):
        indicator = payload.get("indicator") or "EV_DEMAND"
        window = int(payload.get("window", 90))
        return trend_scenario_engine.run_backtest(indicator=indicator, window=window)

    async def trend_scenario(payload: Dict[str, Any]):
        scenario = ScenarioInput(
            indicator=payload.get("indicator", "EV_DEMAND"),
            scenario_name=payload.get("scenario_name", "é»˜è®¤æƒ…æ™¯"),
            demand_shift=float(payload.get("demand_shift", 0.05)),
            policy_intensity=float(payload.get("policy_intensity", 0.08)),
            supply_shift=float(payload.get("supply_shift", 0.02)),
        )
        return trend_scenario_engine.simulate_scenario(scenario)

    service_gateway.register_internal_handler("rag_hub", "search", rag_search)
    service_gateway.register_internal_handler("rag_hub", "experience", rag_experience)
    service_gateway.register_internal_handler("trend_ops", "backtest", trend_backtest)
    service_gateway.register_internal_handler("trend_ops", "scenario", trend_scenario)


_register_default_service_handlers()

# P0-004: å®‰å…¨å®¡è®¡ã€æƒé™ã€é£æ§
audit_pipeline = get_audit_pipeline()
risk_engine = get_risk_engine()
permission_guard = get_permission_guard()
crawler_compliance_service = get_crawler_compliance_service()
approval_manager = get_approval_manager()
security_read_dep = permission_guard.require("security:read")
security_write_dep = permission_guard.require("security:write")
finance_read_dep = permission_guard.require("finance:read")
learning_monitor = SelfLearningMonitor(resource_manager=None, event_bus=super_agent.event_bus)
resource_monitor = ResourceMonitor()
learning_monitor.resource_manager = resource_monitor
resource_adjuster = ResourceAutoAdjuster(resource_manager=resource_monitor)  # èµ„æºè‡ªåŠ¨è°ƒèŠ‚å™¨
# P0-013: åˆå§‹åŒ–å·¥ä½œæµå› æœåˆ†æå™¨
workflow_causal_analyzer = WorkflowCausalAnalyzer(
    workflow_monitor=super_agent.workflow_monitor,
    learning_monitor=learning_monitor
)
# å°†å› æœåˆ†æå™¨æ³¨å…¥åˆ°å·¥ä½œæµç›‘æ§å™¨
if super_agent.workflow_monitor:
    super_agent.workflow_monitor.causal_analyzer = workflow_causal_analyzer

# P0-014: åˆå§‹åŒ–èµ„æºè¯Šæ–­å’Œæˆæƒç®¡ç†å™¨
resource_diagnostic_engine = ResourceDiagnosticEngine(
    resource_monitor=resource_monitor,
    resource_auto_adjuster=resource_adjuster
)
resource_authorization_manager = ResourceAuthorizationManager(
    resource_auto_adjuster=resource_adjuster,
    resource_diagnostic=resource_diagnostic_engine
)

# P0-015: åˆå§‹åŒ–èµ„æºç­–ç•¥å¼•æ“å’Œå†²çªè°ƒåº¦ç³»ç»Ÿ
resource_strategy_engine = ResourceStrategyEngine(
    learning_system=learning_monitor,  # ä¸è‡ªå­¦ä¹ ç³»ç»Ÿè”åŠ¨
    resource_monitor=resource_monitor,
    dynamic_allocator=None  # å¦‚æœéœ€è¦å¯ä»¥æ³¨å…¥
)
resource_conflict_scheduler = ResourceConflictScheduler(
    resource_monitor=resource_monitor,
    strategy_engine=resource_strategy_engine,
    learning_system=learning_monitor,  # ä¸è‡ªå­¦ä¹ ç³»ç»Ÿè”åŠ¨
    dynamic_allocator=None
)

# P0-017: åˆå§‹åŒ–å®‰å…¨ä¸åˆè§„åŸºçº¿ç³»ç»Ÿ
security_compliance_baseline = SecurityComplianceBaseline()

# P0-018: åˆå§‹åŒ–å¯è§‚æµ‹æ€§ç³»ç»Ÿ
observability_system = ObservabilitySystem()
observability_persistence = ObservabilityPersistence()
observability_alerts = ObservabilityAlertSystem(observability_system)
observability_exporter = ObservabilityExporter(observability_system, observability_persistence)

# æ³¨å†Œå‘Šè­¦å›è°ƒï¼ˆå¯ä»¥æ‰©å±•ä¸ºå‘é€é‚®ä»¶ã€Webhookç­‰ï¼‰
def alert_callback(alert):
    """å‘Šè­¦å›è°ƒå‡½æ•°"""
    logger.warning(f"å‘Šè­¦è§¦å‘: {alert.rule_name} - {alert.message}")

observability_alerts.register_alert_callback(alert_callback)

# P0-019: åˆå§‹åŒ–çŸ¥è¯†æ²‰æ·€ç³»ç»Ÿ
knowledge_template_manager = KnowledgeTemplateManager()
knowledge_ingestion_strategy = KnowledgeIngestionStrategy(
    template_manager=knowledge_template_manager,
    rag_service=None  # ç¨åå¯ä»¥é€šè¿‡HTTPè°ƒç”¨RAGæœåŠ¡
)
knowledge_ingestion_strategy.rag_service = super_agent.rag_service


ERP_PROCESS_STAGES = [
    {
        "id": "market_research",
        "name": "å¸‚åœºè°ƒç ”",
        "status": "completed",
        "progress": 100,
        "owner": "å¸‚åœºæ´å¯Ÿç»„",
        "duration_days": 7,
        "started_at": "2025-10-01T09:00:00",
        "completed_at": "2025-10-07T18:00:00",
        "metrics": {
            "market_size": "Â¥1.2B",
            "target_segments": 3,
            "feasibility": "A",
            "opportunities": 12
        },
        "risks": ["ç«äº‰å¯¹æ‰‹ä»·æ ¼æˆ˜"],
        "next_actions": ["ç§»äº¤å®¢æˆ·å¼€å‘å›¢é˜Ÿ"],
        "documents": ["å¸‚åœºæ´å¯ŸæŠ¥å‘Š.pdf"]
    },
    {
        "id": "customer_development",
        "name": "å®¢æˆ·å¼€å‘",
        "status": "completed",
        "progress": 100,
        "owner": "é”€å”®æ‹“å±•",
        "duration_days": 10,
        "started_at": "2025-10-08T09:00:00",
        "completed_at": "2025-10-18T18:00:00",
        "metrics": {
            "leads_contacted": 36,
            "qualified_leads": 14,
            "conversion_rate": 38
        },
        "risks": [],
        "next_actions": ["åˆæ­¥æŠ€æœ¯è¯„ä¼°"],
        "documents": ["å®¢æˆ·æ²Ÿé€šè®°å½•.xlsx"]
    },
    {
        "id": "project_development",
        "name": "é¡¹ç›®å¼€å‘",
        "status": "completed",
        "progress": 100,
        "owner": "è§£å†³æ–¹æ¡ˆéƒ¨",
        "duration_days": 12,
        "started_at": "2025-10-19T09:00:00",
        "completed_at": "2025-10-30T18:00:00",
        "metrics": {
            "bom_ready": True,
            "custom_features": 4,
            "engineering_hours": 320
        },
        "risks": ["éƒ¨åˆ†åŠŸèƒ½éœ€äºŒæ¬¡ç¡®è®¤"],
        "next_actions": ["ç”ŸæˆæŠ•äº§è®¡åˆ’"],
        "documents": ["é¡¹ç›®è§„æ ¼ä¹¦.docx"]
    },
    {
        "id": "production_planning",
        "name": "æŠ•äº§è®¡åˆ’",
        "status": "completed",
        "progress": 100,
        "owner": "è®¡åˆ’è°ƒåº¦ä¸­å¿ƒ",
        "duration_days": 5,
        "started_at": "2025-11-01T09:00:00",
        "completed_at": "2025-11-05T18:00:00",
        "metrics": {
            "lines_reserved": 2,
            "capacity_utilization": 86,
            "planned_batches": 6
        },
        "risks": [],
        "next_actions": ["åˆ›å»ºå®¢æˆ·è®¢å•"],
        "documents": ["ç”Ÿäº§æ’ç¨‹è¡¨.xlsx"]
    },
    {
        "id": "order_management",
        "name": "è®¢å•ç®¡ç†",
        "status": "in_progress",
        "progress": 72,
        "owner": "è®¢å•è¿è¥",
        "duration_days": 9,
        "started_at": "2025-11-06T09:00:00",
        "completed_at": None,
        "metrics": {
            "orders_confirmed": 4,
            "orders_pending": 1,
            "value_confirmed": "Â¥4.5M"
        },
        "risks": ["ä¸€ä¸ªå…³é”®è®¢å•å¾…å®¢æˆ·ç­¾å­—"],
        "next_actions": ["åŒæ­¥é‡‡è´­éœ€æ±‚"],
        "documents": ["è®¢å•ç¡®è®¤ä¹¦.pdf"]
    },
    {
        "id": "procurement",
        "name": "é‡‡è´­æ‰§è¡Œ",
        "status": "in_progress",
        "progress": 58,
        "owner": "é‡‡è´­ç®¡ç†",
        "duration_days": 8,
        "started_at": "2025-11-08T09:00:00",
        "completed_at": None,
        "metrics": {
            "po_sent": 18,
            "po_confirmed": 12,
            "critical_items": 3
        },
        "risks": ["å…³é”®èŠ¯ç‰‡äº¤æœŸ 14 å¤©"],
        "next_actions": ["åŠ æ€¥è·Ÿå‚¬ä¾›åº”å•†"],
        "documents": ["é‡‡è´­æ¸…å•.xlsx"]
    },
    {
        "id": "material_receipt",
        "name": "åˆ°æ–™ç®¡ç†",
        "status": "planned",
        "progress": 20,
        "owner": "ä»“å‚¨éƒ¨",
        "duration_days": 6,
        "started_at": None,
        "completed_at": None,
        "metrics": {
            "expected_shipments": 9,
            "inspected_ready": 0,
            "defect_rate": 0
        },
        "risks": [],
        "next_actions": ["å‡†å¤‡IQCæ£€éªŒ"],
        "documents": []
    },
    {
        "id": "production",
        "name": "ç”Ÿäº§æ‰§è¡Œ",
        "status": "planned",
        "progress": 0,
        "owner": "åˆ¶é€ ä¸­å¿ƒ",
        "duration_days": 14,
        "started_at": None,
        "completed_at": None,
        "metrics": {},
        "risks": [],
        "next_actions": ["ç­‰å¾…ç‰©æ–™é½å¥—"],
        "documents": []
    },
    {
        "id": "quality_check",
        "name": "è´¨é‡æ£€éªŒ",
        "status": "pending",
        "progress": 0,
        "owner": "QAå®éªŒå®¤",
        "duration_days": 4,
        "metrics": {},
        "risks": [],
        "next_actions": [],
        "documents": []
    },
    {
        "id": "warehousing",
        "name": "å…¥åº“ç®¡ç†",
        "status": "pending",
        "progress": 0,
        "owner": "ä»“åº“è¿è¥",
        "duration_days": 3,
        "metrics": {},
        "risks": [],
        "next_actions": [],
        "documents": []
    },
    {
        "id": "delivery",
        "name": "äº¤ä»˜ä¸ç»“ç®—",
        "status": "pending",
        "progress": 0,
        "owner": "äº¤ä»˜å›¢é˜Ÿ",
        "duration_days": 6,
        "metrics": {},
        "risks": [],
        "next_actions": [],
        "documents": []
    }
]

ERP_PROCESS_TIMELINE = [
    {
        "stage": "market_research",
        "title": "å¸‚åœºè°ƒç ”å®Œæˆ",
        "timestamp": "2025-10-07T18:00:00",
        "status": "completed",
        "summary": "é”å®šæ™ºèƒ½ç¡¬ä»¶å’Œå·¥ä¸šæ§åˆ¶ä¸¤ä¸ªç›®æ ‡ç»†åˆ†å¸‚åœº",
        "impact": "+12% è½¬åŒ–ç‡"
    },
    {
        "stage": "customer_development",
        "title": "å®¢æˆ·å¼€å‘å®Œæˆ",
        "timestamp": "2025-10-18T18:00:00",
        "status": "completed",
        "summary": "ç­¾ç½² 4 ä»½æ„å‘ä¹¦ï¼Œé¢„è®¡è®¢å•é‡‘é¢ Â¥4.8M",
        "impact": "+4 ä¸ªå…³é”®å®¢æˆ·"
    },
    {
        "stage": "project_development",
        "title": "é¡¹ç›®æ–¹æ¡ˆå†»ç»“",
        "timestamp": "2025-10-30T18:00:00",
        "status": "completed",
        "summary": "ç¡®è®¤ BOM ä¸ç‰¹æ€§ï¼Œè¿›å…¥æ’äº§",
        "impact": "BOM æˆæœ¬ä¸‹é™ 6%"
    },
    {
        "stage": "production_planning",
        "title": "æ’äº§å®Œæˆ",
        "timestamp": "2025-11-05T18:00:00",
        "status": "completed",
        "summary": "é”å®š 2 æ¡äº§çº¿ï¼Œäº¤ä»˜å‘¨æœŸ 28 å¤©",
        "impact": "äº§èƒ½åˆ©ç”¨ç‡ 86%"
    },
    {
        "stage": "order_management",
        "title": "è®¢å•ç¡®è®¤è¿›åº¦",
        "timestamp": "2025-11-09T09:00:00",
        "status": "in_progress",
        "summary": "4/5 ä»½è®¢å•è¿›å…¥æ‰§è¡Œï¼Œå‰©ä½™å¾…æ³•åŠ¡ç¡®è®¤",
        "impact": "ç°é‡‘æµé¢„æµ‹ +Â¥3.2M"
    },
    {
        "stage": "procurement",
        "title": "é‡‡è´­æ‰§è¡Œæ›´æ–°",
        "timestamp": "2025-11-11T10:00:00",
        "status": "in_progress",
        "summary": "12 ä»½ PO å·²ç¡®è®¤ï¼Œå…³é”®èŠ¯ç‰‡é¢„è®¡ 14 å¤©äº¤ä»˜",
        "impact": "ç‰©æ–™é½å¥—ç‡ 65%"
    }
]

TREND_INDICATOR_LIBRARY = [
    {
        "id": "industry_demand_velocity",
        "category": "industry",
        "name": "è¡Œä¸šéœ€æ±‚å¢é€Ÿ",
        "description": "è·Ÿè¸ªç»†åˆ†è¡Œä¸šè®¢å•ä¸è¯¢ä»·çš„æ»šåŠ¨å¢é€Ÿï¼Œè¯†åˆ«éœ€æ±‚æ‹ç‚¹",
        "unit": "%",
        "current_value": 8.4,
        "trend": "+1.2pp MoM",
        "confidence": 0.82,
        "drivers": ["äº¤ä»˜å‘¨æœŸç¼©çŸ­", "è¡¥åº“å­˜éœ€æ±‚", "æµ·å¤–å›æµè®¢å•"],
        "risks": ["éœ€æ±‚é€æ”¯", "ä»·æ ¼æˆ˜åŠ å‰§"],
        "recommended_actions": [
            "ä¼˜å…ˆæŠ•æ”¾åä¸œ/æ–°èƒ½æºä¾›åº”é“¾èµ„æº",
            "å°†äº¤ä»˜ SLA ä»15å¤©ä¸‹è°ƒåˆ°12å¤©å¹¶ç›‘æ§æˆæœ¬"
        ],
        "regions": ["åä¸œ", "åå—"],
        "industries": ["æ™ºèƒ½åˆ¶é€ ", "æ–°èƒ½æºè®¾å¤‡"]
    },
    {
        "id": "region_capacity_utilization",
        "category": "region",
        "name": "åŒºåŸŸäº§èƒ½åˆ©ç”¨ç‡",
        "description": "ç›‘æ§é‡ç‚¹çœä»½æ ¸å¿ƒäº§çº¿åˆ©ç”¨ç‡ä¸æ’äº§é¥±å’Œåº¦",
        "unit": "%",
        "current_value": 74,
        "trend": "-3pp WoW",
        "confidence": 0.77,
        "drivers": ["é™ç”µæ”¿ç­–è§£é™¤", "äººå·¥çŸ­ç¼º", "OEMè®¢å•æ¨è¿Ÿ"],
        "risks": ["äº§çº¿æ³¢åŠ¨åŠ å‰§", "åŠ ç­æˆæœ¬ä¸Šæ¶¨"],
        "recommended_actions": [
            "é’ˆå¯¹ç ä¸‰è§’å®‰æ’è·¨åŒºåŸŸäº§èƒ½è°ƒæ‹¨",
            "å¯¹ >90% äº§çº¿å¯ç”¨å¤œç­å®ˆæŠ¤æµç¨‹"
        ],
        "regions": ["ç ä¸‰è§’", "æˆæ¸"],
        "industries": ["ç”µå­åˆ¶é€ ", "é«˜ç«¯è£…é…"]
    },
    {
        "id": "policy_grants_tracker",
        "category": "policy",
        "name": "æ”¿ç­–è¡¥è´´å…‘ç°ç‡",
        "description": "ç»Ÿè®¡å„ä¸“é¡¹è¡¥è´´çš„å®¡æ‰¹ç‡/åˆ°è´¦ç‡ï¼Œè¯„ä¼°ç°é‡‘æµæ”¹å–„å¹…åº¦",
        "unit": "%",
        "current_value": 62,
        "trend": "+9pp QoQ",
        "confidence": 0.71,
        "drivers": ["æ™ºèƒ½åˆ¶é€ è¡¥è´´æ”¾æ¬¾", "åœ°æ–¹æŠ€æ”¹å¥–åŠ±"],
        "risks": ["ææ–™çœŸå®æ€§æ ¸æŸ¥", "åˆè§„å®¡è®¡è¡¥è¯"],
        "recommended_actions": [
            "å¯¹æœªåˆ°è´¦çš„ 18% æ”¿ç­–åŒ…å‘èµ·äººå·¥è·Ÿè¿›",
            "åŒæ­¥è´¢åŠ¡åˆ¶å®šâ€œè¡¥è´´åˆ°è´¦å³å¯¹å†²è´·æ¬¾â€ç­–ç•¥"
        ],
        "regions": ["é•¿ä¸‰è§’", "äº¬æ´¥å†€"],
        "industries": ["è£…å¤‡åˆ¶é€ ", "ç»¿è‰²èƒ½æº"]
    },
    {
        "id": "policy_risk_index",
        "category": "policy",
        "name": "æ”¿ç­–æ•æ„Ÿåº¦æŒ‡æ•°",
        "description": "é‡åŒ–å®è§‚è°ƒæ§/åˆè§„æ–°è§„å¯¹ä¸šåŠ¡çš„å½±å“èŒƒå›´ä¸æ¦‚ç‡",
        "unit": "index",
        "current_value": 0.63,
        "trend": "+0.07",
        "confidence": 0.68,
        "drivers": ["åŒç¢³æ’æ”¾æ ¸æŸ¥", "å‡ºå£é€€ç¨å®¡æ ¸åŠ å¼º"],
        "risks": ["æ–°å¢å®¡æ‰¹èŠ‚ç‚¹å¯¼è‡´äº¤ä»˜å»¶æœŸ"],
        "recommended_actions": [
            "ç»„å»ºè·¨éƒ¨é—¨åˆè§„å“åº”å°ç»„",
            "å°† ESG/åŒç¢³æŒ‡æ ‡åµŒå…¥é”€å”®æŠ•æ ‡èµ„æ–™"
        ],
        "regions": ["å…¨å›½"],
        "industries": ["å…¨è¡Œä¸š"]
    }
]

EXPERT_ABILITY_MAP = [
    {
        "id": "rag_expert",
        "name": "çŸ¥è¯†æ¶æ„ä¸“å®¶",
        "icon": "ğŸ“š",
        "level": "L3",
        "modules": ["rag", "knowledge"],
        "confidence": 0.94,
        "coverage": {"scenarios": 42, "avg_latency_ms": 680, "satisfaction": 0.95},
        "capabilities": [
            {"name": "çŸ¥è¯†åˆ†å±‚&æ ‡ç­¾", "status": "ready"},
            {"name": "å¬å›ç‡è°ƒä¼˜", "status": "ready"},
            {"name": "æ–‡æ¡£å»å†—/è’¸é¦", "status": "beta"}
        ],
        "signals": ["æ£€ç´¢å¤±è´¥", "FAQè¦†ç›–ä¸è¶³", "å¬å›ç‡æŒ‡æ ‡ä½äº80%"],
        "playbooks": ["rag/playbook/boost-faq.md", "rag/playbook/graph-routing.md"],
        "tests": ["rag_segment_smoke", "rag_latency_benchmark"]
    },
    {
        "id": "erp_expert",
        "name": "ERPè¿è¥ä¸“å®¶",
        "icon": "ğŸ’¼",
        "level": "L2",
        "modules": ["erp", "operations"],
        "confidence": 0.89,
        "coverage": {"scenarios": 37, "avg_latency_ms": 720, "satisfaction": 0.9},
        "capabilities": [
            {"name": "è®¢å•å±¥çº¦è¿½è¸ª", "status": "ready"},
            {"name": "é‡‡è´­è¡¥è´§å»ºè®®", "status": "ready"},
            {"name": "äº§èƒ½æ’ç¨‹æ ¡éªŒ", "status": "pilot"}
        ],
        "signals": ["è®¢å•äº¤æœŸæŸ¥è¯¢", "æ’äº§å†²çª", "ç‰©æ–™é½å¥—ç‡ä½"],
        "playbooks": ["erp/playbook/exception-handler.md"],
        "tests": ["erp_command_center_regression"]
    },
    {
        "id": "content_expert",
        "name": "å†…å®¹å¢é•¿ä¸“å®¶",
        "icon": "âœï¸",
        "level": "L2",
        "modules": ["content", "douyin"],
        "confidence": 0.9,
        "coverage": {"scenarios": 29, "avg_latency_ms": 610, "satisfaction": 0.92},
        "capabilities": [
            {"name": "å¤šå¹³å°å†…å®¹ç­–ç•¥", "status": "ready"},
            {"name": "ç‰ˆæƒ/åˆè§„æ ¡éªŒ", "status": "ready"},
            {"name": "è§†é¢‘è„šæœ¬æ‹†åˆ†", "status": "beta"}
        ],
        "signals": ["è„šæœ¬ç”Ÿæˆ", "åˆè§„è¯„ä¼°", "å†…å®¹A/Bæ–¹æ¡ˆ"],
        "playbooks": ["content/playbook/script-kit.md"],
        "tests": ["content_flow_blocking", "douyin_callback_smoke"]
    },
    {
        "id": "trend_expert",
        "name": "è¶‹åŠ¿æ´å¯Ÿä¸“å®¶",
        "icon": "ğŸ“ˆ",
        "level": "L2",
        "modules": ["trend", "operations"],
        "confidence": 0.88,
        "coverage": {"scenarios": 31, "avg_latency_ms": 640, "satisfaction": 0.91},
        "capabilities": [
            {"name": "æŒ‡æ ‡å›æµ‹è§£é‡Š", "status": "ready"},
            {"name": "What-ifæƒ…æ™¯è¯„ä¼°", "status": "ready"},
            {"name": "è¡Œä¸šçœ‹æ¿æ¨è", "status": "pilot"}
        ],
        "signals": ["è¶‹åŠ¿å¯¹æ¯”", "æ”¿ç­–å†²å‡»", "æŒ‡æ ‡å¼‚å¸¸"],
        "playbooks": ["trend/playbook/what-if.md"],
        "tests": ["trend_backtest_fixture"]
    },
    {
        "id": "coding_expert",
        "name": "AIç¼–ç¨‹ä¸“å®¶",
        "icon": "ğŸ’»",
        "level": "L3",
        "modules": ["coding"],
        "confidence": 0.91,
        "coverage": {"scenarios": 53, "avg_latency_ms": 520, "satisfaction": 0.89},
        "capabilities": [
            {"name": "é—®é¢˜å®šä½", "status": "ready"},
            {"name": "å•æµ‹è¡¥å…¨", "status": "ready"},
            {"name": "ä»£ç å®¡é˜…", "status": "ready"}
        ],
        "signals": ["CIå¤±è´¥", "ä»£ç å®¡æŸ¥", "APIè®¾è®¡"],
        "playbooks": ["dev/playbook/hotfix.md"],
        "tests": ["coding_unit_patch", "lint_autofix_suite"]
    }
]

EXPERT_ROUTING_STRATEGY = {
    "version": "2025.11.18",
    "confidence_thresholds": {
        "direct_route": 0.72,
        "needs_clarification": 0.45,
        "fallback": 0.3
    },
    "heuristics": [
        {"signal": "å…³é”®è¯æƒé‡", "weight": 0.45, "description": "åŒ¹é…è¯é¢‘>3ä¸”è¦†ç›–ä¸åŒæ§½ä½å³ç›´è¿"},
        {"signal": "æ„å›¾æ¨¡å‹", "weight": 0.25, "description": "åŸºäºæŒ‡ä»¤/é—®é¢˜/è¯·æ±‚åˆ†ç±»"},
        {"signal": "RAGæ¥æº", "weight": 0.15, "description": "çŸ¥è¯†ç‰‡æ®µæ ‡ç­¾ä¸ä¸“å®¶é¢†åŸŸæ˜ å°„"},
        {"signal": "ä¼šè¯ä¸Šä¸‹æ–‡", "weight": 0.1, "description": "æœ€è¿‘ä¸€æ¬¡ä¸“å®¶æˆåŠŸç‡"},
        {"signal": "èµ„æºè´Ÿè½½", "weight": 0.05, "description": "é¿å…å•ä¸“å®¶è¶…è½½"}
    ],
    "fallback_chain": [
        {"condition": "confidence < 0.3", "action": "åˆ‡å›RAGå›ç­”"},
        {"condition": "ä¸“å®¶è¶…è½½>80%", "action": "è·¯ç”±æ¬¡ä¼˜ä¸“å®¶å¹¶æé†’"}
    ],
    "module_load": {
        "rag": 0.32,
        "erp": 0.18,
        "content": 0.15,
        "trend": 0.12,
        "coding": 0.23
    },
    "recent_routes": [
        {
            "query": "å¸®æˆ‘è¯„ä¼°ä¸€ä¸‹åä¸œè®¢å•çš„äº¤ä»˜é£é™©",
            "expert": "erp_expert",
            "domain": "erp",
            "confidence": 0.81,
            "timestamp": datetime.now().isoformat(timespec="seconds")
        },
        {
            "query": "è¿™ä»½FAQå‘½ä¸­ç‡å¤ªä½äº†å¯ä»¥æ€ä¹ˆè°ƒ",
            "expert": "rag_expert",
            "domain": "rag",
            "confidence": 0.9,
            "timestamp": datetime.now().isoformat(timespec="seconds")
        },
        {
            "query": "æŠ–éŸ³ç‰ˆæƒæ ¡éªŒæœªé€šè¿‡æ€ä¹ˆå¤æ ¸",
            "expert": "content_expert",
            "domain": "content",
            "confidence": 0.76,
            "timestamp": datetime.now().isoformat(timespec="seconds")
        }
    ]
}

EXPERT_ACCEPTANCE_MATRIX = [
    {
        "capability": "çŸ¥è¯†åˆ†å±‚&æ ‡ç­¾",
        "owner": "RAG QA",
        "tests": [
            {"name": "rag_segment_smoke", "status": "pass", "metric": "15/15"},
            {"name": "rag_latency_benchmark", "status": "pass", "metric": "1.8s P95"}
        ],
        "acceptance": "å¬å›ç‡>85%ï¼Œå¹³å‡å“åº”<2s",
        "last_run": "2025-11-16T10:00:00"
    },
    {
        "capability": "è®¢å•å±¥çº¦è¿½è¸ª",
        "owner": "ERP QA",
        "tests": [
            {"name": "erp_command_center_regression", "status": "pass", "metric": "32 checks"},
            {"name": "slo_alert_hook", "status": "pass", "metric": "0æ¼æŠ¥"}
        ],
        "acceptance": "å¼‚å¸¸å®šä½å‡†ç¡®ç‡>95%ï¼Œå»ºè®®æ¨é€â‰¤3æ¡",
        "last_run": "2025-11-15T18:30:00"
    },
    {
        "capability": "ç‰ˆæƒ/ä¾µæƒå¤æ ¸",
        "owner": "Content QA",
        "tests": [
            {"name": "content_flow_blocking", "status": "pass", "metric": "100% æ‹¦æˆª"},
            {"name": "douyin_callback_smoke", "status": "pass", "metric": "å®æ—¶"}
        ],
        "acceptance": "å‘½ä¸­ç‡>98%ï¼Œè¯¯æ€<1%",
        "last_run": "2025-11-17T09:45:00"
    },
    {
        "capability": "What-ifæƒ…æ™¯è¯„ä¼°",
        "owner": "Trend QA",
        "tests": [
            {"name": "trend_backtest_fixture", "status": "pass", "metric": "MAPE 6.1%"},
            {"name": "scenario_delta_validation", "status": "pass", "metric": "Î”é¢„æµ‹ä¸€è‡´"}
        ],
        "acceptance": "é¢„æµ‹åå·®<8%ï¼Œæƒ…æ™¯æŠ¥å‘Šâ‰¤2sè¾“å‡º",
        "last_run": "2025-11-14T14:12:00"
    },
    {
        "capability": "ä»£ç å®¡é˜…",
        "owner": "Dev QA",
        "tests": [
            {"name": "coding_unit_patch", "status": "pass", "metric": "18/18"},
            {"name": "lint_autofix_suite", "status": "pass", "metric": "0 blocker"}
        ],
        "acceptance": "å®‰å…¨é—®é¢˜æ£€å‡ºç‡>90%ï¼Œå»ºè®®æ‰§è¡Œç‡>80%",
        "last_run": "2025-11-16T22:00:00"
    }
]

MULTITENANT_EVOLUTION_PLAN = {
    "version": "2025.11.18",
    "vision": {
        "summary": "ä¿æŒå•ä½“ä»£ç åº“ï¼ˆmono-repo + shared runtimeï¼‰ï¼Œé€šè¿‡æ¨¡å—åŒ–è¾¹ç•Œä¸å¤šç§Ÿæˆ·ä¸Šä¸‹æ–‡ï¼Œé€æ­¥æ¼”è¿›è‡³å¯æ‹†åˆ†å¾®æœåŠ¡æ¶æ„ã€‚",
        "goals": [
            "çŸ­æœŸï¼šæå‡ç§Ÿæˆ·éš”ç¦»ã€å®¡è®¡ä¸èµ„æºè·¯ç”±èƒ½åŠ›ï¼Œæ”¯æŒ One Agent Serving Multi-Tenantsã€‚",
            "ä¸­æœŸï¼šä»¥æ¨¡å—ä¸ºå•ä½æŠ½è±¡æœåŠ¡å¥‘çº¦ï¼Œå…·å¤‡ Sidecar/Function æ‰˜ç®¡èƒ½åŠ›ã€‚",
            "é•¿æœŸï¼šå¯å¹³æ»‘è¿ç§»è‡³å¤šè¿›ç¨‹/å¤šå®¹å™¨å¾®æœåŠ¡ï¼Œè€Œæ— éœ€é‡å†™ä¸šåŠ¡é€»è¾‘ã€‚"
        ]
    },
    "tenancy_layers": [
        {"layer": "Request Context", "status": "ready", "notes": "FastAPI è·¯ç”±æ”¯æŒ require_tenantï¼Œä¸­é—´ä»¶æ³¨å…¥ tenant id / SLA / feature flag"},
        {"layer": "Data Segregation", "status": "partial", "notes": "æ ¸å¿ƒæ¨¡æ‹Ÿæ•°æ®å­˜å‚¨ä»ä¸ºå†…å­˜ç»“æ„ï¼Œä¸‹ä¸€é˜¶æ®µæ¥å…¥ç§Ÿæˆ·å‰ç¼€/Schema"},
        {"layer": "Execution Sandbox", "status": "beta", "notes": "ç»ˆç«¯/ç­–ç•¥/ä»»åŠ¡æ‰§è¡Œæ”¯æŒ per-tenant å®¡è®¡è®°å½•"},
        {"layer": "Resource Budgeting", "status": "planned", "notes": "ç»“åˆ resource_monitor & expert_router åšåˆ° per-tenant é™é€Ÿ/é™æµ"},
        {"layer": "Observability", "status": "ready", "notes": "observability_system å…·å¤‡ç§Ÿæˆ·æ ‡ç­¾ï¼ŒTraces å¯åŒºåˆ†ç§Ÿæˆ·"}
    ],
    "module_boundaries": [
        {"module": "chat_orchestrator", "domain": "Interaction", "ownership": "Core Agent", "separation": "LLM routing + conversation state", "ready": True},
        {"module": "rag_hub", "domain": "Knowledge", "ownership": "RAG Service", "separation": "Doc store + vector ops", "ready": True},
        {"module": "erp_stack", "domain": "Execution", "ownership": "ERP Core", "separation": "Process + BPM + analytics", "ready": False},
        {"module": "content_ops", "domain": "Channel Integration", "ownership": "Content Service", "separation": "Douyin + compliance + creative", "ready": True},
        {"module": "trend_ops", "domain": "Analytics", "ownership": "Trend Engine", "separation": "Indicators + scenarios", "ready": True},
        {"module": "expert_router", "domain": "Shared Capability", "ownership": "Core Agent", "separation": "Routing + capability registry", "ready": True}
    ],
    "phases": [
        {
            "name": "Phase 0 Â· Context Isolation",
            "timeline": "Week 0-1",
            "deliverables": [
                "æ¨å¹¿ require_tenant åˆ°å…³é”® APIï¼ˆèµ„æºã€ä»»åŠ¡ã€å†…å®¹é›†æˆç­‰ï¼‰",
                "åœ¨ super_agent.expert_router / resource_monitor æŒä¹…ç¼“å­˜ä¸­åŠ å…¥ tenant key",
                "è¡¥å……ç§Ÿæˆ·å®¡è®¡å­—æ®µï¼ˆtenant_id, workspace_idï¼‰"
            ],
            "risk": "ä½"
        },
        {
            "name": "Phase 1 Â· Module Contracts",
            "timeline": "Week 1-3",
            "deliverables": [
                "ä¸º chat / rag / trend / content / stock æ¨¡å—å£°æ˜ OpenAPI å¥‘çº¦ï¼ˆå†…éƒ¨ï¼‰",
                "å®šä¹‰æ¨¡å—åŒ– adapter å±‚ï¼ˆservice facadeï¼‰å¹¶åœ¨å•ä½“å†…è°ƒç”¨",
                "åœ¨ observability_system ä¸­è®°å½• module-latency æŒ‡æ ‡"
            ],
            "risk": "ä¸­"
        },
        {
            "name": "Phase 2 Â· Service Slice",
            "timeline": "Week 3-6",
            "deliverables": [
                "æŠ½ç¦» rag_hub ä¸ content_ops ä¸ºå¯éƒ¨ç½² Sidecarï¼ˆä»åœ¨è¿›ç¨‹å†…ï¼‰",
                "å¯ç”¨äº‹ä»¶æ€»çº¿ï¼ˆWorkflow monitor eventsï¼‰åŒæ­¥ç§Ÿæˆ·ç”Ÿå‘½å‘¨æœŸ",
                "é¢„ç½® API Gateway/Ingress é…ç½®æ¸…å•"
            ],
            "risk": "ä¸­"
        },
        {
            "name": "Phase 3 Â· Poly-Service Ready",
            "timeline": "Week 6+",
            "deliverables": [
                "æä¾› service registry + health contractï¼Œå…è®¸ä»¥è¿›ç¨‹/å®¹å™¨å½¢å¼éƒ¨ç½²",
                "ä¸ºæ¯ä¸ªæ¨¡å—å‡†å¤‡ data access adapterï¼ˆpostgres / vector / redisï¼‰",
                "å®Œæˆ chaos / failover / rolling deployment æ¼”ç»ƒ"
            ],
            "risk": "é«˜"
        }
    ],
    "guardrails": [
        "ä¿æŒå•ä½“ä»“åº“ä¸åŸºç¡€è®¾æ–½ä¸å˜ï¼Œæ‰€æœ‰æ–°æ¨¡å—å…ˆä»¥å†…åµŒ service adapter å½¢å¼ç¼–æ’ã€‚",
        "Tenant Context å¿…é¡»è´¯ç©¿ API -> service -> storageï¼Œç¦æ­¢åœ¨ service å†…éƒ¨é‡æ–°è§£æ JWTã€‚",
        "æ¯æ¬¡æ‹†åˆ†éƒ½è¦å…ˆè¡¥å……æ¨¡å—çº§æµ‹è¯•/éªŒæ”¶ï¼ˆå‚è€ƒä¸“å®¶éªŒæ”¶çŸ©é˜µå½¢å¼ï¼‰ã€‚",
        "Observability + Resource monitor ä½œä¸ºç»Ÿä¸€ SLO ä¸­æ¢ï¼Œä¸éšæœåŠ¡æ‹†åˆ†è€Œå¤åˆ¶ã€‚",
        "ä¼˜å…ˆæ‹†åˆ†å¯¹å¤–ä¾èµ–åº¦é«˜çš„æ¨¡å—ï¼ˆå†…å®¹ã€RAGã€èµ„æºæ‰§è¡Œï¼‰ï¼ŒERP/ä»»åŠ¡ä¿æŒå•ä½“ç›´åˆ°æ•°æ®æŒä¹…åŒ–å®Œæˆã€‚"
    ],
    "acceptance": {
        "metrics": [
            "Tenancy regression (per-tenant data spill) = 0",
            "Module contract è¦†ç›–ç‡ >= 80%",
            "Service slice smoke æµ‹è¯• (start/stop) å¯åœ¨ 5 min å†…å®Œæˆ",
            "Observability trace è¦†ç›– >= 95%"
        ],
        "tests": ["tenancy_smoke_suite", "module_contract_snapshot", "service_slice_replay"]
    },
    "next_steps": [
        "è½åœ°ç§Ÿæˆ·é…ç½®ä¸­å¿ƒï¼ˆyaml/json + overrideï¼‰",
        "èµ„æº/ä¸“å®¶ç­‰å…±äº«ç»„ä»¶å†™å…¥ tenant-aware cache æ¥å£",
        "ç­¹å¤‡è¿ç§»æ–‡æ¡£ï¼ˆper module runbookï¼‰"
    ]
}

TREND_DASHBOARD_TEMPLATES = [
    {
        "id": "industry_command_center",
        "title": "è¡Œä¸šæ”»é˜²æŒ‡æŒ¥èˆ±",
        "scenario": "è¡Œä¸šæœºä¼šè¯†åˆ« + ç«å“å¯¹æ¯”",
        "widgets": [
            {"type": "kpi", "label": "éœ€æ±‚å¢é€Ÿ", "metric": "industry_demand_velocity"},
            {"type": "bar", "label": "é‡ç‚¹è¡Œä¸šæŠ•æ”¾ ROI", "dimensions": ["è¡Œä¸š", "ROI"]},
            {"type": "table", "label": "ç«å“é¢„è­¦", "columns": ["ä¼ä¸š", "ç­–ç•¥", "é£é™©"]}
        ],
        "recommended_audience": ["CMO", "è¡Œä¸šè¿è¥è´Ÿè´£äºº"],
        "refresh_cycle": "Daily",
        "call_to_action": "å°†çœ‹æ¿åµŒå…¥æœˆåº¦è¡Œä¸šä¾‹ä¼šï¼Œé©±åŠ¨èµ„æºå€¾æ–œå†³ç­–ã€‚"
    },
    {
        "id": "regional_heatmap",
        "title": "åŒºåŸŸç­–ç•¥é©¾é©¶èˆ±",
        "scenario": "åŒºåŸŸä¾›éœ€ & èµ„æºè°ƒåº¦",
        "widgets": [
            {"type": "map", "label": "åŒºåŸŸäº§èƒ½åˆ©ç”¨ç‡", "metric": "region_capacity_utilization"},
            {"type": "line", "label": "åŒºåŸŸè®¢å•/äº¤ä»˜è¶‹åŠ¿", "dimensions": ["å‘¨æ¬¡", "è®¢å•é‡", "äº¤ä»˜é‡"]},
            {"type": "list", "label": "åŒºåŸŸæ”¿ç­–çª—å£æœŸ", "fields": ["æ”¿ç­–", "è¡¥è´´æ¯”ä¾‹", "æˆªæ­¢"]}
        ],
        "recommended_audience": ["åŒºåŸŸæ€»ç»ç†", "ä¾›åº”é“¾è°ƒåº¦ä¸­å¿ƒ"],
        "refresh_cycle": "Hourly",
        "call_to_action": "ç»“åˆäº§çº¿è´Ÿè·è‡ªåŠ¨æ¨é€è·¨åŒºåŸŸè°ƒæ‹¨å»ºè®®ã€‚"
    },
    {
        "id": "policy_risk_wall",
        "title": "æ”¿ç­–é£é™©é›·è¾¾å¢™",
        "scenario": "æ”¿ç­–æ•æ„Ÿåº¦ä¸åˆè§„è¿½è¸ª",
        "widgets": [
            {"type": "radar", "label": "æ”¿ç­–æ•æ„Ÿåº¦æŒ‡æ•°", "metric": "policy_risk_index"},
            {"type": "timeline", "label": "æ”¿ç­–å‘å¸ƒèŠ‚ç‚¹", "fields": ["æ—¶é—´", "æ”¿ç­–", "å½±å“"]},
            {"type": "table", "label": "è¡¥è´´å…‘ç°è¿›åº¦", "columns": ["æ”¿ç­–åŒ…", "ç”³æŠ¥", "åˆ°è´¦ç‡", "è´Ÿè´£äºº"]}
        ],
        "recommended_audience": ["è´¢åŠ¡è´Ÿè´£äºº", "æ”¿åºœäº‹åŠ¡å›¢é˜Ÿ"],
        "refresh_cycle": "Weekly",
        "call_to_action": "ç”Ÿæˆæ”¿ç­–å½±å“å¿«æŠ¥ + åº”å¯¹è„šæœ¬ï¼Œå‡å°‘å®¡æ‰¹é“¾è·¯ã€‚"
    }
]

TREND_INSIGHTS_FEED = [
    {
        "id": "insight_001",
        "title": "åä¸œæ–°èƒ½æºè®¾å¤‡éœ€æ±‚è·ƒå‡",
        "category": "industry",
        "region": "åä¸œ",
        "impact": "positive",
        "summary": "å››å­£åº¦å‚¨èƒ½ EPC æŠ•æ ‡é›†ä¸­é‡Šæ”¾ï¼Œé€†å˜å™¨å‡ºå£æ–°å¢ 12% é¢„ç®—ã€‚",
        "action": "æŠ¢å  2 å®¶é¾™å¤´çš„åˆè§„ä¾›åº”åå½•ï¼Œæå‰é”å®š 1H æŠ•æ”¾äº§çº¿ã€‚",
        "timestamp": "2025-11-18T08:30:00",
        "tags": ["æ–°èƒ½æº", "å‚¨èƒ½"]
    },
    {
        "id": "insight_002",
        "title": "ç ä¸‰è§’åŠ³åŠ¨åŠ›ç´§ç¼ºè§¦å‘äº¤ä»˜é£é™©",
        "category": "region",
        "region": "åå—",
        "impact": "negative",
        "summary": "æ ¸å¿ƒä»£å·¥å‚ç¦»èŒç‡å‡è‡³ 18%ï¼Œå¤œç­æ’ç­ä¸è¶³å¯¼è‡´äº¤ä»˜å»¶è¿Ÿ 2.4 å¤©ã€‚",
        "action": "å¯ç”¨æˆæ¸å¤‡ä»½äº§çº¿å¹¶å¯¹å†²æµè½¬æˆæœ¬ã€‚",
        "timestamp": "2025-11-17T21:10:00",
        "tags": ["ä¾›åº”é“¾", "äº§èƒ½"]
    },
    {
        "id": "insight_003",
        "title": "åŒç¢³æ ¸æŸ¥åŠ å¼º æ”¿ç­–æ•æ„Ÿåº¦ç»§ç»­ä¸Šè¡Œ",
        "category": "policy",
        "region": "å…¨å›½",
        "impact": "warning",
        "summary": "æ–°ä¸€æ‰¹å®¡è®¡è¦æ±‚ä¼ä¸šåœ¨æ‹›æŠ•æ ‡æ–‡ä»¶å†…æŠ«éœ²ç¢³æ’æ”¾åŸºçº¿ä¸å‡æ’è·¯å¾„ã€‚",
        "action": "åœ¨å…¨éƒ¨æŠ•æ ‡æ¨¡æ¿ä¸­æ¤å…¥ ESG é™„é¡µï¼Œå¹¶åŒæ­¥åŸ¹è®­é”€å”®å›¢é˜Ÿã€‚",
        "timestamp": "2025-11-17T14:05:00",
        "tags": ["æ”¿ç­–", "ESG"]
    }
]

TREND_COMPLIANCE_REPORT = {
    "id": "trend_compliance_default",
    "status": "green",
    "last_audit": "2025-11-15T09:00:00",
    "summary": "é‡‡é›†ã€å»æ ‡è¯†åŒ–ã€RAG å†™å›å…¨æµç¨‹é€šè¿‡æœ€è¿‘ä¸€æ¬¡åˆè§„å®¡è®¡ã€‚",
    "controls": [
        {"name": "é‡‡é›†é¢‘æ§", "status": "active", "owner": "Trend Ops"},
        {"name": "åŒ¿ååŒ–å¤„ç†", "status": "active", "owner": "Data Governance"},
        {"name": "å®¡è®¡æ—¥å¿—", "status": "beta", "owner": "AI Safety"},
    ],
    "risks": [
        {"item": "ç¬¬ä¸‰æ–¹æºåˆè§„å£°æ˜æ»å", "level": "medium"},
        {"item": "æ”¿ç­–è°ƒæ•´åŒæ­¥å»¶è¿Ÿ", "level": "low"},
    ],
    "recommendations": [
        "ä¸æ³•åŠ¡å…±å»ºé‡‡é›†æ§åˆ¶å°ï¼Œè‡ªåŠ¨æç¤ºé«˜é£é™©å…³é”®è¯ã€‚",
        "å¯¹å¤–éƒ¨æ•°æ®æºè¡¥é½åè®®ï¼Œå®Œå–„ç•™å­˜/é”€æ¯ç­–ç•¥ã€‚",
    ],
}

OPERATIONS_CHART_LIBRARY = [
    {
        "id": "cash_vs_burn",
        "title": "å‡€ç°é‡‘ vs Burn Rate",
        "chart_type": "area",
        "metrics": ["net_cash", "burn_rate"],
        "dimensions": ["å‘¨"],
        "owner": "å›¾è¡¨ä¸“å®¶ Iris",
        "explanation": "å¯¹æ¯”å‡€ç°é‡‘ä¸æ¯æœˆç°é‡‘æ¶ˆè€—ï¼Œå¯å¿«é€Ÿè¯†åˆ« Runway æ˜¯å¦å°äºå®‰å…¨èŒƒå›´ã€‚",
        "recommended_usage": "è‘£äº‹ä¼šè´¢åŠ¡ä¾‹ä¼š / CFO å‘¨æŠ¥"
    },
    {
        "id": "collection_to_payment",
        "title": "å›æ¬¾ vs ä»˜æ¬¾èŠ‚å¥",
        "chart_type": "stacked_bar",
        "metrics": ["collections", "payments"],
        "dimensions": ["æ—¥"],
        "owner": "å›¾è¡¨ä¸“å®¶ Leo",
        "explanation": "å±•ç¤ºæ”¶ä»˜æ¬¾é”™é…ä¸å³°å€¼ï¼Œè¾…åŠ©è¿è¥å›¢é˜Ÿå®‰æ’é‡‡è´­/ç”Ÿäº§èŠ‚å¥ã€‚",
        "recommended_usage": "è¿è¥ä¾‹ä¼š / ä¾›åº”é“¾å®¡æŸ¥"
    },
    {
        "id": "policy_subsidy_progress",
        "title": "æ”¿ç­–è¡¥è´´å…‘ç°æ¼æ–—",
        "chart_type": "funnel",
        "metrics": ["declared", "approved", "received"],
        "dimensions": ["åœ°åŒº"],
        "owner": "å›¾è¡¨ä¸“å®¶ Nori",
        "explanation": "çªå‡ºè¡¥è´´å®¡æ‰¹/åˆ°è´¦ç“¶é¢ˆï¼Œå¼ºè°ƒåˆè§„èµ„æ–™å‡†å¤‡çš„ä¼˜å…ˆçº§ã€‚",
        "recommended_usage": "æ”¿åºœäº‹åŠ¡ã€è´¢åŠ¡ä¸“é¡¹åˆ†æ"
    }
]

OPERATIONS_FINANCE_GUIDES = [
    {
        "id": "receivable_watch",
        "title": "åº”æ”¶è´¦æœŸæ‹‰é•¿é¢„è­¦",
        "owner": "è´¢åŠ¡ä¸“å®¶ Ethan",
        "severity": "warning",
        "summary": "TOP5 è¡Œä¸šå®¢æˆ·è´¦æœŸå·²è¶…è¿‡ 68 å¤©ï¼Œè¾ƒä¸Šæœˆå¢åŠ  12 å¤©ã€‚",
        "recommended_actions": [
            "å¯¹è¶…è¿‡ 60 å¤©çš„è´¦æ¬¾å¯åŠ¨ååŒå‚¬æ”¶",
            "é”€å”®ææˆç»‘å®šå›æ¬¾èŠ‚ç‚¹ï¼Œå‡å°‘ç¡®è®¤å»¶è¿Ÿ"
        ]
    },
    {
        "id": "policy_cash_gap",
        "title": "è¡¥è´´åˆ°è´¦èŠ‚å¥ä¸å‡è¡¡",
        "owner": "è´¢åŠ¡ä¸“å®¶ Zoe",
        "severity": "info",
        "summary": "æ™ºèƒ½åˆ¶é€ è¡¥è´´è¿›å…¥å®¡æ‰¹å°¾å£°ï¼Œé¢„è®¡ä¸¤å‘¨ååˆ°è´¦ 18%",
        "recommended_actions": [
            "æå‰å‡†å¤‡éªŒæ”¶æŠ½æ£€ææ–™ï¼Œé¿å…å› èµ„æ–™ç¼ºå¤±å†å»¶è¿Ÿ",
            "åˆ°è´¦åä¼˜å…ˆå¯¹å†²çŸ­æœŸè´·æ¬¾ï¼Œé™ä½è´¢åŠ¡è´¹ç”¨"
        ]
    },
    {
        "id": "opex_burn_line",
        "title": "è¿è¥æˆæœ¬å®ˆæŠ¤çº¿",
        "owner": "è´¢åŠ¡ä¸“å®¶ Max",
        "severity": "critical",
        "summary": "è‹¥ç»´æŒç°æœ‰ Burn Rateï¼Œ6.2 ä¸ªæœˆå Runway < 3 ä¸ªæœˆ",
        "recommended_actions": [
            "å†»ç»“éå…³é”®æ‹›è˜ï¼Œé›†ä¸­èµ„æºäºé«˜å›æŠ¥äº§èƒ½",
            "æŠŠé‡‡è´­ä»˜æ¬¾å‘¨æœŸå»¶é•¿ 7 å¤©ï¼Œå¹¶å»ºç«‹æ”¯å‡ºä¼˜å…ˆçº§è¡¨"
        ]
    }
]

OPERATIONS_STRATEGY_LINKS = {
    "version": "2025-11-18",
    "bridges": [
        {
            "name": "é¢„ç®—-ERPè®¢å•è”åŠ¨",
            "source": "operations_finance",
            "target": "erp_orders",
            "description": "é¢„ç®—å†»ç»“é¢åº¦å°†ç›´æ¥å½±å“ ERP è®¢å•å®¡æ‰¹æµï¼Œè¶…å‡ºé¢„ç®—è‡ªåŠ¨å‘èµ·å®¡æ‰¹ä»»åŠ¡ã€‚",
            "status": "ready",
            "signals": ["é¢„ç®—å†»ç»“", "å¤§é¢è®¢å•"],
            "automation": ["task_center.approval.push", "chat.notify.cfo"]
        },
        {
            "name": "æˆæœ¬-äº§èƒ½è”åŠ¨",
            "source": "operations_finance",
            "target": "erp_production",
            "description": "ææ–™æˆæœ¬æ³¢åŠ¨è¶…è¿‡ 5% æ—¶ï¼Œè§¦å‘äº§èƒ½æ’ç¨‹è°ƒæ•´ä¸ä¾›åº”å•†è°ˆåˆ¤æµç¨‹ã€‚",
            "status": "beta",
            "signals": ["unit_cost_spike", "capacity>90%"],
            "automation": ["erp.production.rebalance", "trend.collect.market"]
        },
        {
            "name": "æŠ¥è¡¨-ä¸“å®¶è”åŠ¨",
            "source": "operations_finance",
            "target": "experts",
            "description": "è´¢åŠ¡æŠ¥è¡¨å¼‚å¸¸è‡ªåŠ¨è·¯ç”±å›¾è¡¨/è´¢åŠ¡ä¸“å®¶ï¼Œè¾“å‡ºå»ºè®®å¹¶åŒæ­¥åˆ°çœ‹æ¿ä¸èŠå¤©ã€‚",
            "status": "ready",
            "signals": ["runway<6", "collections_delay"],
            "automation": ["experts.route.finance", "chat.push.alert"]
        }
    ],
    "playbooks": [
        {"name": "é¢„ç®—é”å®šæµç¨‹", "owner": "Finance Ops", "systems": ["operations_finance", "erp"], "doc": "operations/playbook/budget-lock.md"},
        {"name": "ææ–™æ¶¨ä»·åº”å¯¹", "owner": "Supply Chain", "systems": ["operations_finance", "erp_procurement", "trend"], "doc": "operations/playbook/material-rise.md"},
        {"name": "æŠ¥è¡¨å¼‚å¸¸åº”æ€¥", "owner": "CFO Office", "systems": ["operations_finance", "experts"], "doc": "operations/playbook/report-anomaly.md"}
    ],
    "metrics": {
        "automation_rate": 0.74,
        "cross_system_alerts_24h": 5,
        "expert_routing_latency_ms": 820
    }
}

OPERATIONS_FINANCE_STRATEGY = {
    "last_synced": "2025-11-18T09:30:00",
    "cross_system_links": [
        {
            "name": "é¢„ç®— vs ç”Ÿäº§è®¡åˆ’",
            "source_system": "operations_finance",
            "target_system": "erp",
            "status": "active",
            "description": "é¢„ç®—å®¡æ‰¹åè‡ªåŠ¨æ›´æ–° ERP æ’äº§æƒé‡ï¼Œä½é¢„ç®—é¡¹ç›®å»¶åææŠ¥ã€‚",
            "coverage": 0.88
        },
        {
            "name": "æˆæœ¬å¼‚å¸¸æ¨é€åˆ°è¶‹åŠ¿åˆè§„",
            "source_system": "operations_finance",
            "target_system": "trend",
            "status": "pilot",
            "description": "å½“æŸç»†åˆ†æˆæœ¬çªç ´é˜ˆå€¼æ—¶ï¼Œè§¦å‘è¶‹åŠ¿åˆè§„é‡‡é›†æ ¡éªŒã€‚",
            "coverage": 0.52
        },
        {
            "name": "é¢„ç®—é‡Šæ”¾åŒæ­¥åº“å­˜å®‰å…¨åº“å­˜",
            "source_system": "operations_finance",
            "target_system": "erp_inventory",
            "status": "planned",
            "description": "é¢„ç®—ä¸‹è°ƒæ—¶è‡ªåŠ¨æå‡å®‰å…¨åº“å­˜å‘Šè­¦çº§åˆ«ã€‚",
            "coverage": 0.34
        }
    ],
    "budget_playbooks": [
        {
            "id": "budget_guard_001",
            "title": "Runway è§¦åº•å®ˆæŠ¤",
            "owner": "è´¢åŠ¡ä¸“å®¶ Ethan",
            "triggers": ["runway_months < 6", "burn_rate > plan"],
            "actions": [
                {"system": "operations_finance", "action": "å†»ç»“éå…³é”®é¢„ç®—"},
                {"system": "erp", "action": "é‡æ’äº¤ä»˜ä¼˜å…ˆçº§"},
                {"system": "trend", "action": "æç¤ºå¼€æºä¾§åŠ¨ä½œ"}
            ],
            "status": "ready"
        },
        {
            "id": "cost_bridge_002",
            "title": "è·¨ç³»ç»Ÿæˆæœ¬å‹é™",
            "owner": "è¿è¥ä¸“å®¶ Zoe",
            "triggers": ["unit_cost_increase > 5%"],
            "actions": [
                {"system": "erp_procurement", "action": "è§¦å‘ä¾›åº”å•†è°ˆåˆ¤"},
                {"system": "operations_finance", "action": "æ›´æ–°é¢„ç®—åœºæ™¯"},
                {"system": "trend", "action": "é‡‡é›†æœ€æ–°è¡Œæƒ…"}
            ],
            "status": "pilot"
        }
    ],
    "reporting_matrix": [
        {"report": "é¢„ç®—æ‰§è¡ŒæœˆæŠ¥", "frequency": "Monthly", "owner": "Finance Ops", "systems": ["operations_finance", "erp", "trend"], "status": "ready"},
        {"report": "è·¨ç³»ç»Ÿæˆæœ¬ç¨½æ ¸", "frequency": "Bi-weekly", "owner": "Audit Team", "systems": ["operations_finance", "erp", "content"], "status": "beta"},
        {"report": "æ¸ é“ ROI è”åŠ¨", "frequency": "Quarterly", "owner": "Growth Finance", "systems": ["operations_finance", "trend"], "status": "planned"}
    ]
}

# æ³¨å†ŒæŒä¹…åŒ–ç§å­
persistence_seeder.register_seed(
    "trend_indicators",
    module="trend",
    type_field="type",
    type_value="indicator",
    records=TREND_INDICATOR_LIBRARY,
    record_id_field="id",
)
persistence_seeder.register_seed(
    "trend_dashboards",
    module="trend",
    type_field="type",
    type_value="dashboard_template",
    records=TREND_DASHBOARD_TEMPLATES,
    record_id_field="id",
)
persistence_seeder.register_seed(
    "trend_insight_seed",
    module="trend",
    type_field="type",
    type_value="insight",
    records=TREND_INSIGHTS_FEED,
    record_id_field="id",
)
persistence_seeder.register_seed(
    "operations_chart_blueprints",
    module="operations",
    type_field="type",
    type_value="chart_blueprint",
    records=OPERATIONS_CHART_LIBRARY,
    record_id_field="id",
)
persistence_seeder.register_seed(
    "operations_finance_guides",
    module="operations",
    type_field="type",
    type_value="finance_guide",
    records=OPERATIONS_FINANCE_GUIDES,
    record_id_field="id",
)
persistence_seeder.register_seed(
    "trend_compliance_report",
    module="trend",
    type_field="type",
    type_value="compliance_report",
    records=[TREND_COMPLIANCE_REPORT],
    record_id_field="id",
)


def _create_knowledge_entry_from_template(
    template_id: str,
    title: str,
    content: str,
    *,
    summary: Optional[str] = None,
    tags: Optional[List[str]] = None,
    metadata: Optional[Dict[str, Any]] = None,
    source: Optional[str] = None,
    source_id: Optional[str] = None,
    priority: Optional[str] = None
):
    """æ ¹æ®æ¨¡æ¿åˆ›å»ºçŸ¥è¯†æ¡ç›®ï¼Œè‹¥æ¨¡æ¿ä¸å­˜åœ¨åˆ™æŠ›å‡ºå¼‚å¸¸"""
    entry = knowledge_template_manager.create_entry_from_template(
        template_id=template_id,
        title=title,
        content=content,
        summary=summary,
        tags=tags or [],
        metadata=metadata or {},
        source=source,
        source_id=source_id,
        priority=priority
    )
    if not entry:
        raise HTTPException(status_code=404, detail=f"çŸ¥è¯†æ¨¡æ¿ä¸å­˜åœ¨: {template_id}")
    return entry


async def _ingest_knowledge_entry(entry, auto_queue: bool = True):
    """æ ¹æ®å…¥åº“ç­–ç•¥å†™å…¥RAGæˆ–åŠ å…¥é˜Ÿåˆ—"""
    if not super_agent.rag_service:
        raise HTTPException(status_code=503, detail="RAGæœåŠ¡ä¸å¯ç”¨")
    
    knowledge_ingestion_strategy.rag_service = super_agent.rag_service
    should_ingest, rule_id = knowledge_ingestion_strategy.should_ingest(entry)
    rule = knowledge_ingestion_strategy.rules.get(rule_id) if rule_id else None
    
    if should_ingest and rule and rule.trigger == IngestionTrigger.BATCH:
        queue_id = knowledge_ingestion_strategy.queue_for_ingestion(entry, rule_id)
        return {
            "success": True,
            "ingested": False,
            "queued": True,
            "queue_id": queue_id,
            "rule_id": rule_id
        }
    
    if should_ingest:
        result = await knowledge_ingestion_strategy.ingest_immediate(entry, super_agent.rag_service)
        result.setdefault("success", False)
        result["ingested"] = result.get("success", False)
        result["queued"] = False
        result["rule_id"] = rule_id
        return result
    
    if auto_queue:
        queue_id = knowledge_ingestion_strategy.queue_for_ingestion(entry, rule_id)
        return {
            "success": True,
            "ingested": False,
            "queued": True,
            "queue_id": queue_id,
            "rule_id": rule_id
        }
    
    return {
        "success": False,
        "ingested": False,
        "queued": False,
        "rule_id": rule_id,
        "message": "æœªåŒ¹é…åˆ°å…¥åº“è§„åˆ™"
    }

voice_interaction = VoiceInteraction()
translation_service = TranslationService()
# æ–‡ä»¶ç”ŸæˆæœåŠ¡ï¼ˆç¨åæ³¨å…¥RAGæœåŠ¡ï¼‰
file_generation = None
web_search = WebSearchService()
file_format_handler = FileFormatHandler()  # æ–‡ä»¶æ ¼å¼å¤„ç†å™¨
# åˆå§‹åŒ–å®¡è®¡æ—¥å¿—ç³»ç»Ÿ
terminal_audit_logger = TerminalAuditLogger(
    audit_pipeline=audit_pipeline,
    risk_engine=risk_engine,
)
# åˆå§‹åŒ–ç»ˆç«¯æ‰§è¡Œå™¨ï¼ˆå¯ç”¨æ²™ç®±æ¨¡å¼ï¼‰
terminal_executor = TerminalExecutor(
    workflow_monitor=super_agent.workflow_monitor,
    audit_logger=terminal_audit_logger,
    sandbox_enabled=True
)
external_status = ExternalIntegrationStatus()
strategy_engine = StrategyEngine()
# P0-017: å†…å®¹åˆè§„æœåŠ¡é›†æˆå®‰å…¨åˆè§„åŸºçº¿
content_compliance = ContentComplianceService(security_baseline=security_compliance_baseline)
copyright_inspector = CopyrightInspector()
stock_gateway = StockGateway(api_monitor=api_monitor)
stock_sim = StockSimulator()
stock_factor_engine = StockFactorEngine()
douyin = DouyinIntegration(api_monitor=api_monitor)
cursor_bridge = CursorBridge()
storyboard_generator = StoryboardGenerator()

# P1-202: åˆå§‹åŒ– ERP 11 ç¯èŠ‚ç®¡ç†å™¨å’Œåº“å­˜ç®¡ç†å™¨
try:
    import sys
    from pathlib import Path
    erp_path = Path(__file__).parent.parent.parent / "ğŸ’¼ Intelligent ERP & Business Management"
    if erp_path.exists():
        sys.path.insert(0, str(erp_path))
        from core.erp_11_stages_manager import ERP11StagesManager
        from modules.material.material_inventory_manager import MaterialInventoryManager
        erp_11_stages_manager = ERP11StagesManager()
        inventory_manager = MaterialInventoryManager()
    else:
        erp_11_stages_manager = None
        inventory_manager = None
except Exception as e:
    logger.warning(f"ERP æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
    erp_11_stages_manager = None
    inventory_manager = None

# P1-203: åˆå§‹åŒ–åŒRAGæ‰§è¡Œå¼•æ“å’Œæ¨¡å—æ‰§è¡Œå™¨
from core.dual_rag_execution_engine import DualRAGExecutionEngine
from core.module_executors import ContentModuleExecutor, StockModuleExecutor, TrendModuleExecutor
from core.enhanced_expert_router import EnhancedExpertRouter

# P1-204: åˆå§‹åŒ–åˆè§„ç­–ç•¥ç®¡ç†å™¨å’Œå®¡è®¡å·¥ä½œæµ
from core.security.compliance_policy_manager import (
    CompliancePolicyManager,
    get_compliance_manager,
    OperationType,
    RiskLevel,
)
from core.security.compliance_audit_workflow import (
    ComplianceAuditWorkflow,
    get_compliance_audit_workflow,
    AuditStatus,
)

# P2-303: åˆå§‹åŒ–ä¸‰å¤§ç³»ç»Ÿ
from core.task_lifecycle_manager import (
    TaskLifecycleManager,
    get_task_lifecycle_manager,
    TaskStatus,
    TaskPriority,
)
from core.learning_curve_tracker import (
    LearningCurveTracker,
    get_learning_curve_tracker,
)
from core.resource_scheduler_with_hints import (
    ResourceSchedulerWithHints,
    get_resource_scheduler,
    ResourceType,
    HintType,
)

# P2-301: åˆå§‹åŒ–å…¨å±€å®Œæˆåº¦çŸ©é˜µå’Œè¯æ®åº“
from core.completion_matrix_manager import (
    CompletionMatrixManager,
    get_completion_matrix_manager,
    CompletionStatus,
    EightMetrics,
    EvidenceLink,
    EvidenceCategory,
)
from core.evidence_library import (
    EvidenceLibrary,
    get_evidence_library,
    EvidenceSource,
)

# åˆå§‹åŒ–ä¸“å®¶è·¯ç”±å™¨
enhanced_expert_router = EnhancedExpertRouter()

# åˆå§‹åŒ–æ¨¡å—æ‰§è¡Œå™¨
content_executor = ContentModuleExecutor(
    content_analytics=content_analytics,
    llm_service=None,  # å¯ä»¥ä¼ å…¥LLMæœåŠ¡
)
stock_executor = StockModuleExecutor(
    stock_gateway=stock_gateway,
    stock_factor_engine=stock_factor_engine,
    stock_simulator=stock_sim,
)
trend_executor = TrendModuleExecutor(
    trend_data_collector=trend_data_collector,
    trend_analyzer=None,  # å¯ä»¥ä¼ å…¥è¶‹åŠ¿åˆ†æå™¨
)

# æ³¨å†Œæ¨¡å—æ‰§è¡Œå™¨
module_executors = {
    "content": content_executor.execute,
    "stock": stock_executor.execute,
    "trend": trend_executor.execute,
}

# åˆå§‹åŒ–åŒRAGæ‰§è¡Œå¼•æ“
dual_rag_engine = DualRAGExecutionEngine(
    rag_service=super_agent.rag_service if hasattr(super_agent, "rag_service") else None,
    expert_router=enhanced_expert_router,
    module_executors=module_executors,
)

# P1-204: åˆå§‹åŒ–åˆè§„ç­–ç•¥ç®¡ç†å™¨å’Œå®¡è®¡å·¥ä½œæµ
compliance_manager = get_compliance_manager()
compliance_audit_workflow = get_compliance_audit_workflow()

# P2-303: åˆå§‹åŒ–ä¸‰å¤§ç³»ç»Ÿ
task_lifecycle_manager = get_task_lifecycle_manager()
learning_curve_tracker = get_learning_curve_tracker()
resource_scheduler = get_resource_scheduler()

# P2-301: åˆå§‹åŒ–å…¨å±€å®Œæˆåº¦çŸ©é˜µå’Œè¯æ®åº“
completion_matrix_manager = get_completion_matrix_manager()
evidence_library = get_evidence_library()

# P1-001: ä¸‰çº§ç•Œé¢æ•°æ®æ³¨å†Œä¸­å¿ƒ
module_registry = ModuleRegistry(
    data_service=data_service,
    audit_pipeline=audit_pipeline,
    risk_engine=risk_engine,
    trend_data_collector=trend_data_collector,
    trend_rag_output=trend_rag_output,
    content_analytics=content_analytics,
    stock_gateway=stock_gateway,
    stock_factor_engine=stock_factor_engine,
    stock_simulator=stock_sim,
    operations_finance_strategy=operations_finance_strategy,
    chart_expert=chart_expert,
    finance_expert=finance_expert,
    memo_system=memo_system,
    command_replay=command_replay,
    cursor_integration=cursor_ide_integration,
    closed_loop_engine=super_agent.closed_loop_engine,
    expert_collaboration_hub=expert_collaboration_hub,
    enhanced_expert_router=enhanced_expert_router,
    erp_11_stages_manager=erp_11_stages_manager,
    inventory_manager=inventory_manager,
)

# P0-016: åˆå§‹åŒ–Cursoré›†æˆç³»ç»Ÿï¼ˆåè®®/æ’ä»¶/æœ¬åœ°æ¡¥/æˆæƒï¼‰
cursor_protocol = CursorProtocol()
cursor_plugin_system = CursorPluginSystem()
cursor_authorization = CursorAuthorization()
cursor_local_bridge = CursorLocalBridge(
    protocol=cursor_protocol,
    plugin_system=cursor_plugin_system,
    permission_manager=cursor_plugin_system.permission_manager
)
backtest_engine = BacktestEngine()
try:
    factory_data_source = FactoryDataSource()
    factory_data_source_error = None
except FileNotFoundError as exc:
    factory_data_source = None
    factory_data_source_error = str(exc)
if DemoFactoryTrialDataSource:
    try:
        trial_data_source = DemoFactoryTrialDataSource()
        trial_data_source_error = None
    except FileNotFoundError as exc:
        trial_data_source = None
        trial_data_source_error = str(exc)
else:
    trial_data_source = None
    trial_data_source_error = "ERPæ¨¡å—æœªåŠ è½½"

# è®¾ç½®ä¾èµ–
super_agent.set_memo_system(memo_system)
super_agent.set_learning_monitor(learning_monitor)
super_agent.set_resource_monitor(resource_monitor)
super_agent.set_task_planning(task_planning)

# åˆå§‹åŒ–æ–‡ä»¶ç”ŸæˆæœåŠ¡ï¼ˆæ³¨å…¥RAGæœåŠ¡ï¼‰
file_generation = FileGenerationService(rag_service=super_agent.rag_service)

# å¯åŠ¨èµ„æºç›‘æ§ï¼ˆåå°ä»»åŠ¡ï¼‰
import asyncio
asyncio.create_task(resource_monitor.start_monitoring(interval=5))

# å¯åŠ¨ERPç›‘å¬ï¼ˆè½»é‡è½®è¯¢å¯¹æ¯”ï¼‰
_erp_last_order_count = {"count": 0}
async def _erp_listener():
    """æ¯20ç§’è½®è¯¢ä¸€æ¬¡è®¢å•/å·¥å•å˜åŒ–ï¼Œå†™å…¥ç³»ç»Ÿäº‹ä»¶ï¼Œä¾›è‡ªå­¦ä¹ /ä¸»ç•Œé¢ä½¿ç”¨"""
    ds = None
    try:
        ds = _get_factory_data_source()
    except Exception:
        return
    while True:
        try:
            orders = ds.get_orders()
            count = len(orders)
            if count != _erp_last_order_count["count"]:
                _erp_last_order_count["count"] = count
                if super_agent.workflow_monitor:
                    await super_agent.workflow_monitor.record_system_event(
                        event_type="erp_change",
                        source="erp_listener",
                        severity="info",
                        success=True,
                        data={"orders_count": count},
                        error=None
                    )
            await asyncio.sleep(20)
        except asyncio.CancelledError:
            break
        except Exception:
            await asyncio.sleep(20)

asyncio.create_task(_erp_listener())

bpmn_dir = Path(project_root) / "data" / "bpmn"
bpmn_dir.mkdir(parents=True, exist_ok=True)
rag_dir = Path(project_root) / "data" / "rag"
rag_dir.mkdir(parents=True, exist_ok=True)
rag_store_path = rag_dir / "documents.jsonl"
RAG_ACTIVITY_LOG = deque(maxlen=200)
RAG_SEARCH_HISTORY = deque(maxlen=200)

module_chain_manager = ModuleChainManager(
    data_service=data_service,
    service_registry=service_registry,
    rag_store_path=rag_store_path,
    trial_data_source=trial_data_source,
    factory_data_source=factory_data_source,
    trend_data_collector=trend_data_collector,
    content_analytics=content_analytics,
    stock_gateway=stock_gateway,
    cursor_bridge=cursor_bridge,
)


def _record_rag_event(event_type: str, payload: Optional[Dict[str, Any]] = None) -> None:
    try:
        entry = {
            "event": event_type,
            "timestamp": datetime.now().isoformat(),
            "payload": payload or {}
        }
        RAG_ACTIVITY_LOG.appendleft(entry)
        loop = asyncio.get_running_loop()
        loop.create_task(
            data_service.save_data(
                module="rag",
                data={"type": "activity", **entry},
                sync=False,
            )
        )
    except RuntimeError:
        # åœ¨æœªè¿è¡Œäº‹ä»¶å¾ªç¯çš„ä¸Šä¸‹æ–‡ä¸­å¿½ç•¥æŒä¹…åŒ–
        pass
    except Exception:
        pass


def _load_recent_rag_documents(limit: int = 50) -> List[Dict[str, Any]]:
    docs: List[Dict[str, Any]] = []
    if not rag_store_path.exists():
        return docs
    try:
        with open(rag_store_path, "r", encoding="utf-8") as f:
            lines = f.readlines()[-limit:]
            import json as _json

            for line in reversed(lines):
                try:
                    docs.append(_json.loads(line))
                except Exception:
                    continue
    except Exception:
        return docs
    return docs


def _build_search_stats() -> Dict[str, Any]:
    history = list(RAG_SEARCH_HISTORY)
    total_queries = len(history)
    if total_queries == 0:
        return {
            "total_queries": 0,
            "average_results": 0,
            "top_queries": [],
            "recent": [],
        }
    result_counts = [item.get("results", 0) for item in history]
    avg_results = sum(result_counts) / len(result_counts)
    query_names = [item.get("query", "") for item in history if item.get("query")]
    top_queries = Counter(query_names).most_common(5)
    recent = history[:6]
    return {
        "total_queries": total_queries,
        "average_results": round(avg_results, 2),
        "top_queries": [{"query": q, "count": c} for q, c in top_queries],
        "recent": recent,
    }


def _build_kg_summary(limit: int = 10) -> Dict[str, Any]:
    docs = _load_recent_rag_documents(limit=60)
    keywords = Counter()
    doc_nodes = []
    word_nodes = []
    edges = []
    for doc in docs[:limit]:
        doc_nodes.append({
            "id": doc.get("id"),
            "label": doc.get("title", "æ–‡æ¡£"),
            "type": "document",
            "score": doc.get("authenticity", {}).get("score", 60)
        })
    for doc in docs:
        title = doc.get("title") or ""
        tokens = re.findall(r"[A-Za-z0-9\u4e00-\u9fa5]{2,}", title)[:3]
        for token in tokens:
            keywords[token.lower()] += 1
    top_keywords = keywords.most_common(8)
    keyword_to_id = {}
    for idx, (keyword, count) in enumerate(top_keywords):
        node_id = f"kw_{idx}"
        keyword_to_id[keyword] = node_id
        word_nodes.append({
            "id": node_id,
            "label": keyword,
            "type": "entity",
            "score": count
        })
    for doc in docs[:limit]:
        title = doc.get("title") or ""
        tokens = re.findall(r"[A-Za-z0-9\u4e00-\u9fa5]{2,}", title)
        doc_id = doc.get("id")
        for token in tokens:
            token_lower = token.lower()
            if token_lower in keyword_to_id:
                edges.append({
                    "source": doc_id,
                    "target": keyword_to_id[token_lower],
                    "weight": random.randint(1, 3)
                })
    summary = {
        "nodes": doc_nodes + word_nodes,
        "edges": edges[:20],
        "stats": {
            "documents": len(doc_nodes),
            "entities": len(word_nodes),
            "relations": len(edges),
            "last_updated": datetime.now().isoformat()
        },
        "top_entities": [{"name": node["label"], "weight": node["score"]} for node in word_nodes],
    }
    return summary

class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚"""
    message: str
    input_type: str = "text"  # text, voice, file, search
    context: Optional[Dict] = None


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”"""
    success: bool
    response: str
    response_time: float
    rag_retrievals: Optional[Dict] = None
    timestamp: str
    metadata: Optional[Dict[str, Any]] = None


class TaskCreateRequest(BaseModel):
    title: str
    description: Optional[str] = ""
    priority: str = "medium"
    metadata: Optional[Dict[str, Any]] = None
    dependencies: Optional[List[str]] = None


class TaskStatusUpdateRequest(BaseModel):
    status: TaskStatus
    updates: Optional[Dict[str, Any]] = None


class TaskRetrospectRequest(BaseModel):
    """ä»»åŠ¡å¤ç›˜è¯·æ±‚"""
    success: bool
    summary: Optional[str] = ""
    lessons: Optional[List[str]] = None
    metrics: Optional[Dict[str, Any]] = None


class TaskScheduleRequest(BaseModel):
    """ä»»åŠ¡æ’æœŸè¯·æ±‚"""
    scheduled_for: Optional[str] = None
    owner: Optional[str] = None
    notes: Optional[str] = None


class TaskResourceImpact(BaseModel):
    """ä»»åŠ¡æ‰§è¡Œå¯¹èµ„æºçš„å½±å“"""
    summary: str
    category: Optional[str] = "general"
    delta: Optional[str] = None
    severity: Optional[str] = "medium"
    owner: Optional[str] = None


class TaskExecutionRequest(BaseModel):
    """ä»»åŠ¡æ‰§è¡Œé…ç½®"""
    writeback_to_rag: bool = False
    rag_title: Optional[str] = None
    rag_summary: Optional[str] = None
    rag_tags: Optional[List[str]] = None
    resource_impact: Optional[TaskResourceImpact] = None


class LearningRecommendationApplyRequest(BaseModel):
    """äº¤äº’å»ºè®®æ‰§è¡Œè¯·æ±‚"""
    overrides: Optional[Dict[str, Any]] = None


@dataclass
class LearningResourceSuggestion:
    description: str
    action_type: str = "optimize"
    risk_level: str = "medium"
    expected_improvement: Optional[str] = None
    requires_approval: bool = True
    rollback_plan: Optional[str] = None
    severity: str = "medium"


class SystemEventRequest(BaseModel):
    """å¤–éƒ¨ç³»ç»Ÿäº‹ä»¶"""
    event_type: str
    source: str = "external"
    severity: str = "info"
    success: bool = True
    data: Optional[Dict[str, Any]] = None
    error: Optional[str] = None


class LearningEventRequest(BaseModel):
    """å¤–éƒ¨å­¦ä¹ äº‹ä»¶"""
    event_type: str = "custom"
    source: str = "external"
    severity: str = "info"
    payload: Optional[Dict[str, Any]] = None


class TaskLoopRagWriteRequest(BaseModel):
    """ä»»åŠ¡é—­ç¯å†™å›RAG"""
    task_id: Any
    title: str
    summary: str
    metadata: Optional[Dict[str, Any]] = None
    template_id: Optional[str] = "task_execution"
    content: Optional[str] = None
    tags: Optional[List[str]] = None
    priority: Optional[str] = None
    auto_queue: bool = True
    source: Optional[str] = "task_loop"


class KnowledgeEntryRequest(BaseModel):
    """çŸ¥è¯†æ¡ç›®è¯·æ±‚"""
    template_id: str
    title: str
    content: str
    summary: Optional[str] = None
    tags: Optional[List[str]] = None
    metadata: Optional[Dict[str, Any]] = None
    source: Optional[str] = None
    source_id: Optional[str] = None
    priority: Optional[str] = None
    auto_ingest: bool = True
    auto_queue: bool = True


class KnowledgeProcessQueueRequest(BaseModel):
    """å¤„ç†å…¥åº“é˜Ÿåˆ—è¯·æ±‚"""
    batch_size: int = 10


async def _chat_pipeline(request: ChatRequest) -> ChatResponse:
    decision = None
    try:
        if request.message:
            try:
                sensitive_filter.assert_safe(request.message)
            except ValueError as exc:
                raise HTTPException(status_code=400, detail=str(exc)) from exc

        if request.input_type == "file" and request.context and request.context.get("file_data"):
            file_data = request.context.get("file_data")
            filename = request.context.get("filename", "unknown")
            mime_type = request.context.get("mime_type")
            file_result = await file_format_handler.process_file(file_data, filename, mime_type)
            if file_result.get("success") and file_result.get("text"):
                request.message = f"{request.message}\n\næ–‡ä»¶å†…å®¹:\n{file_result['text']}"

        if request.context is None:
            request.context = {}

        decision = await strategy_engine.decide(request.message, request.input_type)

        slo_context = request.context.setdefault("slo", {})
        slo_context.update(
            {
                "rag_top_k": decision.rag_top_k,
                "module_timeout": decision.max_module_time,
                "use_fast_model": decision.use_fast_model,
                "enable_streaming": decision.enable_streaming,
            }
        )

        start_time = time.time()

        async def process_input():
            return await super_agent.process_user_input(
                user_input=request.message,
                input_type=request.input_type,
                context=request.context,
            )

        cache_key = f"chat:{request.message}:{request.input_type}" if len(request.message) < 200 else None

        if decision.use_cache_only and cache_key:
            cached_payload = response_time_optimizer.get_cached_value(cache_key)
            if cached_payload:
                strategy_engine.release(decision)
                cached_payload.setdefault("from_cache", True)
                cached_payload.setdefault("response_time", 0.05)
                slo_meta = {
                    "queue_wait": decision.queue_wait,
                    "degrade_level": decision.degrade_level,
                    "degrade_reason": decision.degrade_reason,
                    "from_cache": True,
                    "streaming": False,
                }
                return ChatResponse(
                    success=cached_payload.get("success", False),
                    response=cached_payload.get("response", ""),
                    response_time=cached_payload.get("response_time", 0.05),
                    rag_retrievals=cached_payload.get("rag_retrievals"),
                    timestamp=cached_payload.get("timestamp", datetime.now().isoformat()),
                    metadata={"slo": slo_meta},
                )

        result = await response_time_optimizer.optimize_with_timeout(
            process_input,
            timeout=decision.timeout_seconds,
            cache_key=cache_key,
        )

        if result is None:
            result = {
                "success": False,
                "response": "å¤„ç†è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
                "response_time": 2.0,
                "rag_retrievals": None,
                "timestamp": datetime.now().isoformat(),
            }

        response_time = time.time() - start_time
        performance_monitor.record_response_time(
            response_time, from_cache=result.get("from_cache", False) if result else False
        )
        strategy_engine.release(decision)

        slo_meta = {
            "queue_wait": decision.queue_wait,
            "degrade_level": decision.degrade_level,
            "degrade_reason": decision.degrade_reason,
            "from_cache": result.get("from_cache", False),
            "streaming": decision.enable_streaming,
        }

        return ChatResponse(
            success=result.get("success", False) if result else False,
            response=result.get("response", "") if result else "",
            response_time=response_time,
            rag_retrievals=result.get("rag_retrievals") if result else None,
            timestamp=result.get("timestamp", datetime.now().isoformat())
            if result
            else datetime.now().isoformat(),
            metadata={"slo": slo_meta},
        )
    except Exception as e:
        strategy_engine.release(decision if decision else None)
        raise


@router.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    èŠå¤©æ¥å£â­ä¼˜åŒ–ç‰ˆï¼ˆ2ç§’å“åº”ç›®æ ‡ï¼‰
    """
    try:
        return await _chat_pipeline(request)
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def _sse_encode(payload: Dict[str, Any]) -> str:
    return f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"


def _chunk_text(text: str, chunk_size: int = 160):
    if not text:
        yield ""
        return
    for i in range(0, len(text), chunk_size):
        yield text[i : i + chunk_size]


@router.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    async def event_generator():
        yield _sse_encode({"type": "status", "message": "accepted"})
        try:
            response = await _chat_pipeline(request)
            text = response.response or ""
            chunk_count = 0
            for chunk in _chunk_text(text):
                if not chunk:
                    continue
                chunk_count += 1
                yield _sse_encode({"type": "token", "data": chunk})
            if chunk_count == 0:
                yield _sse_encode({"type": "token", "data": ""})
            yield _sse_encode({"type": "final", "payload": response.dict()})
        except Exception as exc:
            yield _sse_encode({"type": "error", "message": str(exc)})

    return StreamingResponse(event_generator(), media_type="text/event-stream")


@router.get("/memos")
async def get_memos(
    type: Optional[str] = None,
    importance: Optional[int] = None,
    tags: Optional[str] = None
):
    """è·å–å¤‡å¿˜å½•åˆ—è¡¨"""
    tag_list = tags.split(",") if tags else None
    memos = await memo_system.get_memos(type=type, importance=importance, tags=tag_list)
    return {"memos": memos, "total": len(memos)}


@router.post("/memos")
async def add_memo(memo_data: Dict):
    """æ·»åŠ å¤‡å¿˜å½•"""
    memo = await memo_system.add_memo(memo_data)
    return {"success": True, "memo": memo}


@router.get("/tasks")
async def get_tasks(
    status: Optional[str] = None,
    needs_confirmation: Optional[bool] = None
):
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    tasks = task_planning.get_tasks(status=status, needs_confirmation=needs_confirmation)
    return {"tasks": tasks, "total": len(tasks)}


@router.post("/tasks/extract")
async def extract_tasks():
    """ä»å¤‡å¿˜å½•æç‚¼ä»»åŠ¡â­å¢å¼ºç‰ˆï¼ˆä½¿ç”¨æ¨¡æ¿åº“ï¼‰"""
    tasks = await task_planning.extract_tasks_from_memos()
    return {"tasks": tasks, "total": len(tasks)}


@router.get("/tasks/templates")
async def get_task_templates():
    """è·å–ä»»åŠ¡æ¨¡æ¿åˆ—è¡¨"""
    templates = task_planning.template_library.get_all_templates()
    return {
        "templates": templates,
        "total": len(templates)
    }


@router.get("/file-formats/supported")
async def get_supported_formats():
    """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åˆ—è¡¨"""
    formats = file_format_handler.get_supported_formats()
    return {
        "formats": formats,
        "total": len(formats),
        "categories": list(file_format_handler.supported_formats.keys())
    }

@router.get("/rag/file-formats")
async def rag_file_formats():
    """è¿”å›æŒ‰ç±»åˆ«æ±‡æ€»çš„æ–‡ä»¶æ ¼å¼è¦†ç›–æƒ…å†µ"""
    data = []
    total = 0
    for category, extensions in file_format_handler.supported_formats.items():
        unique_ext = sorted(set(extensions))
        total += len(unique_ext)
        data.append({
            "category": category,
            "count": len(unique_ext),
            "extensions": unique_ext
        })
    return {"success": True, "total_formats": total, "categories": data}


@router.post("/tasks/{task_id}/confirm")
async def confirm_task(
    task_id: int,
    request: Dict[str, Any] = Body(...)
):
    """ç¡®è®¤ä»»åŠ¡"""
    confirmed = request.get("confirmed", False)
    reason = request.get("reason")
    result = await task_planning.confirm_task(task_id, confirmed, reason)
    if result:
        return {"success": True, "task": result}
    else:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")


@router.post("/tasks/{task_id}/schedule")
async def schedule_task(task_id: int, request: TaskScheduleRequest):
    """ä¸ºä»»åŠ¡æ’æœŸå¹¶åˆ†æ´¾è´Ÿè´£äºº"""
    task = await task_planning.schedule_task(
        task_id=task_id,
        scheduled_for=request.scheduled_for,
        owner=request.owner,
        notes=request.notes
    )
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {"success": True, "task": task}


@router.post("/tasks/{task_id}/execute")
async def execute_task(task_id: int, request: Optional[TaskExecutionRequest] = Body(None)):
    """æ‰§è¡Œä»»åŠ¡â­å®Œå–„ç‰ˆ"""
    exec_opts = request or TaskExecutionRequest()

    async def _task_executor(params: Dict[str, Any]) -> Dict[str, Any]:
        return await task_planning.execute_task(params["task_id"])

    execution_id, exec_result = await run_closed_loop_operation(
        module="task_planning",
        function="execute_task",
        parameters={"task_id": task_id},
        executor=_task_executor,
        task_id=str(task_id),
        metadata={"options": exec_opts.model_dump()},
    )
    task_payload = exec_result.get("result") or {}

    if task_payload.get("success"):
        if exec_opts.writeback_to_rag and exec_opts.rag_summary:
            rag_request = TaskLoopRagWriteRequest(
                task_id=task_id,
                title=exec_opts.rag_title or task_payload.get("task", {}).get("title", f"ä»»åŠ¡{task_id}"),
                summary=exec_opts.rag_summary,
                content=exec_opts.rag_summary,
                tags=exec_opts.rag_tags or task_payload.get("task", {}).get("tags"),
                metadata={"task_status": task_payload.get("task", {}).get("status")}
            )
            try:
                await task_loop_rag_writeback(rag_request)
            except Exception as exc:
                logger.warning("å†™å›RAGå¤±è´¥: %s", exc)
        if exec_opts.resource_impact:
            resource_authorization_manager.log_task_impact(
                task_id=task_id,
                impact=exec_opts.resource_impact.dict()
            )
        response = dict(task_payload)
        response["execution_id"] = execution_id
        return response
    else:
        raise HTTPException(status_code=400, detail=task_payload.get("error", "ä»»åŠ¡æ‰§è¡Œå¤±è´¥"))


@router.post("/tasks/{task_id}/retrospect")
async def retrospect_task(task_id: int, request: TaskRetrospectRequest):
    """ä»»åŠ¡å¤ç›˜ï¼šè®°å½•æ€»ç»“/ç»éªŒ/æŒ‡æ ‡å¹¶å®Œæˆç”Ÿå‘½å‘¨æœŸé—­ç¯"""
    # å¤ç›˜æ•°æ®ç»“æ„ç›´æ¥é™„åŠ åˆ°ä»»åŠ¡ï¼ˆåˆ©ç”¨å·²æœ‰task_planningå­˜å‚¨ï¼‰
    tasks = task_planning.get_tasks()
    task = next((t for t in tasks if t.get("id") == task_id), None)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    task.setdefault("retrospect", {})
    task["retrospect"].update({
        "success": request.success,
        "summary": request.summary or "",
        "lessons": request.lessons or [],
        "metrics": request.metrics or {},
        "retrospected_at": datetime.now().isoformat()
    })
    # å¯é€‰ï¼šå°†ç»éªŒå†™å›å­¦ä¹ ç³»ç»Ÿ/RAG
    if hasattr(super_agent, "learning_monitor") and super_agent.learning_monitor:
        try:
            await super_agent.learning_monitor.record_insight({
                "type": "task_retrospect",
                "task_id": task_id,
                "success": request.success,
                "lessons": request.lessons or [],
                "timestamp": datetime.now().isoformat()
            })
        except Exception:
            pass
    return {"success": True, "task": task}


@router.post("/task-loop/rag-writeback")
async def task_loop_rag_writeback(request: TaskLoopRagWriteRequest):
    """ä»»åŠ¡é—­ç¯å†™å›RAGçŸ¥è¯†åº“"""
    metadata = request.metadata or {}
    metadata.setdefault("task_id", request.task_id)
    tags = request.tags or [f"task-{request.task_id}"]
    template_id = request.template_id or "task_execution"
    content = request.content or request.summary
    
    entry = _create_knowledge_entry_from_template(
        template_id=template_id,
        title=request.title,
        content=content,
        summary=request.summary,
        tags=tags,
        metadata=metadata,
        source=request.source or "task_loop",
        source_id=str(request.task_id),
        priority=request.priority
    )
    
    ingestion_result = await _ingest_knowledge_entry(entry, auto_queue=request.auto_queue)
    
    await super_agent.event_bus.publish_event(
        LearningEventType.RAG_ALERT,
        source="task_loop_bridge",
        severity="info",
        payload={
            "task_id": request.task_id,
            "title": request.title,
            "template": template_id,
            "ingestion": ingestion_result
        }
    )
    return {
        "success": ingestion_result.get("success", True),
        "knowledge_entry": entry.to_dict(),
        "ingestion": ingestion_result
    }


# ============ P0-019: çŸ¥è¯†æ¨¡æ¿ä¸è‡ªåŠ¨å…¥åº“ ============


@router.get("/knowledge/templates")
async def list_knowledge_templates():
    """åˆ—å‡ºå¯ç”¨çš„çŸ¥è¯†æ¨¡æ¿"""
    templates = knowledge_template_manager.list_templates()
    return {"success": True, "templates": templates}


@router.post("/knowledge/entries")
async def create_knowledge_entry(request: KnowledgeEntryRequest):
    """æ ¹æ®æ¨¡æ¿åˆ›å»ºçŸ¥è¯†æ¡ç›®å¹¶è‡ªåŠ¨å…¥åº“"""
    entry = _create_knowledge_entry_from_template(
        template_id=request.template_id,
        title=request.title,
        content=request.content,
        summary=request.summary,
        tags=request.tags,
        metadata=request.metadata,
        source=request.source,
        source_id=request.source_id,
        priority=request.priority
    )
    
    auto_queue = request.auto_queue
    ingestion_result = await _ingest_knowledge_entry(entry, auto_queue=auto_queue)
    
    return {
        "success": ingestion_result.get("success", True),
        "entry": entry.to_dict(),
        "ingestion": ingestion_result
    }


@router.get("/knowledge/ingestion/rules")
async def list_ingestion_rules():
    """è·å–çŸ¥è¯†å…¥åº“è§„åˆ™"""
    rules = knowledge_ingestion_strategy.get_rules()
    return {"success": True, "rules": rules}


@router.get("/knowledge/ingestion/queue")
async def get_ingestion_queue():
    """è·å–çŸ¥è¯†å…¥åº“é˜Ÿåˆ—çŠ¶æ€"""
    status = knowledge_ingestion_strategy.get_queue_status()
    return {"success": True, "queue": status}


@router.post("/knowledge/ingestion/process")
async def process_ingestion_queue(request: KnowledgeProcessQueueRequest):
    """æ‰‹åŠ¨è§¦å‘å…¥åº“é˜Ÿåˆ—å¤„ç†"""
    result = await knowledge_ingestion_strategy.process_queue(
        batch_size=request.batch_size,
        rag_service=super_agent.rag_service
    )
    return result


# ============ P1-021: ERP 11ç¯èŠ‚ä¸æµç¨‹å¯è§†åŒ– ============


@router.get("/erp/process/stages")
async def get_erp_process_stages():
    """è·å–ERPæµç¨‹é˜¶æ®µæ¦‚è§ˆ"""
    return {
        "success": True,
        "stages": ERP_PROCESS_STAGES,
        "updated_at": datetime.now().isoformat()
    }


@router.get("/erp/process/stages/{stage_id}")
async def get_erp_process_stage(stage_id: str):
    """è·å–å•ä¸ªERPæµç¨‹é˜¶æ®µè¯¦æƒ…"""
    stage = next((s for s in ERP_PROCESS_STAGES if s["id"] == stage_id), None)
    if not stage:
        raise HTTPException(status_code=404, detail="æµç¨‹é˜¶æ®µä¸å­˜åœ¨")
    extended_stage = dict(stage)
    extended_stage["related_timeline"] = [
        item for item in ERP_PROCESS_TIMELINE if item["stage"] == stage_id
    ]
    return {"success": True, "stage": extended_stage}


@router.get("/erp/process/timeline")
async def get_erp_process_timeline():
    """è·å–ERPæµç¨‹æ—¶é—´çº¿"""
    return {
        "success": True,
        "timeline": ERP_PROCESS_TIMELINE,
        "stage_count": len(ERP_PROCESS_STAGES)
    }


@router.get("/trend/indicators")
async def get_trend_indicators(category: Optional[str] = None):
    """è¡Œä¸š/åŒºåŸŸ/æ”¿ç­–æŒ‡æ ‡åº“"""
    indicators = await persistence_seeder.get_records("trend_indicators", limit=200)
    categories = sorted({ind.get("category") for ind in indicators if ind.get("category")})
    if category:
        indicators = [ind for ind in indicators if ind.get("category") == category]
    return {
        "success": True,
        "categories": categories,
        "count": len(indicators),
        "indicators": indicators
    }


@router.get("/trend/dashboards")
async def get_trend_dashboards(category: Optional[str] = None):
    """è¡Œä¸š/åŒºåŸŸ/æ”¿ç­–çœ‹æ¿æ¨¡æ¿"""
    dashboards = await persistence_seeder.get_records("trend_dashboards", limit=100)
    if category:
        dashboards = [db for db in dashboards if category in (db.get("scenario") or "")]
    return {
        "success": True,
        "dashboards": dashboards,
        "count": len(dashboards)
    }


@router.get("/trend/insights")
async def get_trend_insights(limit: int = 20, category: Optional[str] = None):
    """è¶‹åŠ¿æ´å¯Ÿè®¢é˜… - P0-003: ä½¿ç”¨çœŸå®æ•°æ®åº“"""
    await persistence_seeder.ensure_seed("trend_insight_seed")
    filters = {}
    if category:
        filters["category"] = category
    
    insights = await data_service.query_data(
        module="trend",
        filters=filters,
        limit=limit,
        order_by="_created_at",
        order_desc=True,
    )
    
    # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆä¸å†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼‰
    if not insights:
        # ç§»é™¤æ¨¡æ‹Ÿæ•°æ®ï¼Œè¿”å›ç©ºåˆ—è¡¨
        insights = []
    
    # ç»Ÿè®¡è¦†ç›–èŒƒå›´
    all_insights = await data_service.query_data(module="trend", limit=1000)
    coverage = {
        "industry": len([i for i in all_insights if i.get("category") == "industry"]),
        "region": len([i for i in all_insights if i.get("category") == "region"]),
        "policy": len([i for i in all_insights if i.get("category") == "policy"])
    }
    
    return {
        "success": True,
        "insights": insights,
        "coverage": coverage,
        "total": len(insights)
    }


@router.get("/trend/compliance")
async def get_trend_compliance():
    """è¶‹åŠ¿æ•°æ®é‡‡é›†åˆè§„æŠ¥å‘Šï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆæ•°æ®é‡‡é›†ç»Ÿè®¡ï¼‰"""
    records = await persistence_seeder.get_records("trend_compliance_report", limit=1)
    report = (records[0] if records else {}).copy()
    
    # é›†æˆæ•°æ®é‡‡é›†ç»Ÿè®¡
    collection_stats = trend_data_collector.get_collection_stats(days=30)
    report["data_collection_stats"] = collection_stats
    
    return {
        "success": True,
        "report": report
    }


@router.get("/trend/audit")
async def get_trend_audit(limit: int = 20):
    """è¶‹åŠ¿é‡‡é›†å®¡è®¡è®°å½• - P0-003: ä½¿ç”¨çœŸå®æ•°æ®åº“"""
    # ä»æ•°æ®åº“æŸ¥è¯¢å®¡è®¡æ—¥å¿—
    logs = await data_service.query_data(
        module="trend",
        filters={"type": "audit_log"},
        limit=limit,
        order_by="_created_at",
        order_desc=True,
    )
    
    # ç§»é™¤å†…éƒ¨å­—æ®µ
    logs = [{k: v for k, v in log.items() if not k.startswith("_")} for log in logs]
    
    total = await data_service.count_data(module="trend", filters={"type": "audit_log"})
    
    return {
        "success": True,
        "audit": logs,
        "total": total
    }


async def _trend_backtest_logic(params: Dict[str, Any]) -> Dict[str, Any]:
    indicator = params["indicator"]
    window = params["window"]
    result = trend_scenario_engine.run_backtest(indicator, window)
    trend_data_collector.record_collection(
        source="backtest",
        data_type="backtest_result",
        count=len(result.get("series", [])),
        status="success",
        metadata={
            "indicator": indicator,
            "window": window,
            "mape": result.get("metrics", {}).get("mape"),
        },
    )
    return result


@router.get("/trend/backtest", response_model=TrendBacktestResponse)
async def trend_backtest(
    response: Response,
    indicator: str = Query("EV_DEMAND", description="æŒ‡æ ‡ç¼–ç "),
    window: int = Query(90, ge=30, le=180, description="å›æµ‹çª—å£ï¼ˆå¤©ï¼‰"),
):
    """è¶‹åŠ¿é¢„æµ‹å›æµ‹å¯è§†åŒ–æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆæ•°æ®é‡‡é›†ï¼‰"""
    execution_id, exec_result = await run_closed_loop_operation(
        module="trend",
        function="backtest",
        parameters={"indicator": indicator, "window": window},
        executor=_trend_backtest_logic,
        metadata={"indicator": indicator},
    )
    if response is not None:
        response.headers["X-Execution-ID"] = execution_id
    return exec_result.get("result") or {}


@router.post("/trend/what-if", response_model=TrendScenarioResponse)
async def trend_what_if(req: TrendScenarioRequest):
    """What-if æƒ…æ™¯æ¨¡æ‹Ÿï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆRAGè¾“å‡ºï¼‰"""
    scenario = ScenarioInput(
        indicator=req.indicator or "EV_DEMAND",
        scenario_name=req.scenario_name or "Baseline",
        demand_shift=req.demand_shift,
        policy_intensity=req.policy_intensity,
        supply_shift=req.supply_shift
    )
    result = trend_scenario_engine.simulate_scenario(scenario)
    
    # è®°å½•åˆ°æ•°æ®é‡‡é›†å™¨
    trend_data_collector.record_collection(
        source="what_if",
        data_type="scenario_simulation",
        count=1,
        status="success",
        metadata={
            "indicator": req.indicator,
            "scenario_name": req.scenario_name,
            "probability": result.get("forecast", {}).get("probability"),
        }
    )
    
    # ç”ŸæˆRAGæ–‡æ¡£
    try:
        rag_doc = trend_rag_output.generate_rag_document(
            indicator=req.indicator,
            analysis_result={
                "summary": f"What-ifæƒ…æ™¯æ¨¡æ‹Ÿï¼š{req.scenario_name}",
                "metrics": result.get("forecast", {}),
                "prediction": result.get("forecast", {}),
                "recommendations": result.get("recommendations", []),
                "sources": ["trend_scenario_engine"],
            }
        )
        
        # æ¨¡æ‹Ÿå†™å…¥RAGï¼ˆçœŸå®å®ç°åº”è°ƒç”¨RAG APIï¼‰
        rag_doc_id = f"trend_rag_{int(datetime.now().timestamp())}"
        trend_rag_output.record_rag_output(
            indicator=req.indicator,
            rag_document_id=rag_doc_id,
            status="success"
        )
        
        result["rag_document_id"] = rag_doc_id
        result["rag_document"] = rag_doc
    except Exception as e:
        logger.warning(f"RAGè¾“å‡ºå¤±è´¥: {e}")
    
    return result


# ==================== P2-011: è¶‹åŠ¿åˆ†æ + åˆè§„å®¡è®¡å¢å¼º ====================

@router.get("/trend/data/collection/stats")
async def get_trend_collection_stats(
    source: Optional[str] = Query(None),
    days: int = Query(7, ge=1, le=90)
):
    """
    è·å–æ•°æ®é‡‡é›†ç»Ÿè®¡ï¼ˆå¯è§†åŒ–ï¼‰
    """
    return trend_data_collector.get_collection_stats(source=source, days=days)


@router.get("/trend/data/processing/pipeline")
async def get_trend_processing_pipeline(
    source: Optional[str] = Query(None),
    limit: int = Query(50, ge=1, le=200)
):
    """
    è·å–å¤„ç†æµæ°´çº¿å¯è§†åŒ–æ•°æ®
    """
    return trend_data_collector.get_processing_pipeline(source=source, limit=limit)


@router.post("/trend/data/collection/record")
async def record_trend_collection(
    source: str = Body(..., embed=True),
    data_type: str = Body(..., embed=True),
    count: int = Body(..., embed=True),
    status: str = Body("success", embed=True),
    error: Optional[str] = Body(None, embed=True),
    metadata: Optional[Dict[str, Any]] = Body(None, embed=True)
):
    """
    è®°å½•æ•°æ®é‡‡é›†ï¼ˆç”¨äºå¤–éƒ¨è°ƒç”¨ï¼‰
    """
    trend_data_collector.record_collection(
        source=source,
        data_type=data_type,
        count=count,
        status=status,
        error=error,
        metadata=metadata
    )
    return {"success": True, "message": "é‡‡é›†è®°å½•å·²ä¿å­˜"}


@router.post("/trend/data/processing/record")
async def record_trend_processing(
    source: str = Body(..., embed=True),
    step: str = Body(..., embed=True),
    input_count: int = Body(..., embed=True),
    output_count: int = Body(..., embed=True),
    processing_time: float = Body(..., embed=True),
    status: str = Body("success", embed=True),
    error: Optional[str] = Body(None, embed=True)
):
    """
    è®°å½•æ•°æ®å¤„ç†ï¼ˆç”¨äºå¤–éƒ¨è°ƒç”¨ï¼‰
    """
    trend_data_collector.record_processing(
        source=source,
        step=step,
        input_count=input_count,
        output_count=output_count,
        processing_time=processing_time,
        status=status,
        error=error
    )
    return {"success": True, "message": "å¤„ç†è®°å½•å·²ä¿å­˜"}


@router.post("/trend/rag/generate")
async def generate_trend_rag_document(
    indicator: str = Body(..., embed=True),
    analysis_result: Dict[str, Any] = Body(..., embed=True),
    document_type: str = Body("trend_analysis", embed=True)
):
    """
    ç”Ÿæˆè¶‹åŠ¿åˆ†æRAGæ–‡æ¡£
    """
    rag_doc = trend_rag_output.generate_rag_document(
        indicator=indicator,
        analysis_result=analysis_result,
        document_type=document_type
    )
    
    # æ¨¡æ‹Ÿå†™å…¥RAGï¼ˆçœŸå®å®ç°åº”è°ƒç”¨RAG APIï¼‰
    rag_doc_id = f"trend_rag_{int(datetime.now().timestamp())}"
    trend_rag_output.record_rag_output(
        indicator=indicator,
        rag_document_id=rag_doc_id,
        status="success"
    )
    
    return {
        "success": True,
        "rag_document_id": rag_doc_id,
        "rag_document": rag_doc
    }


@router.get("/trend/rag/connections")
async def get_trend_rag_connections(
    indicator: Optional[str] = Query(None)
):
    """
    è·å–RAGå…³è”ä¿¡æ¯
    """
    return trend_rag_output.get_rag_connections(indicator=indicator)


@router.get("/trend/rag/output/stats")
async def get_trend_rag_output_stats(
    days: int = Query(7, ge=1, le=90)
):
    """
    è·å–RAGè¾“å‡ºç»Ÿè®¡
    """
    return trend_rag_output.get_output_stats(days=days)


# ==================== P2-012: è¿è¥è´¢åŠ¡è·¨ç³»ç»Ÿè”åŠ¨ ====================

@router.get("/operations-finance/kpis", dependencies=[finance_read_dep])
async def get_operations_finance_kpis():
    """
    è·å–è¿è¥è´¢åŠ¡KPIæŒ‡æ ‡ - P0-003: ä½¿ç”¨çœŸå®æ•°æ®åº“
    """
    # ä»æ•°æ®åº“æŸ¥è¯¢è´¢åŠ¡æ•°æ®
    financial_records = await data_service.query_data(
        module="operations",
        filters={"type": "financial_data"},
        limit=1,
        order_by="_created_at",
        order_desc=True,
    )
    
    # å¦‚æœæœ‰æ•°æ®ï¼Œä½¿ç”¨çœŸå®æ•°æ®ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if financial_records:
        financial_data = financial_records[0]
        # ç§»é™¤å†…éƒ¨å­—æ®µ
        financial_data = {k: v for k, v in financial_data.items() if not k.startswith("_")}
    else:
        # é»˜è®¤å€¼ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶ï¼‰
        financial_data = {
            "cash": 500000.0,
            "bank_deposits": 2000000.0,
            "short_term_liabilities": 300000.0,
            "monthly_expense": 400000.0,
            "quarterly_collections": 1500000.0,
            "quarterly_payments": 1200000.0,
        }
    
    kpis = finance_expert.calculate_kpis(financial_data)
    return {
        "success": True,
        "kpis": kpis,
        "definitions": finance_expert.get_kpi_definitions()
    }


@router.get("/operations-finance/insights", dependencies=[finance_read_dep])
async def get_operations_finance_insights():
    """
    è·å–è´¢åŠ¡ä¸“å®¶æ´å¯Ÿ - P0-003: ä½¿ç”¨çœŸå®æ•°æ®åº“
    """
    # ä»æ•°æ®åº“æŸ¥è¯¢è´¢åŠ¡æ•°æ®
    financial_records = await data_service.query_data(
        module="operations",
        filters={"type": "financial_data"},
        limit=1,
        order_by="_created_at",
        order_desc=True,
    )
    
    # å¦‚æœæœ‰æ•°æ®ï¼Œä½¿ç”¨çœŸå®æ•°æ®ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
    if financial_records:
        financial_data = financial_records[0]
        # ç§»é™¤å†…éƒ¨å­—æ®µ
        financial_data = {k: v for k, v in financial_data.items() if not k.startswith("_")}
    else:
        # é»˜è®¤å€¼ï¼ˆé¦–æ¬¡ä½¿ç”¨æ—¶ï¼‰
        financial_data = {
            "cash": 500000.0,
            "bank_deposits": 2000000.0,
            "short_term_liabilities": 300000.0,
            "monthly_expense": 400000.0,
            "quarterly_collections": 1500000.0,
            "quarterly_payments": 1200000.0,
        }
    
    kpis = finance_expert.calculate_kpis(financial_data)
    insights = finance_expert.generate_insights(kpis)
    
    return {
        "success": True,
        "insights": insights,
        "kpis": kpis
    }


@router.post("/operations-finance/chart/recommend")
async def recommend_chart(
    data: Dict[str, Any] = Body(...),
    purpose: str = Body("åˆ†æ", embed=True)
):
    """
    å›¾è¡¨ä¸“å®¶æ¨è
    """
    recommendation = chart_expert.recommend_chart(data, purpose)
    return {
        "success": True,
        "recommendation": recommendation
    }


@router.get("/operations-finance/strategy/status", dependencies=[finance_read_dep])
async def get_strategy_status():
    """
    è·å–ç­–ç•¥è”åŠ¨çŠ¶æ€
    """
    return operations_finance_strategy.get_strategy_status()


@router.post("/operations-finance/strategy/evaluate")
async def evaluate_strategy_triggers(
    context: Dict[str, Any] = Body(...)
):
    """
    è¯„ä¼°ç­–ç•¥è§¦å‘æ¡ä»¶
    """
    triggered = operations_finance_strategy.evaluate_triggers(context)
    
    # æ‰§è¡Œè§¦å‘çš„ç­–ç•¥
    execution_results = []
    for strategy_info in triggered:
        result = await operations_finance_strategy.execute_strategy(strategy_info)
        execution_results.append(result)
    
    return {
        "success": True,
        "triggered_count": len(triggered),
        "executions": execution_results
    }


@router.get("/operations-finance/strategy/history", dependencies=[finance_read_dep])
async def get_strategy_history(
    limit: int = Query(50, ge=1, le=200)
):
    """
    è·å–ç­–ç•¥æ‰§è¡Œå†å²
    """
    history = operations_finance_strategy.get_execution_history(limit)
    return {
        "success": True,
        "history": history,
        "count": len(history)
    }


@router.post("/operations-finance/erp/sync")
async def sync_to_erp(
    data_type: str = Body(..., embed=True),
    data: Dict[str, Any] = Body(...),
    direction: Optional[str] = Body(None, embed=True)
):
    """
    åŒæ­¥æ•°æ®åˆ°ERP
    """
    result = await erp_data_sync.sync_data(data_type, data, direction)
    return {
        "success": result["status"] == "success",
        "result": result
    }


@router.get("/operations-finance/erp/sync/status", dependencies=[finance_read_dep])
async def get_erp_sync_status(
    data_type: Optional[str] = Query(None)
):
    """
    è·å–ERPåŒæ­¥çŠ¶æ€
    """
    status = erp_data_sync.get_sync_status(data_type)
    return {
        "success": True,
        "status": status
    }


@router.get("/operations-finance/erp/sync/history", dependencies=[finance_read_dep])
async def get_erp_sync_history(
    data_type: Optional[str] = Query(None),
    limit: int = Query(50, ge=1, le=200)
):
    """
    è·å–ERPåŒæ­¥å†å²
    """
    history = erp_data_sync.get_sync_history(data_type, limit)
    return {
        "success": True,
        "history": history,
        "count": len(history)
    }


@router.put("/operations-finance/erp/sync/config")
async def update_erp_sync_config(
    data_type: str = Body(..., embed=True),
    config: Dict[str, Any] = Body(...)
):
    """
    æ›´æ–°ERPåŒæ­¥é…ç½®
    """
    updated_config = erp_data_sync.update_sync_config(data_type, config)
    return {
        "success": True,
        "config": updated_config
    }


# ============ P2-034: ä¸“å®¶èƒ½åŠ›åœ°å›¾ & è·¯ç”±ç­–ç•¥ ============


@router.get("/experts/ability-map")
async def get_expert_ability_map():
    """
    è·å–ä¸“å®¶èƒ½åŠ›åœ°å›¾ï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆæ ‡å‡†åŒ–ç³»ç»Ÿï¼‰
    """
    # æ›´æ–°æ ‡å‡†åŒ–ç³»ç»Ÿçš„èƒ½åŠ›åœ°å›¾
    expert_standardization.update_ability_map(EXPERT_ABILITY_MAP)
    
    total = len(EXPERT_ABILITY_MAP)
    avg_confidence = round(sum(item["confidence"] for item in EXPERT_ABILITY_MAP) / total, 2) if total else 0
    modules = sorted({m for item in EXPERT_ABILITY_MAP for m in item["modules"]})
    summary = {
        "total_experts": total,
        "avg_confidence": avg_confidence,
        "modules": modules,
        "ready_capabilities": sum(
            1
            for item in EXPERT_ABILITY_MAP
            for cap in item["capabilities"]
            if cap["status"] == "ready"
        )
    }
    return {"success": True, "summary": summary, "abilities": EXPERT_ABILITY_MAP}


@router.get("/experts/routing")
async def get_expert_routing():
    """
    è·å–ä¸“å®¶è·¯ç”±ç­–ç•¥ï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆæ ‡å‡†åŒ–ç³»ç»Ÿï¼‰
    """
    # æ›´æ–°æ ‡å‡†åŒ–ç³»ç»Ÿçš„è·¯ç”±ç­–ç•¥
    expert_standardization.update_routing_strategy(EXPERT_ROUTING_STRATEGY)
    
    strategy = dict(EXPERT_ROUTING_STRATEGY)
    summary = expert_standardization.get_routing_summary()
    
    return {
        "success": True,
        "strategy": strategy,
        "summary": summary
    }


@router.get("/experts/acceptance")
async def get_expert_acceptance():
    """
    è·å–ä¸“å®¶éªŒæ”¶çŸ©é˜µï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆæ ‡å‡†åŒ–ç³»ç»Ÿï¼‰
    """
    # æ›´æ–°æ ‡å‡†åŒ–ç³»ç»Ÿçš„éªŒæ”¶çŸ©é˜µ
    expert_standardization.update_acceptance_matrix(EXPERT_ACCEPTANCE_MATRIX)
    
    summary = expert_standardization.get_acceptance_summary()
    
    return {
        "success": True,
        "matrix": EXPERT_ACCEPTANCE_MATRIX,
        "count": len(EXPERT_ACCEPTANCE_MATRIX),
        "summary": summary
    }


@router.post("/experts/simulate-route")
async def simulate_expert_route(req: ExpertRouteSimulationRequest):
    """
    æ¨¡æ‹Ÿä¸“å®¶è·¯ç”±ï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆæ ‡å‡†åŒ–ç³»ç»Ÿï¼‰
    """
    # ä½¿ç”¨æ ‡å‡†åŒ–ç³»ç»Ÿè¿›è¡Œæ¨¡æ‹Ÿ
    result = expert_standardization.simulate_routing(
        query=req.query,
        knowledge_hints=req.knowledge_hints,
        expected_domain=req.expected_domain
    )
    
    # å¦‚æœä¸“å®¶è·¯ç”±å™¨å¯ç”¨ï¼Œä¹Ÿä½¿ç”¨å®ƒè¿›è¡Œè·¯ç”±ï¼ˆä½œä¸ºå¯¹æ¯”ï¼‰
    route_from_router = None
    if super_agent.expert_router:
        try:
            rag_stub = {
                "knowledge": [{"content": hint} for hint in (req.knowledge_hints or [])],
                "understanding": {"expected_domain": req.expected_domain}
            }
            route_from_router = await super_agent.expert_router.route(req.query, rag_stub)
        except Exception as e:
            logger.warning(f"ä¸“å®¶è·¯ç”±å™¨è·¯ç”±å¤±è´¥: {e}")
    
    return {
        "success": True,
        "route": result,
        "route_from_router": route_from_router,
        "comparison": {
            "standardization_confidence": result.get("confidence", 0.0),
            "router_confidence": route_from_router.get("confidence", 0.0) if route_from_router else None
        }
    }


@router.get("/experts/overview")
async def get_expert_overview():
    """
    è·å–ä¸“å®¶ç³»ç»Ÿæ¦‚è§ˆï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆæ ‡å‡†åŒ–ç³»ç»Ÿï¼‰
    """
    abilities = await get_expert_ability_map()
    routing = await get_expert_routing()
    acceptance = await get_expert_acceptance()
    
    return {
        "success": True,
        "ability_summary": abilities["summary"],
        "routing": routing["strategy"],
        "routing_summary": routing.get("summary", {}),
        "acceptance": acceptance["matrix"],
        "acceptance_summary": acceptance.get("summary", {})
    }


@router.get("/experts/simulation/history")
async def get_simulation_history(
    limit: int = Query(20, ge=1, le=100)
):
    """
    è·å–æ¨¡æ‹Ÿæ¼”ç»ƒå†å²
    """
    history = expert_standardization.get_simulation_history(limit)
    return {
        "success": True,
        "history": history,
        "count": len(history)
    }


@router.post("/experts/acceptance/validate")
async def validate_acceptance(
    capability: str = Body(..., embed=True),
    test_results: List[Dict[str, Any]] = Body(...)
):
    """
    éªŒè¯éªŒæ”¶æ ‡å‡†
    """
    result = expert_standardization.validate_acceptance(capability, test_results)
    return {
        "success": True,
        "validation": result
    }


@router.post("/experts/collaboration/session")
async def create_collaboration_session(req: CollaborationSessionCreateRequest):
    """
    åˆ›å»ºä¸“å®¶ååŒä¼šè¯
    """
    session = await expert_collaboration_hub.start_session(
        topic=req.topic,
        initiator=req.initiator,
        goals=req.goals,
        experts=[participant.dict() for participant in req.experts],
        channel=req.channel or "multi",
    )
    return {
        "success": True,
        "session": session,
    }


@router.post("/experts/collaboration/session/{session_id}/contribution")
async def add_collaboration_contribution(
    session_id: str,
    req: CollaborationContributionRequest,
):
    """
    åœ¨æŒ‡å®šååŒä¼šè¯ä¸­è¿½åŠ ä¸“å®¶è´¡çŒ®
    """
    try:
        session = await expert_collaboration_hub.add_contribution(
            session_id=session_id,
            expert_id=req.expert_id,
            expert_name=req.expert_name,
            summary=req.summary,
            channel=req.channel,
            action_items=req.action_items,
            impact_score=req.impact_score,
            references=req.references,
        )
    except ValueError as exc:
        raise HTTPException(status_code=404, detail=str(exc))
    return {
        "success": True,
        "session": session,
    }


@router.post("/experts/collaboration/session/{session_id}/decision")
async def finalize_collaboration_session(
    session_id: str,
    req: CollaborationDecisionRequest,
):
    """
    å…³é—­ååŒä¼šè¯å¹¶è®°å½•å†³ç­–
    """
    try:
        session = await expert_collaboration_hub.finalize_session(
            session_id=session_id,
            owner=req.owner,
            summary=req.summary,
            kpis=req.kpis,
            followups=req.followups,
        )
    except ValueError as exc:
        raise HTTPException(status_code=404, detail=str(exc))
    return {
        "success": True,
        "session": session,
    }


@router.get("/experts/collaboration/active")
async def get_active_collaboration_sessions(
    limit: int = Query(5, ge=1, le=20),
):
    """
    æŸ¥çœ‹æ´»è·ƒä¸­çš„ä¸“å®¶ååŒä¼šè¯
    """
    sessions = await expert_collaboration_hub.get_active_sessions(limit)
    return {
        "success": True,
        "sessions": sessions,
        "count": len(sessions),
    }


@router.get("/experts/collaboration/summary")
async def get_collaboration_summary():
    """
    è·å–ååŒä¸­æ¢æŒ‡æ ‡
    """
    summary = await expert_collaboration_hub.get_summary()
    return {
        "success": True,
        "summary": summary,
    }


@router.get("/experts/collaboration/session/{session_id}")
async def get_collaboration_session_detail(session_id: str):
    """
    è·å–å•ä¸ªä¼šè¯è¯¦æƒ…
    """
    try:
        session = await expert_collaboration_hub.get_session(session_id)
    except ValueError as exc:
        raise HTTPException(status_code=404, detail=str(exc))
    return {
        "success": True,
        "session": session,
    }


@router.get("/experts/collaboration/stream")
async def stream_collaboration_events(request: Request):
    """
    SSEï¼šå®æ—¶æ¨é€ä¸“å®¶ååŒäº‹ä»¶
    """
    queue = await collaboration_event_stream.register()

    async def event_generator():
        try:
            while True:
                if await request.is_disconnected():
                    break
                try:
                    event = await asyncio.wait_for(queue.get(), timeout=20)
                    yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                except asyncio.TimeoutError:
                    yield ": keep-alive\n\n"
        finally:
            collaboration_event_stream.unregister(queue)

    return StreamingResponse(event_generator(), media_type="text/event-stream")


# ==================== P1-005: æ—¥å¸¸é…ç½®ä¸éƒ¨ç½²è‡ªåŠ¨åŒ– ====================


@router.get("/devops/config/profiles", dependencies=[security_read_dep])
async def list_config_profiles():
    """åˆ—å‡ºå¯ç”¨ç¯å¢ƒé…ç½®"""
    return {
        "success": True,
        "profiles": env_config_manager.list_profiles(),
        "history": env_config_manager.get_history(limit=5),
    }


@router.post("/devops/config/apply", dependencies=[security_write_dep])
async def apply_config_profile(req: ConfigApplyRequest):
    """åº”ç”¨æŒ‡å®š profile å¹¶ç”Ÿæˆ `.env.runtime`"""
    result = env_config_manager.apply_profile(req.profile, overrides=req.overrides)
    return {
        "success": True,
        "profile": result["profile"]["name"],
        "output": result["output_file"],
    }


@router.get("/devops/deploy/pipeline", dependencies=[security_read_dep])
async def get_deploy_pipeline():
    """æŸ¥çœ‹éƒ¨ç½²æµæ°´çº¿æ­¥éª¤"""
    return {
        "success": True,
        "steps": deployment_manager.list_steps(),
    }


@router.post("/devops/deploy/run", dependencies=[security_write_dep])
async def run_deploy_pipeline(req: DeploymentRunRequest):
    """æ‰§è¡Œæˆ–æ¨¡æ‹Ÿéƒ¨ç½²æµæ°´çº¿"""
    summary = await deployment_manager.run_pipeline(
        profile=req.profile,
        dry_run=req.dry_run,
        selected_steps=req.steps,
        env_overrides=req.overrides or None,
    )
    return {
        "success": summary["completed"],
        "summary": summary,
    }


@router.get("/devops/deploy/history", dependencies=[security_read_dep])
async def get_deploy_history(limit: int = Query(10, ge=1, le=50)):
    """è·å–æœ€è¿‘éƒ¨ç½²è®°å½•"""
    history = deployment_manager.get_history(limit=limit)
    return {
        "success": True,
        "history": history,
    }


# ==================== P3-002: å¾®æœåŠ¡æ‹†åˆ† Â· æœåŠ¡æ³¨å†Œä¸é€šä¿¡ ====================


@router.get("/architecture/services/summary", dependencies=[security_read_dep])
async def get_service_summary():
    return {
        "success": True,
        "contracts": service_registry.list_contracts(),
        "instances": service_registry.list_instances(),
        "changelog": service_registry.get_changelog()[:20],
    }


@router.post("/architecture/services/register", dependencies=[security_write_dep])
async def register_service_instance(req: ServiceRegisterRequest):
    instance = service_registry.register_instance(
        service=req.service,
        endpoint=req.endpoint,
        version=req.version,
        protocol=req.protocol,
        deployment_target=req.deployment_target,
        metadata=req.metadata,
    )
    return {"success": True, "instance": instance.to_dict()}


@router.post("/architecture/services/heartbeat", dependencies=[security_write_dep])
async def service_heartbeat(req: ServiceHeartbeatRequest):
    ok = service_registry.heartbeat(req.service, req.instance_id, status=req.status)
    if not ok:
        raise HTTPException(status_code=404, detail="å®ä¾‹ä¸å­˜åœ¨")
    return {"success": True}


@router.post("/architecture/services/call", dependencies=[security_write_dep])
async def call_service(req: ServiceCallRequest):
    result: ServiceCallResult = await service_gateway.call_service(
        service=req.service,
        operation=req.operation,
        payload=req.payload,
        prefer_internal=req.prefer_internal,
    )
    status_code = status.HTTP_200_OK if result.status == "success" else status.HTTP_400_BAD_REQUEST
    return JSONResponse(
        status_code=status_code,
        content={
            "success": result.status == "success",
            "result": result.to_dict(),
        },
    )


@router.get("/architecture/multitenant-plan")
async def get_multitenant_plan():
    """å¤šç§Ÿæˆ· / å¾®æœåŠ¡æ¼”è¿›è®¡åˆ’ï¼ˆå•ä½“å†…æ¨¡å—åŒ–è¾¹ç•Œï¼‰"""
    return {"success": True, "plan": MULTITENANT_EVOLUTION_PLAN}


# ==================== P3-015: å¤šç§Ÿæˆ· / å¾®æœåŠ¡æ¼”è¿› + 2 ç§’ SLO ====================

@router.get("/architecture/multitenant-evolution/report")
async def get_multitenant_evolution_report():
    """
    è·å–å¤šç§Ÿæˆ·/å¾®æœåŠ¡æ¼”è¿›æŠ¥å‘Š
    """
    report = multitenant_evolution.generate_evolution_report()
    return {
        "success": True,
        "report": report
    }


@router.get("/architecture/service-boundaries")
async def get_service_boundaries():
    """
    è·å–æœåŠ¡æ‹†åˆ†è¾¹ç•Œ
    """
    boundaries = multitenant_evolution.get_service_boundaries()
    return {
        "success": True,
        "boundaries": {
            name: {
                "module_name": boundary.module_name,
                "domain": boundary.domain,
                "ownership": boundary.ownership,
                "separation": boundary.separation,
                "ready": boundary.ready,
                "dependencies": boundary.dependencies,
                "api_contracts": boundary.api_contracts,
                "data_stores": boundary.data_stores,
                "deployment_target": boundary.deployment_target
            }
            for name, boundary in boundaries.items()
        }
    }


@router.get("/architecture/evolution-phases")
async def get_evolution_phases():
    """
    è·å–æ¼”è¿›é˜¶æ®µ
    """
    phases = multitenant_evolution.get_evolution_phases()
    return {
        "success": True,
        "phases": phases
    }


# ==================== å¤šç§Ÿæˆ·ç®¡ç† ====================


@router.get("/tenants")
async def list_tenants(include_inactive: bool = False, _: Dict = Depends(security_read_dep)):
    """åˆ—å‡ºç§Ÿæˆ·ï¼ˆéœ€å®‰å…¨è¯»æƒé™ï¼‰"""
    tenants = tenant_manager.list_tenants(include_inactive=include_inactive)
    return {"success": True, "tenants": tenants}


@router.get("/tenants/current")
async def get_current_tenant_info(request: Request):
    """è·å–å½“å‰è¯·æ±‚æ‰€å¤„ç§Ÿæˆ·"""
    ctx = getattr(request.state, "tenant", None) or get_current_tenant()
    return {
        "success": True,
        "tenant": {
            "tenant_id": ctx.tenant_id,
            "name": ctx.name,
            "metadata": ctx.metadata,
        },
    }


@router.post("/tenants")
async def create_or_update_tenant(req: TenantCreateRequest, _: Dict = Depends(security_write_dep)):
    tenant = tenant_manager.upsert_tenant(
        tenant_id=req.tenant_id,
        name=req.name,
        plan=req.plan or "enterprise",
        active=req.active if req.active is not None else True,
        metadata=req.metadata or {},
    )
    return {"success": True, "tenant": asdict(tenant)}


@router.put("/tenants/{tenant_id}")
async def update_tenant(tenant_id: str, req: TenantUpdateRequest, _: Dict = Depends(security_write_dep)):
    existing = tenant_manager.get_tenant(tenant_id)
    if not existing:
        raise HTTPException(status_code=404, detail="ç§Ÿæˆ·ä¸å­˜åœ¨")
    tenant = tenant_manager.upsert_tenant(
        tenant_id=tenant_id,
        name=req.name or existing.name,
        plan=req.plan or existing.plan,
        active=req.active if req.active is not None else existing.active,
        metadata=req.metadata or existing.metadata,
    )
    return {"success": True, "tenant": asdict(tenant)}


@router.delete("/tenants/{tenant_id}")
async def delete_tenant(tenant_id: str, _: Dict = Depends(security_write_dep)):
    ok = tenant_manager.delete_tenant(tenant_id)
    if not ok:
        raise HTTPException(status_code=400, detail="æ— æ³•åˆ é™¤ç§Ÿæˆ·ï¼ˆå¯èƒ½æ˜¯é»˜è®¤ç§Ÿæˆ·æˆ–ä¸å­˜åœ¨ï¼‰")
    return {"success": True}


@router.post("/slo/performance/vector-index/benchmark")
async def record_vector_index_benchmark(benchmark: VectorIndexBenchmark):
    """
    è®°å½•å‘é‡ç´¢å¼•æ€§èƒ½åŸºå‡†æµ‹è¯•
    """
    slo_performance_reporter.record_vector_index_benchmark(benchmark)
    return {
        "success": True,
        "message": "å‘é‡ç´¢å¼•åŸºå‡†æµ‹è¯•å·²è®°å½•"
    }


@router.post("/slo/performance/streaming/benchmark")
async def record_streaming_benchmark(benchmark: StreamingBenchmark):
    """
    è®°å½•æµå¼å“åº”æ€§èƒ½åŸºå‡†æµ‹è¯•
    """
    slo_performance_reporter.record_streaming_benchmark(benchmark)
    return {
        "success": True,
        "message": "æµå¼å“åº”åŸºå‡†æµ‹è¯•å·²è®°å½•"
    }


@router.post("/slo/performance/context-compression/benchmark")
async def record_context_compression_benchmark(benchmark: ContextCompressionBenchmark):
    """
    è®°å½•ä¸Šä¸‹æ–‡å‹ç¼©æ€§èƒ½åŸºå‡†æµ‹è¯•
    """
    slo_performance_reporter.record_context_compression_benchmark(benchmark)
    return {
        "success": True,
        "message": "ä¸Šä¸‹æ–‡å‹ç¼©åŸºå‡†æµ‹è¯•å·²è®°å½•"
    }


@router.get("/slo/performance/report/vector-index")
async def get_vector_index_report():
    """
    è·å–å‘é‡ç´¢å¼•ä¼˜åŒ–æŠ¥å‘Š
    """
    report = slo_performance_reporter.generate_vector_index_report()
    return {
        "success": True,
        "report": report
    }


@router.get("/slo/performance/report/streaming")
async def get_streaming_report():
    """
    è·å–æµå¼/SSRæ€§èƒ½æŠ¥å‘Š
    """
    report = slo_performance_reporter.generate_streaming_report()
    return {
        "success": True,
        "report": report
    }


@router.get("/slo/performance/report/context-compression")
async def get_context_compression_report():
    """
    è·å–ä¸Šä¸‹æ–‡å‹ç¼©æ€§èƒ½æŠ¥å‘Š
    """
    report = slo_performance_reporter.generate_context_compression_report()
    return {
        "success": True,
        "report": report
    }


@router.get("/slo/performance/report/comprehensive")
async def get_comprehensive_performance_report():
    """
    è·å–ç»¼åˆæ€§èƒ½æŠ¥å‘Šï¼ˆåŒ…å«å‘é‡ç´¢å¼•ã€æµå¼å“åº”ã€ä¸Šä¸‹æ–‡å‹ç¼©ï¼‰
    """
    report = slo_performance_reporter.generate_comprehensive_report()
    return {
        "success": True,
        "report": report
    }


# ==================== P3-016: éªŒæ”¶çŸ©é˜µä¸æŒç»­äº¤ä»˜ ====================

@router.post("/acceptance/matrix/generate")
async def generate_acceptance_matrix():
    """
    ç”ŸæˆéªŒæ”¶çŸ©é˜µExcelæ–‡ä»¶
    """
    try:
        output_file = acceptance_matrix_generator.generate_excel()
        return {
            "success": True,
            "message": "éªŒæ”¶çŸ©é˜µExcelæ–‡ä»¶å·²ç”Ÿæˆ",
            "file_path": str(output_file),
            "file_name": output_file.name
        }
    except Exception as e:
        logger.error(f"ç”ŸæˆéªŒæ”¶çŸ©é˜µå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@router.get("/acceptance/matrix/summary")
async def get_acceptance_matrix_summary():
    """
    è·å–éªŒæ”¶çŸ©é˜µæ‘˜è¦
    """
    summary = acceptance_matrix_generator.get_requirements_summary()
    return {
        "success": True,
        "summary": summary
    }


@router.put("/acceptance/matrix/requirement/{requirement_id}")
async def update_requirement_status(
    requirement_id: str,
    status: Optional[str] = Body(None, embed=True),
    test_result: Optional[str] = Body(None, embed=True),
    evidence: Optional[str] = Body(None, embed=True),
    notes: Optional[str] = Body(None, embed=True)
):
    """
    æ›´æ–°éœ€æ±‚çŠ¶æ€
    """
    acceptance_matrix_generator.update_requirement_status(
        requirement_id=requirement_id,
        status=status,
        test_result=test_result,
        evidence=evidence,
        notes=notes
    )
    return {
        "success": True,
        "message": f"éœ€æ±‚ {requirement_id} çŠ¶æ€å·²æ›´æ–°"
    }


@router.post("/acceptance/recording/start")
async def start_acceptance_recording(
    requirement_id: str = Body(..., embed=True),
    recording_type: str = Body("script", embed=True),
    description: str = Body("", embed=True)
):
    """
    å¼€å§‹éªŒæ”¶è®°å½•
    """
    recording_id = acceptance_recording.start_recording(
        requirement_id=requirement_id,
        recording_type=recording_type,
        description=description
    )
    return {
        "success": True,
        "recording_id": recording_id,
        "message": "éªŒæ”¶è®°å½•å·²å¼€å§‹"
    }


@router.post("/acceptance/recording/{recording_id}/step")
async def add_recording_step(
    recording_id: str,
    step_name: str = Body(..., embed=True),
    command: Optional[str] = Body(None, embed=True),
    output: Optional[str] = Body(None, embed=True),
    screenshot: Optional[str] = Body(None, embed=True),
    notes: Optional[str] = Body(None, embed=True)
):
    """
    æ·»åŠ éªŒæ”¶æ­¥éª¤
    """
    acceptance_recording.add_step(
        recording_id=recording_id,
        step_name=step_name,
        command=command,
        output=output,
        screenshot=screenshot,
        notes=notes
    )
    return {
        "success": True,
        "message": "éªŒæ”¶æ­¥éª¤å·²æ·»åŠ "
    }


@router.post("/acceptance/recording/{recording_id}/command")
async def record_command(
    recording_id: str,
    command: str = Body(..., embed=True),
    step_name: Optional[str] = Body(None, embed=True)
):
    """
    è®°å½•å‘½ä»¤æ‰§è¡Œ
    """
    output = acceptance_recording.record_command(
        recording_id=recording_id,
        command=command,
        step_name=step_name
    )
    return {
        "success": True,
        "output": output,
        "message": "å‘½ä»¤å·²è®°å½•å¹¶æ‰§è¡Œ"
    }


@router.post("/acceptance/recording/{recording_id}/finish")
async def finish_recording(
    recording_id: str,
    result: str = Body("pass", embed=True),
    summary: Optional[str] = Body(None, embed=True)
):
    """
    å®ŒæˆéªŒæ”¶è®°å½•
    """
    acceptance_recording.finish_recording(
        recording_id=recording_id,
        result=result,
        summary=summary
    )
    return {
        "success": True,
        "message": "éªŒæ”¶è®°å½•å·²å®Œæˆ"
    }


@router.get("/acceptance/recording/{recording_id}")
async def get_recording(recording_id: str):
    """
    è·å–éªŒæ”¶è®°å½•
    """
    recording = acceptance_recording.get_recording(recording_id)
    if not recording:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è®°å½•: {recording_id}")
    
    return {
        "success": True,
        "recording": recording
    }


@router.get("/acceptance/recording")
async def list_recordings(requirement_id: Optional[str] = Query(None)):
    """
    åˆ—å‡ºéªŒæ”¶è®°å½•
    """
    recordings = acceptance_recording.list_recordings(requirement_id=requirement_id)
    return {
        "success": True,
        "recordings": recordings,
        "count": len(recordings)
    }


@router.post("/acceptance/recording/{recording_id}/generate-script")
async def generate_recording_script(recording_id: str):
    """
    ç”ŸæˆéªŒæ”¶è„šæœ¬
    """
    try:
        script_file = acceptance_recording.generate_script(recording_id)
        return {
            "success": True,
            "script_file": str(script_file),
            "message": "éªŒæ”¶è„šæœ¬å·²ç”Ÿæˆ"
        }
    except Exception as e:
        logger.error(f"ç”ŸæˆéªŒæ”¶è„šæœ¬å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@router.post("/ci/evidence/upload")
async def upload_ci_evidence(
    requirement_id: str = Body(..., embed=True),
    evidence_type: str = Body(..., embed=True),
    file_path: str = Body(..., embed=True),
    metadata: Optional[Dict[str, Any]] = Body(None, embed=True)
):
    """
    ä¸Šä¼ CIè¯æ®æ–‡ä»¶
    """
    try:
        result = ci_evidence_uploader.upload_evidence(
            requirement_id=requirement_id,
            evidence_type=evidence_type,
            file_path=file_path,
            metadata=metadata
        )
        return result
    except Exception as e:
        logger.error(f"ä¸Šä¼ CIè¯æ®å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@router.post("/ci/evidence/upload-test-results")
async def upload_test_results(
    requirement_id: str = Body(..., embed=True),
    test_results: Dict[str, Any] = Body(...),
    test_report_file: Optional[str] = Body(None, embed=True)
):
    """
    ä¸Šä¼ æµ‹è¯•ç»“æœ
    """
    try:
        result = ci_evidence_uploader.upload_test_results(
            requirement_id=requirement_id,
            test_results=test_results,
            test_report_file=test_report_file
        )
        return result
    except Exception as e:
        logger.error(f"ä¸Šä¼ æµ‹è¯•ç»“æœå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@router.get("/ci/evidence/report")
async def get_evidence_report(requirement_id: Optional[str] = Query(None)):
    """
    è·å–è¯æ®æŠ¥å‘Š
    """
    report = ci_evidence_uploader.generate_evidence_report(requirement_id=requirement_id)
    return {
        "success": True,
        "report": report
    }


@router.get("/ci/environment")
async def get_ci_environment():
    """
    è·å–CIç¯å¢ƒä¿¡æ¯
    """
    env = ci_evidence_uploader.get_ci_environment()
    return {
        "success": True,
        "environment": env
    }


@router.get("/tasks/statistics")
async def get_task_statistics():
    """è·å–ä»»åŠ¡ç»Ÿè®¡ä¿¡æ¯â­å¢å¼ºç‰ˆ"""
    stats = task_planning.get_statistics()
    return stats


# ==================== P0-001: é—­ç¯å®Œæ•´å®ç° ====================

# å…¨å±€é—­ç¯å¼•æ“å®ä¾‹
closed_loop_engine = ClosedLoopEngine()
unified_event_bus = get_unified_event_bus()
execution_checker = ExecutionChecker(unified_event_bus)
feedback_handler = FeedbackHandler(unified_event_bus)
evidence_recorder = EvidenceRecorder(unified_event_bus)


async def run_closed_loop_operation(
    *,
    module: str,
    function: str,
    parameters: Dict[str, Any],
    executor: Callable[[Dict[str, Any]], Awaitable[Dict[str, Any]] | Dict[str, Any]],
    task_id: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None,
) -> tuple[str, Dict[str, Any]]:
    """æ¥å—â†’æ‰§è¡ŒæŒ‡å®šä¸šåŠ¡é€»è¾‘ï¼Œå¹¶åœ¨ç»Ÿä¸€äº‹ä»¶æµä¸­è®°å½•ç»“æœ"""
    meta = metadata.copy() if metadata else {}
    approval_id = meta.get("approval_id")
    if approval_id:
        approval = approval_manager.get_request(approval_id)
        if not approval or approval.status != ApprovalStatus.APPROVED:
            raise HTTPException(
                status_code=423,
                detail=f"æ•æ„Ÿæ“ä½œå®¡æ‰¹æœªé€šè¿‡: {approval_id}",
            )

    exec_task_id = task_id or f"{module}-{function}-{uuid4().hex[:8]}"
    context = await closed_loop_engine.accept_task(
        task_id=exec_task_id,
        module=module,
        function=function,
        parameters=parameters,
        metadata=meta,
    )
    exec_result = await closed_loop_engine.execute(context.execution_id, executor)
    success_flag = exec_result.get("success", True)
    actor = meta.get("actor", "system")
    if audit_pipeline:
        audit_pipeline.log_task_event(
            task_id=exec_task_id,
            actor=actor,
            module=module,
            status="success" if success_flag else "failed",
            metadata={
                "function": function,
                "execution_id": context.execution_id,
                "parameters": parameters,
            },
        )
    await unified_event_bus.publish(
        category=EventCategory.WORKFLOW,
        event_type="closed_loop.completed",
        source="api",
        severity=EventSeverity.INFO if success_flag else EventSeverity.WARNING,
        payload={
            "execution_id": context.execution_id,
            "module": module,
            "function": function,
            "success": success_flag,
        },
        correlation_id=context.execution_id,
    )
    return context.execution_id, exec_result


@router.post("/closed-loop/accept")
async def accept_task(
    task_id: Optional[str] = Body(None, embed=True),
    module: str = Body(..., embed=True),
    function: str = Body(..., embed=True),
    parameters: Dict[str, Any] = Body(...),
    metadata: Optional[Dict[str, Any]] = Body(None, embed=True),
):
    """
    æ¥å—ä»»åŠ¡ï¼ˆACCEPTé˜¶æ®µï¼‰
    """
    try:
        context = await closed_loop_engine.accept_task(
            task_id=task_id or f"task_{uuid4()}",
            module=module,
            function=function,
            parameters=parameters,
            metadata=metadata,
        )
        return {
            "success": True,
            "execution_id": context.execution_id,
            "context": context.__dict__,
        }
    except Exception as e:
        logger.error(f"æ¥å—ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e),
        }


@router.post("/closed-loop/execute/{execution_id}")
async def execute_task(
    execution_id: str,
    executor_type: str = Body("default", embed=True),
    executor_config: Optional[Dict[str, Any]] = Body(None, embed=True),
):
    """
    æ‰§è¡Œä»»åŠ¡ï¼ˆEXECUTEé˜¶æ®µï¼‰
    
    æ³¨æ„ï¼šexecutor_typeæŒ‡å®šæ‰§è¡Œå™¨ç±»å‹ï¼Œå®é™…æ‰§è¡Œé€»è¾‘ç”±åç«¯æ ¹æ®ç±»å‹è°ƒç”¨
    """
    try:
        context = closed_loop_engine.get_execution(execution_id)
        if not context:
            raise HTTPException(status_code=404, detail=f"æ‰§è¡Œä¸Šä¸‹æ–‡ä¸å­˜åœ¨: {execution_id}")
        
        # æ ¹æ®executor_typeè°ƒç”¨ä¸åŒçš„æ‰§è¡Œå™¨
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ®æ¨¡å—å’Œå‡½æ•°è°ƒç”¨å¯¹åº”çš„æ‰§è¡Œå™¨
        async def executor(params: Dict[str, Any]) -> Dict[str, Any]:
            # æ¨¡æ‹Ÿæ‰§è¡Œï¼ˆå®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„æ¨¡å—å‡½æ•°ï¼‰
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
            return {
                "success": True,
                "result": f"æ‰§è¡Œç»“æœ: {context.module}.{context.function}",
                "duration": 0.1,
            }
        
        result = await closed_loop_engine.execute(execution_id, executor)
        
        return {
            "success": True,
            "result": result,
        }
    except Exception as e:
        logger.error(f"æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e),
        }


@router.post("/closed-loop/check/{execution_id}")
async def check_execution(execution_id: str):
    """
    æ£€æŸ¥æ‰§è¡Œç»“æœï¼ˆCHECKé˜¶æ®µï¼‰
    """
    try:
        reports = await closed_loop_engine.check_execution(execution_id)
        return {
            "success": True,
            "reports": reports,
        }
    except Exception as e:
        logger.error(f"æ£€æŸ¥æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e),
        }


@router.post("/closed-loop/feedback/{execution_id}")
async def process_feedback(
    execution_id: str,
    feedback_id: str = Body(..., embed=True),
    action: str = Body(..., embed=True),
):
    """
    å¤„ç†åé¦ˆï¼ˆFEEDBACKé˜¶æ®µï¼‰
    """
    try:
        success = await closed_loop_engine.process_feedback(
            execution_id=execution_id,
            feedback_id=feedback_id,
            action=action,
        )
        return {
            "success": success,
            "message": "åé¦ˆå¤„ç†æˆåŠŸ" if success else "åé¦ˆå¤„ç†å¤±è´¥",
        }
    except Exception as e:
        logger.error(f"å¤„ç†åé¦ˆå¤±è´¥: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e),
        }


@router.post("/closed-loop/re-execute/{execution_id}")
async def re_execute_task(
    execution_id: str,
    reason: Optional[str] = Body(None, embed=True),
):
    """
    å†æ‰§è¡Œï¼ˆRE_EXECUTEé˜¶æ®µï¼‰
    """
    try:
        result = await closed_loop_engine.re_execute(
            execution_id=execution_id,
            reason=reason,
        )
        return {
            "success": True,
            "result": result,
        }
    except Exception as e:
        logger.error(f"å†æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return {
            "success": False,
            "error": str(e),
        }


@router.get("/closed-loop/execution/{execution_id}")
async def get_execution(execution_id: str):
    """
    è·å–æ‰§è¡Œä¸Šä¸‹æ–‡
    """
    context = closed_loop_engine.get_execution(execution_id)
    if not context:
        raise HTTPException(status_code=404, detail=f"æ‰§è¡Œä¸Šä¸‹æ–‡ä¸å­˜åœ¨: {execution_id}")
    
    return {
        "success": True,
        "context": context.__dict__,
    }


@router.get("/closed-loop/timeline/{execution_id}")
async def get_execution_timeline(execution_id: str):
    """
    è·å–æ‰§è¡Œæ—¶é—´çº¿ï¼ˆåŒ…å«æ‰€æœ‰è¯æ®ï¼‰
    """
    timeline = closed_loop_engine.get_execution_timeline(execution_id)
    if not timeline:
        raise HTTPException(status_code=404, detail=f"æ‰§è¡Œæ—¶é—´çº¿ä¸å­˜åœ¨: {execution_id}")
    
    return {
        "success": True,
        "timeline": timeline,
    }


@router.get("/closed-loop/statistics")
async def get_closed_loop_statistics():
    """
    è·å–é—­ç¯ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    """
    stats = closed_loop_engine.get_statistics()
    return {
        "success": True,
        "statistics": stats,
    }


@router.get("/events")
async def get_events(
    limit: int = Query(50),
    category: Optional[str] = Query(None),
    event_type: Optional[str] = Query(None),
    source: Optional[str] = Query(None),
    severity: Optional[str] = Query(None),
    correlation_id: Optional[str] = Query(None),
):
    """
    æŸ¥è¯¢äº‹ä»¶
    """
    from core.unified_event_bus import EventCategory as EC, EventSeverity as ES
    
    events = unified_event_bus.get_events(
        limit=limit,
        category=EC(category) if category else None,
        event_type=event_type,
        source=source,
        severity=ES(severity) if severity else None,
        correlation_id=correlation_id,
    )
    
    return {
        "success": True,
        "events": [e.to_dict() for e in events],
        "count": len(events),
    }


@router.get("/checks/reports")
async def get_check_reports(
    execution_id: Optional[str] = Query(None),
    check_type: Optional[str] = Query(None),
    result: Optional[str] = Query(None),
    limit: int = Query(100),
):
    """
    è·å–æ£€æŸ¥æŠ¥å‘Š
    """
    reports = execution_checker.get_reports(
        execution_id=execution_id,
        check_type=CheckType(check_type) if check_type else None,
        result=CheckResult(result) if result else None,
        limit=limit,
    )
    
    return {
        "success": True,
        "reports": [r.__dict__ for r in reports],
        "count": len(reports),
    }


@router.get("/feedbacks")
async def get_feedbacks(
    execution_id: Optional[str] = Query(None),
    feedback_type: Optional[str] = Query(None),
    status: Optional[str] = Query(None),
    limit: int = Query(100),
):
    """
    è·å–åé¦ˆåˆ—è¡¨
    """
    feedbacks = feedback_handler.get_feedbacks(
        execution_id=execution_id,
        feedback_type=FeedbackType(feedback_type) if feedback_type else None,
        status=FeedbackStatus(status) if status else None,
        limit=limit,
    )
    
    return {
        "success": True,
        "feedbacks": [fb.to_dict() for fb in feedbacks],
        "count": len(feedbacks),
    }


@router.get("/evidence")
async def get_evidence(
    execution_id: Optional[str] = Query(None),
    evidence_type: Optional[str] = Query(None),
    limit: int = Query(100),
):
    """
    è·å–è¯æ®åˆ—è¡¨
    """
    evidence_list = evidence_recorder.get_evidence_by_execution(
        execution_id=execution_id or "",
        evidence_type=EvidenceType(evidence_type) if evidence_type else None,
        limit=limit,
    ) if execution_id else []
    
    return {
        "success": True,
        "evidence": [ev.to_dict() for ev in evidence_list],
        "count": len(evidence_list),
    }


@router.get("/plans")
async def get_plans():
    """è·å–å·¥ä½œè®¡åˆ’åˆ—è¡¨"""
    plans = task_planning.plans
    return {"plans": plans, "total": len(plans)}


@router.get("/plans/{plan_id}")
async def get_plan(plan_id: int):
    """è·å–å·¥ä½œè®¡åˆ’è¯¦æƒ…"""
    plan = next((p for p in task_planning.plans if p["id"] == plan_id), None)
    if plan:
        return {"success": True, "plan": plan}
    else:
        raise HTTPException(status_code=404, detail="è®¡åˆ’ä¸å­˜åœ¨")


@router.post("/plans/{plan_id}/confirm")
async def confirm_plan(
    plan_id: int,
    request: Dict[str, Any] = Body(...)
):
    """ç¡®è®¤å·¥ä½œè®¡åˆ’â­å¢å¼ºç‰ˆ"""
    confirmed = request.get("confirmed", False)
    adjustments = request.get("adjustments", {})  # ç”¨æˆ·è°ƒæ•´
    
    plan = next((p for p in task_planning.plans if p["id"] == plan_id), None)
    if not plan:
        raise HTTPException(status_code=404, detail="è®¡åˆ’ä¸å­˜åœ¨")
    
    if confirmed:
        plan["status"] = "confirmed"
        plan["confirmed_at"] = datetime.now().isoformat()
        plan["needs_confirmation"] = False
        
        # åº”ç”¨ç”¨æˆ·è°ƒæ•´
        if adjustments:
            # è°ƒæ•´ä»»åŠ¡é¡ºåº
            if "task_order" in adjustments:
                task_order = adjustments["task_order"]
                plan["tasks"] = [t for _, t in sorted(zip(task_order, plan["tasks"]), key=lambda x: x[0])]
            
            # è°ƒæ•´ä»»åŠ¡ä¼˜å…ˆçº§
            if "task_priorities" in adjustments:
                for task_id, priority in adjustments["task_priorities"].items():
                    task = next((t for t in plan["tasks"] if t["id"] == task_id), None)
                    if task:
                        task["priority"] = priority
            
            # é‡æ–°è®¡ç®—è®¡åˆ’
            plan["total_duration_minutes"] = sum(t.get("estimated_duration", 0) for t in plan["tasks"])
            plan["estimated_completion_time"] = task_planning._estimate_completion_time(plan["tasks"])
    else:
        plan["status"] = "rejected"
        plan["rejected_at"] = datetime.now().isoformat()
        plan["rejection_reason"] = request.get("reason", "ç”¨æˆ·æ‹’ç»")
    
    return {"success": True, "plan": plan}


@router.post("/plans/{plan_id}/execute")
async def execute_plan(plan_id: int, concurrency: int = 2):
    """æ‰§è¡Œå·¥ä½œè®¡åˆ’ï¼ˆå¹¶å‘+ä¾èµ–å¤„ç†+ç®€å•é‡è¯•ï¼‰"""
    plan = next((p for p in task_planning.plans if p["id"] == plan_id), None)
    if not plan:
        raise HTTPException(status_code=404, detail="è®¡åˆ’ä¸å­˜åœ¨")
    # è‹¥æœªç¡®è®¤åˆ™è‡ªåŠ¨ç¡®è®¤å¹¶å°†pendingä»»åŠ¡ç½®ä¸ºconfirmed
    if plan.get("status") != "confirmed":
        plan["status"] = "confirmed"
        plan["confirmed_at"] = datetime.now().isoformat()
        for t in plan["tasks"]:
            if t.get("status") == "pending":
                t["status"] = "confirmed"
    # è®¡åˆ’å†…ä»»åŠ¡IDé›†åˆ
    plan_task_ids = [t["id"] for t in plan["tasks"]]
    id_to_task = {t["id"]: t for t in task_planning.tasks if t["id"] in plan_task_ids}
    # å¹¶å‘è°ƒåº¦
    import asyncio
    sem = asyncio.Semaphore(max(1, min(10, concurrency)))
    completed = set([tid for tid, t in id_to_task.items() if t.get("status") == "completed"])
    failed: Dict[int, str] = {}
    results: List[Dict[str, Any]] = []
    in_progress: set[int] = set()

    async def can_run(tid: int) -> bool:
        t = id_to_task.get(tid) or {}
        deps = t.get("dependencies") or []
        return all((dep in completed) for dep in deps)

    async def run_one(tid: int):
        async with sem:
            t = id_to_task.get(tid) or {}
            max_retries = int(t.get("retries", 0) or 0)
            backoff = float(t.get("retry_backoff_sec", 0.0) or 0.0)
            attempt = 0
            while True:
                res = await task_planning.execute_task(tid)
                results.append(res)
                if res.get("success"):
                    completed.add(tid)
                    break
                else:
                    if attempt < max_retries:
                        attempt += 1
                        if backoff > 0:
                            await asyncio.sleep(backoff * attempt)
                        continue
                    failed[tid] = res.get("error", "unknown")
                    break

    remaining = set(plan_task_ids) - completed
    while remaining:
        ready = [tid for tid in remaining if tid not in in_progress]
        # è¿‡æ»¤ä¾èµ–æœªæ»¡è¶³çš„
        ready = [tid for tid in ready if (await can_run(tid))]
        if not ready and not in_progress:
            break  # é˜»å¡
        # å¯åŠ¨
        import itertools
        slots = max(0, max(1, min(concurrency, 10)) - len(in_progress))
        for tid in itertools.islice(ready, 0, slots):
            in_progress.add(tid)
            asyncio.create_task(run_one(tid))
        await asyncio.sleep(0.2)
        # æ¸…ç†å·²å®Œæˆ/å¤±è´¥
        in_progress = {tid for tid in in_progress if tid not in completed and tid not in failed}
        remaining = remaining - completed - set(failed.keys())

    return {
        "success": True if not failed else False,
        "plan_id": plan_id,
        "completed_count": len(completed),
        "failed": failed,
        "results": results
    }


@router.get("/resource/status")
async def get_resource_status():
    """è·å–èµ„æºçŠ¶æ€"""
    status = resource_monitor.get_current_status()
    alerts = resource_monitor.get_alerts()
    return {
        "status": status,
        "alerts": alerts,
        "alerts_count": len(alerts)
    }


@router.get("/resource/trends")
async def get_resource_trends(hours: int = 1):
    """è·å–èµ„æºè¶‹åŠ¿"""
    trends = resource_monitor.get_resource_trends(hours)
    return trends


@router.get("/learning/statistics")
async def get_learning_statistics():
    """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
    stats = learning_monitor.get_statistics()
    return stats


@router.get("/learning/recommendations")
async def get_learning_recommendations():
    """è·å–æœ€æ–°äº¤äº’å»ºè®®ä¸èµ„æºä¿¡å·"""
    stats = learning_monitor.get_statistics()
    return {
        "success": True,
        "recommendations": stats.get("interaction_recommendations", []),
        "resource_signals": stats.get("resource_signals", []),
        "alert_level": stats.get("alert_level", "low"),
    }


@router.post("/learning/recommendations/{rec_id}/apply")
async def apply_learning_recommendation(rec_id: str, request: Optional[LearningRecommendationApplyRequest] = Body(None)):
    """æ‰§è¡Œäº¤äº’å»ºè®®"""
    recommendation = learning_monitor.get_recommendation(rec_id)
    if not recommendation:
        stats = learning_monitor.get_statistics()
        recommendation = learning_monitor.get_recommendation(rec_id)
    if not recommendation:
        raise HTTPException(status_code=404, detail="æ¨èä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ")

    overrides = (request.overrides if request else None) or {}
    action_type = recommendation.get("action_type")
    result_payload: Dict[str, Any] = {}

    if action_type == "resource_authorization":
        payload = {**(recommendation.get("payload") or {}), **overrides}
        suggestion = LearningResourceSuggestion(
            description=payload.get("description", recommendation.get("description", "Learning recommendation")),
            action_type=payload.get("action_type", "optimize"),
            risk_level=payload.get("risk_level", "medium"),
            expected_improvement=payload.get("expected_improvement"),
            requires_approval=payload.get("requires_approval", True),
            rollback_plan=payload.get("rollback_plan"),
            severity=recommendation.get("severity", "medium"),
        )
        authorization_request = await resource_authorization_manager.request_authorization(
            suggestion=suggestion,
            requested_by="learning_monitor",
            reason=recommendation.get("description")
        )
        result_payload = {
            "type": "resource_authorization",
            "suggestion_id": authorization_request.suggestion_id
        }
    elif action_type == "interaction":
        result_payload = {
            "type": "interaction",
            "instruction": (recommendation.get("payload") or {}).get("instruction"),
            "module": (recommendation.get("payload") or {}).get("module")
        }
    else:
        result_payload = {
            "type": action_type or "info",
            "message": recommendation.get("description", "å·²è®°å½•æ¨è")
        }

    learning_monitor.mark_recommendation_applied(rec_id)
    return {"success": True, "result": result_payload}


@router.post("/voice/recognize")
async def recognize_voice(
    audio_data: Optional[UploadFile] = File(None),
    audio_text: Optional[str] = None,
    language: Optional[str] = None
):
    """è¯­éŸ³è¯†åˆ«"""
    audio_bytes = None
    if audio_data:
        audio_bytes = await audio_data.read()
    
    result = await voice_interaction.recognize_speech(
        audio_data=audio_bytes,
        audio_text=audio_text,
        language=language
    )
    return result


@router.post("/voice/synthesize")
async def synthesize_voice(
    text: str,
    language: Optional[str] = None,
    voice: Optional[str] = None,
    speed: float = 1.0,
    pitch: float = 1.0
):
    """è¯­éŸ³åˆæˆï¼ˆTTSï¼‰"""
    result = await voice_interaction.synthesize_speech(
        text=text,
        language=language,
        voice=voice,
        speed=speed,
        pitch=pitch
    )
    return result


@router.get("/voice/languages")
async def get_voice_languages():
    """è·å–æ”¯æŒçš„è¯­éŸ³è¯­è¨€åˆ—è¡¨"""
    languages = voice_interaction.get_supported_languages()
    return {"languages": languages, "current": voice_interaction.current_language}


@router.post("/translate")
async def translate(
    text: str,
    target_lang: str = "zh",
    source_lang: Optional[str] = None
):
    """ç¿»è¯‘æ–‡æœ¬ï¼ˆæ”¯æŒ60ç§è¯­è¨€ï¼‰"""
    result = await translation_service.translate(text, target_lang, source_lang)
    return result


@router.post("/translate/batch")
async def batch_translate(
    texts: List[str],
    target_lang: str = "zh",
    source_lang: Optional[str] = None
):
    """æ‰¹é‡ç¿»è¯‘"""
    results = await translation_service.batch_translate(texts, target_lang, source_lang)
    return {"results": results, "count": len(results)}


@router.post("/translate/detect")
async def detect_language(text: str):
    """æ£€æµ‹è¯­è¨€"""
    lang = await translation_service.detect_language(text)
    return {"language": lang, "is_supported": translation_service.is_supported(lang)}


@router.get("/translate/languages")
async def get_translation_languages():
    """è·å–æ”¯æŒçš„ç¿»è¯‘è¯­è¨€åˆ—è¡¨ï¼ˆ60ç§ï¼‰"""
    languages = translation_service.get_supported_languages()
    return {
        "languages": languages,
        "count": len(languages),
        "default_target": translation_service.default_target
    }


@router.post("/search")
async def search(
    query: str,
    engine: Optional[str] = None,
    search_type: str = "web",
    max_results: int = 10
):
    """ç½‘ç»œæœç´¢ï¼ˆä¸èŠå¤©æ¡†åˆå¹¶ï¼‰"""
    result = await web_search.search(query, engine, search_type, max_results)
    return result


@router.post("/search/multi")
async def multi_search(
    query: str,
    engines: Optional[List[str]] = None,
    search_type: str = "web",
    max_results_per_engine: int = 5
):
    """å¤šå¼•æ“æœç´¢å¹¶æ•´åˆç»“æœ"""
    result = await web_search.multi_search(
        query, engines, search_type, max_results_per_engine
    )
    return result


@router.get("/search/engines")
async def get_search_engines():
    """è·å–å¯ç”¨çš„æœç´¢å¼•æ“åˆ—è¡¨"""
    engines = {
        name: {
            "enabled": config["enabled"],
            "has_api_key": config.get("api_key") is not None,
            "supports": config.get("supports", ["web"])
        }
        for name, config in web_search.search_engines.items()
    }
    return {
        "engines": engines,
        "default": web_search.default_engine
    }


@router.post("/generate/file")
async def generate_file(
    file_type: str,  # word, excel, ppt, pdf, image
    content: str,
    template: Optional[str] = None,
    title: Optional[str] = None,
    output_path: Optional[str] = None,
    save_to_rag: bool = True  # æ˜¯å¦è‡ªåŠ¨ä¿å­˜åˆ°RAG
):
    """
    ç”Ÿæˆæ–‡ä»¶ï¼ˆWord/Excel/PPT/PDFï¼‰â­å¢å¼ºç‰ˆ
    
    åŠŸèƒ½ï¼š
    1. æ”¯æŒDOCX/XLSX/PPTX/PDFæ ¼å¼
    2. è‡ªåŠ¨ä¿å­˜åˆ°RAGçŸ¥è¯†åº“ï¼ˆå¯é€‰ï¼‰
    3. è¿”å›base64ç¼–ç çš„æ–‡ä»¶æ•°æ®
    """
    if file_type == "word":
        result = await file_generation.generate_word(content, template, output_path, title)
    elif file_type == "excel":
        # è§£æcontentä¸ºæ•°æ®æ ¼å¼ï¼ˆJSONæ ¼å¼ï¼š{"headers": [...], "data": [[...]]}ï¼‰
        try:
            import json
            content_data = json.loads(content)
            headers = content_data.get("headers")
            data = content_data.get("data", [])
            result = await file_generation.generate_excel(
                data, headers, output_path, content_data.get("sheet_name", "Sheet1")
            )
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"Excelå†…å®¹æ ¼å¼é”™è¯¯ï¼Œéœ€è¦JSONæ ¼å¼ï¼š{{\"headers\": [...], \"data\": [[...]]}}ã€‚é”™è¯¯: {str(e)}")
    elif file_type == "ppt":
        # è§£æcontentä¸ºå¹»ç¯ç‰‡æ ¼å¼
        try:
            import json
            slides_data = json.loads(content)
            slides = slides_data.get("slides", [])
            result = await file_generation.generate_ppt(slides, template, output_path)
        except Exception as e:
            raise HTTPException(status_code=400, detail=f"PPTå†…å®¹æ ¼å¼é”™è¯¯: {str(e)}")
    elif file_type == "pdf":
        result = await file_generation.generate_pdf(content, template, output_path, title)
    elif file_type == "image":
        result = await file_generation.generate_image(content)
    else:
        raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_type}")
    
    if result.get("success"):
        # è¿”å›base64ç¼–ç çš„æ–‡ä»¶æ•°æ®
        file_data = result.get("file_data", b"")
        if isinstance(file_data, bytes):
            import base64
            result["file_data_base64"] = base64.b64encode(file_data).decode('utf-8')
        
        # å¦‚æœè®¾ç½®äº†ä¸ä¿å­˜åˆ°RAGï¼Œç§»é™¤RAGç›¸å…³è­¦å‘Š
        if not save_to_rag and "rag_save_warning" in result:
            del result["rag_save_warning"]
        
        return result
    else:
        raise HTTPException(status_code=500, detail=result.get("error", "æ–‡ä»¶ç”Ÿæˆå¤±è´¥"))


@router.post("/content/export")
async def export_content_to_file(
    content_id: Optional[str] = None,
    content_data: Optional[Dict[str, Any]] = Body(None),
    file_type: str = "docx",
    output_path: Optional[str] = None
):
    """
    ä»å†…å®¹åˆ›ä½œæ¨¡å—å¯¼å‡ºå†…å®¹ä¸ºæ–‡ä»¶â­æ–°å¢
    
    åŠŸèƒ½ï¼š
    1. æ”¯æŒä»å†…å®¹æ¨¡å—å¯¼å‡ºä¸ºDOCX/XLSX/PPTX/PDF
    2. å¦‚æœæä¾›äº†content_idï¼Œä»å†…å®¹æ¨¡å—è·å–å†…å®¹
    3. å¦‚æœæä¾›äº†content_dataï¼Œç›´æ¥ä½¿ç”¨
    4. è‡ªåŠ¨ä¿å­˜åˆ°RAGçŸ¥è¯†åº“
    """
    try:
        # å¦‚æœæä¾›äº†content_idï¼Œä»å†…å®¹æ¨¡å—è·å–
        if content_id:
            import requests
            try:
                # è°ƒç”¨å†…å®¹æ¨¡å—APIè·å–å†…å®¹
                response = requests.get(
                    f"http://localhost:8004/api/content/{content_id}",
                    timeout=10
                )
                if response.status_code == 200:
                    content_data = response.json().get("content", {})
                else:
                    raise HTTPException(status_code=404, detail=f"å†…å®¹ID {content_id} ä¸å­˜åœ¨")
            except Exception as e:
                raise HTTPException(status_code=500, detail=f"è·å–å†…å®¹å¤±è´¥: {str(e)}")
        
        # å¦‚æœæ²¡æœ‰å†…å®¹æ•°æ®ï¼Œè¿”å›é”™è¯¯
        if not content_data:
            raise HTTPException(status_code=400, detail="éœ€è¦æä¾›content_idæˆ–content_data")
        
        # å¯¼å‡ºä¸ºæ–‡ä»¶
        result = await file_generation.export_content_to_file(
            content_data=content_data,
            file_type=file_type,
            output_path=output_path
        )
        
        if result.get("success"):
            # è¿”å›base64ç¼–ç çš„æ–‡ä»¶æ•°æ®
            file_data = result.get("file_data", b"")
            if isinstance(file_data, bytes):
                import base64
                result["file_data_base64"] = base64.b64encode(file_data).decode('utf-8')
            return result
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "æ–‡ä»¶å¯¼å‡ºå¤±è´¥"))
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºå¤±è´¥: {str(e)}")


@router.post("/terminal/execute")
async def execute_terminal_command(
    command: str = Body(..., embed=True),
    timeout: int = Body(30, embed=True),
    cwd: Optional[str] = Body(None, embed=True)
):
    """æ‰§è¡Œç»ˆç«¯å‘½ä»¤"""
    result = await terminal_executor.execute_command(
        command=command,
        timeout=timeout,
        cwd=cwd
    )
    return result


@router.get("/terminal/history")
async def get_terminal_history(limit: int = 20):
    """è·å–ç»ˆç«¯å‘½ä»¤å†å²"""
    history = terminal_executor.get_command_history(limit=limit)
    return {"history": history}


@router.get("/terminal/system-info")
async def get_terminal_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    info = terminal_executor.get_system_info()
    return info


@router.post("/terminal/cd")
async def change_terminal_directory(path: str = Body(..., embed=True)):
    """åˆ‡æ¢ç»ˆç«¯å·¥ä½œç›®å½•"""
    result = terminal_executor.change_directory(path)
    return result


@router.get("/terminal/whitelist")
async def get_terminal_whitelist():
    """è·å–ç»ˆç«¯å‘½ä»¤ç™½åå•é…ç½®"""
    whitelist = terminal_executor.get_whitelist()
    return {
        "success": True,
        **whitelist
    }


@router.post("/terminal/whitelist/update")
async def update_terminal_whitelist(
    add_commands: Optional[List[str]] = Body(None, embed=True),
    remove_commands: Optional[List[str]] = Body(None, embed=True)
):
    """
    æ›´æ–°ç»ˆç«¯å‘½ä»¤ç™½åå•
    
    Args:
        add_commands: è¦æ·»åŠ çš„å‘½ä»¤åˆ—è¡¨
        remove_commands: è¦ç§»é™¤çš„å‘½ä»¤åˆ—è¡¨
    """
    result = terminal_executor.update_whitelist(
        add_commands=add_commands,
        remove_commands=remove_commands
    )
    return result


@router.post("/terminal/sandbox/clear")
async def clear_terminal_sandbox():
    """æ¸…ç†ç»ˆç«¯æ²™ç®±ç›®å½•"""
    result = terminal_executor.clear_sandbox()
    return result


@router.get("/terminal/audit/logs")
async def get_terminal_audit_logs(
    start_time: Optional[str] = None,
    end_time: Optional[str] = None,
    event_type: Optional[str] = None,
    severity: Optional[str] = None,
    command_id: Optional[str] = None,
    user_id: Optional[str] = None,
    success: Optional[bool] = None,
    limit: int = 100
):
    """
    æŸ¥è¯¢ç»ˆç«¯å®¡è®¡æ—¥å¿—
    
    Args:
        start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        event_type: äº‹ä»¶ç±»å‹
        severity: ä¸¥é‡ç¨‹åº¦
        command_id: å‘½ä»¤ID
        user_id: ç”¨æˆ·ID
        success: æ˜¯å¦æˆåŠŸ
        limit: è¿”å›æ•°é‡é™åˆ¶
    """
    logs = terminal_audit_logger.query_logs(
        start_time=start_time,
        end_time=end_time,
        event_type=event_type,
        severity=severity,
        command_id=command_id,
        user_id=user_id,
        success=success,
        limit=limit
    )
    return {
        "success": True,
        "logs": logs,
        "count": len(logs)
    }


@router.get("/terminal/audit/statistics")
async def get_terminal_audit_statistics(
    start_time: Optional[str] = None,
    end_time: Optional[str] = None
):
    """
    è·å–ç»ˆç«¯å®¡è®¡æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
    """
    stats = terminal_audit_logger.get_statistics(
        start_time=start_time,
        end_time=end_time
    )
    return {
        "success": True,
        **stats
    }


@router.post("/terminal/audit/export")
async def export_terminal_audit_logs(
    output_path: str = Body(..., embed=True),
    start_time: Optional[str] = Body(None, embed=True),
    end_time: Optional[str] = Body(None, embed=True),
    format: str = Body("json", embed=True)
):
    """
    å¯¼å‡ºç»ˆç«¯å®¡è®¡æ—¥å¿—
    
    Args:
        output_path: è¾“å‡ºè·¯å¾„
        start_time: å¼€å§‹æ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        end_time: ç»“æŸæ—¶é—´ï¼ˆISOæ ¼å¼ï¼‰
        format: å¯¼å‡ºæ ¼å¼ï¼ˆjson/csvï¼‰
    """
    result = terminal_audit_logger.export_logs(
        output_path=output_path,
        start_time=start_time,
        end_time=end_time,
        format=format
    )
    return result


@router.get("/workflow/system-events")
async def get_system_events(limit: int = 20, event_type: Optional[str] = None):
    """è·å–ç³»ç»Ÿçº§äº‹ä»¶ï¼ˆå¦‚ç»ˆç«¯å‘½ä»¤ã€å®‰å…¨æ—¥å¿—ï¼‰"""
    events: List[Dict[str, Any]] = []
    summary: Dict[str, Any] = {}

    if audit_pipeline:
        pipeline_events = audit_pipeline.query_records(event_type=event_type, limit=limit)
        events = [
            {
                **record,
                "success": record.get("status") != "failed",
                "data": record.get("metadata"),
            }
            for record in pipeline_events
        ]
        stats = audit_pipeline.get_statistics()
        summary = {
            "total": stats.get("total"),
            "distribution": stats.get("distribution_by_type"),
        }

    if not events:
        monitor = super_agent.workflow_monitor
        if monitor:
            events = monitor.get_recent_system_events(limit=limit, event_type=event_type)
            summary = monitor.get_system_event_summary(event_type=event_type)

    return {"events": events, "count": len(events), "summary": summary}


@router.post("/workflow/system-events")
async def create_system_event(request: SystemEventRequest):
    """å¤–éƒ¨æœåŠ¡å†™å…¥ç³»ç»Ÿäº‹ä»¶"""
    if not super_agent.workflow_monitor:
        raise HTTPException(status_code=503, detail="Workflow monitor unavailable")
    event = await super_agent.workflow_monitor.record_system_event(
        event_type=request.event_type,
        source=request.source,
        severity=request.severity,
        success=request.success,
        data=request.data,
        error=request.error,
    )
    return {"success": True, "event": event}


@router.get("/learning/events")
async def get_learning_events(limit: int = 50, event_type: Optional[str] = None):
    """è·å–å­¦ä¹ äº‹ä»¶æ€»çº¿ä¸­çš„äº‹ä»¶"""
    bus = super_agent.event_bus
    try:
        event_type_enum = LearningEventType(event_type) if event_type else None
    except ValueError:
        raise HTTPException(status_code=400, detail=f"æœªçŸ¥çš„äº‹ä»¶ç±»å‹: {event_type}")
    events = [
        event.__dict__
        for event in bus.get_recent_events(limit=limit, event_type=event_type_enum)
    ]
    return {"events": events, "count": len(events), "stats": bus.get_statistics()}


@router.post("/learning/events")
async def publish_learning_event(request: LearningEventRequest):
    """å¤–éƒ¨æœåŠ¡å‘å­¦ä¹ äº‹ä»¶æ€»çº¿æ¨é€äº‹ä»¶"""
    try:
        event_type = LearningEventType(request.event_type)
    except ValueError:
        event_type = LearningEventType.CUSTOM
    event = await super_agent.event_bus.publish_event(
        event_type=event_type,
        source=request.source,
        severity=request.severity,
        payload=request.payload,
    )
    return {"success": True, "event": event.__dict__}


# ============ P0-013: å·¥ä½œæµå› æœåˆ†æ/ç­–ç•¥ä¼˜åŒ–/äº¤äº’å»ºè®® ============

@router.get("/workflow/causal-analysis/report")
async def get_causal_analysis_report(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
):
    """
    è·å–å·¥ä½œæµå› æœåˆ†ææŠ¥å‘Š
    
    Args:
        start_date: å¼€å§‹æ—¥æœŸï¼ˆISOæ ¼å¼ï¼Œå¯é€‰ï¼‰
        end_date: ç»“æŸæ—¥æœŸï¼ˆISOæ ¼å¼ï¼Œå¯é€‰ï¼‰
    """
    if not workflow_causal_analyzer:
        raise HTTPException(status_code=503, detail="å› æœåˆ†æå™¨æœªåˆå§‹åŒ–")
    report = workflow_causal_analyzer.get_causal_analysis_report(start_date, end_date)
    return {"success": True, "report": report}


@router.get("/workflow/causal-analysis/chains")
async def get_causal_chains(limit: int = 20):
    """è·å–æœ€è¿‘çš„å› æœé“¾åˆ†æ"""
    if not workflow_causal_analyzer:
        raise HTTPException(status_code=503, detail="å› æœåˆ†æå™¨æœªåˆå§‹åŒ–")
    chains = workflow_causal_analyzer.causal_chains[-limit:]
    return {"success": True, "chains": chains, "total": len(workflow_causal_analyzer.causal_chains)}


@router.get("/workflow/optimization-strategies")
async def get_optimization_strategies(limit: int = 20):
    """è·å–ä¼˜åŒ–ç­–ç•¥åˆ—è¡¨"""
    if not workflow_causal_analyzer:
        raise HTTPException(status_code=503, detail="å› æœåˆ†æå™¨æœªåˆå§‹åŒ–")
    strategies = workflow_causal_analyzer.optimization_strategies[-limit:]
    return {"success": True, "strategies": strategies, "total": len(workflow_causal_analyzer.optimization_strategies)}


@router.post("/workflow/optimization-strategies/generate")
async def generate_optimization_strategy(chain_id: int):
    """
    ä¸ºæŒ‡å®šå› æœé“¾ç”Ÿæˆä¼˜åŒ–ç­–ç•¥
    
    Args:
        chain_id: å› æœé“¾IDï¼ˆç´¢å¼•ï¼‰
    """
    if not workflow_causal_analyzer:
        raise HTTPException(status_code=503, detail="å› æœåˆ†æå™¨æœªåˆå§‹åŒ–")
    if chain_id < 0 or chain_id >= len(workflow_causal_analyzer.causal_chains):
        raise HTTPException(status_code=404, detail="å› æœé“¾ä¸å­˜åœ¨")
    causal_chain = workflow_causal_analyzer.causal_chains[chain_id]
    strategy = await workflow_causal_analyzer.generate_optimization_strategy(causal_chain)
    return {"success": True, "strategy": strategy}


@router.get("/workflow/interaction-suggestions")
async def get_interaction_suggestions(limit: int = 20):
    """è·å–äº¤äº’å»ºè®®æ‘˜è¦"""
    if not workflow_causal_analyzer:
        raise HTTPException(status_code=503, detail="å› æœåˆ†æå™¨æœªåˆå§‹åŒ–")
    summary = workflow_causal_analyzer.get_interaction_suggestions_summary(limit)
    return {"success": True, "summary": summary}


@router.post("/workflow/interaction-suggestions/generate")
async def generate_interaction_suggestions(
    workflow_id: Optional[str] = None,
    user_context: Optional[Dict[str, Any]] = None
):
    """
    ä¸ºæŒ‡å®šå·¥ä½œæµç”Ÿæˆäº¤äº’å»ºè®®
    
    Args:
        workflow_id: å·¥ä½œæµIDï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä½¿ç”¨æœ€è¿‘çš„å·¥ä½œæµï¼‰
        user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
    """
    if not workflow_causal_analyzer:
        raise HTTPException(status_code=503, detail="å› æœåˆ†æå™¨æœªåˆå§‹åŒ–")
    
    # æŸ¥æ‰¾å·¥ä½œæµè¿½è¸ª
    if workflow_id:
        trace = next(
            (t for t in workflow_causal_analyzer.workflow_traces if t.get("workflow_id") == workflow_id),
            None
        )
        if not trace:
            raise HTTPException(status_code=404, detail="å·¥ä½œæµè¿½è¸ªä¸å­˜åœ¨")
    else:
        # ä½¿ç”¨æœ€è¿‘çš„å·¥ä½œæµè¿½è¸ª
        if not workflow_causal_analyzer.workflow_traces:
            raise HTTPException(status_code=404, detail="æ²¡æœ‰å¯ç”¨çš„å·¥ä½œæµè¿½è¸ª")
        trace = workflow_causal_analyzer.workflow_traces[-1]
    
    suggestions = await workflow_causal_analyzer.generate_interaction_suggestions(trace, user_context)
    return {"success": True, "suggestions": suggestions, "workflow_id": trace.get("workflow_id")}


# ============ P0-014: èµ„æºè¯Šæ–­ä¸è°ƒåº¦å»ºè®® + æˆæƒæ‰§è¡Œ ============

@router.post("/resources/diagnostic/run")
async def run_resource_diagnostic(
    resource_data: Optional[Dict[str, Any]] = None
):
    """
    è¿è¡Œèµ„æºè¯Šæ–­
    
    Args:
        resource_data: èµ„æºæ•°æ®ï¼ˆå¯é€‰ï¼Œä¸æä¾›åˆ™ä»monitorè·å–ï¼‰
    """
    if not resource_diagnostic_engine:
        raise HTTPException(status_code=503, detail="èµ„æºè¯Šæ–­å¼•æ“æœªåˆå§‹åŒ–")
    
    diagnostics = await resource_diagnostic_engine.run_diagnostic(resource_data)
    
    # è‡ªåŠ¨ç”Ÿæˆè°ƒåº¦å»ºè®®
    suggestions = await resource_diagnostic_engine.generate_scheduling_suggestions(diagnostics)
    
    return {
        "success": True,
        "diagnostics": [
            {
                "category": d.category.value,
                "severity": d.severity.value,
                "title": d.title,
                "description": d.description,
                "current_value": d.current_value,
                "threshold": d.threshold,
                "affected_modules": d.affected_modules,
                "root_cause": d.root_cause,
                "impact": d.impact,
                "detected_at": d.detected_at.isoformat()
            }
            for d in diagnostics
        ],
        "suggestions": [
            {
                "action_type": s.action_type,
                "description": s.description,
                "expected_improvement": s.expected_improvement,
                "risk_level": s.risk_level,
                "requires_approval": s.requires_approval,
                "estimated_impact": s.estimated_impact,
                "implementation_steps": s.implementation_steps
            }
            for s in suggestions
        ],
        "diagnostics_count": len(diagnostics),
        "suggestions_count": len(suggestions)
    }


@router.get("/resources/diagnostic/summary")
async def get_resource_diagnostic_summary(hours: int = 24):
    """è·å–èµ„æºè¯Šæ–­æ‘˜è¦"""
    if not resource_diagnostic_engine:
        raise HTTPException(status_code=503, detail="èµ„æºè¯Šæ–­å¼•æ“æœªåˆå§‹åŒ–")
    
    summary = resource_diagnostic_engine.get_diagnostic_summary(hours)
    return {"success": True, "summary": summary}


@router.get("/resources/suggestions")
async def get_resource_suggestions(limit: int = 20):
    """è·å–èµ„æºè°ƒåº¦å»ºè®®"""
    if not resource_diagnostic_engine:
        raise HTTPException(status_code=503, detail="èµ„æºè¯Šæ–­å¼•æ“æœªåˆå§‹åŒ–")
    
    suggestions = resource_diagnostic_engine.suggestions[-limit:]
    return {
        "success": True,
        "suggestions": [
            {
                "action_type": s.action_type,
                "description": s.description,
                "expected_improvement": s.expected_improvement,
                "risk_level": s.risk_level,
                "requires_approval": s.requires_approval,
                "estimated_impact": s.estimated_impact
            }
            for s in suggestions
        ],
        "total": len(resource_diagnostic_engine.suggestions)
    }


@router.post("/resources/authorization/request")
async def request_resource_authorization(
    suggestion_index: int,
    requested_by: str = "user",
    reason: Optional[str] = None
):
    """
    è¯·æ±‚èµ„æºæ“ä½œæˆæƒ
    
    Args:
        suggestion_index: å»ºè®®ç´¢å¼•ï¼ˆåœ¨suggestionsåˆ—è¡¨ä¸­çš„ä½ç½®ï¼‰
        requested_by: è¯·æ±‚è€…
        reason: è¯·æ±‚åŸå› 
    """
    if not resource_authorization_manager or not resource_diagnostic_engine:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    suggestions = resource_diagnostic_engine.suggestions
    if suggestion_index < 0 or suggestion_index >= len(suggestions):
        raise HTTPException(status_code=404, detail="å»ºè®®ä¸å­˜åœ¨")
    
    suggestion = suggestions[suggestion_index]
    request = await resource_authorization_manager.request_authorization(
        suggestion=suggestion,
        requested_by=requested_by,
        reason=reason
    )
    
    return {
        "success": True,
        "request": {
            "suggestion_id": request.suggestion_id,
            "action_type": suggestion.action_type,
            "description": suggestion.description,
            "requested_at": request.requested_at.isoformat(),
            "requested_by": request.requested_by
        }
    }


@router.post("/resources/authorization/approve")
async def approve_resource_authorization(
    suggestion_id: str,
    approved_by: str = "user",
    metadata: Optional[Dict[str, Any]] = None
):
    """
    æ‰¹å‡†èµ„æºæ“ä½œæˆæƒ
    
    Args:
        suggestion_id: å»ºè®®ID
        approved_by: æ‰¹å‡†è€…
        metadata: é¢å¤–å…ƒæ•°æ®
    """
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    try:
        record = await resource_authorization_manager.approve_authorization(
            suggestion_id=suggestion_id,
            approved_by=approved_by,
            metadata=metadata
        )
        
        return {
            "success": True,
            "record": {
                "suggestion_id": record.request.suggestion_id,
                "status": record.status.value,
                "approved_at": record.approved_at.isoformat() if record.approved_at else None,
                "approved_by": record.approved_by,
                "execution_result": record.execution_result
            }
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.post("/resources/authorization/reject")
async def reject_resource_authorization(
    suggestion_id: str,
    rejected_by: str = "user",
    reason: Optional[str] = None
):
    """
    æ‹’ç»èµ„æºæ“ä½œæˆæƒ
    
    Args:
        suggestion_id: å»ºè®®ID
        rejected_by: æ‹’ç»è€…
        reason: æ‹’ç»åŸå› 
    """
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    try:
        record = await resource_authorization_manager.reject_authorization(
            suggestion_id=suggestion_id,
            rejected_by=rejected_by,
            reason=reason
        )
        
        return {
            "success": True,
            "record": {
                "suggestion_id": record.request.suggestion_id,
                "status": record.status.value,
                "metadata": record.metadata
            }
        }
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get("/resources/authorization/pending")
async def get_pending_authorizations():
    """è·å–å¾…å¤„ç†çš„æˆæƒè¯·æ±‚"""
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    pending = resource_authorization_manager.get_pending_authorizations()
    return {"success": True, "pending": pending, "count": len(pending)}


@router.get("/resources/authorization/history")
async def get_authorization_history(
    limit: int = 50,
    status: Optional[str] = None
):
    """
    è·å–æˆæƒå†å²
    
    Args:
        limit: è¿”å›æ•°é‡é™åˆ¶
        status: çŠ¶æ€ç­›é€‰ï¼ˆå¯é€‰ï¼‰
    """
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    from core.resource_authorization import AuthorizationStatus
    
    status_enum = None
    if status:
        try:
            status_enum = AuthorizationStatus(status)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„çŠ¶æ€: {status}")
    
    history = resource_authorization_manager.get_authorization_history(
        limit=limit,
        status=status_enum
    )
    
    return {"success": True, "history": history, "count": len(history)}


@router.get("/resources/authorization/statistics")
async def get_authorization_statistics():
    """è·å–æˆæƒç»Ÿè®¡ä¿¡æ¯"""
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    stats = resource_authorization_manager.get_statistics()
    return {"success": True, "statistics": stats}


@router.get("/resources/executions")
async def get_resource_executions(limit: int = 20):
    """è·å–èµ„æºæ‰§è¡Œè®°å½•"""
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    records = resource_authorization_manager.get_execution_records(limit)
    return {"success": True, "executions": records, "count": len(records)}


@router.get("/resources/rollbacks")
async def get_resource_rollbacks(limit: int = 20):
    """è·å–å›æ»šè®°å½•"""
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    history = resource_authorization_manager.get_rollbacks(limit)
    return {"success": True, "rollbacks": history, "count": len(history)}


@router.post("/resources/rollback", response_model=ResourceRollbackResponse)
async def rollback_resource_action(req: ResourceRollbackRequest):
    """æ‰§è¡Œå›æ»šæ“ä½œ"""
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    try:
        entry = await resource_authorization_manager.rollback_action(
            suggestion_id=req.suggestion_id,
            requested_by="user",
            reason=req.reason
        )
        return entry
    except ValueError as exc:
        raise HTTPException(status_code=400, detail=str(exc)) from exc


@router.get("/resources/overview")
async def get_resource_overview(limit: int = 5):
    """èµ„æºå»ºè®®/æ‰§è¡Œ/å›æ»šè”åŠ¨è§†å›¾"""
    if not resource_authorization_manager:
        raise HTTPException(status_code=503, detail="èµ„æºæˆæƒç®¡ç†å™¨æœªåˆå§‹åŒ–")
    
    suggestions_payload: List[Dict[str, Any]] = []
    if resource_diagnostic_engine and getattr(resource_diagnostic_engine, "suggestions", None):
        recent = resource_diagnostic_engine.suggestions[-limit:]
        for suggestion in reversed(recent):
            suggestions_payload.append({
                "description": getattr(suggestion, "description", ""),
                "action_type": getattr(suggestion, "action_type", ""),
                "risk_level": getattr(suggestion, "risk_level", ""),
                "expected_improvement": getattr(suggestion, "expected_improvement", ""),
                "requires_approval": getattr(suggestion, "requires_approval", False),
                "rollback_plan": getattr(suggestion, "rollback_plan", None)
            })
    
    executions = resource_authorization_manager.get_execution_records(limit)
    rollbacks = resource_authorization_manager.get_rollbacks(limit)
    
    return {
        "success": True,
        "suggestions": suggestions_payload,
        "executions": executions,
        "rollbacks": rollbacks
    }


@router.get("/resources/task-impacts")
async def list_task_impacts(limit: int = 10):
    """è·å–ä»»åŠ¡æ‰§è¡Œåå¯¹èµ„æºçš„å½±å“è®°å½•"""
    impacts = resource_authorization_manager.get_task_impacts(limit=limit)
    return {"success": True, "impacts": impacts, "count": len(impacts)}


# ============ P0-015: èµ„æºç­–ç•¥å¼•æ“ä¸å†²çªè°ƒåº¦ ============

@router.post("/resources/strategy/select")
async def select_resource_strategy(
    context: Optional[str] = None,
    resource_data: Optional[Dict[str, Any]] = None
):
    """
    é€‰æ‹©èµ„æºç­–ç•¥
    
    Args:
        context: ç³»ç»Ÿä¸Šä¸‹æ–‡ï¼ˆnormal/high_load/low_load/critical/maintenanceï¼‰
        resource_data: èµ„æºæ•°æ®ï¼ˆå¯é€‰ï¼‰
    """
    if not resource_strategy_engine:
        raise HTTPException(status_code=503, detail="èµ„æºç­–ç•¥å¼•æ“æœªåˆå§‹åŒ–")
    
    context_enum = None
    if context:
        try:
            context_enum = StrategyContext(context)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ä¸Šä¸‹æ–‡: {context}")
    
    strategy = await resource_strategy_engine.select_strategy(context_enum, resource_data)
    
    return {
        "success": True,
        "strategy": strategy.value,
        "context": resource_strategy_engine.current_context.value if resource_strategy_engine.current_context else None
    }


@router.post("/resources/strategy/execute")
async def execute_resource_strategy(
    strategy: Optional[str] = None,
    target_modules: Optional[List[str]] = None
):
    """
    æ‰§è¡Œèµ„æºç­–ç•¥
    
    Args:
        strategy: ç­–ç•¥åç§°ï¼ˆå¯é€‰ï¼‰
        target_modules: ç›®æ ‡æ¨¡å—åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    """
    if not resource_strategy_engine:
        raise HTTPException(status_code=503, detail="èµ„æºç­–ç•¥å¼•æ“æœªåˆå§‹åŒ–")
    
    strategy_enum = None
    if strategy:
        try:
            strategy_enum = ResourceStrategy(strategy)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ç­–ç•¥: {strategy}")
    
    result = await resource_strategy_engine.execute_strategy(strategy_enum, target_modules)
    return {"success": True, "result": result}


@router.get("/resources/strategy/statistics")
async def get_strategy_statistics():
    """è·å–ç­–ç•¥ç»Ÿè®¡ä¿¡æ¯"""
    if not resource_strategy_engine:
        raise HTTPException(status_code=503, detail="èµ„æºç­–ç•¥å¼•æ“æœªåˆå§‹åŒ–")
    
    stats = resource_strategy_engine.get_strategy_statistics()
    return {"success": True, "statistics": stats}


@router.post("/resources/strategy/update-from-learning")
async def update_strategy_from_learning(
    learning_recommendations: Dict[str, Any]
):
    """
    ä»è‡ªå­¦ä¹ ç³»ç»Ÿæ›´æ–°ç­–ç•¥
    
    Args:
        learning_recommendations: è‡ªå­¦ä¹ ç³»ç»Ÿçš„å»ºè®®
    """
    if not resource_strategy_engine:
        raise HTTPException(status_code=503, detail="èµ„æºç­–ç•¥å¼•æ“æœªåˆå§‹åŒ–")
    
    await resource_strategy_engine.update_strategy_from_learning(learning_recommendations)
    return {"success": True, "message": "ç­–ç•¥å·²ä»è‡ªå­¦ä¹ ç³»ç»Ÿæ›´æ–°"}


@router.post("/resources/conflicts/detect")
async def detect_resource_conflicts(
    resource_data: Optional[Dict[str, Any]] = None
):
    """
    æ£€æµ‹èµ„æºå†²çª
    
    Args:
        resource_data: èµ„æºæ•°æ®ï¼ˆå¯é€‰ï¼‰
    """
    if not resource_conflict_scheduler:
        raise HTTPException(status_code=503, detail="å†²çªè°ƒåº¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    conflicts = await resource_conflict_scheduler.detect_conflicts(resource_data)
    
    return {
        "success": True,
        "conflicts": [
            {
                "conflict_id": c.conflict_id,
                "conflict_type": c.conflict_type.value,
                "conflicting_modules": c.conflicting_modules,
                "resource_type": c.resource_type,
                "conflict_severity": c.conflict_severity,
                "detected_at": c.detected_at.isoformat(),
                "root_cause": c.root_cause
            }
            for c in conflicts
        ],
        "count": len(conflicts)
    }


@router.post("/resources/conflicts/resolve")
async def resolve_resource_conflict(
    conflict_id: str,
    preferred_strategy: Optional[str] = None
):
    """
    è§£å†³èµ„æºå†²çª
    
    Args:
        conflict_id: å†²çªID
        preferred_strategy: é¦–é€‰è§£å†³ç­–ç•¥ï¼ˆå¯é€‰ï¼‰
    """
    if not resource_conflict_scheduler:
        raise HTTPException(status_code=503, detail="å†²çªè°ƒåº¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    # æŸ¥æ‰¾å†²çª
    conflict = next(
        (c for c in resource_conflict_scheduler.detected_conflicts if c.conflict_id == conflict_id),
        None
    )
    
    if not conflict:
        raise HTTPException(status_code=404, detail="å†²çªä¸å­˜åœ¨")
    
    strategy_enum = None
    if preferred_strategy:
        try:
            strategy_enum = ResolutionStrategy(preferred_strategy)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ç­–ç•¥: {preferred_strategy}")
    
    resolution = await resource_conflict_scheduler.resolve_conflict(conflict, strategy_enum)
    
    return {
        "success": True,
        "resolution": {
            "conflict_id": resolution.conflict.conflict_id,
            "resolution_strategy": resolution.resolution_strategy.value,
            "resolution_actions": resolution.resolution_actions,
            "expected_improvement": resolution.expected_improvement,
            "risk_level": resolution.risk_level,
            "requires_approval": resolution.requires_approval
        }
    }


@router.post("/resources/conflicts/execute-resolution")
async def execute_conflict_resolution(
    conflict_id: str,
    approved: bool = False
):
    """
    æ‰§è¡Œå†²çªè§£å†³æ–¹æ¡ˆ
    
    Args:
        conflict_id: å†²çªID
        approved: æ˜¯å¦å·²è·å¾—æˆæƒ
    """
    if not resource_conflict_scheduler:
        raise HTTPException(status_code=503, detail="å†²çªè°ƒåº¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    # æŸ¥æ‰¾è§£å†³æ–¹æ¡ˆ
    resolution = next(
        (r for r in resource_conflict_scheduler.resolutions if r.conflict.conflict_id == conflict_id),
        None
    )
    
    if not resolution:
        raise HTTPException(status_code=404, detail="è§£å†³æ–¹æ¡ˆä¸å­˜åœ¨")
    
    result = await resource_conflict_scheduler.execute_resolution(resolution, approved)
    return {"success": True, "result": result}


@router.get("/resources/conflicts/statistics")
async def get_conflict_statistics():
    """è·å–å†²çªç»Ÿè®¡ä¿¡æ¯"""
    if not resource_conflict_scheduler:
        raise HTTPException(status_code=503, detail="å†²çªè°ƒåº¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    stats = resource_conflict_scheduler.get_conflict_statistics()
    return {"success": True, "statistics": stats}


def _get_task_orchestrator():
    orchestrator = super_agent.task_orchestrator
    if not orchestrator:
        raise HTTPException(status_code=503, detail="ä»»åŠ¡ç¼–æ’å™¨å°šæœªåˆå§‹åŒ–")
    return orchestrator


def _get_factory_data_source():
    if factory_data_source:
        return factory_data_source
    raise HTTPException(
        status_code=503,
        detail=factory_data_source_error or "demo_factory æ•°æ®æºå°šæœªå‡†å¤‡ï¼Œè¯·å…ˆç”Ÿæˆæ•°æ®åº“",
    )

def _get_trial_data_source():
    if trial_data_source:
        return trial_data_source
    raise HTTPException(
        status_code=503,
        detail=trial_data_source_error or "trial æ•°æ®æºå°šæœªå‡†å¤‡ï¼Œè¯·å…ˆç”Ÿæˆ demo_factory æ•°æ®åº“",
    )


@router.get("/tasks")
async def list_tasks():
    orchestrator = _get_task_orchestrator()
    return {"tasks": orchestrator.list_tasks()}

class TaskMetadataUpdateRequest(BaseModel):
    updates: Dict[str, Any]

@router.post("/tasks/{task_id}/metadata")
async def update_task_metadata(task_id: str, req: TaskMetadataUpdateRequest):
    """æ›´æ–°ç¼–æ’å™¨ä»»åŠ¡çš„å…ƒæ•°æ®ï¼ˆå¯ç”¨äºè®¾ç½® steps/total_steps ç­‰ï¼‰"""
    orchestrator = _get_task_orchestrator()
    data = await orchestrator.update_task_metadata(task_id, req.updates or {})
    if not data:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {"task": data}
@router.get("/tasks/{task_id}")
async def get_task_detail(task_id: str):
    """è·å–ç¼–æ’ä»»åŠ¡è¯¦æƒ…ï¼ˆOrchestratorç®¡ç†çš„ä»»åŠ¡ï¼‰"""
    orchestrator = _get_task_orchestrator()
    data = orchestrator.get_task(task_id)
    if not data:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {"task": data}

@router.get("/planning/tasks")
async def list_planning_tasks(status: Optional[str] = None):
    """è·å–ä»»åŠ¡è§„åˆ’ç³»ç»Ÿä¸­çš„ä»»åŠ¡åˆ—è¡¨ï¼ˆéç¼–æ’å™¨ï¼‰"""
    tasks = task_planning.get_tasks(status=status)
    return {"tasks": tasks, "count": len(tasks)}

@router.get("/planning/tasks/{task_id}")
async def get_planning_task(task_id: int):
    """è·å–ä»»åŠ¡è§„åˆ’ç³»ç»Ÿä¸­çš„å•ä¸ªä»»åŠ¡"""
    tasks = task_planning.get_tasks()
    t = next((x for x in tasks if x.get("id") == task_id), None)
    if not t:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {"task": t}

@router.delete("/planning/tasks/{task_id}")
async def delete_planning_task(task_id: int):
    """åˆ é™¤ä»»åŠ¡è§„åˆ’ç³»ç»Ÿä¸­çš„ä»»åŠ¡ï¼ˆæœ€å°å¯ç”¨ï¼‰"""
    tasks = task_planning.get_tasks()
    idx = None
    for i, t in enumerate(tasks):
        if t.get("id") == task_id:
            idx = i
            break
    if idx is None:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    try:
        # ä»å†…éƒ¨åˆ—è¡¨ç§»é™¤
        del task_planning.tasks[idx]
        return {"success": True, "deleted_id": task_id}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
@router.get("/tasks/{task_id}")
async def get_task_detail(task_id: str):
    """è·å–ç¼–æ’ä»»åŠ¡è¯¦æƒ…ï¼ˆOrchestratorç®¡ç†çš„ä»»åŠ¡ï¼‰"""
    orchestrator = _get_task_orchestrator()
    data = orchestrator.get_task(task_id)
    if not data:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {"task": data}


@router.post("/tasks")
async def create_task(request: TaskCreateRequest):
    orchestrator = _get_task_orchestrator()
    task = await orchestrator.register_task(
        title=request.title,
        description=request.description or "",
        priority=request.priority,
        metadata=request.metadata,
        dependencies=request.dependencies,
        source="api",
    )
    return {"task": task}

@router.get("/tasks/summary/24h")
async def tasks_summary_24h():
    """
    ä»»åŠ¡è¿‘24å°æ—¶ç»Ÿè®¡ï¼š
    - orch: started/ completed / completion_rate ï¼ˆåŸºäºcreated_at/metadata.completed_atï¼‰
    - plan: started/ completed / completion_rate ï¼ˆåŸºäº started_at/completed_atï¼‰
    """
    now = datetime.now()
    cutoff = now - timedelta(hours=24)
    # ç¼–æ’å™¨
    orch_started = 0
    orch_completed = 0
    try:
        orchestrator = _get_task_orchestrator()
        for t in orchestrator.list_tasks():
            created_at = t.get("created_at")
            if created_at:
                try:
                    if datetime.fromisoformat(created_at) >= cutoff:
                        orch_started += 1
                except Exception:
                    pass
            comp_at = (t.get("metadata") or {}).get("completed_at")
            if comp_at:
                try:
                    if datetime.fromisoformat(comp_at) >= cutoff:
                        orch_completed += 1
                except Exception:
                    pass
    except Exception:
        pass
    orch_rate = (orch_completed / orch_started * 100) if orch_started > 0 else 0.0
    # è§„åˆ’
    plan_started = 0
    plan_completed = 0
    try:
        for t in task_planning.tasks:
            st = t.get("started_at")
            if st:
                try:
                    if datetime.fromisoformat(st) >= cutoff:
                        plan_started += 1
                except Exception:
                    pass
            ct = t.get("completed_at")
            if ct:
                try:
                    if datetime.fromisoformat(ct) >= cutoff:
                        plan_completed += 1
                except Exception:
                    pass
    except Exception:
        pass
    plan_rate = (plan_completed / plan_started * 100) if plan_started > 0 else 0.0
    return {
        "success": True,
        "cutoff": cutoff.isoformat(),
        "orch": {
            "started": orch_started,
            "completed": orch_completed,
            "completion_rate": round(orch_rate, 2)
        },
        "plan": {
            "started": plan_started,
            "completed": plan_completed,
            "completion_rate": round(plan_rate, 2)
        }
    }

@router.post("/tasks/{task_id}/status")
async def update_task_status(task_id: str, request: TaskStatusUpdateRequest):
    orchestrator = _get_task_orchestrator()
    task = await orchestrator.update_task_status(
        task_id=task_id,
        status=request.status,
        updates=request.updates,
    )
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    # è®°å½•ç³»ç»Ÿäº‹ä»¶ï¼ˆå®¡è®¡ï¼‰
    try:
        if super_agent.workflow_monitor:
            reason = None
            if request.updates:
                reason = request.updates.get("blocked_reason") or request.updates.get("reason")
            await super_agent.workflow_monitor.record_system_event(
                event_type="orchestrator_task_status",
                source="task_api",
                severity="warning" if str(request.status).lower() == "blocked" else "info",
                success=True,
                data={
                    "task_id": task_id,
                    "new_status": str(request.status),
                    "reason": reason
                },
                error=None
            )
    except Exception:
        pass
    return {"task": task}

@router.get("/planning/tasks/{task_id}")
async def get_planning_task_detail(task_id: int):
    """è·å–è§„åˆ’ç³»ç»Ÿä¸­çš„ä»»åŠ¡è¯¦æƒ…ï¼ˆåŒ…å«æ‰§è¡Œæ—¥å¿—/å¤ç›˜ç­‰ï¼‰"""
    task = next((t for t in task_planning.tasks if t.get("id") == task_id), None)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {"task": task}

@router.get("/erp/demo/dashboard")
async def get_demo_dashboard():
    ds = _get_factory_data_source()
    return ds.get_dashboards()


@router.get("/operations/analytics")
async def get_operations_analytics():
    """
    è·å–è¿è¥è´¢åŠ¡åˆ†ææ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆä¸“å®¶ç³»ç»Ÿï¼‰
    """
    ds = _get_factory_data_source()
    cash_flow = ds.get_cash_flow_summary() or {}
    collections = float(cash_flow.get("total_collections") or 0.0)
    payments = float(cash_flow.get("total_payments") or 0.0)
    balance = cash_flow.get("balance")
    if balance is None:
        balance = collections - payments
    balance = float(balance or 0.0)
    period_months = 3.0  # demo æ•°æ®æŒ‰å­£åº¦æ±‡æ€»
    burn_rate = payments / period_months if payments else 0.0
    runway_months = balance / burn_rate if burn_rate > 0 else None
    collection_payment_ratio = collections / payments if payments else float("inf")

    kpi_summary = {
        "net_cash": balance,
        "burn_rate": burn_rate,
        "collections": collections,
        "payments": payments,
        "runway_months": runway_months,
        "collection_payment_ratio": collection_payment_ratio
    }

    scorecards = [
        {
            "label": "å‡€ç°é‡‘ä½™é¢",
            "value": f"Â¥{balance:,.0f}",
            "trend": "+8% QoQ" if balance >= 0 else "-",
            "status": "positive" if balance > payments else "warning"
        },
        {
            "label": "æœˆåº¦ Burn Rate",
            "value": f"Â¥{burn_rate:,.0f}",
            "trend": "+2% MoM" if burn_rate else "-",
            "status": "warning" if burn_rate > 0.6 * collections else "neutral"
        },
        {
            "label": "Runwayï¼ˆæœˆï¼‰",
            "value": f"{runway_months:.1f} æœˆ" if runway_months else "âˆ",
            "trend": "å®‰å…¨çº¿ â‰¥ 6",
            "status": "critical" if runway_months and runway_months < 6 else "positive"
        }
    ]

    trend_points = []
    base_cash = balance if balance > 0 else 1_200_000
    for idx, label in enumerate(["W-4", "W-3", "W-2", "W-1", "æœ¬å‘¨"]):
        factor = 0.7 + idx * 0.08
        trend_points.append({
            "label": label,
            "net_cash": round(base_cash * factor / 1_000_000, 2),
            "burn": round(max(burn_rate, 1.0) * (0.9 + idx * 0.05) / 1_000_000, 2)
        })

    chart_blueprints = await persistence_seeder.get_records("operations_chart_blueprints", limit=20)
    finance_guides = await persistence_seeder.get_records("operations_finance_guides", limit=20)

    return {
        "success": True,
        "kpi_summary": kpi_summary,
        "scorecards": scorecards,
        "trend_points": trend_points,
        "chart_blueprints": chart_blueprints,
        "finance_insights": finance_guides,
        "strategy": OPERATIONS_FINANCE_STRATEGY,
        "strategy_links": OPERATIONS_STRATEGY_LINKS,
        "cash_flow": cash_flow,
        "last_refreshed": datetime.now().isoformat()
    }


@router.get("/erp/demo/orders")
async def get_demo_orders(
    status: Optional[str] = None,
    q: Optional[str] = None,
    page: int = 1,
    page_size: int = 20
):
    """
    è®¢å•åˆ—è¡¨ï¼ˆæ”¯æŒçŠ¶æ€ç­›é€‰/å…³é”®è¯è¿‡æ»¤/åˆ†é¡µï¼‰
    å…³é”®è¯åŒ¹é…å­—æ®µï¼šorder_id / customer / product_code / product_name
    """
    ds = _get_factory_data_source()
    items = ds.get_orders(status=status)
    # å…³é”®è¯è¿‡æ»¤ï¼ˆç®€åŒ–ï¼‰
    if q:
        ql = q.lower()
        def match(o):
            for k in ["order_id", "customer", "product_code", "product_name"]:
                v = str(o.get(k, "")).lower()
                if ql in v:
                    return True
            return False
        items = [o for o in items if match(o)]
    total = len(items)
    # åˆ†é¡µ
    page = max(1, page)
    page_size = max(1, min(200, page_size))
    start = (page - 1) * page_size
    end = start + page_size
    page_items = items[start:end]
    # çŠ¶æ€åˆ†å¸ƒï¼ˆç®€æ˜“å›¾è¡¨æ•°æ®ï¼‰
    status_dist = {}
    for o in items:
        s = o.get("status", "unknown")
        status_dist[s] = status_dist.get(s, 0) + 1
    return {
        "orders": page_items,
        "total": total,
        "page": page,
        "page_size": page_size,
        "status_distribution": status_dist
    }


@router.get("/erp/demo/production-jobs")
async def get_production_jobs(
    order_id: Optional[str] = None,
    q: Optional[str] = None,
    page: int = 1,
    page_size: int = 20
):
    ds = _get_factory_data_source()
    items = ds.get_production_jobs(order_id=order_id)
    # å…³é”®è¯è¿‡æ»¤ï¼ˆjob_id/order_id/machine/operationç­‰å­—æ®µï¼‰
    if q:
        ql = q.lower()
        def match(o):
            for k in ["job_id", "order_id", "machine", "operation"]:
                v = str(o.get(k, "")).lower()
                if ql in v:
                    return True
            return False
        items = [o for o in items if match(o)]
    total = len(items)
    page = max(1, page); page_size = max(1, min(200, page_size))
    start = (page - 1) * page_size; end = start + page_size
    page_items = items[start:end]
    # çŠ¶æ€åˆ†å¸ƒ
    state_dist = {}
    for j in items:
        s = j.get("status", "unknown")
        state_dist[s] = state_dist.get(s, 0) + 1
    return {"jobs": page_items, "total": total, "page": page, "page_size": page_size, "status_distribution": state_dist}


@router.get("/erp/demo/procurements")
async def get_procurement_alerts(
    q: Optional[str] = None,
    page: int = 1,
    page_size: int = 20
):
    ds = _get_factory_data_source()
    items = ds.get_procurement_alerts()
    if q:
        ql = q.lower()
        def match(o):
            for k in ["po_id", "supplier", "material_code", "material_name", "alert", "status"]:
                v = str(o.get(k, "")).lower()
                if ql in v:
                    return True
            return False
        items = [o for o in items if match(o)]
    total = len(items)
    page = max(1, page); page_size = max(1, min(200, page_size))
    start = (page - 1) * page_size; end = start + page_size
    page_items = items[start:end]
    # çŠ¶æ€åˆ†å¸ƒ
    state_dist = {}
    for p in items:
        s = p.get("status", "unknown")
        state_dist[s] = state_dist.get(s, 0) + 1
    return {"procurements": page_items, "total": total, "page": page, "page_size": page_size, "status_distribution": state_dist}

@router.get("/erp/demo/inventory")
async def get_inventory(
    q: Optional[str] = None,
    page: int = 1,
    page_size: int = 20
):
    ds = _get_factory_data_source()
    items = ds.get_inventory_status()
    if q:
        ql = q.lower()
        def match(o):
            for k in ["material_code", "material_name", "status_flag"]:
                v = str(o.get(k, "")).lower()
                if ql in v:
                    return True
            return False
        items = [o for o in items if match(o)]
    total = len(items)
    page = max(1, page); page_size = max(1, min(200, page_size))
    start = (page - 1) * page_size; end = start + page_size
    page_items = items[start:end]
    # çŠ¶æ€åˆ†å¸ƒï¼ˆä½äºå®‰å…¨/æ­£å¸¸ï¼‰
    flag_dist = {}
    for it in items:
        s = it.get("status_flag", "normal")
        flag_dist[s] = flag_dist.get(s, 0) + 1
    return {"inventory": page_items, "total": total, "page": page, "page_size": page_size, "status_distribution": flag_dist}


@router.get("/erp/demo/cash-flow")
async def get_cash_flow_summary():
    ds = _get_factory_data_source()
    return ds.get_cash_flow_summary()


async def _erp_trial_calc_logic(params: Dict[str, Any]) -> Dict[str, Any]:
    target_weekly_revenue = params.get("target_weekly_revenue")
    target_daily_units = params.get("target_daily_units")
    product_code = params.get("product_code")
    order_id = params.get("order_id")

    ds = _get_trial_data_source()
    product = await ds.get_product_data(
        order_id=order_id,
        product_code=product_code,
        legacy_identifier=product_code or order_id,
    )
    if not product:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°å¯ç”¨äºè¯•ç®—çš„è®¢å•/äº§å“æ•°æ®")

    unit_price = float(product.get("unit_price") or 0.0)
    available_days = max(1, int(product.get("available_days") or 7))

    result: Dict[str, Any] = {
        "product": {
            "order_id": product.get("order_id"),
            "product_code": product.get("product_code"),
            "product_name": product.get("product_name"),
            "unit_price": unit_price,
            "available_days": available_days,
            "promise_date": product.get("promise_date"),
            "requested_date": product.get("requested_date"),
            "priority": product.get("priority"),
        },
        "inputs": {
            "target_weekly_revenue": target_weekly_revenue,
            "target_daily_units": target_daily_units,
        },
    }

    if target_weekly_revenue and unit_price > 0:
        required_units_week = target_weekly_revenue / unit_price
        required_units_day = required_units_week / 7.0
        result["trial"] = {
            "type": "by_weekly_revenue",
            "required_units_per_day": round(required_units_day, 2),
            "assumptions": {"unit_price": unit_price, "days_per_week": 7},
        }
    elif target_daily_units:
        expected_week_revenue = target_daily_units * unit_price * 7.0
        result["trial"] = {
            "type": "by_daily_units",
            "expected_weekly_revenue": round(expected_week_revenue, 2),
            "assumptions": {"unit_price": unit_price, "days_per_week": 7},
        }
    else:
        quantity = int(product.get("quantity") or 0)
        if quantity > 0:
            required_units_day = quantity / available_days
            result["trial"] = {
                "type": "by_order_quantity",
                "required_units_per_day": round(required_units_day, 2),
                "assumptions": {
                    "available_days": available_days,
                    "order_quantity": quantity,
                },
            }
        else:
            result["trial"] = {
                "type": "insufficient_data",
                "message": "ç¼ºå°‘ç›®æ ‡æˆ–è®¢å•æ•°é‡ï¼Œæ— æ³•è®¡ç®—",
            }
    return result

@router.post("/erp/trial/calc")
async def trial_calculation(
    target_weekly_revenue: Optional[float] = Body(None, embed=True),
    target_daily_units: Optional[int] = Body(None, embed=True),
    product_code: Optional[str] = Body(None, embed=True),
    order_id: Optional[str] = Body(None, embed=True)
):
    """
    è¿è¥è¯•ç®—å™¨ï¼šä¸ºè¾¾åˆ°ç›®æ ‡ï¼ˆå‘¨è¥æ”¶æˆ–æ—¥äº§é‡ï¼‰ï¼Œéœ€è¦çš„æ—¥å‡äº§å‡º/è®¢å•é…ç½®å»ºè®®
    - è‹¥æä¾› target_weekly_revenueï¼šæ ¹æ®äº§å“å•ä»·ä¸å¯ç”¨å¤©æ•°ï¼Œå€’æ¨å‡ºå»ºè®®æ—¥äº§é‡
    - è‹¥æä¾› target_daily_unitsï¼šè®¡ç®—é¢„è®¡å‘¨è¥æ”¶
    """
    execution_id, exec_result = await run_closed_loop_operation(
        module="erp",
        function="trial_calculation",
        parameters={
            "target_weekly_revenue": target_weekly_revenue,
            "target_daily_units": target_daily_units,
            "product_code": product_code,
            "order_id": order_id,
        },
        executor=_erp_trial_calc_logic,
        metadata={"order_id": order_id, "product_code": product_code},
    )
    payload = exec_result.get("result") or {}
    payload["execution_id"] = execution_id
    return payload

@router.post("/erp/8d/analyze")
async def erp_8d_analyze(payload: Dict[str, Any] = Body(...)):
    """
    ERPå…«ç»´åº¦åˆ†æï¼šè´¨é‡/æˆæœ¬/äº¤æœŸ/å®‰å…¨/åˆ©æ¶¦/æ•ˆç‡/ç®¡ç†/æŠ€æœ¯
    ä¼ å…¥å„ç»´åº¦å¿…è¦æŒ‡æ ‡ï¼ˆå¯ç¼ºçœï¼Œé‡‡ç”¨ä¿å®ˆé»˜è®¤ï¼‰ï¼Œè¿”å›æŒ‡æ ‡ä¸æ€»è§ˆè¯„åˆ†
    """
    if not analyze_8d:
        raise HTTPException(status_code=503, detail="ERP 8Dåˆ†ææ¨¡å—æœªåŠ è½½")
    try:
        result = analyze_8d(payload)
        return result
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"8Dåˆ†æå¤±è´¥: {str(e)}")

# ====== ERP BPMN æµç¨‹ç¼–è¾‘/ç®¡ç† ======
@router.get("/erp/bpmn/processes")
async def list_bpmn_processes():
    items = []
    for file in bpmn_dir.glob("*.json"):
        try:
            items.append({
                "id": file.stem,
                "filename": file.name,
                "size": file.stat().st_size,
                "updated_at": datetime.fromtimestamp(file.stat().st_mtime).isoformat()
            })
        except Exception:
            continue
    return {"processes": sorted(items, key=lambda x: x["updated_at"], reverse=True)}

@router.get("/erp/bpmn/process/{process_id}")
async def get_bpmn_process(process_id: str):
    path = bpmn_dir / f"{process_id}.json"
    if not path.exists():
        raise HTTPException(status_code=404, detail="æµç¨‹ä¸å­˜åœ¨")
    try:
        content = path.read_text(encoding="utf-8")
        data = json.loads(content)
        return {"id": process_id, "data": data}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class SaveBPMNRequest(BaseModel):
    id: Optional[str] = None
    data: Dict[str, Any]

@router.post("/erp/bpmn/process")
async def save_bpmn_process(req: SaveBPMNRequest):
    pid = req.id or f"proc_{int(datetime.now().timestamp())}"
    path = bpmn_dir / f"{pid}.json"
    try:
        path.write_text(json.dumps(req.data, ensure_ascii=False, indent=2), encoding="utf-8")
        return {"success": True, "id": pid}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/erp/bpmn/process/{process_id}")
async def delete_bpmn_process(process_id: str):
    path = bpmn_dir / f"{process_id}.json"
    if not path.exists():
        raise HTTPException(status_code=404, detail="æµç¨‹ä¸å­˜åœ¨")
    try:
        path.unlink()
        return {"success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ====== BPMN è¿è¡Œæ—¶è¿½è¸ªï¼ˆæœ€å°å¯ç”¨ï¼‰ ======
runtime_path = bpmn_dir / "runtime.jsonl"
SAMPLE_RUNTIME_EVENTS = [
    {
        "instance_id": "BP202511150001",
        "process_id": "proc_full_cycle",
        "node_id": "market_research",
        "node_name": "å¸‚åœºè°ƒç ”",
        "status": "completed",
        "message": "é”å®šç›®æ ‡ç»†åˆ†å¸‚åœº",
        "timestamp": "2025-11-01T09:10:00"
    },
    {
        "instance_id": "BP202511150001",
        "process_id": "proc_full_cycle",
        "node_id": "customer_development",
        "node_name": "å®¢æˆ·å¼€å‘",
        "status": "completed",
        "message": "ç­¾ç½²4ä»½æ„å‘ä¹¦",
        "timestamp": "2025-11-02T14:25:00"
    },
    {
        "instance_id": "BP202511150001",
        "process_id": "proc_full_cycle",
        "node_id": "project_development",
        "node_name": "é¡¹ç›®å¼€å‘",
        "status": "completed",
        "message": "ç¡®è®¤BOM",
        "timestamp": "2025-11-03T19:40:00"
    },
    {
        "instance_id": "BP202511150001",
        "process_id": "proc_full_cycle",
        "node_id": "order_management",
        "node_name": "è®¢å•ç®¡ç†",
        "status": "in_progress",
        "message": "ç­‰å¾…å®¢æˆ·ç­¾å­—",
        "timestamp": "2025-11-05T12:05:00"
    },
    {
        "instance_id": "BP202511150002",
        "process_id": "proc_fast_track",
        "node_id": "market_research",
        "node_name": "å¸‚åœºè°ƒç ”",
        "status": "completed",
        "message": "ç´§æ€¥é¡¹ç›®",
        "timestamp": "2025-11-04T09:00:00"
    },
    {
        "instance_id": "BP202511150002",
        "process_id": "proc_fast_track",
        "node_id": "customer_development",
        "node_name": "å®¢æˆ·å¼€å‘",
        "status": "completed",
        "message": "å®¢æˆ·ç»¿ç¯",
        "timestamp": "2025-11-04T16:00:00"
    },
    {
        "instance_id": "BP202511150002",
        "process_id": "proc_fast_track",
        "node_id": "production_planning",
        "node_name": "æŠ•äº§è®¡åˆ’",
        "status": "started",
        "message": "æ’äº§é”å®š",
        "timestamp": "2025-11-05T09:45:00"
    }
]


def _load_runtime_events(limit: int = 1000) -> List[Dict[str, Any]]:
    """åŠ è½½è¿è¡Œæ—¶äº‹ä»¶ï¼Œå…¼å®¹ç©ºæ–‡ä»¶åœºæ™¯"""
    events: List[Dict[str, Any]] = []
    import json as _json
    if runtime_path.exists():
        try:
            with open(runtime_path, "r", encoding="utf-8") as f:
                lines = f.readlines()[-limit:]
                for line in lines:
                    try:
                        events.append(_json.loads(line))
                    except Exception:
                        continue
        except Exception:
            events = []
    if not events:
        events = SAMPLE_RUNTIME_EVENTS[-limit:]
    return events

class BpmnRuntimeEvent(BaseModel):
    instance_id: str
    process_id: str
    node_id: str
    node_name: Optional[str] = None
    status: str  # started/completed/error
    message: Optional[str] = None

@router.post("/erp/bpmn/runtime/event")
async def bpmn_runtime_event(ev: BpmnRuntimeEvent):
    """è®°å½•æµç¨‹å®ä¾‹èŠ‚ç‚¹äº‹ä»¶"""
    rec = ev.dict()
    rec["timestamp"] = datetime.now().isoformat()
    try:
        with open(runtime_path, "a", encoding="utf-8") as f:
            import json as _json
            f.write(_json.dumps(rec, ensure_ascii=False) + "\n")
        return {"success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/erp/bpmn/runtime/instances")
async def bpmn_runtime_instances(limit: int = 50):
    """æŒ‰å®ä¾‹èšåˆæœ€è¿‘äº‹ä»¶ï¼ˆæœ€å°å¯ç”¨ï¼‰"""
    from collections import defaultdict
    try:
        events = _load_runtime_events(limit=1000)
        agg = defaultdict(list)
        for e in events:
            agg[e["instance_id"]].append(e)
        instances = []
        for iid, events in agg.items():
            events_sorted = sorted(events, key=lambda x: x.get("timestamp", ""))
            last = events_sorted[-1]
            instances.append({
                "instance_id": iid,
                "process_id": last.get("process_id"),
                "last_node": last.get("node_id"),
                "last_status": last.get("status"),
                "events_count": len(events_sorted),
                "updated_at": last.get("timestamp")
            })
        instances = sorted(instances, key=lambda x: x["updated_at"], reverse=True)[:limit]
        return {"instances": instances, "count": len(instances)}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/erp/bpmn/runtime/instance/{instance_id}")
async def get_bpmn_runtime_instance(instance_id: str):
    """è·å–å•ä¸ªæµç¨‹å®ä¾‹çš„äº‹ä»¶æ—¶é—´çº¿"""
    events = [e for e in _load_runtime_events() if e.get("instance_id") == instance_id]
    if not events:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥æµç¨‹å®ä¾‹")
    events_sorted = sorted(events, key=lambda x: x.get("timestamp", ""))
    first = events_sorted[0]
    last = events_sorted[-1]
    duration = None
    if first.get("timestamp") and last.get("timestamp"):
        try:
            start_dt = datetime.fromisoformat(first["timestamp"])
            end_dt = datetime.fromisoformat(last["timestamp"])
            duration = (end_dt - start_dt).total_seconds()
        except Exception:
            duration = None
    return {
        "success": True,
        "instance": {
            "instance_id": instance_id,
            "process_id": last.get("process_id"),
            "current_node": last.get("node_id"),
            "current_status": last.get("status"),
            "events_count": len(events_sorted),
            "started_at": first.get("timestamp"),
            "updated_at": last.get("timestamp"),
            "duration_seconds": duration
        },
        "events": events_sorted
    }

@router.get("/integrations/status")
async def get_external_integrations():
    return {"integrations": external_status.get_status()}


@router.get("/workflow/statistics")
async def get_workflow_statistics():
    """è·å–å·¥ä½œæµç»Ÿè®¡ä¿¡æ¯"""
    stats = super_agent.workflow_monitor.get_statistics() if super_agent.workflow_monitor else {}
    return stats


@router.get("/workflow/recent")
async def get_recent_workflows(limit: int = 10):
    """è·å–æœ€è¿‘çš„å·¥ä½œæµè®°å½•"""
    workflows = super_agent.workflow_monitor.get_recent_workflows(limit) if super_agent.workflow_monitor else []
    return {"workflows": workflows, "count": len(workflows)}


@router.get("/workflow/orchestrator/metrics")
async def get_workflow_orchestrator_metrics():
    """è·å–å·¥ä½œæµç¼–æ’å™¨æŒ‡æ ‡ï¼ˆJSONæ ¼å¼ï¼‰"""
    try:
        from core.workflow_orchestrator import get_workflow_orchestrator
        orchestrator = get_workflow_orchestrator()
        metrics = await orchestrator.get_metrics_json()
        return {"success": True, "metrics": metrics}
    except Exception as e:
        return {"success": False, "error": str(e)}


@router.get("/workflow/orchestrator/metrics/prometheus")
async def get_workflow_orchestrator_prometheus_metrics():
    """è·å–å·¥ä½œæµç¼–æ’å™¨ Prometheus æŒ‡æ ‡"""
    from fastapi.responses import Response
    try:
        from core.workflow_orchestrator import get_workflow_orchestrator
        orchestrator = get_workflow_orchestrator()
        metrics_data = orchestrator.get_prometheus_metrics()
        return Response(
            content=metrics_data,
            media_type="text/plain; version=0.0.4; charset=utf-8"
        )
    except Exception as e:
        return Response(
            content=f"# Error: {str(e)}\n",
            media_type="text/plain",
            status_code=500
        )


@router.get("/workflow/status")
async def get_workflow_status(
    workflow_type: Optional[str] = None,
    state: Optional[str] = None,
    limit: int = 50
):
    """
    è·å–å·¥ä½œæµçŠ¶æ€
    
    Args:
        workflow_type: å·¥ä½œæµç±»å‹ï¼ˆintelligent/directï¼‰
        state: å·¥ä½œæµçŠ¶æ€ï¼ˆinitialized/rag_retrieval_1/expert_routing/module_execution/rag_retrieval_2/response_generation/completed/failed/cancelledï¼‰
        limit: è¿”å›æ•°é‡é™åˆ¶
        
    Returns:
        å·¥ä½œæµçŠ¶æ€ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç»Ÿè®¡ã€æ´»è·ƒå·¥ä½œæµåˆ—è¡¨ç­‰
    """
    try:
        from core.workflow_orchestrator import (
            get_workflow_orchestrator,
            WorkflowType,
            WorkflowState,
        )
        
        orchestrator = get_workflow_orchestrator()
        
        # è·å–æŒ‡æ ‡
        metrics = await orchestrator.get_metrics_json()
        
        # è·å–å·¥ä½œæµåˆ—è¡¨
        wf_type = WorkflowType(workflow_type) if workflow_type else None
        wf_state = WorkflowState(state) if state else None
        
        all_workflows = await orchestrator.list_workflows(
            workflow_type=wf_type,
            state=wf_state,
            limit=limit
        )
        
        # åˆ†ç¦»æ™ºèƒ½çº¿å’Œç›´æ¥æ“ä½œçº¿
        intelligent_workflows = [
            wf for wf in all_workflows
            if wf.get("workflow_type") == "intelligent"
            and wf.get("state") not in ["completed", "failed", "cancelled"]
        ]
        
        direct_workflows = [
            wf for wf in all_workflows
            if wf.get("workflow_type") == "direct"
            and wf.get("state") not in ["completed", "failed", "cancelled"]
        ]
        
        # æ´»è·ƒå·¥ä½œæµï¼ˆæ‰€æœ‰éç»ˆæ€å·¥ä½œæµï¼‰
        active_workflows = [
            wf for wf in all_workflows
            if wf.get("state") not in ["completed", "failed", "cancelled"]
        ]
        
        return {
            "success": True,
            "data": {
                "statistics": metrics,
                "intelligent_workflows": intelligent_workflows[:10],  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                "direct_workflows": direct_workflows[:10],  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                "active_workflows": active_workflows[:20],  # æœ€å¤šæ˜¾ç¤º20ä¸ª
                "type_state_counts": metrics.get("type_state_counts", {}),
            }
        }
    except Exception as e:
        import traceback
        return {
            "success": False,
            "error": str(e),
            "traceback": traceback.format_exc()
        }


@router.get("/resource/adjuster/statistics")
async def get_resource_adjuster_statistics():
    """è·å–èµ„æºè‡ªåŠ¨è°ƒèŠ‚ç»Ÿè®¡ä¿¡æ¯"""
    stats = resource_adjuster.get_statistics()
    return stats


@router.post("/resource/adjuster/monitor")
async def monitor_resources():
    """ç›‘æ§èµ„æºå¹¶æ£€æµ‹é—®é¢˜"""
    issues = await resource_adjuster.monitor_resources()
    return {"issues": [{
        "type": issue.issue_type.value,
        "severity": issue.severity,
        "description": issue.description,
        "current_value": issue.current_value,
        "threshold": issue.threshold,
        "affected_modules": issue.affected_modules,
        "detected_at": issue.detected_at.isoformat()
    } for issue in issues], "count": len(issues)}


@router.post("/resource/adjuster/analyze")
async def analyze_resource_issue(issue_type: str, severity: str):
    """åˆ†æèµ„æºé—®é¢˜å¹¶ç”Ÿæˆè°ƒèŠ‚å»ºè®®"""
    # æŸ¥æ‰¾åŒ¹é…çš„é—®é¢˜
    matching_issues = [
        issue for issue in resource_adjuster.issues[-100:]
        if issue.issue_type.value == issue_type and issue.severity == severity
    ]
    
    if not matching_issues:
        return {"suggestions": [], "message": "æœªæ‰¾åˆ°åŒ¹é…çš„é—®é¢˜"}
    
    issue = matching_issues[-1]  # ä½¿ç”¨æœ€æ–°çš„é—®é¢˜
    suggestions = await resource_adjuster.analyze_issue(issue)
    
    return {
        "suggestions": [{
            "action": suggestion.action.value,
            "description": suggestion.description,
            "expected_impact": suggestion.expected_impact,
            "risk_level": suggestion.risk_level,
            "requires_approval": suggestion.requires_approval,
            "estimated_improvement": suggestion.estimated_improvement
        } for suggestion in suggestions],
        "count": len(suggestions)
    }


@router.post("/resource/adjuster/execute")
async def execute_adjustment(
    action: str,
    description: str,
    approved: bool = False
):
    """æ‰§è¡Œèµ„æºè°ƒèŠ‚åŠ¨ä½œ"""
    # æŸ¥æ‰¾åŒ¹é…çš„å»ºè®®
    matching_suggestions = [
        s for s in resource_adjuster.suggestions[-100:]
        if s.action.value == action and s.description == description
    ]
    
    if not matching_suggestions:
        return {"success": False, "message": "æœªæ‰¾åˆ°åŒ¹é…çš„å»ºè®®"}
    
    suggestion = matching_suggestions[-1]
    result = await resource_adjuster.execute_adjustment(suggestion, approved=approved)
    
    return result


@router.post("/resource/adjuster/enable")
async def enable_auto_adjust(threshold: str = "medium"):
    """å¯ç”¨èµ„æºè‡ªåŠ¨è°ƒèŠ‚"""
    resource_adjuster.enable_auto_adjust(threshold)
    return {"success": True, "message": f"å·²å¯ç”¨è‡ªåŠ¨è°ƒèŠ‚ï¼Œé˜ˆå€¼ï¼š{threshold}"}


@router.post("/resource/adjuster/disable")
async def disable_auto_adjust():
    """ç¦ç”¨èµ„æºè‡ªåŠ¨è°ƒèŠ‚"""
    resource_adjuster.disable_auto_adjust()
    return {"success": True, "message": "å·²ç¦ç”¨è‡ªåŠ¨è°ƒèŠ‚"}


@router.get("/learning/workflow-statistics")
async def get_learning_workflow_statistics():
    """è·å–å­¦ä¹ ç³»ç»Ÿå·¥ä½œæµç»Ÿè®¡"""
    stats = learning_monitor.get_workflow_statistics() if hasattr(learning_monitor, 'get_workflow_statistics') else {}
    return stats


@router.get("/learning/resource-statistics")
async def get_learning_resource_statistics():
    """è·å–å­¦ä¹ ç³»ç»Ÿèµ„æºç»Ÿè®¡"""
    stats = learning_monitor.get_resource_statistics() if hasattr(learning_monitor, 'get_resource_statistics') else {}
    return stats


@router.get("/performance/stats")
async def get_performance_stats():
    """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯ï¼ˆ2ç§’å“åº”ç›‘æ§ï¼‰"""
    stats = performance_monitor.get_performance_stats()
    return {
        "success": True,
        **stats,
        "strategy": await strategy_engine.get_stats()
    }

@router.get("/dashboard/overview")
async def get_dashboard_overview():
    """ç»Ÿä¸€é¥æµ‹æ€»è§ˆï¼šæ€§èƒ½/ç­–ç•¥/èµ„æº/å­¦ä¹ /å·¥ä½œæµç»Ÿè®¡"""
    perf = performance_monitor.get_performance_stats()
    strategy = await strategy_engine.get_stats()
    resource = resource_monitor.get_current_status()
    alerts = resource_monitor.get_alerts()
    workflow_stats = super_agent.workflow_monitor.get_statistics() if super_agent.workflow_monitor else {}
    learning_stats = learning_monitor.get_statistics() if learning_monitor else {}
    return {
        "success": True,
        "performance": perf,
        "strategy": strategy,
        "resource": {
            "status": resource,
            "alerts": alerts,
            "alerts_count": len(alerts)
        },
        "workflow": workflow_stats,
        "learning": learning_stats,
        "timestamp": datetime.now().isoformat()
    }


@router.get("/performance/slow-queries")
async def get_slow_queries(limit: int = 10):
    """è·å–æ…¢æŸ¥è¯¢åˆ—è¡¨"""
    slow_queries = performance_monitor.get_slow_queries(limit)
    return {
        "success": True,
        "slow_queries": slow_queries,
        "count": len(slow_queries)
    }


@router.get("/performance/bottlenecks")
async def get_bottlenecks():
    """è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ"""
    bottlenecks = performance_monitor.get_bottlenecks()
    return {
        "success": True,
        "bottlenecks": bottlenecks,
        "count": len(bottlenecks)
    }

@router.get("/security/audit/overview", dependencies=[security_read_dep])
async def security_audit_overview(limit: int = 20):
    """ç»Ÿä¸€å®‰å…¨ä¸åˆè§„å®¡è®¡æ€»è§ˆ"""
    if not audit_pipeline:
        return {"events": [], "count": 0, "statistics": {}}
    records = audit_pipeline.query_records(limit=limit)
    stats = audit_pipeline.get_statistics()
    simplified = []
    for record in records:
        simplified.append({
            "event_id": record.get("record_id"),
            "type": record.get("event_type"),
            "source": record.get("source"),
            "success": record.get("status") == "success",
            "severity": record.get("severity"),
            "timestamp": record.get("timestamp"),
            "short": str(record.get("metadata", {}))[:120],
        })
    return {"events": simplified, "count": len(simplified), "statistics": stats}


@router.get("/security/audit/http", dependencies=[security_read_dep])
async def security_audit_http(limit: int = 50):
    if not audit_pipeline:
        return {"records": []}
    return {"records": audit_pipeline.get_http_records(limit)}


@router.get("/security/audit/tasks", dependencies=[security_read_dep])
async def security_audit_tasks(limit: int = 50):
    if not audit_pipeline:
        return {"records": []}
    return {"records": audit_pipeline.get_task_records(limit)}


@router.get("/security/audit/commands", dependencies=[security_read_dep])
async def security_audit_commands(limit: int = 50):
    if not audit_pipeline:
        return {"records": []}
    return {"records": audit_pipeline.get_command_records(limit)}


@router.get("/performance/cache-stats")
async def get_cache_stats():
    """è·å–ç¼“å­˜ç»Ÿè®¡"""
    cache_stats = response_time_optimizer.get_cache_stats()
    return {
        "success": True,
        **cache_stats
    }


@router.post("/performance/clear-cache")
async def clear_cache():
    """æ¸…ç©ºç¼“å­˜"""
    response_time_optimizer.clear_cache()
    return {
        "success": True,
        "message": "ç¼“å­˜å·²æ¸…ç©º"
    }


@router.get("/resource/system")
async def get_system_resources():
    """è·å–ç³»ç»Ÿèµ„æºå ç”¨æƒ…å†µï¼ˆCPU/å†…å­˜/ç£ç›˜/å¤–æ¥ç¡¬ç›˜ï¼‰â­P0åŠŸèƒ½"""
    status = resource_monitor.get_current_status()
    alerts = resource_monitor.get_alerts(severity="high")
    
    # æ ¼å¼åŒ–èµ„æºä¿¡æ¯
    cpu_info = status.get("cpu", {})
    memory_info = status.get("memory", {})
    disk_info = status.get("disk", {})
    external_drives = status.get("external_drives", [])
    
    return {
        "success": True,
        "resources": {
            "cpu": {
                "percent": cpu_info.get("percent", 0),
                "count": cpu_info.get("count", 0),
                "freq": cpu_info.get("freq"),
                "status": "normal" if cpu_info.get("percent", 0) < 80 else "high"
            },
            "memory": {
                "total_gb": round(memory_info.get("total", 0) / (1024**3), 2),
                "used_gb": round(memory_info.get("used", 0) / (1024**3), 2),
                "available_gb": round(memory_info.get("available", 0) / (1024**3), 2),
                "percent": memory_info.get("percent", 0),
                "status": "normal" if memory_info.get("percent", 0) < 85 else "high"
            },
            "disk": {
                "total_gb": round(disk_info.get("total", 0) / (1024**3), 2),
                "used_gb": round(disk_info.get("used", 0) / (1024**3), 2),
                "free_gb": round(disk_info.get("free", 0) / (1024**3), 2),
                "percent": disk_info.get("percent", 0),
                "status": "normal" if disk_info.get("percent", 0) < 90 else "high"
            },
            "external_drives": [
                {
                    "device": drive.get("device"),
                    "mountpoint": drive.get("mountpoint"),
                    "total_gb": round(drive.get("total", 0) / (1024**3), 2),
                    "used_gb": round(drive.get("used", 0) / (1024**3), 2),
                    "free_gb": round(drive.get("free", 0) / (1024**3), 2),
                    "percent": drive.get("percent", 0),
                    "connected": drive.get("connected", False),
                    "status": "normal" if drive.get("percent", 0) < 90 else "high"
                }
                for drive in external_drives
            ]
        },
        "alerts": alerts,
        "alerts_count": len(alerts),
        "timestamp": datetime.now().isoformat()
    }


@router.get("/resource/external-drives")
async def get_external_drives():
    """è·å–å¤–æ¥ç¡¬ç›˜è¿æ¥æƒ…å†µâ­P0åŠŸèƒ½"""
    status = resource_monitor.get_current_status()
    external_drives = status.get("external_drives", [])
    
    return {
        "success": True,
        "external_drives": [
            {
                "device": drive.get("device"),
                "mountpoint": drive.get("mountpoint"),
                "fstype": drive.get("fstype"),
                "total_gb": round(drive.get("total", 0) / (1024**3), 2),
                "used_gb": round(drive.get("used", 0) / (1024**3), 2),
                "free_gb": round(drive.get("free", 0) / (1024**3), 2),
                "percent": drive.get("percent", 0),
                "connected": drive.get("connected", False)
            }
            for drive in external_drives
        ],
        "count": len(external_drives),
        "timestamp": datetime.now().isoformat()
    }


@router.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "services": {
            "super_agent": True,
            "memo_system": True,
            "task_planning": True,
            "learning_monitor": True,
            "resource_monitor": True,
            "resource_adjuster": True,
            "workflow_monitor": super_agent.workflow_monitor is not None,
            "voice_interaction": True,
            "translation": True,
            "file_generation": True,
            "web_search": True,
            "file_format_handler": True,
            "terminal_executor": True,
            "performance_monitor": True
        }
    }


class LLMConfigRequest(BaseModel):
    """LLMé…ç½®è¯·æ±‚"""
    provider: str  # ollama/openai/anthropic/azure_openai
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    model: Optional[str] = None


class LLMConfigResponse(BaseModel):
    """LLMé…ç½®å“åº”"""
    success: bool
    provider: str
    model: str
    base_url: str
    message: str


@router.post("/llm/config", response_model=LLMConfigResponse)
async def configure_llm(request: LLMConfigRequest):
    """
    é…ç½®LLMæœåŠ¡â­æ–°å¢
    
    æ”¯æŒï¼š
    - ollama: æœ¬åœ°Ollama
    - openai: OpenAI API
    - anthropic: Anthropic Claude API
    - azure_openai: Azure OpenAI
    """
    try:
        # éªŒè¯æä¾›å•†
        try:
            provider = LLMProvider(request.provider.lower())
        except ValueError:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {request.provider}ã€‚æ”¯æŒ: ollama, openai, anthropic, azure_openai"
            )
        
        # æ›´æ–°LLMæœåŠ¡é…ç½®
        llm_service = get_llm_service(
            provider=request.provider.lower(),
            api_key=request.api_key,
            base_url=request.base_url,
            model=request.model
        )
        
        # æµ‹è¯•è¿æ¥ï¼ˆå¯é€‰ï¼‰
        try:
            test_response = await llm_service.generate("æµ‹è¯•", max_tokens=10)
            test_status = "è¿æ¥æˆåŠŸ"
        except Exception as e:
            test_status = f"é…ç½®æˆåŠŸï¼Œä½†è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
        
        return LLMConfigResponse(
            success=True,
            provider=llm_service.provider.value,
            model=llm_service.model,
            base_url=llm_service.base_url,
            message=f"LLMé…ç½®æˆåŠŸ ({llm_service.provider.value})ã€‚{test_status}"
        )
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"LLMé…ç½®å¤±è´¥: {str(e)}")


@router.get("/llm/config")
async def get_llm_config():
    """è·å–å½“å‰LLMé…ç½®"""
    try:
        llm_service = get_llm_service()
        return {
            "provider": llm_service.provider.value,
            "model": llm_service.model,
            "base_url": llm_service.base_url,
            "has_api_key": llm_service.api_key is not None
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/llm/providers")
async def get_llm_providers():
    """è·å–æ”¯æŒçš„LLMæä¾›å•†åˆ—è¡¨"""
    return {
        "providers": [
            {
                "id": "ollama",
                "name": "Ollama (æœ¬åœ°)",
                "description": "æœ¬åœ°è¿è¡Œçš„OllamaæœåŠ¡",
                "default_url": "http://localhost:11434",
                "requires_api_key": False
            },
            {
                "id": "openai",
                "name": "OpenAI",
                "description": "OpenAI GPT-4/GPT-3.5",
                "default_url": "https://api.openai.com/v1",
                "requires_api_key": True
            },
            {
                "id": "anthropic",
                "name": "Anthropic Claude",
                "description": "Anthropic Claude API",
                "default_url": "https://api.anthropic.com/v1",
                "requires_api_key": True
            },
            {
                "id": "azure_openai",
                "name": "Azure OpenAI",
                "description": "Azure OpenAIæœåŠ¡",
                "default_url": "",
                "requires_api_key": True
            }
        ]
    }

@router.post("/content/compliance/check")
async def check_content_compliance(
    text: str = Body(..., embed=True),
    references: Optional[List[str]] = Body(None, embed=True)
):
    """å†…å®¹åˆè§„æ£€æŸ¥ï¼šåŸåˆ›åº¦/ç›¸ä¼¼åº¦/æ•æ„Ÿè¯ï¼ˆè½»é‡ç‰ˆï¼‰"""
    result = await content_compliance.check_text(text, references or [])
    return result

# ====== è‚¡ç¥¨é‡åŒ–ï¼šæ•°æ®æºç½‘å…³ä¸æ¨¡æ‹Ÿæ’®åˆ ======
@router.get("/stock/sources")
async def list_stock_sources():
    return stock_gateway.list_sources()

@router.post("/stock/switch-source")
async def switch_stock_source(source: str = Body(..., embed=True)):
    ok = stock_gateway.switch(source)
    if not ok:
        raise HTTPException(status_code=400, detail="æ•°æ®æºä¸å­˜åœ¨")
    return {"success": True, "active": source}

@router.get("/stock/quote")
async def get_stock_quote(symbol: str, market: str = "A"):
    data = await stock_gateway.quote(symbol, market)
    # åŒæ­¥ç»™æ¨¡æ‹Ÿå™¨æ’®åˆï¼ˆè‹¥æœ‰æŒ‚å•ï¼‰
    fills = stock_sim.mark_to_market_and_fill(symbol, data["price"])
    return {"quote": data, "sim_fills": fills}

@router.post("/stock/sim/place-order")
async def sim_place_order(
    symbol: str = Body(..., embed=True),
    side: str = Body(..., embed=True),  # buy/sell
    qty: int = Body(..., embed=True),
    order_type: str = Body("market", embed=True),  # market/limit
    price: Optional[float] = Body(None, embed=True)
):
    result = stock_sim.place_order(symbol, side, qty, order_type, price)
    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "ä¸‹å•å¤±è´¥"))
    return result

@router.post("/stock/sim/cancel")
async def sim_cancel(order_id: str = Body(..., embed=True)):
    result = stock_sim.cancel_order(order_id)
    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "æ’¤å•å¤±è´¥"))
    return result

@router.get("/stock/sim/state")
async def sim_state():
    return stock_sim.get_state()


@router.get("/stock/sim/risk-report")
async def sim_risk_report():
    return {"success": True, "report": stock_sim.get_risk_report()}


@router.get("/stock/sim/execution-report")
async def sim_execution_report():
    return {"success": True, "report": stock_sim.get_execution_report()}


@router.get("/stock/sim/trades")
async def sim_trades(limit: int = 50):
    return {"success": True, "trades": stock_sim.get_trades(limit=limit)}


@router.get("/stock/sim/risk-config")
async def sim_risk_config():
    return {"success": True, "config": stock_sim.get_risk_config()}


@router.post("/stock/sim/risk-config")
async def sim_update_risk_config(
    max_position_ratio: Optional[float] = Body(None, embed=True),
    stop_loss_ratio: Optional[float] = Body(None, embed=True),
    slip_bps: Optional[float] = Body(None, embed=True),
    max_single_trade_ratio: Optional[float] = Body(None, embed=True),
    max_daily_loss_ratio: Optional[float] = Body(None, embed=True),
    max_concentration_ratio: Optional[float] = Body(None, embed=True),
):
    """æ›´æ–°é£æ§é…ç½®ï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒæ›´å¤šå‚æ•°ï¼‰"""
    config = stock_sim.update_risk_config(
        max_position_ratio=max_position_ratio,
        stop_loss_ratio=stop_loss_ratio,
        slip_bps=slip_bps,
        max_single_trade_ratio=max_single_trade_ratio,
        max_daily_loss_ratio=max_daily_loss_ratio,
        max_concentration_ratio=max_concentration_ratio,
    )
    return {"success": True, "config": config}

@router.get("/stock/analysis/factors")
async def stock_factor_analysis(stock_code: str = Query(...)):
    """
    å¤šæ¨¡å› å­åˆ†æä¸é¢„æµ‹ä¿¡å·
    """
    return stock_factor_engine.get_factor_analysis(stock_code)


@router.get("/stock/backtest")
async def stock_backtest(symbol: str = "000001", days: int = 60, seed: int = 7):
    return backtest_engine.run(symbol, days, seed)


# ==================== P1-010: è‚¡ç¥¨é‡åŒ–å¢å¼º ====================

@router.get("/stock/sources/health")
async def stock_get_source_health():
    """è·å–æ•°æ®æºå¥åº·çŠ¶æ€"""
    return stock_gateway.get_source_health()


@router.get("/stock/execution/report")
async def stock_get_execution_report(
    symbol: Optional[str] = Query(None),
    days: int = Query(7, ge=1, le=90)
):
    """è·å–æ‰§è¡Œåˆ†ææŠ¥å‘Š"""
    return execution_analyzer.get_execution_report(symbol=symbol, days=days)


@router.get("/stock/execution/performance")
async def stock_get_execution_performance(
    symbol: Optional[str] = Query(None),
    days: int = Query(7, ge=1, le=90)
):
    """è·å–æ‰§è¡Œæ€§èƒ½æŒ‡æ ‡"""
    return execution_analyzer.get_performance_metrics(symbol=symbol, days=days)


@router.get("/stock/analysis/factors/importance")
async def stock_get_factor_importance(symbol: str = Query(...)):
    """è·å–å› å­é‡è¦æ€§æ’åº"""
    return stock_factor_engine.get_factor_importance(symbol)


@router.get("/stock/brokers")
async def stock_list_brokers():
    """åˆ—å‡ºæ‰€æœ‰åˆ¸å•†"""
    return broker_manager.list_brokers()


@router.post("/stock/brokers/{broker_name}/authorize")
async def stock_authorize_broker(
    broker_name: str,
    credentials: Dict[str, Any] = Body(...)
):
    """æˆæƒåˆ¸å•†"""
    broker = broker_manager.get_broker(broker_name)
    if not broker:
        raise HTTPException(status_code=404, detail=f"åˆ¸å•† {broker_name} ä¸å­˜åœ¨")
    
    result = await broker.authorize(credentials)
    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "æˆæƒå¤±è´¥"))
    
    return result


@router.get("/stock/brokers/{broker_name}/account")
async def stock_get_broker_account(broker_name: str):
    """è·å–åˆ¸å•†è´¦æˆ·ä¿¡æ¯"""
    broker = broker_manager.get_broker(broker_name)
    if not broker:
        raise HTTPException(status_code=404, detail=f"åˆ¸å•† {broker_name} ä¸å­˜åœ¨")
    
    if not broker.is_authorized():
        raise HTTPException(status_code=403, detail="åˆ¸å•†æœªæˆæƒ")
    
    return await broker.get_account_info()


@router.post("/stock/brokers/{broker_name}/switch")
async def stock_switch_broker(broker_name: str):
    """åˆ‡æ¢åˆ¸å•†"""
    success = broker_manager.switch_broker(broker_name)
    if not success:
        raise HTTPException(status_code=400, detail=f"åˆ‡æ¢å¤±è´¥ï¼šåˆ¸å•† {broker_name} ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨")
    
    return {
        "success": True,
        "active_broker": broker_name,
        "broker_name": broker_manager.get_broker(broker_name).get_name()
    }

# ====== æŠ–éŸ³é›†æˆï¼šæˆæƒä¸è‰ç¨¿å‘å¸ƒï¼ˆåˆè§„å‰ç½®ï¼‰ ======
@router.get("/douyin/status")
async def douyin_status():
    return douyin.get_status()

@router.post("/douyin/begin-auth")
async def douyin_begin_auth():
    return douyin.begin_auth()

@router.post("/douyin/revoke")
async def douyin_revoke():
    return douyin.revoke()

class DouyinDraftRequest(BaseModel):
    title: str
    content: str
    tags: Optional[List[str]] = None
    references: Optional[List[str]] = None
    min_originality: float = 60.0
    block_sensitive: bool = True


class DouyinAuthCallbackRequest(BaseModel):
    code: str
    state: str


class DouyinPublishRequest(DouyinDraftRequest):
    media_url: Optional[str] = None
    deai_enabled: bool = Field(False, description="æ˜¯å¦å¯ç”¨å»AIåŒ–")
    deai_style: str = Field("casual", description="å»AIåŒ–é£æ ¼ï¼ˆcasual/formal/creativeï¼‰")
    deai_intensity: float = Field(0.5, ge=0.0, le=1.0, description="å»AIåŒ–å¼ºåº¦ï¼ˆ0.0-1.0ï¼‰")


class TenantCreateRequest(BaseModel):
    tenant_id: str = Field(..., min_length=2, max_length=32, regex=r"^[a-z0-9\-_]+$")
    name: str
    plan: Optional[str] = "enterprise"
    active: Optional[bool] = True
    metadata: Optional[Dict[str, Any]] = None


class TenantUpdateRequest(BaseModel):
    name: Optional[str]
    plan: Optional[str]
    active: Optional[bool]
    metadata: Optional[Dict[str, Any]]


class DouyinWebhookPayload(BaseModel):
    event: str
    job_id: Optional[str] = None
    status: Optional[str] = None
    error: Optional[str] = None
    payload: Optional[Dict[str, Any]] = None


@router.post("/douyin/create-draft")
async def douyin_create_draft(req: DouyinDraftRequest):
    compliance = await content_compliance.check_text(req.content, req.references or [])
    if not compliance.get("success"):
        raise HTTPException(status_code=400, detail=f"åˆè§„æ£€æµ‹å¤±è´¥ï¼š{compliance.get('error','æœªçŸ¥é”™è¯¯')}")
    if compliance["originality_percent"] < req.min_originality:
        return {
            "success": False,
            "blocked": True,
            "reason": "åŸåˆ›åº¦ä¸è¶³",
            "compliance": compliance
        }
    if req.block_sensitive and compliance.get("sensitive_hits"):
        return {
            "success": False,
            "blocked": True,
            "reason": "å‘½ä¸­æ•æ„Ÿè¯",
            "compliance": compliance
        }
    draft = await douyin.create_draft(req.title, req.content, req.tags or [])
    if not draft.get("success"):
        raise HTTPException(status_code=400, detail=draft.get("error", "è‰ç¨¿åˆ›å»ºå¤±è´¥"))
    return {
        "success": True,
        "draft": draft,
        "compliance": compliance
    }


@router.post("/content/copyright/check", response_model=CopyrightCheckResponse)
async def copyright_check(req: CopyrightCheckRequest):
    """
    ç‰ˆæƒ/ä¾µæƒæ£€æµ‹ï¼ˆå¢å¼ºç‰ˆï¼šå¤šå¹³å°ç›¸ä¼¼åº¦æ¯”å¯¹ï¼‰
    """
    report = await copyright_inspector.run_workflow(
        text=req.text,
        sources=req.sources,
        platforms=req.platforms or ["douyin", "xiaohongshu", "kuaishou", "weibo", "bilibili"],
        threshold=req.threshold
    )
    return report


async def _storyboard_generate_logic(params: Dict[str, Any]) -> Dict[str, Any]:
    req = StoryboardRequest(**params["request"])
    return storyboard_generator.generate_storyboard(
        concept=req.concept,
        template_name=req.template or "fast_promo",
        duration=getattr(req, "duration", None),
        style=getattr(req, "style", "modern"),
    )


@router.post("/content/storyboard/generate", response_model=StoryboardResponse)
async def generate_storyboard(req: StoryboardRequest, response: Response):
    """
    è§†é¢‘è„šæœ¬/åˆ†é•œ/èŠ‚å¥æ¨¡æ¿ç”Ÿæˆï¼ˆå¢å¼ºç‰ˆï¼‰
    """
    execution_id, exec_result = await run_closed_loop_operation(
        module="content",
        function="storyboard_generate",
        parameters={"request": req.model_dump()},
        executor=_storyboard_generate_logic,
        metadata={"concept": req.concept},
    )
    response.headers["X-Execution-ID"] = execution_id
    return exec_result.get("result") or {}


@router.post("/douyin/complete-auth")
async def douyin_complete_auth(req: DouyinAuthCallbackRequest):
    result = douyin.complete_auth(req.code, req.state)
    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "æˆæƒå¤±è´¥"))
    return result


@router.get("/douyin/jobs")
async def douyin_list_jobs():
    return {"jobs": douyin.list_jobs()}


@router.get("/douyin/callbacks")
async def douyin_list_callbacks():
    return {"callbacks": douyin.list_callbacks()}


@router.post("/douyin/publish")
async def douyin_publish(req: DouyinPublishRequest):
    """
    æŠ–éŸ³å†…å®¹å‘å¸ƒï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆå»AIåŒ–ã€è¿è¥åˆ†æï¼‰
    """
    status = douyin.get_status()
    if not status.get("authorized"):
        raise HTTPException(status_code=403, detail="æŠ–éŸ³è´¦å·æœªæˆæƒ")
    
    # 1. åˆè§„æ£€æµ‹
    compliance = await content_compliance.check_text(req.content, req.references or [])
    if not compliance.get("success"):
        raise HTTPException(status_code=400, detail=f"åˆè§„æ£€æµ‹å¤±è´¥ï¼š{compliance.get('error','æœªçŸ¥é”™è¯¯')}")
    if compliance["originality_percent"] < req.min_originality:
        return {
            "success": False,
            "blocked": True,
            "reason": "åŸåˆ›åº¦ä¸è¶³",
            "compliance": compliance
        }
    if req.block_sensitive and compliance.get("sensitive_hits"):
        return {
            "success": False,
            "blocked": True,
            "reason": "å‘½ä¸­æ•æ„Ÿè¯",
            "compliance": compliance
        }
    
    # 2. å»AIåŒ–å¤„ç†ï¼ˆå¯é€‰ï¼‰
    processed_content = req.content
    deai_result = None
    if getattr(req, "deai_enabled", False):
        deai_result = deai_pipeline.process(
            content=req.content,
            style=getattr(req, "deai_style", "casual"),
            intensity=getattr(req, "deai_intensity", 0.5)
        )
        processed_content = deai_result["processed"]
    
    # 3. é£æ§è¯„ä¼°
    tags = req.tags or []
    risk = douyin.evaluate_risk(req.title, processed_content, tags)
    
    # 4. æäº¤å‘å¸ƒ
    job = douyin.submit_publication(
        title=req.title,
        content=processed_content,
        tags=tags,
        media_url=req.media_url,
        compliance=compliance,
        risk=risk
    )
    
    # 5. è®°å½•åˆ°è¿è¥åˆ†æï¼ˆå¦‚æœå‘å¸ƒæˆåŠŸï¼‰
    if job["status"] == "success" or job["status"] == "publishing":
        content_id = job.get("job_id") or f"content_{int(datetime.now().timestamp())}"
        content_analytics.record_publication(
            content_id=content_id,
            platform="douyin",
            title=req.title,
            tags=tags,
            published_at=datetime.now(),
            metadata={
                "job_id": job.get("job_id"),
                "deai_applied": deai_result is not None,
                "deai_score": deai_result["human_score"] if deai_result else None,
            }
        )
    
    return {
        "success": job["status"] == "success",
        "job": job,
        "risk": risk,
        "compliance": compliance,
        "deai": deai_result,
        "message": job.get("last_error")
    }


@router.post("/douyin/retry/{job_id}")
async def douyin_retry(job_id: str):
    try:
        job = douyin.retry_job(job_id)
        return {"success": job["status"] == "success", "job": job}
    except ValueError as exc:
        raise HTTPException(status_code=400, detail=str(exc))


@router.post("/douyin/webhook")
async def douyin_webhook(payload: DouyinWebhookPayload):
    """å¤„ç†æŠ–éŸ³Webhookå›è°ƒ"""
    event = douyin.handle_webhook(payload.dict())
    
    # å¦‚æœå‘å¸ƒæˆåŠŸï¼Œæ›´æ–°è¿è¥åˆ†ææ•°æ®
    if payload.status == "success" and payload.job_id:
        try:
            # æ¨¡æ‹Ÿè·å–ç»Ÿè®¡æ•°æ®ï¼ˆçœŸå®ç¯å¢ƒåº”ä»æŠ–éŸ³APIè·å–ï¼‰
            import random
            stats = {
                "views": random.randint(1000, 50000),
                "likes": random.randint(100, 5000),
                "comments": random.randint(50, 2000),
                "shares": random.randint(20, 1000),
                "followers_gained": random.randint(0, 100),
            }
            content_analytics.update_stats(payload.job_id, stats)
        except Exception as e:
            logger.warning(f"æ›´æ–°è¿è¥åˆ†æå¤±è´¥: {e}")
    
    return {"success": True, "event": event}


@router.get("/integrations/api-monitor")
async def list_api_calls(system: Optional[str] = None, limit: int = 50):
    """æŸ¥è¯¢ç¬¬ä¸‰æ–¹ API è°ƒç”¨è®°å½•"""
    records = api_monitor.list_recent(limit=limit, system=system)
    return {"success": True, "records": records, "count": len(records)}


@router.get("/integrations/api-monitor/stats")
async def api_monitor_statistics(system: Optional[str] = None, window_minutes: int = 60):
    """è·å– API è°ƒç”¨ç»Ÿè®¡"""
    stats = api_monitor.get_statistics(window_minutes=window_minutes, system=system)
    return {"success": True, "statistics": stats}


# ==================== P1-009: å†…å®¹åˆ›ä½œç³»ç»Ÿå…¨æµç¨‹ ====================

class DeAIRequest(BaseModel):
    """å»AIåŒ–è¯·æ±‚"""
    content: str = Field(..., description="åŸå§‹å†…å®¹")
    style: str = Field("casual", description="é£æ ¼ï¼ˆcasual/formal/creativeï¼‰")
    intensity: float = Field(0.5, ge=0.0, le=1.0, description="å¤„ç†å¼ºåº¦ï¼ˆ0.0-1.0ï¼‰")


class DeAIResponse(BaseModel):
    """å»AIåŒ–å“åº”"""
    original: str
    processed: str
    changes: List[str]
    ai_score: float
    human_score: float
    improvement: float
    style: str
    intensity: float


@router.post("/content/deai", response_model=DeAIResponse)
async def deai_process(req: DeAIRequest):
    """
    å†…å®¹å»AIåŒ–å¤„ç†
    """
    result = deai_pipeline.process(
        content=req.content,
        style=req.style,
        intensity=req.intensity
    )
    return result


@router.get("/content/analytics")
async def get_content_analytics(
    content_id: Optional[str] = Query(None),
    platform: Optional[str] = Query(None),
    days: int = Query(7, ge=1, le=90)
):
    """
    è·å–å†…å®¹è¿è¥åˆ†ææŠ¥å‘Š
    """
    result = content_analytics.get_analytics(
        content_id=content_id,
        platform=platform,
        days=days
    )
    return result


@router.get("/content/{content_id}/timeline")
async def get_content_timeline(content_id: str):
    """
    è·å–å†…å®¹ç”Ÿå‘½å‘¨æœŸæ—¶é—´çº¿
    """
    result = content_analytics.get_content_timeline(content_id)
    if not result.get("success"):
        raise HTTPException(status_code=404, detail=result.get("error", "å†…å®¹ä¸å­˜åœ¨"))
    return result


@router.post("/content/{content_id}/stats")
async def update_content_stats(
    content_id: str,
    stats: Dict[str, Any] = Body(...)
):
    """
    æ›´æ–°å†…å®¹ç»Ÿè®¡æ•°æ®
    """
    result = content_analytics.update_stats(content_id, stats)
    if not result.get("success"):
        raise HTTPException(status_code=404, detail=result.get("error", "å†…å®¹ä¸å­˜åœ¨"))
    return result

# ====== RAG é¢„å¤„ç†ä¸çœŸå®æ€§éªŒè¯ ======
class RagPreprocessRequest(BaseModel):
    text: str

class RagPreprocessPipelineRequest(BaseModel):
    text: str
    steps: Optional[List[str]] = None  # é»˜è®¤ä¸ºå…¨éƒ¨
    min_authenticity: float = 55.0

@router.post("/rag/preprocess/clean")
async def rag_preprocess_clean(req: RagPreprocessRequest):
    if rag_clean is None:
        raise HTTPException(status_code=503, detail="é¢„å¤„ç†æ¨¡å—æœªå°±ç»ª")
    cleaned = rag_clean(req.text)
    _record_rag_event("preprocess_clean", {"length": len(req.text)})
    return {"success": True, "text": cleaned}

@router.post("/rag/preprocess/standardize")
async def rag_preprocess_standardize(req: RagPreprocessRequest):
    if rag_standardize is None:
        raise HTTPException(status_code=503, detail="é¢„å¤„ç†æ¨¡å—æœªå°±ç»ª")
    normalized = rag_standardize(req.text)
    _record_rag_event("preprocess_standardize", {"length": len(req.text)})
    return {"success": True, "text": normalized}

@router.post("/rag/preprocess/deduplicate")
async def rag_preprocess_deduplicate(req: RagPreprocessRequest):
    if rag_dedup is None:
        raise HTTPException(status_code=503, detail="é¢„å¤„ç†æ¨¡å—æœªå°±ç»ª")
    res = rag_dedup(req.text)
    _record_rag_event("preprocess_deduplicate", {"removed": res.get("removed", 0)})
    return {"success": True, **res}

@router.post("/rag/preprocess/validate")
async def rag_preprocess_validate(req: RagPreprocessRequest):
    if rag_validate is None:
        raise HTTPException(status_code=503, detail="é¢„å¤„ç†æ¨¡å—æœªå°±ç»ª")
    res = rag_validate(req.text)
    _record_rag_event("preprocess_validate", {"valid": res.get("valid", True)})
    return {"success": True, **res}

@router.post("/rag/authenticity/check")
async def rag_authenticity_check(req: RagPreprocessRequest):
    if rag_auth_score is None:
        raise HTTPException(status_code=503, detail="çœŸå®æ€§æ¨¡å—æœªå°±ç»ª")
    res = rag_auth_score(req.text)
    _record_rag_event("authenticity_check", {"score": res.get("score")})
    return res

@router.post("/rag/preprocess/run")
async def rag_preprocess_pipeline(req: RagPreprocessPipelineRequest):
    if not req.text:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘æ–‡æœ¬")
    steps = req.steps or ["clean", "standardize", "deduplicate", "validate"]
    text = req.text
    outputs: Dict[str, Any] = {"original_length": len(text)}
    try:
        if "clean" in steps and rag_clean:
            text = rag_clean(text)
            outputs["clean"] = {"length": len(text)}
        if "standardize" in steps and rag_standardize:
            text = rag_standardize(text)
            outputs["standardize"] = {"length": len(text)}
        if "deduplicate" in steps and rag_dedup:
            dedup_result = rag_dedup(text)
            text = dedup_result.get("unique_text", text)
            outputs["deduplicate"] = dedup_result
        if "validate" in steps and rag_validate:
            outputs["validate"] = rag_validate(text)
        authenticity = rag_auth_score(text) if rag_auth_score else {"score": 0}
        outputs["authenticity"] = authenticity
        accepted = authenticity.get("score", 0) >= req.min_authenticity
        _record_rag_event("preprocess_pipeline", {
            "steps": steps,
            "accepted": accepted,
            "score": authenticity.get("score")
        })
        return {
            "success": True,
            "accepted": accepted,
            "text": text,
            "outputs": outputs
        }
    except Exception as exc:
        _record_rag_event("preprocess_pipeline_error", {"error": str(exc)})
        raise

# ====== RAG æµæ°´çº¿åŒ–ï¼šä¸Šä¼ â†’é¢„å¤„ç†â†’çœŸå®æ€§â†’å…¥åº“ï¼ˆæœ€å°å¯ç”¨ï¼‰ ======
class RagIngestRequest(BaseModel):
    text: Optional[str] = None
    title: Optional[str] = None
    run_clean: bool = True
    run_standardize: bool = True
    run_dedup: bool = True
    min_authenticity: float = 55.0


class SensitiveOperationRequest(BaseModel):
    applicant: str
    operation: str
    justification: str
    metadata: Optional[Dict[str, Any]] = None


class ApprovalDecisionRequest(BaseModel):
    reviewer: str
    reason: Optional[str] = None


async def _rag_pipeline_ingest_logic(params: Dict[str, Any]) -> Dict[str, Any]:
    req = RagIngestRequest(**params["request"])
    if not req.text:
        raise HTTPException(status_code=400, detail="ç¼ºå°‘æ–‡æœ¬")
    text = req.text
    steps: Dict[str, Any] = {}
    if req.run_clean and rag_clean:
        text = rag_clean(text)
        steps["clean"] = True
    if req.run_standardize and rag_standardize:
        text = rag_standardize(text)
        steps["standardize"] = True
    if req.run_dedup and rag_dedup:
        d = rag_dedup(text)
        text = d.get("unique_text", text)
        steps["deduplicate"] = {
            "removed": d.get("removed"),
            "kept": d.get("kept"),
        }
    valid = rag_validate(text) if rag_validate else {"valid": True}
    auth = rag_auth_score(text) if rag_auth_score else {"score": 100.0}
    accepted = auth.get("score", 0) >= req.min_authenticity and valid.get("valid", True)
    doc = {
        "id": f"doc_{int(datetime.now().timestamp() * 1000)}",
        "title": req.title or (text[:30] if text else "æ–‡æ¡£"),
        "content": text,
        "ingested_at": datetime.now().isoformat(),
        "authenticity": auth,
        "validation": valid,
    }
    try:
        with open(rag_store_path, "a", encoding="utf-8") as f:
            import json as _json

            f.write(_json.dumps(doc, ensure_ascii=False) + "\n")
    except Exception as exc:
        raise HTTPException(status_code=500, detail=f"æŒä¹…åŒ–å¤±è´¥: {str(exc)}")

    return {
        "success": True,
        "accepted": accepted,
        "document": doc,
        "steps": steps,
    }

@router.post("/rag/pipeline/ingest")
async def rag_pipeline_ingest(req: RagIngestRequest):
    execution_id, exec_result = await run_closed_loop_operation(
        module="rag",
        function="pipeline_ingest",
        parameters={"request": req.model_dump()},
        executor=_rag_pipeline_ingest_logic,
        metadata={"title": req.title},
    )
    payload = exec_result.get("result") or {}
    payload["execution_id"] = execution_id
    return payload

@router.get("/rag/pipeline/documents")
async def rag_pipeline_list_docs(limit: int = 20):
    """åˆ—å‡ºæœ€è¿‘å…¥åº“çš„RAGæ–‡æ¡£ï¼ˆå ä½å­˜å‚¨ï¼‰"""
    items = []
    try:
        if rag_store_path.exists():
            with open(rag_store_path, "r", encoding="utf-8") as f:
                lines = f.readlines()[-limit:]
                import json as _json
                for line in reversed(lines):
                    try:
                        items.append(_json.loads(line))
                    except Exception:
                        continue
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    return {"documents": items, "count": len(items)}

@router.get("/rag/pipeline/search")
async def rag_pipeline_search(q: str, limit: int = 10):
    """å ä½æ£€ç´¢ï¼šåŸºäºå­ä¸²ä¸ç®€å•å…³é”®è¯åŒ¹é…"""
    results = []
    try:
        if not rag_store_path.exists():
            return {"results": [], "count": 0}
        with open(rag_store_path, "r", encoding="utf-8") as f:
            import json as _json, re as _re
            kws = [k for k in _re.split(r"\W+", q) if k]
            for line in reversed(f.readlines()):
                try:
                    doc = _json.loads(line)
                except Exception:
                    continue
                text = (doc.get("title", "") + "\n" + doc.get("content", ""))
                score = 0
                if q in text:
                    score += 2
                score += sum(1 for k in kws if k and k in text)
                if score > 0:
                    results.append({"id": doc.get("id"), "title": doc.get("title"), "score": score})
                if len(results) >= limit:
                    break
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
    return {"results": results, "count": len(results)}

# ====== ç¼–ç¨‹åŠ©æ‰‹ï¼šCursor æ¡¥æ¥ ======
@router.get("/coding/cursor/status")
async def cursor_status():
    return cursor_bridge.get_status()

class CursorOpenRequest(BaseModel):
    file_path: str
    line_number: Optional[int] = None

@router.post("/coding/cursor/open-file")
async def cursor_open_file(req: CursorOpenRequest):
    result = await cursor_bridge.open_in_cursor(req.file_path, req.line_number)
    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "æ‰“å¼€å¤±è´¥"))
    return result

class CursorSyncRequest(BaseModel):
    file_path: str
    code: str

@router.post("/coding/cursor/sync-code")
async def cursor_sync_code(req: CursorSyncRequest):
    return await cursor_bridge.sync_code(req.file_path, req.code)

class CursorEdit(BaseModel):
    type: str
    start_line: int
    end_line: int
    content: Optional[str] = ""

class CursorEditRequest(BaseModel):
    file_path: str
    edits: List[CursorEdit]

@router.post("/coding/cursor/edit-code")
async def cursor_edit_code(req: CursorEditRequest):
    edits = [e.dict() for e in req.edits]
    return await cursor_bridge.edit_code(req.file_path, edits)

class CursorCompletionRequest(BaseModel):
    file_path: str
    line_number: int
    column: int
    context_lines: int = 5

@router.post("/coding/cursor/completion")
async def cursor_completion(req: CursorCompletionRequest):
    return await cursor_bridge.get_code_completion(req.file_path, req.line_number, req.column, req.context_lines)

class CursorDetectRequest(BaseModel):
    file_path: str

@router.post("/coding/cursor/detect-errors")
async def cursor_detect_errors(req: CursorDetectRequest):
    return await cursor_bridge.detect_errors(req.file_path)

class CursorProjectRequest(BaseModel):
    project_path: str
    files: Optional[List[str]] = None

# ==================== P3-014: AI ç¼–ç¨‹åŠ©æ‰‹ + Cursor é›†æˆ ====================

@router.post("/coding/documentation/generate-docstring")
async def generate_docstring(
    code: str = Body(..., embed=True),
    language: str = Body("python", embed=True),
    style: str = Body("google", embed=True)
):
    """
    ç”Ÿæˆæ–‡æ¡£å­—ç¬¦ä¸²
    """
    result = documentation_generator.generate_docstring(code, language, style)
    return result


@router.post("/coding/documentation/generate-api-doc")
async def generate_api_documentation(
    code: str = Body(..., embed=True),
    api_type: str = Body("rest", embed=True)
):
    """
    ç”ŸæˆAPIæ–‡æ¡£
    """
    result = documentation_generator.generate_api_documentation(code, api_type)
    return result


@router.post("/coding/documentation/generate-readme")
async def generate_readme(
    project_info: Dict[str, Any] = Body(...)
):
    """
    ç”ŸæˆREADMEæ–‡æ¡£
    """
    readme_content = documentation_generator.generate_readme(project_info)
    return {
        "success": True,
        "readme": readme_content,
        "generated_at": datetime.now().isoformat()
    }


@router.get("/coding/command-replay/history")
async def get_command_replay_history(
    limit: int = Query(50, ge=1, le=200),
    filter_command: Optional[str] = Query(None)
):
    """
    è·å–å‘½ä»¤å›æ”¾å†å²
    """
    history = command_replay.get_replay_history(limit, filter_command)
    return {
        "success": True,
        "history": history,
        "count": len(history)
    }


@router.post("/coding/command-replay/replay")
async def replay_command(
    command_id: Optional[str] = Body(None, embed=True),
    command: Optional[str] = Body(None, embed=True)
):
    """
    å›æ”¾å‘½ä»¤
    """
    result = command_replay.replay_command(command_id, command)
    return result


@router.get("/coding/cursor/status-enhanced")
async def get_cursor_status_enhanced():
    """
    è·å–CursorçŠ¶æ€ï¼ˆå¢å¼ºç‰ˆï¼‰
    """
    status = cursor_ide_integration.get_status()
    return {
        "success": True,
        "status": status
    }


@router.post("/coding/cursor/open-file-enhanced")
async def open_file_in_cursor_enhanced(
    file_path: str = Body(..., embed=True),
    line_number: Optional[int] = Body(None, embed=True)
):
    """
    åœ¨Cursorä¸­æ‰“å¼€æ–‡ä»¶ï¼ˆå¢å¼ºç‰ˆï¼‰
    """
    result = await cursor_ide_integration.open_file(file_path, line_number)
    return result


@router.post("/coding/cursor/apply-edits")
async def apply_edits_in_cursor(
    file_path: str = Body(..., embed=True),
    edits: List[Dict[str, Any]] = Body(...)
):
    """
    åœ¨Cursorä¸­åº”ç”¨ä»£ç ç¼–è¾‘
    """
    result = await cursor_ide_integration.apply_edits(file_path, edits)
    return result


@router.post("/coding/sandbox/link-main-interface")
async def link_sandbox_to_main_interface(
    command_id: str = Body(..., embed=True),
    action: str = Body(..., embed=True)  # execute, review, optimize
):
    """
    å®‰å…¨æ²™ç®±ä¸ä¸»ç•Œé¢è”åŠ¨
    å°†æ²™ç®±ä¸­çš„å‘½ä»¤æ‰§è¡Œç»“æœåŒæ­¥åˆ°ä¸»ç•Œé¢
    """
    # æŸ¥æ‰¾å‘½ä»¤è®°å½•
    command_record = next(
        (r for r in terminal_executor.command_history if r.command_id == command_id),
        None
    )
    
    if not command_record:
        return {
            "success": False,
            "error": f"æœªæ‰¾åˆ°å‘½ä»¤ID: {command_id}"
        }
    
    # æ ¹æ®actionæ‰§è¡Œç›¸åº”æ“ä½œ
    if action == "execute":
        # è®°å½•åˆ°å‘½ä»¤å›æ”¾ç³»ç»Ÿ
        command_replay.record_command(
            command=command_record.command,
            result={
                "success": command_record.success,
                "return_code": command_record.return_code,
                "error": command_record.error
            },
            metadata={
                "command_id": command_id,
                "timestamp": command_record.timestamp,
                "cwd": command_record.cwd
            }
        )
    
    return {
        "success": True,
        "command_id": command_id,
        "action": action,
        "linked_at": datetime.now().isoformat(),
        "command": command_record.command
    }


@router.get("/coding/sandbox/main-interface-status")
async def get_sandbox_main_interface_status():
    """
    è·å–æ²™ç®±ä¸ä¸»ç•Œé¢è”åŠ¨çŠ¶æ€
    """
    return {
        "success": True,
        "sandbox_enabled": terminal_executor.sandbox_enabled,
        "sandbox_dir": str(terminal_executor.sandbox_dir) if terminal_executor.sandbox_dir else None,
        "command_history_count": len(terminal_executor.command_history),
        "replay_history_count": len(command_replay.replay_history),
        "cursor_available": cursor_ide_integration.is_cursor_available
    }


@router.post("/coding/review")
async def review_code(
    code: str = Body(..., embed=True),
    language: str = Body("python", embed=True)
):
    """
    ä»£ç å®¡æŸ¥ï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆç¼–ç¨‹åŠ©æ‰‹ï¼‰
    """
    try:
        # å°è¯•å¯¼å…¥ç¼–ç¨‹åŠ©æ‰‹çš„ä»£ç å®¡æŸ¥å™¨
        try:
            import sys
            coding_module_path = project_root / "ğŸ’» AI Programming Assistant"
            if str(coding_module_path) not in sys.path:
                sys.path.insert(0, str(coding_module_path))
            from core.code_reviewer import CodeReviewer
            reviewer = CodeReviewer()
            result = await reviewer.review_code(code, language)
            return result
        except ImportError:
            # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œè¿”å›ç®€åŒ–ç»“æœ
            return {
                "success": True,
                "issues": [],
                "suggestions": ["å»ºè®®ä½¿ç”¨å®Œæ•´çš„ä»£ç å®¡æŸ¥åŠŸèƒ½"],
                "score": 100,
                "summary": {
                    "total_issues": 0,
                    "critical": 0,
                    "high": 0,
                    "medium": 0,
                    "low": 0
                }
            }
    except Exception as e:
        logger.error(f"ä»£ç å®¡æŸ¥å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@router.post("/coding/optimize")
async def optimize_code(
    problem_description: str = Body(..., embed=True),
    context: Optional[Dict[str, Any]] = Body(None, embed=True)
):
    """
    æ€§èƒ½ä¼˜åŒ–ï¼ˆå¢å¼ºç‰ˆï¼šé›†æˆç¼–ç¨‹åŠ©æ‰‹ï¼‰
    """
    try:
        # å°è¯•å¯¼å…¥ç¼–ç¨‹åŠ©æ‰‹çš„ä»£ç ä¼˜åŒ–å™¨
        try:
            import sys
            coding_module_path = project_root / "ğŸ’» AI Programming Assistant"
            if str(coding_module_path) not in sys.path:
                sys.path.insert(0, str(coding_module_path))
            from core.code_optimizer import CodeOptimizer
            optimizer = CodeOptimizer()
            result = await optimizer.optimize_performance(problem_description, context)
            return result
        except ImportError:
            # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œè¿”å›é€šç”¨å»ºè®®
            return {
                "success": True,
                "optimization": {
                    "problem": problem_description,
                    "suggestions": [
                        "ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—",
                        "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢",
                        "ä½¿ç”¨å¼‚æ­¥å¤„ç†",
                        "å‡å°‘ä¸å¿…è¦çš„å¾ªç¯"
                    ],
                    "optimized_code": "# ä¼˜åŒ–åçš„ä»£ç \n# TODO: æä¾›ä»£ç ä»¥è¿›è¡Œä¼˜åŒ–",
                    "expected_improvement": "å“åº”æ—¶é—´å‡å°‘50%"
                }
            }
    except Exception as e:
        logger.error(f"æ€§èƒ½ä¼˜åŒ–å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@router.post("/coding/cursor/open-project")
async def cursor_open_project(req: CursorProjectRequest):
    result = await cursor_bridge.sync_project(req.project_path, req.files)
    if not result.get("success"):
        raise HTTPException(status_code=400, detail=result.get("error", "æ‰“å¼€é¡¹ç›®å¤±è´¥"))
    return result


# ============ P0-016: Cursoråè®®/æ’ä»¶/æœ¬åœ°æ¡¥/æˆæƒç³»ç»Ÿ ============

@router.post("/cursor/protocol/start")
async def start_cursor_protocol():
    """å¯åŠ¨Cursoråè®®æœåŠ¡å™¨"""
    if not cursor_protocol:
        raise HTTPException(status_code=503, detail="Cursoråè®®æœªåˆå§‹åŒ–")
    
    await cursor_local_bridge.start()
    return {"success": True, "message": "Cursoråè®®æœåŠ¡å™¨å·²å¯åŠ¨"}


@router.post("/cursor/protocol/stop")
async def stop_cursor_protocol():
    """åœæ­¢Cursoråè®®æœåŠ¡å™¨"""
    if not cursor_protocol:
        raise HTTPException(status_code=503, detail="Cursoråè®®æœªåˆå§‹åŒ–")
    
    await cursor_local_bridge.stop()
    return {"success": True, "message": "Cursoråè®®æœåŠ¡å™¨å·²åœæ­¢"}


@router.post("/cursor/protocol/send")
async def send_cursor_protocol_message(
    command: str,
    params: Dict[str, Any],
    token_id: Optional[str] = None
):
    """
    å‘é€Cursoråè®®æ¶ˆæ¯
    
    Args:
        command: å‘½ä»¤åç§°
        params: å‘½ä»¤å‚æ•°
        token_id: æˆæƒä»¤ç‰ŒIDï¼ˆå¯é€‰ï¼‰
    """
    if not cursor_protocol:
        raise HTTPException(status_code=503, detail="Cursoråè®®æœªåˆå§‹åŒ–")
    
    # éªŒè¯æˆæƒ
    if token_id and not cursor_authorization.validate_token(token_id):
        raise HTTPException(status_code=401, detail="æ— æ•ˆçš„æˆæƒä»¤ç‰Œ")
    
    try:
        cmd = ProtocolCommand(command)
        message = await cursor_local_bridge.send_to_cursor(cmd, params)
        
        return {
            "success": message.message_type.value != "error",
            "message_type": message.message_type.value,
            "result": message.result,
            "error": message.error
        }
    except ValueError:
        raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„å‘½ä»¤: {command}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/cursor/plugins/load")
async def load_cursor_plugin(
    plugin_path: str,
    config: Optional[Dict[str, Any]] = None
):
    """
    åŠ è½½Cursoræ’ä»¶
    
    Args:
        plugin_path: æ’ä»¶è·¯å¾„
        config: æ’ä»¶é…ç½®ï¼ˆå¯é€‰ï¼‰
    """
    if not cursor_plugin_system:
        raise HTTPException(status_code=503, detail="æ’ä»¶ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        plugin = cursor_plugin_system.load_plugin(plugin_path, config)
        return {
            "success": True,
            "plugin": {
                "plugin_id": plugin.metadata.plugin_id,
                "name": plugin.metadata.name,
                "version": plugin.metadata.version,
                "status": plugin.status.value
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/cursor/plugins")
async def list_cursor_plugins():
    """åˆ—å‡ºæ‰€æœ‰Cursoræ’ä»¶"""
    if not cursor_plugin_system:
        raise HTTPException(status_code=503, detail="æ’ä»¶ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    plugins = cursor_plugin_system.list_plugins()
    return {"success": True, "plugins": plugins}


@router.post("/cursor/plugins/{plugin_id}/enable")
async def enable_cursor_plugin(plugin_id: str):
    """å¯ç”¨Cursoræ’ä»¶"""
    if not cursor_plugin_system:
        raise HTTPException(status_code=503, detail="æ’ä»¶ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        cursor_plugin_system.enable_plugin(plugin_id)
        return {"success": True, "message": f"æ’ä»¶å·²å¯ç”¨: {plugin_id}"}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.post("/cursor/plugins/{plugin_id}/disable")
async def disable_cursor_plugin(plugin_id: str):
    """ç¦ç”¨Cursoræ’ä»¶"""
    if not cursor_plugin_system:
        raise HTTPException(status_code=503, detail="æ’ä»¶ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        cursor_plugin_system.disable_plugin(plugin_id)
        return {"success": True, "message": f"æ’ä»¶å·²ç¦ç”¨: {plugin_id}"}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.delete("/cursor/plugins/{plugin_id}")
async def unload_cursor_plugin(plugin_id: str):
    """å¸è½½Cursoræ’ä»¶"""
    if not cursor_plugin_system:
        raise HTTPException(status_code=503, detail="æ’ä»¶ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        cursor_plugin_system.unload_plugin(plugin_id)
        return {"success": True, "message": f"æ’ä»¶å·²å¸è½½: {plugin_id}"}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.post("/cursor/authorization/create-token")
async def create_cursor_token(
    client_id: str,
    authorization_level: str,
    access_scope: str,
    allowed_paths: Optional[List[str]] = None,
    denied_paths: Optional[List[str]] = None,
    expires_in_hours: Optional[int] = None
):
    """
    åˆ›å»ºCursoræˆæƒä»¤ç‰Œ
    
    Args:
        client_id: å®¢æˆ·ç«¯ID
        authorization_level: æˆæƒçº§åˆ«ï¼ˆnone/read_only/limited/standard/fullï¼‰
        access_scope: è®¿é—®èŒƒå›´ï¼ˆsingle_file/project/workspace/systemï¼‰
        allowed_paths: å…è®¸çš„è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        denied_paths: æ‹’ç»çš„è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        expires_in_hours: è¿‡æœŸæ—¶é—´ï¼ˆå°æ—¶ï¼Œå¯é€‰ï¼‰
    """
    if not cursor_authorization:
        raise HTTPException(status_code=503, detail="æˆæƒç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        level = AuthorizationLevel(authorization_level)
        scope = AccessScope(access_scope)
        
        token = cursor_authorization.create_token(
            client_id=client_id,
            authorization_level=level,
            access_scope=scope,
            allowed_paths=allowed_paths,
            denied_paths=denied_paths,
            expires_in_hours=expires_in_hours
        )
        
        return {
            "success": True,
            "token": {
                "token_id": token.token_id,
                "client_id": token.client_id,
                "authorization_level": token.authorization_level.value,
                "access_scope": token.access_scope.value,
                "expires_at": token.expires_at.isoformat() if token.expires_at else None
            }
        }
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))


@router.post("/cursor/authorization/validate")
async def validate_cursor_token(token_id: str):
    """éªŒè¯Cursoræˆæƒä»¤ç‰Œ"""
    if not cursor_authorization:
        raise HTTPException(status_code=503, detail="æˆæƒç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    is_valid = cursor_authorization.validate_token(token_id)
    token = cursor_authorization.get_token(token_id)
    
    return {
        "success": True,
        "is_valid": is_valid,
        "token": {
            "token_id": token_id,
            "authorization_level": token.authorization_level.value if token else None,
            "expires_at": token.expires_at.isoformat() if token and token.expires_at else None
        } if token else None
    }


@router.post("/cursor/authorization/check-permission")
async def check_cursor_permission(
    token_id: str,
    resource_type: str,
    resource_path: str,
    action: str
):
    """
    æ£€æŸ¥Cursoræƒé™
    
    Args:
        token_id: ä»¤ç‰ŒID
        resource_type: èµ„æºç±»å‹
        resource_path: èµ„æºè·¯å¾„
        action: æ“ä½œï¼ˆread/write/executeï¼‰
    """
    if not cursor_authorization:
        raise HTTPException(status_code=503, detail="æˆæƒç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    has_permission = cursor_authorization.check_permission(
        token_id, resource_type, resource_path, action
    )
    
    return {
        "success": True,
        "has_permission": has_permission,
        "resource_type": resource_type,
        "resource_path": resource_path,
        "action": action
    }


@router.delete("/cursor/authorization/tokens/{token_id}")
async def revoke_cursor_token(token_id: str, reason: Optional[str] = None):
    """æ’¤é”€Cursoræˆæƒä»¤ç‰Œ"""
    if not cursor_authorization:
        raise HTTPException(status_code=503, detail="æˆæƒç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    cursor_authorization.revoke_token(token_id, reason)
    return {"success": True, "message": f"ä»¤ç‰Œå·²æ’¤é”€: {token_id}"}


@router.get("/cursor/authorization/tokens")
async def list_cursor_tokens(client_id: Optional[str] = None):
    """åˆ—å‡ºCursoræˆæƒä»¤ç‰Œ"""
    if not cursor_authorization:
        raise HTTPException(status_code=503, detail="æˆæƒç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    tokens = cursor_authorization.list_tokens(client_id)
    return {"success": True, "tokens": tokens}


@router.get("/cursor/authorization/audit-log")
async def get_cursor_audit_log(
    token_id: Optional[str] = None,
    event_type: Optional[str] = None,
    limit: int = 100
):
    """è·å–Cursorå®¡è®¡æ—¥å¿—"""
    if not cursor_authorization:
        raise HTTPException(status_code=503, detail="æˆæƒç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    logs = cursor_authorization.get_audit_log(token_id, event_type, limit)
    return {"success": True, "logs": logs, "count": len(logs)}


@router.get("/cursor/bridge/status")
async def get_cursor_bridge_status():
    """è·å–Cursoræ¡¥æ¥çŠ¶æ€"""
    if not cursor_local_bridge:
        raise HTTPException(status_code=503, detail="æœ¬åœ°æ¡¥æ¥æœªåˆå§‹åŒ–")
    
    status = cursor_local_bridge.get_status()
    return {"success": True, "status": status}


@router.get("/cursor/bridge/connections")
async def list_cursor_bridge_connections():
    """åˆ—å‡ºCursoræ¡¥æ¥è¿æ¥"""
    if not cursor_local_bridge:
        raise HTTPException(status_code=503, detail="æœ¬åœ°æ¡¥æ¥æœªåˆå§‹åŒ–")
    
    connections = cursor_local_bridge.list_connections()
    return {"success": True, "connections": connections}


@router.get("/cursor/authorization/statistics")
async def get_cursor_authorization_statistics():
    """è·å–Cursoræˆæƒç»Ÿè®¡ä¿¡æ¯"""
    if not cursor_authorization:
        raise HTTPException(status_code=503, detail="æˆæƒç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    stats = cursor_authorization.get_statistics()
    return {"success": True, "statistics": stats}


# ============ P0-017: å®‰å…¨ä¸åˆè§„åŸºçº¿ ============

@router.post("/security/crawler/check", dependencies=[security_read_dep])
async def check_crawler_security(
    url: str,
    source: str = "system",
    user_agent: Optional[str] = None,
    client_ip: Optional[str] = None,
):
    """
    æ£€æŸ¥çˆ¬è™«è¯·æ±‚å®‰å…¨æ€§
    """
    compliance = crawler_compliance_service.evaluate(user_agent, url, client_ip)
    baseline_result = None
    if security_compliance_baseline:
        baseline_result = await security_compliance_baseline.check_crawler_request(url, source)
    result = {"crawler_policy": compliance, "baseline": baseline_result}
    if audit_pipeline:
        audit_pipeline.log_security_event(
            event_type="crawler.check",
            source="api",
            severity="warning" if not compliance["allowed"] else "info",
            metadata=result,
        )
    return {"success": True, "result": result}


@router.post("/security/content/check", dependencies=[security_read_dep])
async def check_content_security(
    content: str,
    content_type: str = "text",
    source: str = "system"
):
    """
    æ£€æŸ¥å†…å®¹å®‰å…¨æ€§
    
    Args:
        content: å†…å®¹
        content_type: å†…å®¹ç±»å‹
        source: æ¥æº
    """
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    result = await security_compliance_baseline.check_content_security(content, content_type, source)
    return {"success": True, "result": result}


@router.post("/security/data/check-permission", dependencies=[security_read_dep])
async def check_data_permission(
    resource_path: str,
    action: str,
    user_id: str,
    user_permissions: Optional[List[str]] = None
):
    """
    æ£€æŸ¥æ•°æ®æƒé™
    
    Args:
        resource_path: èµ„æºè·¯å¾„
        action: æ“ä½œç±»å‹ï¼ˆread/write/deleteï¼‰
        user_id: ç”¨æˆ·ID
        user_permissions: ç”¨æˆ·æƒé™åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
    """
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    result = await security_compliance_baseline.check_data_permission(
        resource_path, action, user_id, user_permissions
    )
    return {"success": True, "result": result}


@router.post("/security/command/check", dependencies=[security_read_dep])
async def check_command_security(
    command: str,
    source: str = "system"
):
    """
    æ£€æŸ¥å‘½ä»¤å®‰å…¨æ€§
    
    Args:
        command: å‘½ä»¤
        source: æ¥æº
    """
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    result = await security_compliance_baseline.check_command_security(command, source)
    return {"success": True, "result": result}


@router.post("/security/privacy/check", dependencies=[security_read_dep])
async def check_privacy_compliance(
    data: str,
    data_type: str = "text",
    source: str = "system"
):
    """
    æ£€æŸ¥éšç§åˆè§„æ€§
    
    Args:
        data: æ•°æ®
        data_type: æ•°æ®ç±»å‹
        source: æ¥æº
    """
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    result = await security_compliance_baseline.check_privacy_compliance(data, data_type, source)
    return {"success": True, "result": result}


@router.post("/security/approvals/request", dependencies=[security_write_dep])
async def submit_sensitive_operation(req: SensitiveOperationRequest):
    approval = approval_manager.submit_request(
        applicant=req.applicant,
        operation=req.operation,
        justification=req.justification,
        metadata=req.metadata,
    )
    return {"success": True, "approval": asdict(approval)}


@router.post("/security/approvals/{approval_id}/approve", dependencies=[security_write_dep])
async def approve_sensitive_operation(approval_id: str, decision: ApprovalDecisionRequest):
    approval = approval_manager.approve(approval_id, decision.reviewer, decision.reason)
    if not approval:
        raise HTTPException(status_code=404, detail="å®¡æ‰¹ä¸å­˜åœ¨")
    return {"success": True, "approval": asdict(approval)}


@router.post("/security/approvals/{approval_id}/reject", dependencies=[security_write_dep])
async def reject_sensitive_operation(approval_id: str, decision: ApprovalDecisionRequest):
    approval = approval_manager.reject(approval_id, decision.reviewer, decision.reason)
    if not approval:
        raise HTTPException(status_code=404, detail="å®¡æ‰¹ä¸å­˜åœ¨")
    return {"success": True, "approval": asdict(approval)}


@router.get("/security/approvals/{approval_id}", dependencies=[security_read_dep])
async def get_sensitive_operation(approval_id: str):
    approval = approval_manager.get_request(approval_id)
    if not approval:
        raise HTTPException(status_code=404, detail="å®¡æ‰¹ä¸å­˜åœ¨")
    return {"success": True, "approval": asdict(approval)}


@router.get("/security/approvals/pending", dependencies=[security_read_dep])
async def list_pending_approvals(limit: int = 50):
    rows = approval_manager.list_requests(status=ApprovalStatus.PENDING, limit=limit)
    return {"success": True, "approvals": rows}


@router.get("/security/violations", dependencies=[security_read_dep])
async def get_security_violations(
    category: Optional[str] = None,
    severity: Optional[str] = None,
    limit: int = 100
):
    """
    è·å–å®‰å…¨è¿è§„è®°å½•
    
    Args:
        category: ç±»åˆ«ç­›é€‰ï¼ˆcrawler/content/data/command/privacyï¼‰
        severity: ä¸¥é‡ç¨‹åº¦ç­›é€‰ï¼ˆlow/medium/high/criticalï¼‰
        limit: è¿”å›æ•°é‡é™åˆ¶
    """
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    category_enum = None
    if category:
        try:
            category_enum = ComplianceCategory(category)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ç±»åˆ«: {category}")
    
    severity_enum = None
    if severity:
        try:
            severity_enum = SecurityLevel(severity)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ä¸¥é‡ç¨‹åº¦: {severity}")
    
    violations = security_compliance_baseline.get_violations(category_enum, severity_enum, limit)
    return {"success": True, "violations": violations, "count": len(violations)}


@router.get("/security/audit-log", dependencies=[security_read_dep])
async def get_security_audit_log(
    event_type: Optional[str] = None,
    severity: Optional[str] = None,
    limit: int = 1000
):
    """
    è·å–å®‰å…¨å®¡è®¡æ—¥å¿—
    
    Args:
        event_type: äº‹ä»¶ç±»å‹ç­›é€‰ï¼ˆå¯é€‰ï¼‰
        severity: ä¸¥é‡ç¨‹åº¦ç­›é€‰ï¼ˆå¯é€‰ï¼‰
        limit: è¿”å›æ•°é‡é™åˆ¶
    """
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    logs = security_compliance_baseline.get_audit_log(event_type, severity, limit)
    return {"success": True, "logs": logs, "count": len(logs)}


@router.get("/security/policies", dependencies=[security_read_dep])
async def list_security_policies():
    """åˆ—å‡ºæ‰€æœ‰å®‰å…¨åˆè§„ç­–ç•¥"""
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    policies = security_compliance_baseline.list_policies()
    return {"success": True, "policies": policies}


@router.get("/security/policies/{policy_id}", dependencies=[security_read_dep])
async def get_security_policy(policy_id: str):
    """è·å–å®‰å…¨åˆè§„ç­–ç•¥"""
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    policy = security_compliance_baseline.get_policy(policy_id)
    if not policy:
        raise HTTPException(status_code=404, detail="ç­–ç•¥ä¸å­˜åœ¨")
    
    return {"success": True, "policy": policy}


@router.put("/security/policies/{policy_id}", dependencies=[security_write_dep])
async def update_security_policy(
    policy_id: str,
    rules: Optional[Dict[str, Any]] = None,
    enabled: Optional[bool] = None
):
    """
    æ›´æ–°å®‰å…¨åˆè§„ç­–ç•¥
    
    Args:
        policy_id: ç­–ç•¥ID
        rules: æ–°è§„åˆ™ï¼ˆå¯é€‰ï¼‰
        enabled: æ˜¯å¦å¯ç”¨ï¼ˆå¯é€‰ï¼‰
    """
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        result = security_compliance_baseline.update_policy(policy_id, rules, enabled)
        return {"success": True, "result": result}
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get("/security/statistics", dependencies=[security_read_dep])
async def get_security_statistics():
    """è·å–å®‰å…¨åˆè§„ç»Ÿè®¡ä¿¡æ¯"""
    if not security_compliance_baseline:
        raise HTTPException(status_code=503, detail="å®‰å…¨åˆè§„åŸºçº¿ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    stats = security_compliance_baseline.get_statistics()
    return {"success": True, "statistics": stats}


@router.get("/security/risk/summary", dependencies=[security_read_dep])
async def get_security_risk_summary():
    """è·å–é£æ§æ¦‚è§ˆ"""
    summary = risk_engine.get_summary() if risk_engine else {}
    return {"success": True, "summary": summary}


@router.get("/security/risk/events", dependencies=[security_read_dep])
async def get_security_risk_events(limit: int = 50):
    """è·å–é£æ§äº‹ä»¶åˆ—è¡¨"""
    events = risk_engine.list_events(limit) if risk_engine else []
    return {"success": True, "events": events, "count": len(events)}


# ============ P1-001: æ¨¡å—ä¸‰çº§ç•Œé¢ ============


@router.get("/modules/tree")
async def get_module_tree():
    """è·å–æ‰€æœ‰æ¨¡å—çš„ä¸‰çº§ç•Œé¢ç»“æ„"""
    modules = await module_registry.get_tree()
    return {"success": True, "modules": modules}


@router.get("/modules/view-data")
async def get_module_view_data(module: str, stage: str, view: str):
    """è·å–æŒ‡å®šè§†å›¾çš„å®æ—¶æ•°æ®"""
    try:
        data = await module_registry.get_view_data(module, stage, view)
    except KeyError as exc:
        raise HTTPException(status_code=404, detail=str(exc))
    return {"success": True, "module": module, "stage": stage, "view": view, "data": data}


@router.get("/modules/view-capabilities")
async def get_module_view_capabilities(module: str, stage: str, view: str):
    """è·å–è§†å›¾å¯¹åº”çš„å››çº§èƒ½åŠ›å•å…ƒ"""
    capabilities = FOUR_LEVEL_FUNCTIONS.get(module, {}).get(stage, {}).get(view, [])
    return {
        "success": True,
        "module": module,
        "stage": stage,
        "view": view,
        "capabilities": capabilities,
    }


@router.get("/modules/chains")
async def list_module_chains(refresh: bool = Query(False, description="æ˜¯å¦å¼ºåˆ¶åˆ·æ–°é“¾è·¯")):
    chains = await module_chain_manager.list_chains(refresh=refresh)
    return {"success": True, "chains": chains, "count": len(chains)}


@router.get("/modules/chains/{module_id}")
async def get_module_chain_entry(module_id: str):
    try:
        chain = await module_chain_manager.get_chain(module_id)
    except KeyError:
        raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°æ¨¡å—é“¾è·¯: {module_id}")
    return {"success": True, "chain": chain}


@router.post("/modules/chains/refresh", dependencies=[security_read_dep])
async def refresh_module_chains():
    chains = await module_chain_manager.refresh()
    return {"success": True, "chains": chains, "count": len(chains)}


# ============ P0-018: å¯è§‚æµ‹æ€§ç³»ç»Ÿ ============

@router.get("/observability/traces/{trace_id}")
async def get_trace(trace_id: str):
    """è·å–Traceè¯¦æƒ…"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    trace = observability_system.get_trace(trace_id)
    if not trace:
        raise HTTPException(status_code=404, detail="Traceä¸å­˜åœ¨")
    
    return {"success": True, "trace": trace.to_dict()}


@router.get("/observability/traces")
async def list_traces(
    request_id: Optional[str] = None,
    service_name: Optional[str] = None,
    limit: int = 100
):
    """åˆ—å‡ºTrace"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    if request_id:
        trace = observability_system.get_trace_by_request_id(request_id)
        if trace:
            return {"success": True, "traces": [trace.to_dict()], "count": 1}
        return {"success": True, "traces": [], "count": 0}
    
    # è¿”å›æ´»è·ƒçš„Trace
    active_traces = observability_system.get_active_traces()
    return {"success": True, "traces": active_traces[:limit], "count": len(active_traces)}


@router.get("/observability/long-tasks")
async def list_long_tasks(
    task_type: Optional[str] = None,
    status: Optional[str] = None,
    limit: int = 100
):
    """åˆ—å‡ºé•¿ä»»åŠ¡"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    active_tasks = observability_system.get_active_long_tasks()
    
    # è¿‡æ»¤
    if task_type:
        active_tasks = [t for t in active_tasks if t.get("task_type") == task_type]
    if status:
        active_tasks = [t for t in active_tasks if t.get("status") == status]
    
    return {"success": True, "tasks": active_tasks[:limit], "count": len(active_tasks)}


@router.get("/observability/long-tasks/{task_id}")
async def get_long_task(task_id: str):
    """è·å–é•¿ä»»åŠ¡è¯¦æƒ…"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    task = observability_system.get_long_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    
    return {"success": True, "task": task.to_dict()}


@router.get("/observability/long-tasks/{task_id}/replay")
async def get_long_task_replay(task_id: str):
    """è·å–é•¿ä»»åŠ¡å›æ”¾æ•°æ®"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    replay_data = observability_system.get_long_task_replay(task_id)
    if not replay_data:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–æ²¡æœ‰å›æ”¾æ•°æ®")
    
    return {"success": True, "replay": replay_data}


@router.post("/observability/long-tasks")
async def create_long_task(
    name: str,
    task_type: str,
    trace_id: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None
):
    """åˆ›å»ºé•¿ä»»åŠ¡"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    task = observability_system.create_long_task(
        name=name,
        task_type=task_type,
        trace_id=trace_id,
        metadata=metadata
    )
    
    return {"success": True, "task": task.to_dict()}


@router.put("/observability/long-tasks/{task_id}/progress")
async def update_long_task_progress(
    task_id: str,
    progress: float,
    step: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None
):
    """æ›´æ–°é•¿ä»»åŠ¡è¿›åº¦"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    observability_system.update_long_task_progress(
        task_id=task_id,
        progress=progress,
        step=step,
        metadata=metadata
    )
    
    return {"success": True, "message": "è¿›åº¦å·²æ›´æ–°"}


@router.post("/observability/long-tasks/{task_id}/complete")
async def complete_long_task(
    task_id: str,
    status: str = "completed",
    error: Optional[str] = None
):
    """å®Œæˆé•¿ä»»åŠ¡"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    observability_system.complete_long_task(
        task_id=task_id,
        status=status,
        error=error
    )
    
    return {"success": True, "message": "ä»»åŠ¡å·²å®Œæˆ"}


@router.get("/observability/metrics")
async def get_metrics(
    name: Optional[str] = None,
    start_time: Optional[float] = None,
    end_time: Optional[float] = None,
    tags: Optional[Dict[str, str]] = None
):
    """è·å–æŒ‡æ ‡"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    metrics = observability_system.get_metrics(
        name=name,
        start_time=start_time,
        end_time=end_time,
        tags=tags
    )
    
    return {
        "success": True,
        "metrics": [
            {
                "name": m.name,
                "value": m.value,
                "timestamp": m.timestamp,
                "tags": m.tags,
                "metric_type": m.metric_type
            }
            for m in metrics
        ],
        "count": len(metrics)
    }


@router.post("/observability/metrics")
async def record_metric(
    name: str,
    value: float,
    tags: Optional[Dict[str, str]] = None,
    metric_type: str = "gauge"
):
    """è®°å½•æŒ‡æ ‡"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    observability_system.record_metric(
        name=name,
        value=value,
        tags=tags,
        metric_type=metric_type
    )
    
    return {"success": True, "message": "æŒ‡æ ‡å·²è®°å½•"}


@router.post("/observability/events")
async def track_event(
    event_name: str,
    trace_id: Optional[str] = None,
    span_id: Optional[str] = None,
    properties: Optional[Dict[str, Any]] = None,
    level: str = "info"
):
    """åŸ‹ç‚¹äº‹ä»¶"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    observability_system.track_event(
        event_name=event_name,
        trace_id=trace_id,
        span_id=span_id,
        properties=properties,
        level=level
    )
    
    return {"success": True, "message": "äº‹ä»¶å·²è®°å½•"}


@router.get("/observability/events")
async def get_events(
    event_name: Optional[str] = None,
    trace_id: Optional[str] = None,
    start_time: Optional[float] = None,
    end_time: Optional[float] = None,
    limit: int = 1000
):
    """è·å–åŸ‹ç‚¹äº‹ä»¶"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    events = observability_system.get_events(
        event_name=event_name,
        trace_id=trace_id,
        start_time=start_time,
        end_time=end_time,
        limit=limit
    )
    
    return {"success": True, "events": events, "count": len(events)}


@router.get("/observability/statistics")
async def get_observability_statistics():
    """è·å–å¯è§‚æµ‹æ€§ç»Ÿè®¡ä¿¡æ¯"""
    if not observability_system:
        raise HTTPException(status_code=503, detail="å¯è§‚æµ‹æ€§ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    stats = observability_system.get_statistics()
    return {"success": True, "statistics": stats}


# ============ P0-018: å‘Šè­¦ç³»ç»Ÿ ============

@router.get("/observability/alerts")
async def get_alerts(
    rule_id: Optional[str] = None,
    severity: Optional[str] = None,
    resolved: Optional[bool] = None,
    limit: int = 100
):
    """è·å–å‘Šè­¦åˆ—è¡¨"""
    if not observability_alerts:
        raise HTTPException(status_code=503, detail="å‘Šè­¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    severity_enum = None
    if severity:
        try:
            severity_enum = AlertSeverity(severity)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ä¸¥é‡ç¨‹åº¦: {severity}")
    
    alerts = observability_alerts.get_alerts(rule_id, severity_enum, resolved, limit)
    return {"success": True, "alerts": alerts, "count": len(alerts)}


@router.post("/observability/alerts/{alert_id}/resolve")
async def resolve_alert(alert_id: str):
    """è§£å†³å‘Šè­¦"""
    if not observability_alerts:
        raise HTTPException(status_code=503, detail="å‘Šè­¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    success = observability_alerts.resolve_alert(alert_id)
    if not success:
        raise HTTPException(status_code=404, detail="å‘Šè­¦ä¸å­˜åœ¨")
    
    return {"success": True, "message": "å‘Šè­¦å·²è§£å†³"}


@router.get("/observability/alert-rules")
async def get_alert_rules():
    """è·å–å‘Šè­¦è§„åˆ™åˆ—è¡¨"""
    if not observability_alerts:
        raise HTTPException(status_code=503, detail="å‘Šè­¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    rules = observability_alerts.get_rules()
    return {"success": True, "rules": rules}


@router.post("/observability/alert-rules")
async def create_alert_rule(
    name: str,
    description: str,
    rule_type: str,
    condition: str,
    threshold: Any,
    severity: str,
    metric_name: Optional[str] = None,
    event_name: Optional[str] = None,
    tags: Optional[Dict[str, str]] = None,
    duration: Optional[float] = None,
    cooldown: Optional[float] = None
):
    """åˆ›å»ºå‘Šè­¦è§„åˆ™"""
    if not observability_alerts:
        raise HTTPException(status_code=503, detail="å‘Šè­¦ç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        condition_enum = AlertCondition(condition)
        severity_enum = AlertSeverity(severity)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„å‚æ•°: {e}")
    
    rule = AlertRule(
        rule_id=f"rule_{int(time.time() * 1000)}",
        name=name,
        description=description,
        rule_type=rule_type,
        condition=condition_enum,
        threshold=threshold,
        severity=severity_enum,
        metric_name=metric_name,
        event_name=event_name,
        tags=tags or {},
        duration=duration,
        cooldown=cooldown
    )
    
    observability_alerts.add_rule(rule)
    
    return {"success": True, "rule": observability_alerts.get_rules()[-1]}


# ============ P0-018: å¯¼å‡ºåŠŸèƒ½ ============

@router.get("/observability/export/traces/{trace_id}")
async def export_trace(trace_id: str, format: str = "json"):
    """å¯¼å‡ºTrace"""
    if not observability_exporter:
        raise HTTPException(status_code=503, detail="å¯¼å‡ºç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        if format == "json":
            data = observability_exporter.export_trace_json(trace_id)
            from fastapi.responses import JSONResponse
            return JSONResponse(content=data)
        elif format == "csv":
            csv_data = observability_exporter.export_trace_csv(trace_id)
            from fastapi.responses import Response
            return Response(content=csv_data, media_type="text/csv", headers={
                "Content-Disposition": f"attachment; filename=trace_{trace_id}.csv"
            })
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ ¼å¼")
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


@router.get("/observability/export/traces")
async def export_traces(
    start_time: Optional[float] = None,
    end_time: Optional[float] = None,
    limit: int = 100,
    format: str = "json"
):
    """å¯¼å‡ºå¤šä¸ªTraces"""
    if not observability_exporter:
        raise HTTPException(status_code=503, detail="å¯¼å‡ºç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    if format == "json":
        data = observability_exporter.export_traces_json(start_time, end_time, limit)
        from fastapi.responses import JSONResponse
        return JSONResponse(content=data, headers={
            "Content-Disposition": f"attachment; filename=traces_{int(time.time())}.json"
        })
    else:
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ ¼å¼")


@router.get("/observability/export/metrics")
async def export_metrics(
    metric_name: Optional[str] = None,
    start_time: Optional[float] = None,
    end_time: Optional[float] = None,
    format: str = "csv"
):
    """å¯¼å‡ºæŒ‡æ ‡"""
    if not observability_exporter:
        raise HTTPException(status_code=503, detail="å¯¼å‡ºç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    if format == "csv":
        csv_data = observability_exporter.export_metrics_csv(metric_name, start_time, end_time)
        from fastapi.responses import Response
        return Response(content=csv_data, media_type="text/csv", headers={
            "Content-Disposition": f"attachment; filename=metrics_{int(time.time())}.csv"
        })
    else:
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ ¼å¼")


# ============ P1-203: åŒRAGæ‰§è¡Œå¼•æ“ ============

class DualRAGQueryRequest(BaseModel):
    """åŒRAGæŸ¥è¯¢è¯·æ±‚"""
    query: str
    context: Optional[Dict[str, Any]] = None
    top_k_first: int = Field(5, ge=1, le=20, description="ç¬¬ä¸€æ¬¡RAGæ£€ç´¢è¿”å›æ•°é‡")
    top_k_second: int = Field(3, ge=1, le=10, description="ç¬¬äºŒæ¬¡RAGæ£€ç´¢è¿”å›æ•°é‡")
    enable_second_rag: bool = Field(True, description="æ˜¯å¦å¯ç”¨ç¬¬äºŒæ¬¡RAGæ£€ç´¢")


@router.post("/dual-rag/execute")
async def dual_rag_execute(
    request: DualRAGQueryRequest,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """
    æ‰§è¡ŒåŒRAGæµç¨‹
    
    å®ç°"åŒRAG + ä¸“å®¶è·¯ç”± + æ¨¡å—æ‰§è¡Œ + å†æ£€ç´¢"æ¨¡å‹
    """
    if not dual_rag_engine:
        raise HTTPException(status_code=503, detail="åŒRAGæ‰§è¡Œå¼•æ“æœªåˆå§‹åŒ–")
    
    try:
        result = await dual_rag_engine.execute(
            query=request.query,
            context=request.context,
            top_k_first=request.top_k_first,
            top_k_second=request.top_k_second,
            enable_second_rag=request.enable_second_rag,
        )
        
        return {
            "success": True,
            "result": result.to_dict(),
        }
    except Exception as e:
        logger.error(f"åŒRAGæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.get("/dual-rag/performance")
async def get_dual_rag_performance(
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–åŒRAGæ‰§è¡Œæ€§èƒ½æŒ‡æ ‡"""
    if not dual_rag_engine:
        raise HTTPException(status_code=503, detail="åŒRAGæ‰§è¡Œå¼•æ“æœªåˆå§‹åŒ–")
    
    try:
        metrics = dual_rag_engine.get_performance_metrics()
        return {
            "success": True,
            "metrics": metrics,
        }
    except Exception as e:
        logger.error(f"è·å–æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.get("/dual-rag/history")
async def get_dual_rag_history(
    limit: int = Field(10, ge=1, le=100, description="è¿”å›æ•°é‡"),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–åŒRAGæ‰§è¡Œå†å²"""
    if not dual_rag_engine:
        raise HTTPException(status_code=503, detail="åŒRAGæ‰§è¡Œå¼•æ“æœªåˆå§‹åŒ–")
    
    try:
        history = dual_rag_engine.get_execution_history(limit=limit)
        return {
            "success": True,
            "history": history,
            "total": len(history),
        }
    except Exception as e:
        logger.error(f"è·å–æ‰§è¡Œå†å²å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.get("/observability/export/events")
async def export_events(
    event_name: Optional[str] = None,
    trace_id: Optional[str] = None,
    start_time: Optional[float] = None,
    end_time: Optional[float] = None,
    limit: int = 1000,
    format: str = "csv"
):
    """å¯¼å‡ºäº‹ä»¶"""
    if not observability_exporter:
        raise HTTPException(status_code=503, detail="å¯¼å‡ºç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    if format == "csv":
        csv_data = observability_exporter.export_events_csv(
            event_name, trace_id, start_time, end_time, limit
        )
        from fastapi.responses import Response
        return Response(content=csv_data, media_type="text/csv", headers={
            "Content-Disposition": f"attachment; filename=events_{int(time.time())}.csv"
        })
    else:
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ ¼å¼")


@router.get("/observability/export/long-tasks/{task_id}/replay")
async def export_task_replay(task_id: str, format: str = "json"):
    """å¯¼å‡ºé•¿ä»»åŠ¡å›æ”¾æ•°æ®"""
    if not observability_exporter:
        raise HTTPException(status_code=503, detail="å¯¼å‡ºç³»ç»Ÿæœªåˆå§‹åŒ–")
    
    try:
        if format == "json":
            data = observability_exporter.export_long_task_replay_json(task_id)
            from fastapi.responses import JSONResponse
            return JSONResponse(content=data, headers={
                "Content-Disposition": f"attachment; filename=task_replay_{task_id}.json"
            })
        else:
            raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ ¼å¼")
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))


# ============ P2-303: æ™ºèƒ½ä»»åŠ¡/è‡ªæˆ‘å­¦ä¹ /èµ„æºç®¡ç† ============

class TaskCreateRequest(BaseModel):
    """åˆ›å»ºä»»åŠ¡è¯·æ±‚"""
    task_name: str
    task_type: str
    priority: str = "medium"
    metadata: Optional[Dict[str, Any]] = None


class LearningPointRequest(BaseModel):
    """æ·»åŠ å­¦ä¹ ç‚¹è¯·æ±‚"""
    curve_id: str
    accuracy: float = Field(..., ge=0, le=100)
    loss: Optional[float] = None
    epoch: Optional[int] = None
    dataset_size: Optional[int] = None
    metadata: Optional[Dict[str, Any]] = None


class ResourceAllocateRequest(BaseModel):
    """èµ„æºåˆ†é…è¯·æ±‚"""
    task_id: str
    resource_type: str
    requested_amount: float = Field(..., ge=0, le=100)
    priority: int = Field(5, ge=1, le=10)
    metadata: Optional[Dict[str, Any]] = None


@router.post("/task-lifecycle/create")
async def create_task(
    request: TaskCreateRequest,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """åˆ›å»ºä»»åŠ¡"""
    try:
        priority = TaskPriority(request.priority)
        lifecycle = task_lifecycle_manager.create_task(
            task_name=request.task_name,
            task_type=request.task_type,
            priority=priority,
            metadata=request.metadata,
        )
        return {
            "success": True,
            "task": lifecycle.to_dict(),
        }
    except Exception as e:
        logger.error(f"åˆ›å»ºä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå¤±è´¥: {str(e)}")


@router.post("/task-lifecycle/{task_id}/start")
async def start_task(
    task_id: str,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """å¯åŠ¨ä»»åŠ¡"""
    try:
        success = task_lifecycle_manager.start_task(task_id)
        if not success:
            raise HTTPException(status_code=400, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–çŠ¶æ€ä¸æ­£ç¡®")
        
        task = task_lifecycle_manager.get_task(task_id)
        return {
            "success": True,
            "task": task.to_dict(),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å¯åŠ¨ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨å¤±è´¥: {str(e)}")


@router.post("/task-lifecycle/{task_id}/update-progress")
async def update_task_progress(
    task_id: str,
    progress: float = Field(..., ge=0, le=100),
    current_step: Optional[str] = None,
    completed_steps: Optional[int] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
    try:
        success = task_lifecycle_manager.update_progress(
            task_id=task_id,
            progress=progress,
            current_step=current_step,
            completed_steps=completed_steps,
        )
        if not success:
            raise HTTPException(status_code=400, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        task = task_lifecycle_manager.get_task(task_id)
        return {
            "success": True,
            "task": task.to_dict(),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ›´æ–°å¤±è´¥: {str(e)}")


@router.post("/task-lifecycle/{task_id}/complete")
async def complete_task(
    task_id: str,
    result: Optional[Dict[str, Any]] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """å®Œæˆä»»åŠ¡"""
    try:
        success = task_lifecycle_manager.complete_task(task_id, result)
        if not success:
            raise HTTPException(status_code=400, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–çŠ¶æ€ä¸æ­£ç¡®")
        
        task = task_lifecycle_manager.get_task(task_id)
        return {
            "success": True,
            "task": task.to_dict(),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å®Œæˆä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å®Œæˆå¤±è´¥: {str(e)}")


@router.get("/task-lifecycle/list")
async def list_tasks(
    status: Optional[str] = None,
    task_type: Optional[str] = None,
    limit: int = Field(100, ge=1, le=1000),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """åˆ—å‡ºä»»åŠ¡"""
    try:
        task_status = TaskStatus(status) if status else None
        tasks = task_lifecycle_manager.list_tasks(
            status=task_status,
            task_type=task_type,
            limit=limit,
        )
        return {
            "success": True,
            "tasks": [t.to_dict() for t in tasks],
            "total": len(tasks),
        }
    except Exception as e:
        logger.error(f"åˆ—å‡ºä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ—å‡ºå¤±è´¥: {str(e)}")


@router.get("/task-lifecycle/statistics")
async def get_task_statistics(
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–ä»»åŠ¡ç»Ÿè®¡"""
    try:
        stats = task_lifecycle_manager.get_task_statistics()
        return {
            "success": True,
            "statistics": stats,
        }
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/learning-curve/create")
async def create_learning_curve(
    model_name: str,
    task_type: str,
    curve_id: Optional[str] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """åˆ›å»ºå­¦ä¹ æ›²çº¿"""
    try:
        curve = learning_curve_tracker.create_curve(
            model_name=model_name,
            task_type=task_type,
            curve_id=curve_id,
        )
        return {
            "success": True,
            "curve": curve.to_dict(),
        }
    except Exception as e:
        logger.error(f"åˆ›å»ºå­¦ä¹ æ›²çº¿å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºå¤±è´¥: {str(e)}")


@router.post("/learning-curve/add-point")
async def add_learning_point(
    request: LearningPointRequest,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """æ·»åŠ å­¦ä¹ ç‚¹"""
    try:
        success = learning_curve_tracker.add_point(
            curve_id=request.curve_id,
            accuracy=request.accuracy,
            loss=request.loss,
            epoch=request.epoch,
            dataset_size=request.dataset_size,
            metadata=request.metadata,
        )
        if not success:
            raise HTTPException(status_code=400, detail="å­¦ä¹ æ›²çº¿ä¸å­˜åœ¨")
        
        curve = learning_curve_tracker.get_curve(request.curve_id)
        return {
            "success": True,
            "curve": curve.to_dict(),
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ·»åŠ å­¦ä¹ ç‚¹å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ·»åŠ å¤±è´¥: {str(e)}")


@router.get("/learning-curve/{curve_id}/data")
async def get_learning_curve_data(
    curve_id: str,
    include_loss: bool = False,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–å­¦ä¹ æ›²çº¿æ•°æ®"""
    try:
        data = learning_curve_tracker.get_curve_data(
            curve_id=curve_id,
            include_loss=include_loss,
        )
        if not data:
            raise HTTPException(status_code=404, detail="å­¦ä¹ æ›²çº¿ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "data": data,
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å­¦ä¹ æ›²çº¿æ•°æ®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.get("/learning-curve/list")
async def list_learning_curves(
    model_name: Optional[str] = None,
    task_type: Optional[str] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """åˆ—å‡ºå­¦ä¹ æ›²çº¿"""
    try:
        curves = learning_curve_tracker.list_curves(
            model_name=model_name,
            task_type=task_type,
        )
        return {
            "success": True,
            "curves": [c.to_dict() for c in curves],
            "total": len(curves),
        }
    except Exception as e:
        logger.error(f"åˆ—å‡ºå­¦ä¹ æ›²çº¿å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ—å‡ºå¤±è´¥: {str(e)}")


@router.get("/learning-curve/statistics")
async def get_learning_statistics(
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–å­¦ä¹ ç»Ÿè®¡"""
    try:
        stats = learning_curve_tracker.get_learning_statistics()
        return {
            "success": True,
            "statistics": stats,
        }
    except Exception as e:
        logger.error(f"è·å–å­¦ä¹ ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/resource/allocate")
async def allocate_resource(
    request: ResourceAllocateRequest,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """åˆ†é…èµ„æº"""
    try:
        resource_type = ResourceType(request.resource_type)
        allocation = await resource_scheduler.allocate_resource(
            task_id=request.task_id,
            resource_type=resource_type,
            requested_amount=request.requested_amount,
            priority=request.priority,
            metadata=request.metadata,
        )
        return {
            "success": True,
            "allocation": allocation.to_dict(),
        }
    except Exception as e:
        logger.error(f"åˆ†é…èµ„æºå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åˆ†é…å¤±è´¥: {str(e)}")


@router.post("/resource/release/{allocation_id}")
async def release_resource(
    allocation_id: str,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """é‡Šæ”¾èµ„æº"""
    try:
        success = await resource_scheduler.release_resource(allocation_id)
        if not success:
            raise HTTPException(status_code=400, detail="èµ„æºåˆ†é…ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "message": "èµ„æºå·²é‡Šæ”¾",
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é‡Šæ”¾èµ„æºå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é‡Šæ”¾å¤±è´¥: {str(e)}")


@router.get("/resource/status")
async def get_resource_status(
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–èµ„æºçŠ¶æ€"""
    try:
        status = resource_scheduler.get_resource_status()
        return {
            "success": True,
            "status": status,
        }
    except Exception as e:
        logger.error(f"è·å–èµ„æºçŠ¶æ€å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.get("/resource/hints")
async def get_resource_hints(
    hint_type: Optional[str] = None,
    unacknowledged_only: bool = False,
    limit: int = Field(50, ge=1, le=200),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–äº¤äº’æç¤º"""
    try:
        hint_type_enum = HintType(hint_type) if hint_type else None
        hints = resource_scheduler.get_hints(
            hint_type=hint_type_enum,
            unacknowledged_only=unacknowledged_only,
            limit=limit,
        )
        return {
            "success": True,
            "hints": [h.to_dict() for h in hints],
            "total": len(hints),
        }
    except Exception as e:
        logger.error(f"è·å–äº¤äº’æç¤ºå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/resource/hints/{hint_id}/acknowledge")
async def acknowledge_hint(
    hint_id: str,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """ç¡®è®¤æç¤º"""
    try:
        success = resource_scheduler.acknowledge_hint(hint_id)
        if not success:
            raise HTTPException(status_code=400, detail="æç¤ºä¸å­˜åœ¨")
        
        return {
            "success": True,
            "message": "æç¤ºå·²ç¡®è®¤",
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ç¡®è®¤æç¤ºå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç¡®è®¤å¤±è´¥: {str(e)}")


@router.get("/resource/suggestions")
async def get_scheduling_suggestions(
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–è°ƒåº¦å»ºè®®"""
    try:
        suggestions = resource_scheduler.get_scheduling_suggestions()
        return {
            "success": True,
            "suggestions": suggestions,
        }
    except Exception as e:
        logger.error(f"è·å–è°ƒåº¦å»ºè®®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


# ============ P3-402: å¤šç§Ÿæˆ·æ·±åº¦éš”ç¦» ============

from core.tenant_data_isolation import get_tenant_data_isolation
from core.tenant_quota_manager import get_quota_manager, QuotaType
from core.tenant_audit_logger import get_audit_logger, AuditAction
from core.tenant_manager import tenant_manager

class QuotaSetRequest(BaseModel):
    """è®¾ç½®é…é¢è¯·æ±‚"""
    tenant_id: str
    quota_type: str
    limit: int
    reset_period: str = "monthly"
    metadata: Optional[Dict[str, Any]] = None


class QuotaUseRequest(BaseModel):
    """ä½¿ç”¨é…é¢è¯·æ±‚"""
    tenant_id: str
    quota_type: str
    amount: int


@router.get("/tenant/quota/list")
async def list_tenant_quotas(
    tenant_id: str,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–ç§Ÿæˆ·æ‰€æœ‰é…é¢"""
    try:
        quota_mgr = get_quota_manager()
        quotas = quota_mgr.get_all_quotas(tenant_id)
        return {
            "success": True,
            "quotas": {k: v.to_dict() for k, v in quotas.items()},
        }
    except Exception as e:
        logger.error(f"è·å–é…é¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.get("/tenant/quota/usage")
async def get_quota_usage(
    tenant_id: str,
    quota_type: Optional[str] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–é…é¢ä½¿ç”¨æƒ…å†µ"""
    try:
        quota_mgr = get_quota_manager()
        usage = quota_mgr.get_usage(tenant_id, quota_type)
        return {
            "success": True,
            "usage": usage,
        }
    except Exception as e:
        logger.error(f"è·å–ä½¿ç”¨é‡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/tenant/quota/set")
async def set_tenant_quota(
    request: QuotaSetRequest,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è®¾ç½®ç§Ÿæˆ·é…é¢"""
    try:
        quota_mgr = get_quota_manager()
        quota_type = QuotaType(request.quota_type)
        quota = quota_mgr.set_quota(
            tenant_id=request.tenant_id,
            quota_type=quota_type,
            limit=request.limit,
            reset_period=request.reset_period,
            metadata=request.metadata,
        )
        return {
            "success": True,
            "quota": quota.to_dict(),
        }
    except Exception as e:
        logger.error(f"è®¾ç½®é…é¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è®¾ç½®å¤±è´¥: {str(e)}")


@router.post("/tenant/quota/use")
async def use_tenant_quota(
    request: QuotaUseRequest,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """ä½¿ç”¨é…é¢"""
    try:
        quota_mgr = get_quota_manager()
        success, error = quota_mgr.use_quota(
            tenant_id=request.tenant_id,
            quota_type=request.quota_type,
            amount=request.amount,
        )
        if not success:
            raise HTTPException(status_code=400, detail=error or "é…é¢ä¸è¶³")
        
        return {
            "success": True,
            "message": "é…é¢ä½¿ç”¨æˆåŠŸ",
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ä½¿ç”¨é…é¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ä½¿ç”¨å¤±è´¥: {str(e)}")


@router.get("/tenant/storage/stats")
async def get_tenant_storage_stats(
    tenant_id: str,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–ç§Ÿæˆ·å­˜å‚¨ç»Ÿè®¡"""
    try:
        isolation = get_tenant_data_isolation()
        storage_size = isolation.get_tenant_storage_size(tenant_id)
        files = isolation.list_tenant_files(tenant_id)
        
        return {
            "success": True,
            "stats": {
                "storage_size": storage_size,
                "storage_size_mb": round(storage_size / 1024 / 1024, 2),
                "file_count": len(files),
            },
        }
    except Exception as e:
        logger.error(f"è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.get("/tenant/audit/query")
async def query_audit_logs(
    tenant_id: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    action: Optional[str] = None,
    resource_type: Optional[str] = None,
    user_id: Optional[str] = None,
    limit: int = Field(100, ge=1, le=1000),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """æŸ¥è¯¢å®¡è®¡æ—¥å¿—"""
    try:
        audit_logger = get_audit_logger()
        action_enum = AuditAction(action) if action else None
        logs = audit_logger.query_logs(
            tenant_id=tenant_id,
            start_date=start_date,
            end_date=end_date,
            action=action_enum,
            resource_type=resource_type,
            user_id=user_id,
            limit=limit,
        )
        return {
            "success": True,
            "logs": [log.to_dict() for log in logs],
            "total": len(logs),
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å®¡è®¡æ—¥å¿—å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/tenant/audit/report")
async def get_audit_report(
    tenant_id: str,
    start_date: str,
    end_date: str,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """ç”Ÿæˆå®¡è®¡æŠ¥è¡¨"""
    try:
        audit_logger = get_audit_logger()
        report = audit_logger.generate_audit_report(
            tenant_id=tenant_id,
            start_date=start_date,
            end_date=end_date,
        )
        return {
            "success": True,
            "report": report,
        }
    except Exception as e:
        logger.error(f"ç”Ÿæˆå®¡è®¡æŠ¥è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.get("/tenant/audit/export")
async def export_audit_logs(
    tenant_id: str,
    start_date: str,
    end_date: str,
    format: str = Field("json", pattern="^(json|csv)$"),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """å¯¼å‡ºå®¡è®¡æ—¥å¿—"""
    try:
        audit_logger = get_audit_logger()
        export_path = audit_logger.export_audit_logs(
            tenant_id=tenant_id,
            start_date=start_date,
            end_date=end_date,
            format=format,
        )
        return {
            "success": True,
            "export_path": export_path,
            "message": "å®¡è®¡æ—¥å¿—å·²å¯¼å‡º",
        }
    except Exception as e:
        logger.error(f"å¯¼å‡ºå®¡è®¡æ—¥å¿—å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºå¤±è´¥: {str(e)}")


@router.get("/tenant/info")
async def get_tenant_info(
    tenant_id: str,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–ç§Ÿæˆ·ä¿¡æ¯"""
    try:
        tenant = tenant_manager.get_tenant(tenant_id)
        if not tenant:
            raise HTTPException(status_code=404, detail="ç§Ÿæˆ·ä¸å­˜åœ¨")
        
        return {
            "success": True,
            "tenant": {
                "tenant_id": tenant.tenant_id,
                "name": tenant.name,
                "plan": tenant.plan,
                "active": tenant.active,
                "metadata": tenant.metadata,
            },
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ç§Ÿæˆ·ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/tenant/audit/log")
async def log_audit_event(
    tenant_id: str,
    action: str,
    resource_type: str,
    user_id: Optional[str] = None,
    resource_id: Optional[str] = None,
    details: Optional[Dict[str, Any]] = None,
    ip_address: Optional[str] = None,
    user_agent: Optional[str] = None,
    success: bool = True,
    error_message: Optional[str] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è®°å½•å®¡è®¡äº‹ä»¶"""
    try:
        audit_logger = get_audit_logger()
        action_enum = AuditAction(action)
        log = audit_logger.log(
            tenant_id=tenant_id,
            action=action_enum,
            resource_type=resource_type,
            user_id=user_id,
            resource_id=resource_id,
            details=details,
            ip_address=ip_address,
            user_agent=user_agent,
            success=success,
            error_message=error_message,
        )
        return {
            "success": True,
            "log": log.to_dict(),
        }
    except Exception as e:
        logger.error(f"è®°å½•å®¡è®¡äº‹ä»¶å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è®°å½•å¤±è´¥: {str(e)}")


# ============ P3-403: æ€§èƒ½ä¸å¯é æ€§ ============

from tests.performance.test_performance_suite import PerformanceTestSuite
from core.slo_report_generator import get_slo_report_generator
from scripts.chaos_engineering.chaos_test_runner import ChaosTestRunner, ChaosScenario

@router.post("/performance/test/load")
async def run_load_test(
    endpoint: str = "/health",
    concurrent_users: int = Field(10, ge=1, le=1000),
    requests_per_user: int = Field(10, ge=1, le=100),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
    try:
        suite = PerformanceTestSuite()
        result = await suite.load_test(
            endpoint=endpoint,
            concurrent_users=concurrent_users,
            requests_per_user=requests_per_user,
        )
        await suite.close()
        return {
            "success": True,
            "result": result.to_dict(),
        }
    except Exception as e:
        logger.error(f"è´Ÿè½½æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æµ‹è¯•å¤±è´¥: {str(e)}")


@router.post("/performance/test/stress")
async def run_stress_test(
    endpoint: str = "/health",
    initial_users: int = Field(10, ge=1),
    max_users: int = Field(100, ge=1),
    step: int = Field(10, ge=1),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è¿è¡Œå‹åŠ›æµ‹è¯•"""
    try:
        suite = PerformanceTestSuite()
        results = await suite.stress_test(
            endpoint=endpoint,
            initial_users=initial_users,
            max_users=max_users,
            step=step,
        )
        await suite.close()
        return {
            "success": True,
            "results": [r.to_dict() for r in results],
        }
    except Exception as e:
        logger.error(f"å‹åŠ›æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æµ‹è¯•å¤±è´¥: {str(e)}")


@router.get("/slo/report")
async def get_slo_report(
    measurement_period: Optional[str] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è·å–SLOæŠ¥å‘Š"""
    try:
        generator = get_slo_report_generator()
        report = generator.generate_slo_report(measurement_period)
        return {
            "success": True,
            "report": report,
        }
    except Exception as e:
        logger.error(f"ç”ŸæˆSLOæŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/slo/target")
async def set_slo_target(
    name: str,
    target_value: float,
    measurement_window: str = "30d",
    error_budget: float = Field(0.01, ge=0, le=1),
    metadata: Optional[Dict[str, Any]] = None,
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è®¾ç½®SLOç›®æ ‡"""
    try:
        generator = get_slo_report_generator()
        target = generator.set_slo_target(
            name=name,
            target_value=target_value,
            measurement_window=measurement_window,
            error_budget=error_budget,
            metadata=metadata,
        )
        return {
            "success": True,
            "target": {
                "name": target.name,
                "target_value": target.target_value,
                "measurement_window": target.measurement_window,
                "error_budget": target.error_budget,
            },
        }
    except Exception as e:
        logger.error(f"è®¾ç½®SLOç›®æ ‡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è®¾ç½®å¤±è´¥: {str(e)}")


@router.post("/chaos/test/sidecar-down")
async def run_chaos_test_sidecar_down(
    sidecar_name: str = "rag-sidecar",
    duration: int = Field(60, ge=10, le=300),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è¿è¡ŒSidecarå®•æœºæ•…éšœæ¼”ç»ƒ"""
    try:
        runner = ChaosTestRunner()
        result = await runner.test_sidecar_down(
            sidecar_name=sidecar_name,
            duration=duration,
        )
        return {
            "success": result.success,
            "result": result.to_dict(),
        }
    except Exception as e:
        logger.error(f"æ•…éšœæ¼”ç»ƒå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æµ‹è¯•å¤±è´¥: {str(e)}")


@router.post("/chaos/test/database-degraded")
async def run_chaos_test_database_degraded(
    database_name: str = "postgres",
    degradation_type: str = Field("slow_queries", pattern="^(slow_queries|connection_limit|disk_full)$"),
    duration: int = Field(60, ge=10, le=300),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è¿è¡Œæ•°æ®åº“é™çº§æ•…éšœæ¼”ç»ƒ"""
    try:
        runner = ChaosTestRunner()
        result = await runner.test_database_degraded(
            database_name=database_name,
            degradation_type=degradation_type,
            duration=duration,
        )
        return {
            "success": result.success,
            "result": result.to_dict(),
        }
    except Exception as e:
        logger.error(f"æ•…éšœæ¼”ç»ƒå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æµ‹è¯•å¤±è´¥: {str(e)}")


@router.post("/chaos/test/api-timeout")
async def run_chaos_test_api_timeout(
    endpoint: str = "/gateway/rag/search",
    timeout_duration: int = Field(30, ge=5, le=300),
    test_duration: int = Field(60, ge=10, le=600),
    _: bool = Depends(_get_require_api_key()),
) -> Dict[str, Any]:
    """è¿è¡ŒAPIè¶…æ—¶æ•…éšœæ¼”ç»ƒ"""
    try:
        runner = ChaosTestRunner()
        result = await runner.test_api_timeout(
            endpoint=endpoint,
            timeout_duration=timeout_duration,
            test_duration=test_duration,
        )
        return {
            "success": result.success,
            "result": result.to_dict(),
        }
    except Exception as e:
        logger.error(f"æ•…éšœæ¼”ç»ƒå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æµ‹è¯•å¤±è´¥: {str(e)}")


# ============ 3.2: å››æ¨¡å—æŸ¥è¯¢ã€æ‰§è¡Œã€å›å†™æ¥å£ï¼ˆä½¿ç”¨ configurable_api_connectorï¼‰ ============

# åˆå§‹åŒ–å¯é…ç½®APIè¿æ¥å™¨
from core.configurable_api_connector import ConfigurableAPIConnector
from core.rag_service_adapter import RAGServiceAdapter

configurable_api_connector = ConfigurableAPIConnector()

# æ³¨å†ŒRAGæœåŠ¡è¿æ¥å™¨
if super_agent.rag_service:
    configurable_api_connector.register_connector("rag", RAGServiceAdapter, {
        "rag_api_url": os.getenv("RAG_API_URL", "http://localhost:8011")
    })

# æƒé™ä¾èµ–
rag_read_dep = permission_guard.require("rag:read")
rag_write_dep = permission_guard.require("rag:write")
erp_read_dep = permission_guard.require("erp:read")
erp_write_dep = permission_guard.require("erp:write")
content_read_dep = permission_guard.require("content:read")
content_write_dep = permission_guard.require("content:write")
trend_read_dep = permission_guard.require("trend:read")
trend_write_dep = permission_guard.require("trend:write")


# ============ RAG æ¨¡å—æ¥å£ ============

@router.get("/rag/documents", dependencies=[rag_read_dep])
async def get_rag_documents(
    limit: int = 50,
    offset: int = 0,
    doc_type: Optional[str] = None,
    _: Dict[str, Any] = Depends(rag_read_dep)
):
    """æŸ¥è¯¢RAGæ–‡æ¡£åˆ—è¡¨"""
    try:
        # ä¼˜å…ˆä½¿ç”¨RAGæœåŠ¡é€‚é…å™¨
        if super_agent.rag_service:
            try:
                # å°è¯•è°ƒç”¨RAGæœåŠ¡çš„æ–‡æ¡£åˆ—è¡¨æ¥å£
                async with httpx.AsyncClient() as client:
                    response = await client.get(
                        f"{os.getenv('RAG_API_URL', 'http://localhost:8011')}/api/documents",
                        params={"limit": limit, "offset": offset, "doc_type": doc_type},
                        timeout=10.0
                    )
                    if response.status_code == 200:
                        data = response.json()
                        return {
                            "success": True,
                            "documents": data.get("documents", []),
                            "count": data.get("count", 0),
                            "limit": limit,
                            "offset": offset
                        }
            except Exception:
                pass
        
        # ä½¿ç”¨configurable_api_connectorè°ƒç”¨RAGæœåŠ¡
        result = await configurable_api_connector.call_api(
            platform="rag",
            endpoint="/api/documents",
            method="GET",
            params={"limit": limit, "offset": offset, "doc_type": doc_type}
        )
        return {
            "success": True,
            "documents": result.get("documents", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢RAGæ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/rag/documents/{doc_id}", dependencies=[rag_read_dep])
async def get_rag_document(
    doc_id: str,
    _: Dict[str, Any] = Depends(rag_read_dep)
):
    """æŸ¥è¯¢RAGæ–‡æ¡£è¯¦æƒ…"""
    try:
        if super_agent.rag_service:
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(
                        f"{os.getenv('RAG_API_URL', 'http://localhost:8011')}/api/documents/{doc_id}",
                        timeout=10.0
                    )
                    if response.status_code == 200:
                        return {"success": True, "document": response.json()}
            except Exception:
                pass
        
        result = await configurable_api_connector.call_api(
            platform="rag",
            endpoint=f"/api/documents/{doc_id}",
            method="GET"
        )
        return {"success": True, "document": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢RAGæ–‡æ¡£è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/rag/search", dependencies=[rag_read_dep])
async def search_rag(
    query: str,
    top_k: int = 10,
    filter_type: Optional[str] = None,
    _: Dict[str, Any] = Depends(rag_read_dep)
):
    """æ‰§è¡ŒRAGæ£€ç´¢"""
    try:
        if super_agent.rag_service:
            results = await super_agent.rag_service.retrieve(
                query=query,
                top_k=top_k,
                filter_type=filter_type
            )
            return {
                "success": True,
                "results": results,
                "count": len(results),
                "query": query
            }
        else:
            result = await configurable_api_connector.call_api(
                platform="rag",
                endpoint="/api/search",
                method="POST",
                data={
                    "query": query,
                    "top_k": top_k,
                    "filter_type": filter_type
                }
            )
            return {
                "success": True,
                "results": result.get("results", []),
                "count": len(result.get("results", [])),
                "query": query
            }
    except Exception as e:
        logger.error(f"RAGæ£€ç´¢å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ£€ç´¢å¤±è´¥: {str(e)}")


@router.get("/rag/stats", dependencies=[rag_read_dep])
async def get_rag_stats(
    _: Dict[str, Any] = Depends(rag_read_dep)
):
    """è·å–RAGç»Ÿè®¡ä¿¡æ¯"""
    try:
        if super_agent.rag_service:
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.get(
                        f"{os.getenv('RAG_API_URL', 'http://localhost:8011')}/api/stats",
                        timeout=10.0
                    )
                    if response.status_code == 200:
                        return {"success": True, "statistics": response.json()}
            except Exception:
                pass
        
        result = await configurable_api_connector.call_api(
            platform="rag",
            endpoint="/api/stats",
            method="GET"
        )
        return {"success": True, "statistics": result}
    except Exception as e:
        logger.error(f"è·å–RAGç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}")


@router.post("/rag/writeback", dependencies=[rag_write_dep])
async def rag_writeback(
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(rag_write_dep)
):
    """RAGæ•°æ®å›å†™"""
    try:
        title = request.get("title", "")
        content = request.get("content", "")
        tags = request.get("tags", [])
        metadata = request.get("metadata", {})
        
        if super_agent.rag_service:
            try:
                async with httpx.AsyncClient() as client:
                    response = await client.post(
                        f"{os.getenv('RAG_API_URL', 'http://localhost:8011')}/api/writeback",
                        json={
                            "title": title,
                            "content": content,
                            "tags": tags,
                            "metadata": metadata
                        },
                        timeout=10.0
                    )
                    if response.status_code == 200:
                        return {"success": True, "result": response.json()}
            except Exception:
                pass
        
        result = await configurable_api_connector.call_api(
            platform="rag",
            endpoint="/api/writeback",
            method="POST",
            data={
                "title": title,
                "content": content,
                "tags": tags,
                "metadata": metadata
            }
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"RAGå›å†™å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å›å†™å¤±è´¥: {str(e)}")


# ============ ERP æ¨¡å—æ¥å£ ============

@router.get("/erp/orders", dependencies=[erp_read_dep])
async def get_erp_orders(
    limit: int = 50,
    offset: int = 0,
    status: Optional[str] = None,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPè®¢å•åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint="/api/orders",
            method="GET",
            params={"limit": limit, "offset": offset, "status": status}
        )
        return {
            "success": True,
            "orders": result.get("orders", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPè®¢å•åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/erp/orders/{order_id}", dependencies=[erp_read_dep])
async def get_erp_order(
    order_id: str,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPè®¢å•è¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint=f"/api/orders/{order_id}",
            method="GET"
        )
        return {"success": True, "order": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPè®¢å•è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/erp/customers", dependencies=[erp_read_dep])
async def get_erp_customers(
    limit: int = 50,
    offset: int = 0,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPå®¢æˆ·åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint="/api/customers",
            method="GET",
            params={"limit": limit, "offset": offset}
        )
        return {
            "success": True,
            "customers": result.get("customers", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPå®¢æˆ·åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/erp/customers/{customer_id}", dependencies=[erp_read_dep])
async def get_erp_customer(
    customer_id: str,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPå®¢æˆ·è¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint=f"/api/customers/{customer_id}",
            method="GET"
        )
        return {"success": True, "customer": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPå®¢æˆ·è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/erp/projects", dependencies=[erp_read_dep])
async def get_erp_projects(
    limit: int = 50,
    offset: int = 0,
    status: Optional[str] = None,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPé¡¹ç›®åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint="/api/projects",
            method="GET",
            params={"limit": limit, "offset": offset, "status": status}
        )
        return {
            "success": True,
            "projects": result.get("projects", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPé¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/erp/projects/{project_id}", dependencies=[erp_read_dep])
async def get_erp_project(
    project_id: str,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPé¡¹ç›®è¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint=f"/api/projects/{project_id}",
            method="GET"
        )
        return {"success": True, "project": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPé¡¹ç›®è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/erp/inventory", dependencies=[erp_read_dep])
async def get_erp_inventory(
    limit: int = 50,
    offset: int = 0,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPåº“å­˜åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint="/api/inventory",
            method="GET",
            params={"limit": limit, "offset": offset}
        )
        return {
            "success": True,
            "items": result.get("items", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPåº“å­˜åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/erp/inventory/{item_id}", dependencies=[erp_read_dep])
async def get_erp_inventory_item(
    item_id: str,
    _: Dict[str, Any] = Depends(erp_read_dep)
):
    """æŸ¥è¯¢ERPåº“å­˜è¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint=f"/api/inventory/{item_id}",
            method="GET"
        )
        return {"success": True, "item": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ERPåº“å­˜è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.post("/erp/{type}/{id}/execute", dependencies=[erp_write_dep])
async def execute_erp_action(
    type: str,
    id: str,
    action: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(erp_write_dep)
):
    """æ‰§è¡ŒERPæ“ä½œï¼ˆæ‰¹å‡†ã€æ‹’ç»ã€æ›´æ–°ç­‰ï¼‰"""
    try:
        action_type = action.get("action_type", "")
        action_data = action.get("data", {})
        
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint=f"/api/{type}/{id}/{action_type}",
            method="POST",
            data=action_data
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"æ‰§è¡ŒERPæ“ä½œå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.post("/erp/writeback", dependencies=[erp_write_dep])
async def erp_writeback(
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(erp_write_dep)
):
    """ERPæ•°æ®å›å†™"""
    try:
        entity_type = request.get("entity_type")  # order, customer, project, inventory
        entity_id = request.get("entity_id")
        data = request.get("data", {})
        
        result = await configurable_api_connector.call_api(
            platform="erp",
            endpoint=f"/api/{entity_type}/{entity_id}/writeback",
            method="POST",
            data=data
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"ERPå›å†™å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å›å†™å¤±è´¥: {str(e)}")


# ============ å†…å®¹æ¨¡å—æ¥å£ ============

@router.get("/content/list", dependencies=[content_read_dep])
async def get_content_list(
    limit: int = 50,
    offset: int = 0,
    content_type: Optional[str] = None,
    status: Optional[str] = None,
    _: Dict[str, Any] = Depends(content_read_dep)
):
    """æŸ¥è¯¢å†…å®¹åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="content",
            endpoint="/api/contents",
            method="GET",
            params={"limit": limit, "offset": offset, "content_type": content_type, "status": status}
        )
        return {
            "success": True,
            "contents": result.get("contents", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å†…å®¹åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/content/{content_id}", dependencies=[content_read_dep])
async def get_content(
    content_id: str,
    _: Dict[str, Any] = Depends(content_read_dep)
):
    """æŸ¥è¯¢å†…å®¹è¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="content",
            endpoint=f"/api/contents/{content_id}",
            method="GET"
        )
        return {"success": True, "content": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å†…å®¹è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.post("/content/generate", dependencies=[content_write_dep])
async def generate_content(
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(content_write_dep)
):
    """æ‰§è¡Œå†…å®¹ç”Ÿæˆ"""
    try:
        prompt = request.get("prompt", "")
        content_type = request.get("content_type", "text")
        platform = request.get("platform", "")
        
        result = await configurable_api_connector.call_api(
            platform="content",
            endpoint="/api/generate",
            method="POST",
            data={
                "prompt": prompt,
                "content_type": content_type,
                "platform": platform
            }
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"å†…å®¹ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@router.post("/content/{content_id}/publish", dependencies=[content_write_dep])
async def publish_content(
    content_id: str,
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(content_write_dep)
):
    """æ‰§è¡Œå†…å®¹å‘å¸ƒ"""
    try:
        platform = request.get("platform", "")
        publish_data = request.get("data", {})
        
        result = await configurable_api_connector.call_api(
            platform="content",
            endpoint=f"/api/contents/{content_id}/publish",
            method="POST",
            data={
                "platform": platform,
                **publish_data
            }
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"å†…å®¹å‘å¸ƒå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å‘å¸ƒå¤±è´¥: {str(e)}")


@router.get("/content/materials", dependencies=[content_read_dep])
async def get_content_materials(
    limit: int = 50,
    offset: int = 0,
    _: Dict[str, Any] = Depends(content_read_dep)
):
    """æŸ¥è¯¢ç´ æåˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="content",
            endpoint="/api/materials",
            method="GET",
            params={"limit": limit, "offset": offset}
        )
        return {
            "success": True,
            "materials": result.get("materials", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ç´ æåˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/content/published", dependencies=[content_read_dep])
async def get_published_content(
    limit: int = 50,
    offset: int = 0,
    platform: Optional[str] = None,
    _: Dict[str, Any] = Depends(content_read_dep)
):
    """æŸ¥è¯¢å·²å‘å¸ƒå†…å®¹åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="content",
            endpoint="/api/published",
            method="GET",
            params={"limit": limit, "offset": offset, "platform": platform}
        )
        return {
            "success": True,
            "published": result.get("published", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å·²å‘å¸ƒå†…å®¹å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.post("/content/writeback", dependencies=[content_write_dep])
async def content_writeback(
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(content_write_dep)
):
    """å†…å®¹æ•°æ®å›å†™"""
    try:
        content_id = request.get("content_id")
        data = request.get("data", {})
        
        result = await configurable_api_connector.call_api(
            platform="content",
            endpoint=f"/api/contents/{content_id}/writeback",
            method="POST",
            data=data
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"å†…å®¹å›å†™å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å›å†™å¤±è´¥: {str(e)}")


# ============ è¶‹åŠ¿æ¨¡å—æ¥å£ ============

@router.get("/trend/reports", dependencies=[trend_read_dep])
async def get_trend_reports(
    limit: int = 50,
    offset: int = 0,
    indicator: Optional[str] = None,
    _: Dict[str, Any] = Depends(trend_read_dep)
):
    """æŸ¥è¯¢è¶‹åŠ¿æŠ¥å‘Šåˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint="/api/reports",
            method="GET",
            params={"limit": limit, "offset": offset, "indicator": indicator}
        )
        return {
            "success": True,
            "reports": result.get("reports", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢è¶‹åŠ¿æŠ¥å‘Šåˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/trend/reports/{report_id}", dependencies=[trend_read_dep])
async def get_trend_report(
    report_id: str,
    _: Dict[str, Any] = Depends(trend_read_dep)
):
    """æŸ¥è¯¢è¶‹åŠ¿æŠ¥å‘Šè¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint=f"/api/reports/{report_id}",
            method="GET"
        )
        return {"success": True, "report": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢è¶‹åŠ¿æŠ¥å‘Šè¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/trend/indicators", dependencies=[trend_read_dep])
async def get_trend_indicators(
    limit: int = 50,
    offset: int = 0,
    _: Dict[str, Any] = Depends(trend_read_dep)
):
    """æŸ¥è¯¢è¶‹åŠ¿æŒ‡æ ‡åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint="/api/indicators",
            method="GET",
            params={"limit": limit, "offset": offset}
        )
        return {
            "success": True,
            "indicators": result.get("indicators", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢è¶‹åŠ¿æŒ‡æ ‡åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/trend/indicators/{indicator_id}", dependencies=[trend_read_dep])
async def get_trend_indicator(
    indicator_id: str,
    _: Dict[str, Any] = Depends(trend_read_dep)
):
    """æŸ¥è¯¢è¶‹åŠ¿æŒ‡æ ‡è¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint=f"/api/indicators/{indicator_id}",
            method="GET"
        )
        return {"success": True, "indicator": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢è¶‹åŠ¿æŒ‡æ ‡è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/trend/analysis/tasks", dependencies=[trend_read_dep])
async def get_trend_analysis_tasks(
    limit: int = 50,
    offset: int = 0,
    status: Optional[str] = None,
    _: Dict[str, Any] = Depends(trend_read_dep)
):
    """æŸ¥è¯¢è¶‹åŠ¿åˆ†æä»»åŠ¡åˆ—è¡¨"""
    try:
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint="/api/analysis/tasks",
            method="GET",
            params={"limit": limit, "offset": offset, "status": status}
        )
        return {
            "success": True,
            "tasks": result.get("tasks", []),
            "count": result.get("count", 0),
            "limit": limit,
            "offset": offset
        }
    except Exception as e:
        logger.error(f"æŸ¥è¯¢è¶‹åŠ¿åˆ†æä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.get("/trend/analysis/tasks/{task_id}", dependencies=[trend_read_dep])
async def get_trend_analysis_task(
    task_id: str,
    _: Dict[str, Any] = Depends(trend_read_dep)
):
    """æŸ¥è¯¢è¶‹åŠ¿åˆ†æä»»åŠ¡è¯¦æƒ…"""
    try:
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint=f"/api/analysis/tasks/{task_id}",
            method="GET"
        )
        return {"success": True, "task": result}
    except Exception as e:
        logger.error(f"æŸ¥è¯¢è¶‹åŠ¿åˆ†æä»»åŠ¡è¯¦æƒ…å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢å¤±è´¥: {str(e)}")


@router.post("/trend/analysis/start", dependencies=[trend_write_dep])
async def start_trend_analysis(
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(trend_write_dep)
):
    """å¯åŠ¨è¶‹åŠ¿åˆ†æä»»åŠ¡"""
    try:
        indicator = request.get("indicator", "")
        analysis_type = request.get("analysis_type", "standard")
        
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint="/api/analysis/start",
            method="POST",
            data={
                "indicator": indicator,
                "analysis_type": analysis_type
            }
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"å¯åŠ¨è¶‹åŠ¿åˆ†æå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨å¤±è´¥: {str(e)}")


@router.post("/trend/analysis/execute", dependencies=[trend_write_dep])
async def execute_trend_analysis(
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(trend_write_dep)
):
    """æ‰§è¡Œè¶‹åŠ¿åˆ†æ"""
    try:
        report_id = request.get("report_id")
        indicator_id = request.get("indicator_id")
        
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint="/api/analysis/execute",
            method="POST",
            data={
                "report_id": report_id,
                "indicator_id": indicator_id
            }
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"æ‰§è¡Œè¶‹åŠ¿åˆ†æå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


@router.get("/trend/reports/{report_id}/export", dependencies=[trend_read_dep])
async def export_trend_report(
    report_id: str,
    format: str = "pdf",
    _: Dict[str, Any] = Depends(trend_read_dep)
):
    """å¯¼å‡ºè¶‹åŠ¿æŠ¥å‘Š"""
    try:
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint=f"/api/reports/{report_id}/export",
            method="GET",
            params={"format": format}
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"å¯¼å‡ºè¶‹åŠ¿æŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å¯¼å‡ºå¤±è´¥: {str(e)}")


@router.post("/trend/writeback", dependencies=[trend_write_dep])
async def trend_writeback(
    request: Dict[str, Any] = Body(...),
    _: Dict[str, Any] = Depends(trend_write_dep)
):
    """è¶‹åŠ¿æ•°æ®å›å†™"""
    try:
        report_id = request.get("report_id")
        data = request.get("data", {})
        
        result = await configurable_api_connector.call_api(
            platform="trend",
            endpoint=f"/api/reports/{report_id}/writeback",
            method="POST",
            data=data
        )
        return {"success": True, "result": result}
    except Exception as e:
        logger.error(f"è¶‹åŠ¿å›å†™å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å›å†™å¤±è´¥: {str(e)}")
