#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
T016 Â· ç”Ÿäº§ç®¡ç†API

èƒ½åŠ›è¦æ±‚ï¼š
- ç”Ÿäº§å…¨ç”Ÿå‘½å‘¨æœŸï¼ˆè®¡åˆ’â†’æ’ç¨‹â†’æ‰§è¡Œâ†’åé¦ˆâ†’ç»“æ¡ˆï¼‰
- 40é¡¹èƒ½åŠ›æ¸…å•ï¼ˆä¸ERPè“å›¾ä¿æŒä¸€è‡´ï¼‰
- 8ç»´åº¦åˆ†æï¼ˆè´¨é‡/æˆæœ¬/äº¤ä»˜/å®‰å…¨/åˆ©æ¶¦/æ•ˆç‡/ç®¡ç†/æŠ€æœ¯ï¼‰
- é›†æˆè´¨é‡ç®¡ç†åŠŸèƒ½
"""
from __future__ import annotations

from collections import Counter, defaultdict
from datetime import datetime, timezone
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel, Field

from api.super_agent_api import erp_process_service
from core.erp_process_service import BASE_STAGE_LIFECYCLES, DIMENSIONS

router = APIRouter(prefix="/api/production", tags=["ERP Production Management"])


def _now() -> str:
    return datetime.now(timezone.utc).isoformat()


def _dimension_status(score: float) -> str:
    if score >= 0.85:
        return "excellent"
    if score >= 0.7:
        return "watch"
    return "risk"


def _production_status(status: str) -> str:
    """åˆ¤æ–­ç”Ÿäº§çŠ¶æ€ï¼šè®¡åˆ’ä¸­/æ’ç¨‹ä¸­/æ‰§è¡Œä¸­/å·²å®Œæˆ/å·²æš‚åœ"""
    status_mapping = {
        "planned": "è®¡åˆ’ä¸­",
        "scheduled": "æ’ç¨‹ä¸­",
        "ready": "å°±ç»ª",
        "executing": "æ‰§è¡Œä¸­",
        "paused": "å·²æš‚åœ",
        "completed": "å·²å®Œæˆ",
        "cancelled": "å·²å–æ¶ˆ",
    }
    return status_mapping.get(status, status)


def _production_source() -> List[Dict[str, Any]]:
    return erp_process_service.production_jobs


def _quality_source() -> List[Dict[str, Any]]:
    return erp_process_service.quality_checks


def _find_production_job(job_id: str) -> Optional[Dict[str, Any]]:
    for job in _production_source():
        if str(job.get("job_id")) == str(job_id):
            return job
    return None


def _find_quality_check(lot_id: Optional[str]) -> Optional[Dict[str, Any]]:
    if not lot_id:
        return None
    for qc in _quality_source():
        if str(qc.get("lot_id")) == str(lot_id):
            return qc
    return None


class ProductionJobInput(BaseModel):
    order_id: str
    line: str = Field(..., description="äº§çº¿ç¼–å·")
    quantity: float = Field(..., gt=0, description="è®¡åˆ’æ•°é‡")
    start_plan: Optional[str] = Field(None, description="è®¡åˆ’å¼€å§‹æ—¥æœŸï¼ˆISO8601ï¼‰")
    end_plan: Optional[str] = Field(None, description="è®¡åˆ’ç»“æŸæ—¥æœŸï¼ˆISO8601ï¼‰")
    priority: Optional[str] = "normal"
    product_code: Optional[str] = None
    product_name: Optional[str] = None


class ProductionJobUpdateRequest(BaseModel):
    status: Optional[str] = None
    completed: Optional[float] = Field(None, ge=0, description="å·²å®Œæˆæ•°é‡")
    quantity: Optional[float] = Field(None, gt=0, description="è®¡åˆ’æ•°é‡ï¼ˆè°ƒæ•´ï¼‰")
    start_plan: Optional[str] = None
    end_plan: Optional[str] = None
    line: Optional[str] = None
    note: Optional[str] = None


class ProductionProgressRequest(BaseModel):
    completed: float = Field(..., ge=0, description="å·²å®Œæˆæ•°é‡")
    defects: Optional[float] = Field(0, ge=0, description="ä¸è‰¯å“æ•°é‡")
    note: Optional[str] = None


@router.get("/overview")
async def get_production_overview():
    """æ•´ä½“æ¦‚è§ˆ + 8ç»´åº¦ + 40é¡¹èƒ½åŠ› + è´¨é‡é›†æˆ"""
    view = erp_process_service.get_production_view()
    dimension_analysis = erp_process_service.get_dimension_analysis("production")
    blueprint = erp_process_service.get_stage_blueprint("production")
    lifecycle = BASE_STAGE_LIFECYCLES.get("production", [])
    jobs = _production_source()
    quality_checks = _quality_source()

    # ç»Ÿè®¡ç”Ÿäº§çŠ¶æ€
    status_counter = Counter(job.get("status", "unknown") for job in jobs)
    
    # ç»Ÿè®¡äº§çº¿
    line_counter = Counter(job.get("line", "æœªçŸ¥") for job in jobs)
    
    # è®¡ç®—æ€»è®¡åˆ’æ•°é‡å’Œå®Œæˆæ•°é‡
    total_quantity = sum(job.get("quantity", 0) for job in jobs)
    total_completed = sum(job.get("completed", 0) for job in jobs)
    completion_rate = (total_completed / total_quantity * 100) if total_quantity > 0 else 0
    
    # è®¡ç®—OEEï¼ˆè®¾å¤‡ç»¼åˆæ•ˆç‡ï¼‰ç®€åŒ–ç®—æ³•
    executing_jobs = [job for job in jobs if job.get("status") == "executing"]
    oee = 0.85 if executing_jobs else 0.0  # ç®€åŒ–ç®—æ³•
    
    # è´¨é‡ç»Ÿè®¡
    quality_pending = len([qc for qc in quality_checks if qc.get("status") not in ("completed", "passed")])
    quality_total = len(quality_checks)
    
    # è“å›¾å·²è‡ªåŠ¨æ‰©å±•èƒ½åŠ›æ¸…å•åˆ°40é¡¹ï¼ˆé€šè¿‡_build_stage_capabilitiesï¼‰
    capabilities = blueprint.get("blueprint", {}).get("capabilities", [])

    return {
        "success": True,
        "updated_at": _now(),
        "summary": {
            **view.get("summary", {}),
            "total_quantity": round(total_quantity, 2),
            "total_completed": round(total_completed, 2),
            "completion_rate": round(completion_rate, 2),
            "oee": round(oee, 2),
            "quality_pending": quality_pending,
            "quality_total": quality_total,
        },
        "dimension_analysis": dimension_analysis,
        "lifecycle": [
            {
                "name": step,
                "completed": index < len(lifecycle) - 1,
                "sequence": index + 1,
            }
            for index, step in enumerate(lifecycle)
        ],
        "status_distribution": {_production_status(k): v for k, v in status_counter.items()},
        "line_distribution": line_counter,
        "risk_heatmap": {
            "delayed": len([job for job in jobs if _is_delayed(job)]),
            "low_progress": len([job for job in jobs if _is_low_progress(job)]),
            "quality_issues": quality_pending,
        },
        "capabilities": capabilities,
        "dimension_summary": dimension_analysis.get("dimensions", []),
        "quality_summary": {
            "total_checks": quality_total,
            "pending_checks": quality_pending,
            "passed_rate": _calculate_passed_rate(quality_checks),
        },
    }


def _is_delayed(job: Dict[str, Any]) -> bool:
    """åˆ¤æ–­æ˜¯å¦å»¶æœŸ"""
    if job.get("status") in ("completed", "cancelled"):
        return False
    end_plan = job.get("end_plan")
    if not end_plan:
        return False
    try:
        end_date = datetime.fromisoformat(end_plan.replace("Z", "+00:00"))
        return datetime.now(timezone.utc) > end_date
    except Exception:
        return False


def _is_low_progress(job: Dict[str, Any]) -> bool:
    """åˆ¤æ–­è¿›åº¦æ˜¯å¦åä½"""
    if job.get("status") not in ("executing", "ready"):
        return False
    quantity = job.get("quantity", 0)
    completed = job.get("completed", 0)
    if quantity <= 0:
        return False
    progress = completed / quantity
    start_plan = job.get("start_plan")
    if not start_plan:
        return False
    try:
        start_date = datetime.fromisoformat(start_plan.replace("Z", "+00:00"))
        total_days = (datetime.now(timezone.utc) - start_date).days
        expected_progress = min(1.0, total_days / 30.0) if total_days > 0 else 0
        return progress < expected_progress * 0.8
    except Exception:
        return False


def _calculate_passed_rate(quality_checks: List[Dict[str, Any]]) -> float:
    """è®¡ç®—è´¨æ£€é€šè¿‡ç‡"""
    if not quality_checks:
        return 0.0
    completed = [qc for qc in quality_checks if qc.get("status") in ("completed", "passed", "failed")]
    if not completed:
        return 0.0
    passed = len([qc for qc in completed if qc.get("status") == "passed"])
    return round((passed / len(completed)) * 100, 2) if completed else 0.0


@router.get("/")
async def list_production_jobs(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=200),
    status: Optional[str] = None,
    line: Optional[str] = None,
    order_id: Optional[str] = None,
    q: Optional[str] = Query(None, alias="search"),
):
    """ç”Ÿäº§å·¥å•åˆ—è¡¨ + ç»Ÿè®¡"""
    jobs = _production_source()
    filtered: List[Dict[str, Any]] = []
    
    for job in jobs:
        # çŠ¶æ€ç­›é€‰
        if status and job.get("status") != status:
            continue
        
        # äº§çº¿ç­›é€‰
        if line and job.get("line") != line:
            continue
        
        # è®¢å•ç­›é€‰
        if order_id and job.get("order_id") != order_id:
            continue
        
        # å…³é”®è¯æœç´¢
        if q:
            text = f"{job.get('job_id','')}{job.get('order_id','')}{job.get('line','')}{job.get('product_code','')}{job.get('product_name','')}"
            if q.lower() not in text.lower():
                continue
        
        filtered.append(job)

    total = len(filtered)
    start = (page - 1) * page_size
    page_items = filtered[start : start + page_size]

    # ä¸ºæ¯ä¸ªå·¥å•æ·»åŠ è¿›åº¦å’ŒçŠ¶æ€æ ‡ç­¾
    for job in page_items:
        quantity = job.get("quantity", 0)
        completed = job.get("completed", 0)
        job["progress"] = round((completed / quantity * 100), 2) if quantity > 0 else 0
        job["status_label"] = _production_status(job.get("status", "unknown"))
        job["is_delayed"] = _is_delayed(job)
        job["is_low_progress"] = _is_low_progress(job)
        # å…³è”è´¨é‡æ£€æŸ¥
        job["quality_check"] = _find_quality_check(job.get("qc_lot_id"))

    status_counter = Counter(job.get("status", "unknown") for job in filtered)
    line_counter = Counter(job.get("line", "æœªçŸ¥") for job in filtered)
    
    total_quantity = sum(job.get("quantity", 0) for job in filtered)
    total_completed = sum(job.get("completed", 0) for job in filtered)

    return {
        "success": True,
        "page": page,
        "page_size": page_size,
        "total": total,
        "jobs": page_items,
        "status_distribution": {_production_status(k): v for k, v in status_counter.items()},
        "line_distribution": line_counter,
        "total_quantity": round(total_quantity, 2),
        "total_completed": round(total_completed, 2),
    }


@router.post("/")
async def create_production_job(payload: ProductionJobInput):
    """åˆ›å»ºç”Ÿäº§å·¥å•ï¼ˆæœ¬åœ°å›å†™ERP11ç¯èŠ‚ï¼‰"""
    data = payload.dict(exclude_none=True)
    job_id = f"MO-{datetime.now(timezone.utc).strftime('%y%m%d%H%M%S')}"
    data["job_id"] = job_id
    data.setdefault("status", "planned")
    data.setdefault("completed", 0)
    data.setdefault("priority", "normal")
    
    # è®¾ç½®é»˜è®¤ç»´åº¦è¯„åˆ†
    if not data.get("dimensions"):
        data["dimensions"] = {dim: 0.75 for dim in DIMENSIONS}
    
    data.setdefault("created_at", _now())
    erp_process_service.production_jobs.append(data)
    
    return {
        "success": True,
        "job": data,
        "message": "ç”Ÿäº§å·¥å•åˆ›å»ºæˆåŠŸ"
    }


@router.get("/{job_id}")
async def get_production_job_detail(job_id: str):
    """å•ä¸ªç”Ÿäº§å·¥å• + ç”Ÿå‘½å‘¨æœŸ + 8ç»´åº¦ + è´¨é‡é›†æˆ"""
    job = _find_production_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="ç”Ÿäº§å·¥å•ä¸å­˜åœ¨")

    # è®¡ç®—è¿›åº¦å’Œæ•ˆç‡æŒ‡æ ‡
    quantity = job.get("quantity", 0)
    completed = job.get("completed", 0)
    progress = round((completed / quantity * 100), 2) if quantity > 0 else 0
    
    lifecycle_steps = BASE_STAGE_LIFECYCLES.get("production", [])
    status_mapping = {
        "planned": 0,
        "scheduled": 1,
        "ready": 2,
        "executing": 3,
        "paused": 2,
        "completed": len(lifecycle_steps),
        "cancelled": 0,
    }
    current_index = status_mapping.get(job.get("status"), 0)
    lifecycle = []
    for idx, step in enumerate(lifecycle_steps, start=1):
        lifecycle.append(
            {
                "stage": step,
                "sequence": idx,
                "status": "completed"
                if idx <= current_index
                else "current"
                if idx == current_index + 1
                else "pending",
            }
        )

    dimensions = []
    for dim, score in (job.get("dimensions") or {}).items():
        dimensions.append(
            {
                "dimension": dim,
                "score": round(score, 3),
                "status": _dimension_status(score),
            }
        )

    # å…³è”è´¨é‡æ£€æŸ¥
    quality_check = _find_quality_check(job.get("qc_lot_id"))
    
    insights = []
    if _is_delayed(job):
        insights.append("âš ï¸ å·¥å•å·²å»¶æœŸï¼Œå»ºè®®åŠ å¿«è¿›åº¦")
    if _is_low_progress(job):
        insights.append("ğŸŸ¡ ç”Ÿäº§è¿›åº¦åä½ï¼Œå»ºè®®æ£€æŸ¥ç“¶é¢ˆ")
    if job.get("status") == "executing" and progress >= 95:
        insights.append("âœ… æ¥è¿‘å®Œæˆï¼Œå¯å‡†å¤‡ç»“æ¡ˆ")
    if quality_check:
        qc_status = quality_check.get("status")
        if qc_status not in ("passed", "completed"):
            insights.append(f"ğŸ” å…³è”è´¨æ£€ï¼š{qc_status}ï¼Œè¯·å…³æ³¨è´¨é‡çŠ¶æ€")
        defects = quality_check.get("defects", 0)
        samples = quality_check.get("samples", 0)
        if defects > 0 and samples > 0:
            defect_rate = (defects / samples) * 100
            insights.append(f"ğŸ“Š ä¸è‰¯ç‡ï¼š{defect_rate:.2f}%")

    return {
        "success": True,
        "job": job,
        "progress": progress,
        "status_label": _production_status(job.get("status", "unknown")),
        "is_delayed": _is_delayed(job),
        "is_low_progress": _is_low_progress(job),
        "lifecycle": lifecycle,
        "dimension_breakdown": dimensions,
        "quality_check": quality_check,
        "insights": insights,
    }


@router.patch("/{job_id}")
async def update_production_job(job_id: str, payload: ProductionJobUpdateRequest):
    """æ›´æ–°ç”Ÿäº§å·¥å•ï¼ˆçŠ¶æ€/è¿›åº¦/è®¡åˆ’ç­‰ï¼‰"""
    job = _find_production_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="ç”Ÿäº§å·¥å•ä¸å­˜åœ¨")

    # æ›´æ–°å­—æ®µ
    if payload.status:
        job["status"] = payload.status
    if payload.completed is not None:
        job["completed"] = payload.completed
    if payload.quantity is not None:
        job["quantity"] = payload.quantity
    if payload.start_plan:
        job["start_plan"] = payload.start_plan
    if payload.end_plan:
        job["end_plan"] = payload.end_plan
    if payload.line:
        job["line"] = payload.line

    # è®°å½•å˜æ›´å†å²
    history = job.setdefault("change_history", [])
    history.append(
        {
            "type": "update",
            "fields": payload.dict(exclude_none=True, exclude={"note"}),
            "note": payload.note,
            "timestamp": _now(),
        }
    )
    job["updated_at"] = _now()
    
    return {"success": True, "job": job}


@router.post("/{job_id}/progress")
async def update_production_progress(job_id: str, payload: ProductionProgressRequest):
    """æ›´æ–°ç”Ÿäº§è¿›åº¦ï¼ˆæŠ¥å·¥ï¼‰"""
    job = _find_production_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="ç”Ÿäº§å·¥å•ä¸å­˜åœ¨")

    # æ›´æ–°å®Œæˆæ•°é‡
    job["completed"] = payload.completed
    quantity = job.get("quantity", 0)
    
    # å¦‚æœå®Œæˆæ•°é‡è¾¾åˆ°è®¡åˆ’æ•°é‡ï¼Œè‡ªåŠ¨ç»“æ¡ˆ
    if payload.completed >= quantity and job.get("status") == "executing":
        job["status"] = "completed"
    
    # è®°å½•æŠ¥å·¥å†å²
    progress_history = job.setdefault("progress_history", [])
    progress_history.append(
        {
            "completed": payload.completed,
            "defects": payload.defects,
            "defect_rate": round((payload.defects / payload.completed * 100), 2) if payload.completed > 0 else 0,
            "note": payload.note,
            "timestamp": _now(),
        }
    )
    
    # å¦‚æœå­˜åœ¨ä¸è‰¯å“ï¼Œè§¦å‘è´¨é‡æ£€æŸ¥æé†’
    if payload.defects > 0:
        insights = job.setdefault("insights", [])
        insights.append(f"âš ï¸ å‘ç°ä¸è‰¯å“ {payload.defects} ä»¶ï¼Œå»ºè®®å¯åŠ¨è´¨é‡æ£€æŸ¥")
    
    job["updated_at"] = _now()
    
    return {
        "success": True,
        "job": job,
        "progress": round((payload.completed / quantity * 100), 2) if quantity > 0 else 0,
    }


@router.get("/analytics/dimensions")
async def analyze_dimensions():
    """8ç»´åº¦å®è§‚å¯¹æ¯”"""
    dimension_analysis = erp_process_service.get_dimension_analysis("production")
    jobs = _production_source()
    avg_dimension = defaultdict(list)
    for job in jobs:
        for dim, score in (job.get("dimensions") or {}).items():
            avg_dimension[dim].append(score)

    avg_dimension = {
        dim: round(sum(values) / len(values), 3)
        for dim, values in avg_dimension.items()
        if values
    }

    return {
        "success": True,
        "dimension_analysis": dimension_analysis,
        "dimension_average": avg_dimension,
        "job_sample_size": len(jobs),
    }


@router.get("/analytics/efficiency")
async def analyze_production_efficiency():
    """ç”Ÿäº§æ•ˆç‡åˆ†æï¼ˆOEEã€è‰¯å“ç‡ã€è®¡åˆ’è¾¾æˆç‡ç­‰ï¼‰"""
    jobs = _production_source()
    executing_jobs = [job for job in jobs if job.get("status") == "executing"]
    completed_jobs = [job for job in jobs if job.get("status") == "completed"]
    
    # OEEè®¡ç®—ï¼ˆç®€åŒ–ï¼‰
    total_quantity = sum(job.get("quantity", 0) for job in executing_jobs)
    total_completed = sum(job.get("completed", 0) for job in executing_jobs)
    availability = 0.9  # è®¾å¤‡å¯ç”¨ç‡
    performance = (total_completed / total_quantity) if total_quantity > 0 else 0
    quality_rate = 0.95  # è‰¯å“ç‡ï¼ˆç®€åŒ–ï¼‰
    oee = availability * performance * quality_rate
    
    # è®¡åˆ’è¾¾æˆç‡
    planned_total = sum(job.get("quantity", 0) for job in completed_jobs)
    actual_total = sum(job.get("completed", 0) for job in completed_jobs)
    achievement_rate = (actual_total / planned_total * 100) if planned_total > 0 else 0
    
    # æŒ‰äº§çº¿ç»Ÿè®¡
    line_stats = defaultdict(lambda: {"total": 0, "completed": 0, "jobs": 0})
    for job in jobs:
        line = job.get("line", "æœªçŸ¥")
        line_stats[line]["total"] += job.get("quantity", 0)
        line_stats[line]["completed"] += job.get("completed", 0)
        line_stats[line]["jobs"] += 1
    
    line_efficiency = []
    for line, stats in line_stats.items():
        efficiency = (stats["completed"] / stats["total"] * 100) if stats["total"] > 0 else 0
        line_efficiency.append({
            "line": line,
            "jobs": stats["jobs"],
            "planned": stats["total"],
            "completed": stats["completed"],
            "efficiency": round(efficiency, 2),
        })
    
    line_efficiency.sort(key=lambda x: x["efficiency"], reverse=True)
    
    return {
        "success": True,
        "oee": round(oee * 100, 2),
        "availability": round(availability * 100, 2),
        "performance": round(performance * 100, 2),
        "quality_rate": round(quality_rate * 100, 2),
        "achievement_rate": round(achievement_rate, 2),
        "line_efficiency": line_efficiency,
    }


@router.get("/analytics/quality")
async def analyze_production_quality():
    """ç”Ÿäº§è´¨é‡åˆ†æï¼ˆé›†æˆè´¨é‡æ¨¡å—ï¼‰"""
    jobs = _production_source()
    quality_checks = _quality_source()
    
    # ç»Ÿè®¡è´¨æ£€çŠ¶æ€
    qc_status_counter = Counter(qc.get("status", "unknown") for qc in quality_checks)
    
    # è®¡ç®—ä¸è‰¯ç‡
    total_samples = sum(qc.get("samples", 0) for qc in quality_checks)
    total_defects = sum(qc.get("defects", 0) for qc in quality_checks)
    defect_rate = (total_defects / total_samples * 100) if total_samples > 0 else 0
    
    # è®¡ç®—é€šè¿‡ç‡
    passed_rate = _calculate_passed_rate(quality_checks)
    
    # æŒ‰å·¥å•å…³è”è´¨é‡æ•°æ®
    job_quality = []
    for job in jobs:
        qc = _find_quality_check(job.get("qc_lot_id"))
        if qc:
            samples = qc.get("samples", 0)
            defects = qc.get("defects", 0)
            job_defect_rate = (defects / samples * 100) if samples > 0 else 0
            job_quality.append({
                "job_id": job.get("job_id"),
                "order_id": job.get("order_id"),
                "line": job.get("line"),
                "qc_lot_id": qc.get("lot_id"),
                "samples": samples,
                "defects": defects,
                "defect_rate": round(job_defect_rate, 2),
                "status": qc.get("status"),
            })
    
    return {
        "success": True,
        "qc_status_distribution": dict(qc_status_counter),
        "total_samples": total_samples,
        "total_defects": total_defects,
        "defect_rate": round(defect_rate, 2),
        "passed_rate": passed_rate,
        "job_quality": job_quality[:20],  # è¿”å›å‰20æ¡
    }

